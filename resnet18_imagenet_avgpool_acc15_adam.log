2025-05-01 11:50:08,837 - train - INFO - Namespace(data_dir='/data/dataset/imagenet/', dataset='image_folder', train_split='train', val_split='validation', model='ResNet18', pretrained=False, initial_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=224, input_size=None, crop_pct=None, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], interpolation='', batch_size=1024, validation_batch_size_multiplier=1, gpu=0, opt='adam', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.0001, clip_grad=None, clip_mode='norm', sched='cosine', lr=0.0001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=0.0001, min_lr=1e-05, epochs=200, epoch_repeats=0.0, start_epoch=None, decay_epochs=30, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0, vflip=0.0, color_jitter=None, aa='rand-m9-mstd0.5-inc1', aug_splits=0, jsd=False, reprob=0, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0, cutmix_minmax=None, mixup_prob=0.0, mixup_switch_prob=0.0, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=True, dist_bn='', split_bn=False, log_interval=50, recovery_interval=0, checkpoint_hist=1, save_images=False, amp=False, apex_amp=False, native_amp=False, channels_last=False, pin_mem=True, output='', experiment='', eval_metric='top1', tta=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False, wq_enable=True, wq_mode='LSQ', wq_bitw=32, wq_pos=None, wq_neg=None, wq_per_channel=True, wq_asym=False, aq_enable=True, aq_mode='LSQ', aq_bitw=32, aq_pos=None, aq_neg=None, aq_asym=True, qmodules=['convbn_first;wq:bit:8;aq:bit:8', 'layer1.0.convbn1', 'layer1.0.convbn2', 'layer1.1.convbn1', 'layer1.1.convbn2', 'layer2.0.convbn1', 'layer2.0.convbn2', 'layer2.1.convbn1', 'layer2.1.convbn2', 'layer3.0.convbn1', 'layer3.0.convbn2', 'layer3.1.convbn1', 'layer3.1.convbn2', 'layer4.0.convbn1', 'layer4.0.convbn2', 'layer4.1.convbn1', 'layer4.1.convbn2', 'fc;wq:bit:8;aq:bit:8'], resq_modules=['relu', 'layer1.0.relu2', 'layer1.1.relu2', 'layer2.0.relu2', 'layer3.0.downsample', 'layer2.1.relu2', 'layer3.0.relu2', 'layer3.0.downsample', 'layer3.1.relu2', 'layer4.0.downsample', 'layer4.0.relu2', 'layer4.1.relu2'], resq_enable=True, resq_mode='LSQ', resq_bitw=12, resq_pos=None, resq_neg=None, resq_asym=False, aq_per_channel=False, powerof2=True, world_size=4, local_rank=-1, dist_on_itp=False, dist_url='env://', device='cuda', seed=0, dist_eval=False, use_kd=False, kd_alpha=1.0, teacher='ResNet18', teacher_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', log_name='resnet18_imagenet_avgpool_acc15_adam', budget=1, bw_list='5, 5, 5, 5, 5, 4, 5, 3, 5, 4, 3, 3, 3, 2, 2, 2', ba_list='4, 4, 4, 4, 4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3', workers=4, multiprocessing_distributed=True, rank=0, distributed=True, dist_backend='nccl', **{'weight-decay': '1e-4'})
2025-05-01 11:50:11,998 - train - INFO - Model ResNet18 created, param count:11689512
2025-05-01 11:50:12,284 - train - INFO - Converted model to use Synchronized BatchNorm. WARNING: You may have issues if using zero initialized BN layers (enabled by default for ResNets) while sync-bn enabled.
2025-05-01 11:50:12,286 - train - INFO - Using native Torch AMP. Training in mixed precision.
2025-05-01 11:50:12,286 - train - INFO - Scheduled epochs: 210
2025-05-01 11:50:12,286 - train - INFO - Verifying initial model in test dataset
2025-05-01 11:50:12,286 - train - INFO - cuda:0
2025-05-01 11:50:22,264 - train - INFO - Test: [   0/48]  Time: 9.977 (9.977)  Loss:  5.6562 (5.6562)  Acc@1:  5.5664 ( 5.5664)  Acc@5: 15.9180 (15.9180)
2025-05-01 11:51:19,309 - train - INFO - Test: [  48/48]  Time: 2.947 (1.368)  Loss:  5.4297 (6.4206)  Acc@1:  7.0755 ( 1.6800)  Acc@5: 17.2170 ( 6.2200)
2025-05-01 11:51:19,463 - train - INFO - DistributedDataParallel(
  (module): ResNet(
    (relu): ReLU(
      (quan_a_fn): LsqQuantizer(bit=12, pos=4095, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
    )
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (maxpool): AvgPool2d(kernel_size=3, stride=2, padding=1)
    (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (convbn_first): QConvBn2d(
      3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
      (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-127, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
      (quan_a_fn): LsqQuantizer(bit=8, pos=127, neg=-127, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
      (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-15, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-15, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=12, pos=4095, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-15, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-15, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=12, pos=4095, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-15, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-7, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=12, pos=4095, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-15, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=12, pos=4095, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-15, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-7, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (quan_a_fn): LsqQuantizer(bit=12, pos=2047, neg=-2047, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=12, pos=4095, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=12, pos=4095, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-3, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (quan_a_fn): LsqQuantizer(bit=12, pos=2047, neg=-2047, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=12, pos=4095, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-1, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=12, pos=4095, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): QLinear(
      in_features=512, out_features=1000, bias=True
      (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-127, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True, apot=False )
      (quan_a_fn): LsqQuantizer(bit=8, pos=255, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
    )
  )
)
2025-05-01 11:51:30,549 - train - INFO - Train: 0 [   0/312 (  0%)]  Loss:  5.464468 (5.4645)  Time: 10.981s,  373.00/s  (10.981s,  373.00/s)  LR: 1.000e-04  Data: 5.658 (5.658)
2025-05-01 11:52:29,615 - train - INFO - Train: 0 [  50/312 ( 16%)]  Loss:  3.891918 (4.6782)  Time: 3.065s, 1336.33/s  (1.373s, 2982.29/s)  LR: 1.000e-04  Data: 0.000 (0.151)
2025-05-01 11:53:28,254 - train - INFO - Train: 0 [ 100/312 ( 32%)]  Loss:  3.714782 (4.3571)  Time: 0.525s, 7804.86/s  (1.274s, 3214.89/s)  LR: 1.000e-04  Data: 0.000 (0.077)
2025-05-01 11:54:29,554 - train - INFO - Train: 0 [ 150/312 ( 48%)]  Loss:  3.544159 (4.1538)  Time: 3.235s, 1266.05/s  (1.258s, 3255.60/s)  LR: 1.000e-04  Data: 0.000 (0.051)
2025-05-01 11:55:29,015 - train - INFO - Train: 0 [ 200/312 ( 64%)]  Loss:  3.490041 (4.0211)  Time: 0.527s, 7766.33/s  (1.241s, 3300.61/s)  LR: 1.000e-04  Data: 0.000 (0.039)
2025-05-01 11:56:29,819 - train - INFO - Train: 0 [ 250/312 ( 80%)]  Loss:  3.361356 (3.9111)  Time: 2.983s, 1373.21/s  (1.236s, 3313.87/s)  LR: 1.000e-04  Data: 0.000 (0.031)
2025-05-01 11:57:27,479 - train - INFO - Train: 0 [ 300/312 ( 96%)]  Loss:  3.351529 (3.8312)  Time: 0.534s, 7677.53/s  (1.222s, 3351.19/s)  LR: 1.000e-04  Data: 0.001 (0.026)
2025-05-01 11:57:40,555 - train - INFO - Train: 0 [ 311/312 (100%)]  Loss:  3.325406 (3.7680)  Time: 0.523s, 7839.10/s  (1.221s, 3354.44/s)  LR: 1.000e-04  Data: 0.000 (0.025)
2025-05-01 11:57:49,454 - train - INFO - Test: [   0/48]  Time: 8.755 (8.755)  Loss:  1.3887 (1.3887)  Acc@1: 72.1680 (72.1680)  Acc@5: 90.6250 (90.6250)
2025-05-01 11:59:00,156 - train - INFO - Test: [  48/48]  Time: 4.149 (1.622)  Loss:  1.3594 (2.0075)  Acc@1: 72.9953 (56.8520)  Acc@5: 88.7972 (80.7380)
2025-05-01 11:59:09,014 - train - INFO - Train: 1 [   0/312 (  0%)]  Loss:  3.287901 (3.2879)  Time: 8.386s,  488.45/s  (8.386s,  488.45/s)  LR: 1.000e-04  Data: 7.506 (7.506)
2025-05-01 12:00:32,626 - train - INFO - Train: 1 [  50/312 ( 16%)]  Loss:  3.287198 (3.2875)  Time: 0.610s, 6712.14/s  (1.804s, 2270.90/s)  LR: 1.000e-04  Data: 0.000 (0.622)
2025-05-01 12:01:53,059 - train - INFO - Train: 1 [ 100/312 ( 32%)]  Loss:  3.286952 (3.2874)  Time: 2.406s, 1702.31/s  (1.707s, 2399.36/s)  LR: 1.000e-04  Data: 0.000 (0.314)
2025-05-01 12:02:49,077 - train - INFO - Train: 1 [ 150/312 ( 48%)]  Loss:  3.274719 (3.2842)  Time: 0.531s, 7706.70/s  (1.513s, 2707.54/s)  LR: 1.000e-04  Data: 0.000 (0.210)
2025-05-01 12:03:47,347 - train - INFO - Train: 1 [ 200/312 ( 64%)]  Loss:  3.205766 (3.2685)  Time: 2.302s, 1779.07/s  (1.426s, 2871.59/s)  LR: 1.000e-04  Data: 0.000 (0.158)
2025-05-01 12:04:44,320 - train - INFO - Train: 1 [ 250/312 ( 80%)]  Loss:  3.158669 (3.2502)  Time: 0.526s, 7784.44/s  (1.369s, 2991.47/s)  LR: 1.000e-04  Data: 0.000 (0.127)
2025-05-01 12:05:41,639 - train - INFO - Train: 1 [ 300/312 ( 96%)]  Loss:  3.163033 (3.2377)  Time: 0.558s, 7343.50/s  (1.332s, 3074.61/s)  LR: 1.000e-04  Data: 0.000 (0.106)
2025-05-01 12:05:55,629 - train - INFO - Train: 1 [ 311/312 (100%)]  Loss:  3.163209 (3.2284)  Time: 0.523s, 7826.64/s  (1.330s, 3079.54/s)  LR: 1.000e-04  Data: 0.000 (0.102)
2025-05-01 12:06:02,567 - train - INFO - Test: [   0/48]  Time: 6.769 (6.769)  Loss:  1.1367 (1.1367)  Acc@1: 74.1211 (74.1211)  Acc@5: 92.2852 (92.2852)
2025-05-01 12:07:01,823 - train - INFO - Test: [  48/48]  Time: 2.309 (1.347)  Loss:  1.0244 (1.7652)  Acc@1: 77.2406 (60.5560)  Acc@5: 91.7453 (83.4220)
2025-05-01 12:07:08,264 - train - INFO - Train: 2 [   0/312 (  0%)]  Loss:  3.109054 (3.1091)  Time: 5.917s,  692.19/s  (5.917s,  692.19/s)  LR: 1.000e-04  Data: 5.289 (5.289)
2025-05-01 12:08:17,814 - train - INFO - Train: 2 [  50/312 ( 16%)]  Loss:  3.174981 (3.1420)  Time: 0.864s, 4741.53/s  (1.480s, 2768.15/s)  LR: 1.000e-04  Data: 0.000 (0.345)
2025-05-01 12:09:38,336 - train - INFO - Train: 2 [ 100/312 ( 32%)]  Loss:  3.129117 (3.1377)  Time: 4.422s,  926.37/s  (1.544s, 2652.21/s)  LR: 1.000e-04  Data: 0.000 (0.174)
2025-05-01 12:10:35,763 - train - INFO - Train: 2 [ 150/312 ( 48%)]  Loss:  3.097708 (3.1277)  Time: 0.529s, 7743.88/s  (1.413s, 2898.23/s)  LR: 1.000e-04  Data: 0.000 (0.117)
2025-05-01 12:11:37,837 - train - INFO - Train: 2 [ 200/312 ( 64%)]  Loss:  3.051445 (3.1125)  Time: 3.218s, 1272.92/s  (1.371s, 2988.62/s)  LR: 1.000e-04  Data: 0.000 (0.088)
2025-05-01 12:12:37,042 - train - INFO - Train: 2 [ 250/312 ( 80%)]  Loss:  3.080615 (3.1072)  Time: 1.482s, 2763.20/s  (1.333s, 3071.87/s)  LR: 1.000e-04  Data: 0.000 (0.070)
2025-05-01 12:13:36,963 - train - INFO - Train: 2 [ 300/312 ( 96%)]  Loss:  3.101771 (3.1064)  Time: 1.989s, 2059.15/s  (1.311s, 3124.41/s)  LR: 1.000e-04  Data: 0.000 (0.059)
2025-05-01 12:13:49,351 - train - INFO - Train: 2 [ 311/312 (100%)]  Loss:  3.137011 (3.1102)  Time: 0.529s, 7738.60/s  (1.304s, 3140.02/s)  LR: 1.000e-04  Data: 0.000 (0.057)
2025-05-01 12:13:56,263 - train - INFO - Test: [   0/48]  Time: 6.734 (6.734)  Loss:  1.1406 (1.1406)  Acc@1: 76.1719 (76.1719)  Acc@5: 92.5781 (92.5781)
2025-05-01 12:14:53,574 - train - INFO - Test: [  48/48]  Time: 2.175 (1.307)  Loss:  1.1943 (1.8072)  Acc@1: 76.6509 (61.1040)  Acc@5: 91.7453 (83.7080)
2025-05-01 12:15:00,765 - train - INFO - Train: 3 [   0/312 (  0%)]  Loss:  3.055768 (3.0558)  Time: 6.496s,  630.53/s  (6.496s,  630.53/s)  LR: 1.000e-04  Data: 5.971 (5.971)
2025-05-01 12:15:56,360 - train - INFO - Train: 3 [  50/312 ( 16%)]  Loss:  3.057374 (3.0566)  Time: 0.534s, 7664.55/s  (1.217s, 3364.45/s)  LR: 1.000e-04  Data: 0.000 (0.608)
2025-05-01 12:16:54,318 - train - INFO - Train: 3 [ 100/312 ( 32%)]  Loss:  3.029416 (3.0475)  Time: 3.208s, 1276.97/s  (1.189s, 3446.15/s)  LR: 1.000e-04  Data: 0.001 (0.394)
2025-05-01 12:17:49,915 - train - INFO - Train: 3 [ 150/312 ( 48%)]  Loss:  3.092873 (3.0589)  Time: 0.521s, 7862.42/s  (1.163s, 3521.36/s)  LR: 1.000e-04  Data: 0.000 (0.264)
2025-05-01 12:18:47,872 - train - INFO - Train: 3 [ 200/312 ( 64%)]  Loss:  3.083797 (3.0638)  Time: 3.062s, 1337.58/s  (1.162s, 3524.43/s)  LR: 1.000e-04  Data: 0.000 (0.198)
2025-05-01 12:19:43,635 - train - INFO - Train: 3 [ 250/312 ( 80%)]  Loss:  3.050227 (3.0616)  Time: 0.530s, 7729.48/s  (1.153s, 3553.01/s)  LR: 1.000e-04  Data: 0.000 (0.159)
2025-05-01 12:20:40,183 - train - INFO - Train: 3 [ 300/312 ( 96%)]  Loss:  3.087693 (3.0653)  Time: 1.063s, 3852.28/s  (1.149s, 3564.25/s)  LR: 1.000e-04  Data: 0.000 (0.132)
2025-05-01 12:20:53,070 - train - INFO - Train: 3 [ 311/312 (100%)]  Loss:  3.081281 (3.0673)  Time: 0.527s, 7776.54/s  (1.150s, 3561.83/s)  LR: 1.000e-04  Data: 0.000 (0.128)
2025-05-01 12:20:59,603 - train - INFO - Test: [   0/48]  Time: 6.346 (6.346)  Loss:  1.2363 (1.2363)  Acc@1: 77.1484 (77.1484)  Acc@5: 92.4805 (92.4805)
2025-05-01 12:21:56,707 - train - INFO - Test: [  48/48]  Time: 1.945 (1.295)  Loss:  1.2598 (1.8000)  Acc@1: 76.1792 (61.1340)  Acc@5: 90.8019 (83.6380)
2025-05-01 12:22:03,329 - train - INFO - Train: 4 [   0/312 (  0%)]  Loss:  3.021805 (3.0218)  Time: 6.093s,  672.26/s  (6.093s,  672.26/s)  LR: 1.000e-04  Data: 5.289 (5.289)
2025-05-01 12:22:58,638 - train - INFO - Train: 4 [  50/312 ( 16%)]  Loss:  3.013388 (3.0176)  Time: 0.527s, 7779.27/s  (1.204s, 3402.18/s)  LR: 1.000e-04  Data: 0.000 (0.586)
2025-05-01 12:23:57,116 - train - INFO - Train: 4 [ 100/312 ( 32%)]  Loss:  3.056124 (3.0304)  Time: 2.941s, 1392.65/s  (1.187s, 3450.98/s)  LR: 1.000e-04  Data: 0.000 (0.356)
2025-05-01 12:24:53,104 - train - INFO - Train: 4 [ 150/312 ( 48%)]  Loss:  3.032054 (3.0308)  Time: 0.526s, 7780.54/s  (1.165s, 3516.89/s)  LR: 1.000e-04  Data: 0.000 (0.238)
2025-05-01 12:25:51,305 - train - INFO - Train: 4 [ 200/312 ( 64%)]  Loss:  3.031584 (3.0310)  Time: 2.840s, 1442.07/s  (1.164s, 3517.41/s)  LR: 1.000e-04  Data: 0.000 (0.179)
2025-05-01 12:26:47,114 - train - INFO - Train: 4 [ 250/312 ( 80%)]  Loss:  3.035284 (3.0317)  Time: 0.532s, 7693.67/s  (1.155s, 3546.77/s)  LR: 1.000e-04  Data: 0.000 (0.143)
2025-05-01 12:27:46,123 - train - INFO - Train: 4 [ 300/312 ( 96%)]  Loss:  3.034773 (3.0321)  Time: 2.490s, 1645.26/s  (1.159s, 3533.90/s)  LR: 1.000e-04  Data: 0.000 (0.120)
2025-05-01 12:27:57,102 - train - INFO - Train: 4 [ 311/312 (100%)]  Loss:  3.017350 (3.0303)  Time: 0.962s, 4258.06/s  (1.153s, 3551.32/s)  LR: 1.000e-04  Data: 0.000 (0.116)
2025-05-01 12:28:03,569 - train - INFO - Test: [   0/48]  Time: 6.287 (6.287)  Loss:  1.1123 (1.1123)  Acc@1: 76.7578 (76.7578)  Acc@5: 92.5781 (92.5781)
2025-05-01 12:29:00,508 - train - INFO - Test: [  48/48]  Time: 2.600 (1.290)  Loss:  1.0791 (1.7533)  Acc@1: 78.7736 (61.8420)  Acc@5: 92.5708 (83.8420)
2025-05-01 12:29:07,288 - train - INFO - Train: 5 [   0/312 (  0%)]  Loss:  2.996936 (2.9969)  Time: 6.057s,  676.20/s  (6.057s,  676.20/s)  LR: 1.000e-04  Data: 5.526 (5.526)
2025-05-01 12:30:03,658 - train - INFO - Train: 5 [  50/312 ( 16%)]  Loss:  3.075679 (3.0363)  Time: 0.533s, 7687.83/s  (1.224s, 3346.29/s)  LR: 1.000e-04  Data: 0.000 (0.481)
2025-05-01 12:31:01,150 - train - INFO - Train: 5 [ 100/312 ( 32%)]  Loss:  3.029705 (3.0341)  Time: 2.778s, 1474.31/s  (1.187s, 3449.93/s)  LR: 1.000e-04  Data: 0.000 (0.248)
2025-05-01 12:31:58,532 - train - INFO - Train: 5 [ 150/312 ( 48%)]  Loss:  3.030166 (3.0331)  Time: 0.532s, 7700.95/s  (1.174s, 3488.54/s)  LR: 1.000e-04  Data: 0.000 (0.166)
2025-05-01 12:32:54,972 - train - INFO - Train: 5 [ 200/312 ( 64%)]  Loss:  3.044561 (3.0354)  Time: 1.132s, 3618.14/s  (1.163s, 3522.39/s)  LR: 1.000e-04  Data: 0.000 (0.125)
2025-05-01 12:33:53,707 - train - INFO - Train: 5 [ 250/312 ( 80%)]  Loss:  3.044422 (3.0369)  Time: 0.534s, 7669.39/s  (1.165s, 3515.28/s)  LR: 1.000e-04  Data: 0.000 (0.100)
2025-05-01 12:34:50,826 - train - INFO - Train: 5 [ 300/312 ( 96%)]  Loss:  3.067089 (3.0412)  Time: 0.537s, 7630.51/s  (1.161s, 3526.76/s)  LR: 1.000e-04  Data: 0.000 (0.083)
2025-05-01 12:35:04,830 - train - INFO - Train: 5 [ 311/312 (100%)]  Loss:  3.015774 (3.0380)  Time: 0.532s, 7693.33/s  (1.165s, 3514.86/s)  LR: 1.000e-04  Data: 0.000 (0.081)
2025-05-01 12:35:10,873 - train - INFO - Test: [   0/48]  Time: 5.867 (5.867)  Loss:  1.1660 (1.1660)  Acc@1: 76.5625 (76.5625)  Acc@5: 90.9180 (90.9180)
2025-05-01 12:36:09,531 - train - INFO - Test: [  48/48]  Time: 1.519 (1.317)  Loss:  1.0869 (1.7187)  Acc@1: 77.3585 (61.9640)  Acc@5: 92.2170 (84.0220)
2025-05-01 12:36:17,319 - train - INFO - Train: 6 [   0/312 (  0%)]  Loss:  3.034764 (3.0348)  Time: 7.267s,  563.68/s  (7.267s,  563.68/s)  LR: 1.000e-04  Data: 5.301 (5.301)
2025-05-01 12:37:15,799 - train - INFO - Train: 6 [  50/312 ( 16%)]  Loss:  3.019429 (3.0271)  Time: 0.525s, 7795.03/s  (1.289s, 3177.32/s)  LR: 1.000e-04  Data: 0.000 (0.294)
2025-05-01 12:38:15,872 - train - INFO - Train: 6 [ 100/312 ( 32%)]  Loss:  2.975746 (3.0100)  Time: 2.996s, 1367.18/s  (1.246s, 3288.05/s)  LR: 1.000e-04  Data: 0.000 (0.149)
2025-05-01 12:39:12,235 - train - INFO - Train: 6 [ 150/312 ( 48%)]  Loss:  3.039215 (3.0173)  Time: 0.532s, 7693.80/s  (1.206s, 3394.99/s)  LR: 1.000e-04  Data: 0.000 (0.099)
2025-05-01 12:40:11,684 - train - INFO - Train: 6 [ 200/312 ( 64%)]  Loss:  3.030143 (3.0199)  Time: 3.095s, 1323.56/s  (1.202s, 3407.31/s)  LR: 1.000e-04  Data: 0.000 (0.075)
2025-05-01 12:41:08,532 - train - INFO - Train: 6 [ 250/312 ( 80%)]  Loss:  2.986367 (3.0143)  Time: 0.539s, 7605.26/s  (1.189s, 3444.53/s)  LR: 1.000e-04  Data: 0.000 (0.060)
2025-05-01 12:42:08,152 - train - INFO - Train: 6 [ 300/312 ( 96%)]  Loss:  3.017401 (3.0147)  Time: 3.615s, 1133.19/s  (1.190s, 3442.98/s)  LR: 1.000e-04  Data: 0.000 (0.050)
2025-05-01 12:42:18,896 - train - INFO - Train: 6 [ 311/312 (100%)]  Loss:  3.105849 (3.0261)  Time: 0.523s, 7837.34/s  (1.182s, 3464.85/s)  LR: 1.000e-04  Data: 0.000 (0.048)
2025-05-01 12:42:25,866 - train - INFO - Test: [   0/48]  Time: 6.804 (6.804)  Loss:  1.2236 (1.2236)  Acc@1: 77.9297 (77.9297)  Acc@5: 93.8477 (93.8477)
2025-05-01 12:43:24,116 - train - INFO - Test: [  48/48]  Time: 2.467 (1.328)  Loss:  1.3018 (1.9290)  Acc@1: 77.7123 (61.0220)  Acc@5: 91.2736 (83.7040)
2025-05-01 12:43:30,731 - train - INFO - Train: 7 [   0/312 (  0%)]  Loss:  3.044941 (3.0449)  Time: 6.220s,  658.51/s  (6.220s,  658.51/s)  LR: 1.000e-04  Data: 5.529 (5.529)
2025-05-01 12:44:29,420 - train - INFO - Train: 7 [  50/312 ( 16%)]  Loss:  2.997198 (3.0211)  Time: 0.526s, 7789.89/s  (1.273s, 3218.36/s)  LR: 1.000e-04  Data: 0.000 (0.256)
2025-05-01 12:45:29,409 - train - INFO - Train: 7 [ 100/312 ( 32%)]  Loss:  3.026687 (3.0229)  Time: 3.275s, 1250.55/s  (1.237s, 3312.36/s)  LR: 1.000e-04  Data: 0.000 (0.129)
2025-05-01 12:46:27,947 - train - INFO - Train: 7 [ 150/312 ( 48%)]  Loss:  3.056745 (3.0314)  Time: 0.529s, 7739.63/s  (1.215s, 3371.81/s)  LR: 1.000e-04  Data: 0.000 (0.086)
2025-05-01 12:47:27,143 - train - INFO - Train: 7 [ 200/312 ( 64%)]  Loss:  3.083372 (3.0418)  Time: 2.259s, 1813.05/s  (1.207s, 3393.27/s)  LR: 1.000e-04  Data: 0.000 (0.065)
2025-05-01 12:48:24,334 - train - INFO - Train: 7 [ 250/312 ( 80%)]  Loss:  3.028764 (3.0396)  Time: 0.526s, 7784.20/s  (1.194s, 3429.09/s)  LR: 1.000e-04  Data: 0.000 (0.052)
2025-05-01 12:49:23,620 - train - INFO - Train: 7 [ 300/312 ( 96%)]  Loss:  3.021275 (3.0370)  Time: 0.841s, 4869.81/s  (1.193s, 3433.29/s)  LR: 1.000e-04  Data: 0.000 (0.043)
2025-05-01 12:49:35,933 - train - INFO - Train: 7 [ 311/312 (100%)]  Loss:  3.033183 (3.0365)  Time: 1.664s, 2461.49/s  (1.190s, 3440.79/s)  LR: 1.000e-04  Data: 0.000 (0.042)
2025-05-01 12:49:42,849 - train - INFO - Test: [   0/48]  Time: 6.732 (6.732)  Loss:  1.2959 (1.2959)  Acc@1: 75.0977 (75.0977)  Acc@5: 91.4062 (91.4062)
2025-05-01 12:50:40,932 - train - INFO - Test: [  48/48]  Time: 1.541 (1.323)  Loss:  1.2324 (1.8735)  Acc@1: 77.5943 (60.8800)  Acc@5: 91.3915 (83.6440)
2025-05-01 12:50:47,467 - train - INFO - Train: 8 [   0/312 (  0%)]  Loss:  3.031840 (3.0318)  Time: 6.074s,  674.30/s  (6.074s,  674.30/s)  LR: 1.000e-04  Data: 5.537 (5.537)
2025-05-01 12:51:43,790 - train - INFO - Train: 8 [  50/312 ( 16%)]  Loss:  3.056610 (3.0442)  Time: 0.523s, 7834.14/s  (1.223s, 3348.01/s)  LR: 1.000e-04  Data: 0.000 (0.458)
2025-05-01 12:52:41,821 - train - INFO - Train: 8 [ 100/312 ( 32%)]  Loss:  3.037520 (3.0420)  Time: 2.822s, 1451.70/s  (1.192s, 3435.41/s)  LR: 1.000e-04  Data: 0.000 (0.231)
2025-05-01 12:53:37,225 - train - INFO - Train: 8 [ 150/312 ( 48%)]  Loss:  3.028945 (3.0387)  Time: 0.523s, 7827.71/s  (1.164s, 3517.77/s)  LR: 1.000e-04  Data: 0.000 (0.155)
2025-05-01 12:54:35,321 - train - INFO - Train: 8 [ 200/312 ( 64%)]  Loss:  3.087800 (3.0485)  Time: 2.714s, 1509.33/s  (1.164s, 3519.68/s)  LR: 1.000e-04  Data: 0.000 (0.116)
2025-05-01 12:55:29,961 - train - INFO - Train: 8 [ 250/312 ( 80%)]  Loss:  3.037291 (3.0467)  Time: 0.523s, 7832.91/s  (1.150s, 3562.99/s)  LR: 1.000e-04  Data: 0.000 (0.093)
2025-05-01 12:56:27,566 - train - INFO - Train: 8 [ 300/312 ( 96%)]  Loss:  3.037332 (3.0453)  Time: 2.906s, 1409.27/s  (1.150s, 3561.73/s)  LR: 1.000e-04  Data: 0.000 (0.078)
2025-05-01 12:56:38,375 - train - INFO - Train: 8 [ 311/312 (100%)]  Loss:  3.043636 (3.0451)  Time: 0.529s, 7736.50/s  (1.144s, 3580.15/s)  LR: 1.000e-04  Data: 0.000 (0.075)
2025-05-01 12:56:44,855 - train - INFO - Test: [   0/48]  Time: 6.302 (6.302)  Loss:  1.7861 (1.7861)  Acc@1: 71.6797 (71.6797)  Acc@5: 88.7695 (88.7695)
2025-05-01 12:57:42,516 - train - INFO - Test: [  48/48]  Time: 2.307 (1.305)  Loss:  1.3896 (2.0422)  Acc@1: 73.1132 (59.3080)  Acc@5: 89.1509 (82.4580)
2025-05-01 12:57:49,230 - train - INFO - Train: 9 [   0/312 (  0%)]  Loss:  3.007057 (3.0071)  Time: 6.304s,  649.76/s  (6.304s,  649.76/s)  LR: 1.000e-04  Data: 5.763 (5.763)
2025-05-01 12:58:45,507 - train - INFO - Train: 9 [  50/312 ( 16%)]  Loss:  3.051451 (3.0293)  Time: 0.533s, 7688.42/s  (1.227s, 3338.26/s)  LR: 1.000e-04  Data: 0.000 (0.574)
2025-05-01 12:59:44,321 - train - INFO - Train: 9 [ 100/312 ( 32%)]  Loss:  3.006040 (3.0215)  Time: 2.785s, 1470.48/s  (1.202s, 3408.02/s)  LR: 1.000e-04  Data: 0.000 (0.410)
2025-05-01 13:00:42,379 - train - INFO - Train: 9 [ 150/312 ( 48%)]  Loss:  3.050400 (3.0287)  Time: 1.140s, 3593.15/s  (1.188s, 3446.79/s)  LR: 1.000e-04  Data: 0.000 (0.274)
2025-05-01 13:01:40,856 - train - INFO - Train: 9 [ 200/312 ( 64%)]  Loss:  3.054119 (3.0338)  Time: 2.048s, 1999.58/s  (1.184s, 3460.50/s)  LR: 1.000e-04  Data: 0.000 (0.206)
2025-05-01 13:02:38,280 - train - INFO - Train: 9 [ 250/312 ( 80%)]  Loss:  3.019138 (3.0314)  Time: 0.533s, 7683.08/s  (1.177s, 3481.13/s)  LR: 1.000e-04  Data: 0.000 (0.165)
2025-05-01 13:03:38,270 - train - INFO - Train: 9 [ 300/312 ( 96%)]  Loss:  3.036183 (3.0321)  Time: 3.252s, 1259.57/s  (1.180s, 3469.81/s)  LR: 1.000e-04  Data: 0.000 (0.138)
2025-05-01 13:03:49,153 - train - INFO - Train: 9 [ 311/312 (100%)]  Loss:  3.046103 (3.0338)  Time: 0.529s, 7745.38/s  (1.174s, 3489.74/s)  LR: 1.000e-04  Data: 0.000 (0.133)
2025-05-01 13:03:55,902 - train - INFO - Test: [   0/48]  Time: 6.567 (6.567)  Loss:  1.0625 (1.0625)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.4805 (92.4805)
2025-05-01 13:04:55,123 - train - INFO - Test: [  48/48]  Time: 2.986 (1.343)  Loss:  1.0156 (1.7207)  Acc@1: 77.4764 (61.0500)  Acc@5: 92.9245 (84.0440)
2025-05-01 13:05:02,191 - train - INFO - Train: 10 [   0/312 (  0%)]  Loss:  3.008781 (3.0088)  Time: 6.569s,  623.52/s  (6.569s,  623.52/s)  LR: 9.945e-05  Data: 6.039 (6.039)
2025-05-01 13:05:57,372 - train - INFO - Train: 10 [  50/312 ( 16%)]  Loss:  3.031644 (3.0202)  Time: 0.525s, 7799.91/s  (1.211s, 3383.01/s)  LR: 9.945e-05  Data: 0.000 (0.682)
2025-05-01 13:06:55,551 - train - INFO - Train: 10 [ 100/312 ( 32%)]  Loss:  3.010455 (3.0170)  Time: 2.872s, 1426.26/s  (1.187s, 3449.61/s)  LR: 9.945e-05  Data: 0.144 (0.515)
2025-05-01 13:07:51,981 - train - INFO - Train: 10 [ 150/312 ( 48%)]  Loss:  3.035423 (3.0216)  Time: 0.525s, 7797.18/s  (1.168s, 3507.14/s)  LR: 9.945e-05  Data: 0.000 (0.345)
2025-05-01 13:08:50,301 - train - INFO - Train: 10 [ 200/312 ( 64%)]  Loss:  3.045262 (3.0263)  Time: 2.916s, 1404.83/s  (1.168s, 3508.29/s)  LR: 9.945e-05  Data: 0.000 (0.259)
2025-05-01 13:09:46,209 - train - INFO - Train: 10 [ 250/312 ( 80%)]  Loss:  3.027868 (3.0266)  Time: 0.526s, 7792.72/s  (1.158s, 3538.10/s)  LR: 9.945e-05  Data: 0.000 (0.207)
2025-05-01 13:10:44,314 - train - INFO - Train: 10 [ 300/312 ( 96%)]  Loss:  3.028247 (3.0268)  Time: 2.473s, 1656.41/s  (1.158s, 3535.87/s)  LR: 9.945e-05  Data: 0.000 (0.173)
2025-05-01 13:10:55,983 - train - INFO - Train: 10 [ 311/312 (100%)]  Loss:  3.034363 (3.0278)  Time: 0.532s, 7700.46/s  (1.155s, 3546.41/s)  LR: 9.945e-05  Data: 0.000 (0.167)
2025-05-01 13:11:02,992 - train - INFO - Test: [   0/48]  Time: 6.837 (6.837)  Loss:  1.0957 (1.0957)  Acc@1: 77.4414 (77.4414)  Acc@5: 92.1875 (92.1875)
2025-05-01 13:12:02,117 - train - INFO - Test: [  48/48]  Time: 2.204 (1.346)  Loss:  1.1074 (1.7711)  Acc@1: 77.7123 (61.1680)  Acc@5: 92.3349 (83.5300)
2025-05-01 13:12:08,560 - train - INFO - Train: 11 [   0/312 (  0%)]  Loss:  3.015229 (3.0152)  Time: 6.107s,  670.75/s  (6.107s,  670.75/s)  LR: 9.933e-05  Data: 5.058 (5.058)
2025-05-01 13:13:04,382 - train - INFO - Train: 11 [  50/312 ( 16%)]  Loss:  3.026634 (3.0209)  Time: 0.526s, 7783.45/s  (1.214s, 3373.27/s)  LR: 9.933e-05  Data: 0.000 (0.430)
2025-05-01 13:14:03,050 - train - INFO - Train: 11 [ 100/312 ( 32%)]  Loss:  3.006487 (3.0161)  Time: 2.835s, 1444.63/s  (1.194s, 3430.52/s)  LR: 9.933e-05  Data: 0.000 (0.264)
2025-05-01 13:14:59,008 - train - INFO - Train: 11 [ 150/312 ( 48%)]  Loss:  3.001151 (3.0124)  Time: 0.533s, 7684.89/s  (1.169s, 3503.29/s)  LR: 9.933e-05  Data: 0.000 (0.177)
2025-05-01 13:15:58,129 - train - INFO - Train: 11 [ 200/312 ( 64%)]  Loss:  2.995550 (3.0090)  Time: 3.403s, 1203.58/s  (1.172s, 3493.47/s)  LR: 9.933e-05  Data: 0.000 (0.133)
2025-05-01 13:16:54,498 - train - INFO - Train: 11 [ 250/312 ( 80%)]  Loss:  3.012381 (3.0096)  Time: 0.532s, 7694.70/s  (1.163s, 3520.46/s)  LR: 9.933e-05  Data: 0.000 (0.106)
2025-05-01 13:17:54,210 - train - INFO - Train: 11 [ 300/312 ( 96%)]  Loss:  2.989371 (3.0067)  Time: 3.213s, 1274.97/s  (1.169s, 3505.11/s)  LR: 9.933e-05  Data: 0.000 (0.089)
2025-05-01 13:18:05,045 - train - INFO - Train: 11 [ 311/312 (100%)]  Loss:  2.993260 (3.0050)  Time: 0.521s, 7857.29/s  (1.162s, 3524.65/s)  LR: 9.933e-05  Data: 0.000 (0.086)
2025-05-01 13:18:11,318 - train - INFO - Test: [   0/48]  Time: 6.100 (6.100)  Loss:  1.2754 (1.2754)  Acc@1: 74.4141 (74.4141)  Acc@5: 92.1875 (92.1875)
2025-05-01 13:19:09,559 - train - INFO - Test: [  48/48]  Time: 1.543 (1.313)  Loss:  1.2275 (1.9159)  Acc@1: 75.7076 (60.3920)  Acc@5: 93.6321 (83.2780)
2025-05-01 13:19:16,191 - train - INFO - Train: 12 [   0/312 (  0%)]  Loss:  3.057141 (3.0571)  Time: 6.305s,  649.65/s  (6.305s,  649.65/s)  LR: 9.920e-05  Data: 5.074 (5.074)
2025-05-01 13:20:11,836 - train - INFO - Train: 12 [  50/312 ( 16%)]  Loss:  2.982170 (3.0197)  Time: 0.526s, 7791.66/s  (1.215s, 3372.10/s)  LR: 9.920e-05  Data: 0.000 (0.435)
2025-05-01 13:21:10,768 - train - INFO - Train: 12 [ 100/312 ( 32%)]  Loss:  3.110519 (3.0499)  Time: 2.632s, 1556.13/s  (1.197s, 3422.38/s)  LR: 9.920e-05  Data: 0.000 (0.244)
2025-05-01 13:22:06,803 - train - INFO - Train: 12 [ 150/312 ( 48%)]  Loss:  2.992094 (3.0355)  Time: 0.528s, 7761.96/s  (1.172s, 3496.03/s)  LR: 9.920e-05  Data: 0.000 (0.164)
2025-05-01 13:23:04,677 - train - INFO - Train: 12 [ 200/312 ( 64%)]  Loss:  3.017274 (3.0318)  Time: 2.630s, 1557.61/s  (1.168s, 3506.58/s)  LR: 9.920e-05  Data: 0.000 (0.123)
2025-05-01 13:24:00,295 - train - INFO - Train: 12 [ 250/312 ( 80%)]  Loss:  3.060701 (3.0366)  Time: 0.532s, 7703.93/s  (1.157s, 3540.26/s)  LR: 9.920e-05  Data: 0.000 (0.098)
2025-05-01 13:24:59,907 - train - INFO - Train: 12 [ 300/312 ( 96%)]  Loss:  3.045686 (3.0379)  Time: 0.525s, 7802.70/s  (1.163s, 3522.44/s)  LR: 9.920e-05  Data: 0.000 (0.082)
2025-05-01 13:25:13,014 - train - INFO - Train: 12 [ 311/312 (100%)]  Loss:  3.013006 (3.0348)  Time: 2.778s, 1474.20/s  (1.164s, 3519.41/s)  LR: 9.920e-05  Data: 0.000 (0.079)
2025-05-01 13:25:19,448 - train - INFO - Test: [   0/48]  Time: 6.250 (6.250)  Loss:  0.9458 (0.9458)  Acc@1: 77.6367 (77.6367)  Acc@5: 92.5781 (92.5781)
2025-05-01 13:26:15,887 - train - INFO - Test: [  48/48]  Time: 1.777 (1.279)  Loss:  0.9229 (1.7136)  Acc@1: 79.3632 (61.2160)  Acc@5: 94.1038 (83.7660)
2025-05-01 13:26:22,562 - train - INFO - Train: 13 [   0/312 (  0%)]  Loss:  3.034520 (3.0345)  Time: 6.352s,  644.81/s  (6.352s,  644.81/s)  LR: 9.907e-05  Data: 4.977 (4.977)
2025-05-01 13:27:18,428 - train - INFO - Train: 13 [  50/312 ( 16%)]  Loss:  3.008927 (3.0217)  Time: 0.525s, 7796.77/s  (1.220s, 3357.55/s)  LR: 9.907e-05  Data: 0.000 (0.272)
2025-05-01 13:28:16,142 - train - INFO - Train: 13 [ 100/312 ( 32%)]  Loss:  3.009102 (3.0175)  Time: 2.234s, 1833.75/s  (1.187s, 3449.52/s)  LR: 9.907e-05  Data: 0.000 (0.140)
2025-05-01 13:29:12,968 - train - INFO - Train: 13 [ 150/312 ( 48%)]  Loss:  3.053957 (3.0266)  Time: 0.527s, 7772.19/s  (1.171s, 3499.18/s)  LR: 9.907e-05  Data: 0.000 (0.094)
2025-05-01 13:30:09,859 - train - INFO - Train: 13 [ 200/312 ( 64%)]  Loss:  3.062893 (3.0339)  Time: 1.446s, 2832.82/s  (1.162s, 3523.74/s)  LR: 9.907e-05  Data: 0.000 (0.071)
2025-05-01 13:31:07,899 - train - INFO - Train: 13 [ 250/312 ( 80%)]  Loss:  3.049448 (3.0365)  Time: 0.533s, 7684.14/s  (1.162s, 3524.73/s)  LR: 9.907e-05  Data: 0.000 (0.057)
2025-05-01 13:32:05,762 - train - INFO - Train: 13 [ 300/312 ( 96%)]  Loss:  2.997738 (3.0309)  Time: 3.007s, 1362.17/s  (1.161s, 3527.20/s)  LR: 9.907e-05  Data: 0.000 (0.047)
2025-05-01 13:32:16,938 - train - INFO - Train: 13 [ 311/312 (100%)]  Loss:  2.974342 (3.0239)  Time: 0.627s, 6530.40/s  (1.156s, 3542.84/s)  LR: 9.907e-05  Data: 0.000 (0.046)
2025-05-01 13:32:23,382 - train - INFO - Test: [   0/48]  Time: 6.258 (6.258)  Loss:  1.5791 (1.5791)  Acc@1: 75.0000 (75.0000)  Acc@5: 89.4531 (89.4531)
2025-05-01 13:33:21,005 - train - INFO - Test: [  48/48]  Time: 2.211 (1.304)  Loss:  1.3896 (2.0199)  Acc@1: 77.4764 (61.0460)  Acc@5: 92.0991 (83.4340)
2025-05-01 13:33:27,438 - train - INFO - Train: 14 [   0/312 (  0%)]  Loss:  2.988943 (2.9889)  Time: 6.103s,  671.15/s  (6.103s,  671.15/s)  LR: 9.892e-05  Data: 5.570 (5.570)
2025-05-01 13:34:23,865 - train - INFO - Train: 14 [  50/312 ( 16%)]  Loss:  3.033892 (3.0114)  Time: 0.535s, 7660.94/s  (1.226s, 3340.80/s)  LR: 9.892e-05  Data: 0.000 (0.699)
2025-05-01 13:35:21,636 - train - INFO - Train: 14 [ 100/312 ( 32%)]  Loss:  3.055687 (3.0262)  Time: 2.912s, 1406.58/s  (1.191s, 3438.98/s)  LR: 9.892e-05  Data: 2.388 (0.664)
2025-05-01 13:36:16,058 - train - INFO - Train: 14 [ 150/312 ( 48%)]  Loss:  2.987126 (3.0164)  Time: 0.535s, 7661.05/s  (1.157s, 3539.99/s)  LR: 9.892e-05  Data: 0.000 (0.629)
2025-05-01 13:37:13,356 - train - INFO - Train: 14 [ 200/312 ( 64%)]  Loss:  2.984242 (3.0100)  Time: 2.550s, 1606.10/s  (1.154s, 3548.52/s)  LR: 9.892e-05  Data: 1.761 (0.605)
2025-05-01 13:38:09,436 - train - INFO - Train: 14 [ 250/312 ( 80%)]  Loss:  3.046132 (3.0160)  Time: 0.531s, 7716.92/s  (1.148s, 3568.67/s)  LR: 9.892e-05  Data: 0.000 (0.597)
2025-05-01 13:39:06,142 - train - INFO - Train: 14 [ 300/312 ( 96%)]  Loss:  3.069477 (3.0236)  Time: 1.250s, 3277.54/s  (1.145s, 3575.75/s)  LR: 9.892e-05  Data: 0.000 (0.576)
2025-05-01 13:39:18,286 - train - INFO - Train: 14 [ 311/312 (100%)]  Loss:  3.016816 (3.0228)  Time: 1.425s, 2874.94/s  (1.144s, 3580.35/s)  LR: 9.892e-05  Data: 0.000 (0.563)
2025-05-01 13:39:24,360 - train - INFO - Test: [   0/48]  Time: 5.886 (5.886)  Loss:  1.0488 (1.0488)  Acc@1: 79.0039 (79.0039)  Acc@5: 92.7734 (92.7734)
2025-05-01 13:40:21,666 - train - INFO - Test: [  48/48]  Time: 2.388 (1.290)  Loss:  1.2041 (1.7732)  Acc@1: 76.4151 (61.2260)  Acc@5: 90.0943 (83.8860)
2025-05-01 13:40:28,462 - train - INFO - Train: 15 [   0/312 (  0%)]  Loss:  2.973224 (2.9732)  Time: 6.418s,  638.16/s  (6.418s,  638.16/s)  LR: 9.876e-05  Data: 5.423 (5.423)
2025-05-01 13:41:24,621 - train - INFO - Train: 15 [  50/312 ( 16%)]  Loss:  3.011259 (2.9922)  Time: 0.533s, 7689.68/s  (1.227s, 3338.25/s)  LR: 9.876e-05  Data: 0.000 (0.279)
2025-05-01 13:42:22,976 - train - INFO - Train: 15 [ 100/312 ( 32%)]  Loss:  3.018454 (3.0010)  Time: 2.966s, 1381.18/s  (1.197s, 3420.96/s)  LR: 9.876e-05  Data: 0.000 (0.141)
2025-05-01 13:43:18,826 - train - INFO - Train: 15 [ 150/312 ( 48%)]  Loss:  3.028975 (3.0080)  Time: 0.535s, 7655.29/s  (1.171s, 3498.72/s)  LR: 9.876e-05  Data: 0.000 (0.094)
2025-05-01 13:44:17,230 - train - INFO - Train: 15 [ 200/312 ( 64%)]  Loss:  3.015106 (3.0094)  Time: 2.993s, 1368.60/s  (1.170s, 3500.71/s)  LR: 9.876e-05  Data: 0.000 (0.071)
2025-05-01 13:45:12,425 - train - INFO - Train: 15 [ 250/312 ( 80%)]  Loss:  3.022189 (3.0115)  Time: 0.536s, 7646.05/s  (1.157s, 3540.64/s)  LR: 9.876e-05  Data: 0.000 (0.057)
2025-05-01 13:46:10,378 - train - INFO - Train: 15 [ 300/312 ( 96%)]  Loss:  3.007235 (3.0109)  Time: 3.122s, 1312.07/s  (1.157s, 3539.53/s)  LR: 9.876e-05  Data: 0.000 (0.047)
2025-05-01 13:46:21,312 - train - INFO - Train: 15 [ 311/312 (100%)]  Loss:  3.031395 (3.0135)  Time: 0.533s, 7679.90/s  (1.151s, 3557.22/s)  LR: 9.876e-05  Data: 0.000 (0.046)
2025-05-01 13:46:27,685 - train - INFO - Test: [   0/48]  Time: 6.192 (6.192)  Loss:  0.9321 (0.9321)  Acc@1: 77.9297 (77.9297)  Acc@5: 94.1406 (94.1406)
2025-05-01 13:47:23,937 - train - INFO - Test: [  48/48]  Time: 2.104 (1.274)  Loss:  1.0068 (1.7368)  Acc@1: 78.4198 (61.2400)  Acc@5: 93.5142 (83.7680)
2025-05-01 13:47:30,469 - train - INFO - Train: 16 [   0/312 (  0%)]  Loss:  2.992229 (2.9922)  Time: 6.205s,  660.15/s  (6.205s,  660.15/s)  LR: 9.859e-05  Data: 5.385 (5.385)
2025-05-01 13:48:26,428 - train - INFO - Train: 16 [  50/312 ( 16%)]  Loss:  3.032242 (3.0122)  Time: 0.546s, 7502.30/s  (1.219s, 3360.48/s)  LR: 9.859e-05  Data: 0.000 (0.449)
2025-05-01 13:49:25,220 - train - INFO - Train: 16 [ 100/312 ( 32%)]  Loss:  2.954209 (2.9929)  Time: 3.044s, 1345.48/s  (1.198s, 3420.35/s)  LR: 9.859e-05  Data: 0.000 (0.235)
2025-05-01 13:50:21,122 - train - INFO - Train: 16 [ 150/312 ( 48%)]  Loss:  3.044668 (3.0058)  Time: 0.533s, 7689.20/s  (1.171s, 3497.28/s)  LR: 9.859e-05  Data: 0.000 (0.157)
2025-05-01 13:51:19,121 - train - INFO - Train: 16 [ 200/312 ( 64%)]  Loss:  2.996839 (3.0040)  Time: 3.071s, 1333.88/s  (1.168s, 3505.71/s)  LR: 9.859e-05  Data: 0.000 (0.118)
2025-05-01 13:52:14,101 - train - INFO - Train: 16 [ 250/312 ( 80%)]  Loss:  3.022643 (3.0071)  Time: 0.545s, 7516.63/s  (1.155s, 3547.35/s)  LR: 9.859e-05  Data: 0.000 (0.095)
2025-05-01 13:53:11,886 - train - INFO - Train: 16 [ 300/312 ( 96%)]  Loss:  2.994811 (3.0054)  Time: 3.169s, 1292.53/s  (1.155s, 3546.83/s)  LR: 9.859e-05  Data: 0.000 (0.079)
2025-05-01 13:53:23,215 - train - INFO - Train: 16 [ 311/312 (100%)]  Loss:  3.017542 (3.0069)  Time: 0.533s, 7684.25/s  (1.150s, 3560.42/s)  LR: 9.859e-05  Data: 0.000 (0.076)
2025-05-01 13:53:29,410 - train - INFO - Test: [   0/48]  Time: 6.010 (6.010)  Loss:  1.6201 (1.6201)  Acc@1: 74.7070 (74.7070)  Acc@5: 90.8203 (90.8203)
2025-05-01 13:54:26,924 - train - INFO - Test: [  48/48]  Time: 2.221 (1.296)  Loss:  1.3916 (2.0132)  Acc@1: 76.5330 (60.4460)  Acc@5: 90.9198 (83.4100)
2025-05-01 13:54:33,244 - train - INFO - Train: 17 [   0/312 (  0%)]  Loss:  3.028556 (3.0286)  Time: 6.001s,  682.57/s  (6.001s,  682.57/s)  LR: 9.841e-05  Data: 5.469 (5.469)
2025-05-01 13:55:29,006 - train - INFO - Train: 17 [  50/312 ( 16%)]  Loss:  2.983101 (3.0058)  Time: 0.525s, 7798.95/s  (1.211s, 3382.36/s)  LR: 9.841e-05  Data: 0.000 (0.673)
2025-05-01 13:56:26,429 - train - INFO - Train: 17 [ 100/312 ( 32%)]  Loss:  2.962412 (2.9914)  Time: 2.986s, 1371.70/s  (1.180s, 3471.13/s)  LR: 9.841e-05  Data: 1.918 (0.576)
2025-05-01 13:57:21,478 - train - INFO - Train: 17 [ 150/312 ( 48%)]  Loss:  2.946938 (2.9803)  Time: 0.525s, 7797.45/s  (1.154s, 3549.92/s)  LR: 9.841e-05  Data: 0.000 (0.480)
2025-05-01 13:58:18,064 - train - INFO - Train: 17 [ 200/312 ( 64%)]  Loss:  2.989396 (2.9821)  Time: 2.220s, 1844.99/s  (1.148s, 3566.95/s)  LR: 9.841e-05  Data: 1.706 (0.456)
2025-05-01 13:59:13,098 - train - INFO - Train: 17 [ 250/312 ( 80%)]  Loss:  3.020579 (2.9885)  Time: 0.526s, 7786.24/s  (1.139s, 3596.70/s)  LR: 9.841e-05  Data: 0.000 (0.465)
2025-05-01 14:00:10,980 - train - INFO - Train: 17 [ 300/312 ( 96%)]  Loss:  2.964620 (2.9851)  Time: 2.854s, 1435.00/s  (1.142s, 3586.88/s)  LR: 9.841e-05  Data: 2.330 (0.493)
2025-05-01 14:00:21,645 - train - INFO - Train: 17 [ 311/312 (100%)]  Loss:  3.031120 (2.9908)  Time: 0.532s, 7694.07/s  (1.136s, 3606.07/s)  LR: 9.841e-05  Data: 0.000 (0.491)
2025-05-01 14:00:28,069 - train - INFO - Test: [   0/48]  Time: 6.217 (6.217)  Loss:  1.0859 (1.0859)  Acc@1: 76.6602 (76.6602)  Acc@5: 91.0156 (91.0156)
2025-05-01 14:01:25,602 - train - INFO - Test: [  48/48]  Time: 2.131 (1.301)  Loss:  1.0820 (1.7053)  Acc@1: 77.0047 (61.0780)  Acc@5: 91.2736 (83.6600)
2025-05-01 14:01:32,167 - train - INFO - Train: 18 [   0/312 (  0%)]  Loss:  3.021266 (3.0213)  Time: 6.179s,  662.87/s  (6.179s,  662.87/s)  LR: 9.821e-05  Data: 5.382 (5.382)
2025-05-01 14:02:28,193 - train - INFO - Train: 18 [  50/312 ( 16%)]  Loss:  3.002705 (3.0120)  Time: 0.534s, 7667.35/s  (1.220s, 3358.25/s)  LR: 9.821e-05  Data: 0.000 (0.491)
2025-05-01 14:03:26,384 - train - INFO - Train: 18 [ 100/312 ( 32%)]  Loss:  2.957424 (2.9938)  Time: 3.030s, 1351.98/s  (1.192s, 3436.30/s)  LR: 9.821e-05  Data: 0.000 (0.267)
2025-05-01 14:04:21,138 - train - INFO - Train: 18 [ 150/312 ( 48%)]  Loss:  2.997308 (2.9947)  Time: 0.524s, 7813.30/s  (1.160s, 3531.41/s)  LR: 9.821e-05  Data: 0.000 (0.179)
2025-05-01 14:05:18,813 - train - INFO - Train: 18 [ 200/312 ( 64%)]  Loss:  3.079650 (3.0117)  Time: 1.357s, 3018.67/s  (1.158s, 3536.25/s)  LR: 9.821e-05  Data: 0.000 (0.134)
2025-05-01 14:06:13,956 - train - INFO - Train: 18 [ 250/312 ( 80%)]  Loss:  3.000867 (3.0099)  Time: 0.528s, 7763.40/s  (1.147s, 3570.31/s)  LR: 9.821e-05  Data: 0.000 (0.108)
2025-05-01 14:07:09,726 - train - INFO - Train: 18 [ 300/312 ( 96%)]  Loss:  2.965750 (3.0036)  Time: 0.706s, 5804.43/s  (1.142s, 3586.87/s)  LR: 9.821e-05  Data: 0.000 (0.090)
2025-05-01 14:07:22,697 - train - INFO - Train: 18 [ 311/312 (100%)]  Loss:  2.978693 (3.0005)  Time: 0.532s, 7705.82/s  (1.143s, 3582.75/s)  LR: 9.821e-05  Data: 0.000 (0.087)
2025-05-01 14:07:29,255 - train - INFO - Test: [   0/48]  Time: 6.359 (6.359)  Loss:  1.0879 (1.0879)  Acc@1: 77.1484 (77.1484)  Acc@5: 92.4805 (92.4805)
2025-05-01 14:08:25,342 - train - INFO - Test: [  48/48]  Time: 1.793 (1.274)  Loss:  0.9917 (1.7344)  Acc@1: 80.3066 (61.8920)  Acc@5: 93.7500 (84.2800)
2025-05-01 14:08:31,825 - train - INFO - Train: 19 [   0/312 (  0%)]  Loss:  3.017462 (3.0175)  Time: 6.160s,  664.89/s  (6.160s,  664.89/s)  LR: 9.801e-05  Data: 5.368 (5.368)
2025-05-01 14:09:28,204 - train - INFO - Train: 19 [  50/312 ( 16%)]  Loss:  3.042012 (3.0297)  Time: 0.524s, 7823.23/s  (1.226s, 3340.27/s)  LR: 9.801e-05  Data: 0.000 (0.412)
2025-05-01 14:10:27,257 - train - INFO - Train: 19 [ 100/312 ( 32%)]  Loss:  3.053245 (3.0376)  Time: 2.993s, 1368.43/s  (1.204s, 3402.38/s)  LR: 9.801e-05  Data: 0.000 (0.217)
2025-05-01 14:11:24,163 - train - INFO - Train: 19 [ 150/312 ( 48%)]  Loss:  3.004972 (3.0294)  Time: 0.525s, 7801.05/s  (1.182s, 3465.07/s)  LR: 9.801e-05  Data: 0.000 (0.146)
2025-05-01 14:12:22,365 - train - INFO - Train: 19 [ 200/312 ( 64%)]  Loss:  3.017554 (3.0270)  Time: 2.934s, 1395.92/s  (1.178s, 3478.28/s)  LR: 9.801e-05  Data: 0.000 (0.109)
2025-05-01 14:13:17,639 - train - INFO - Train: 19 [ 250/312 ( 80%)]  Loss:  3.024934 (3.0267)  Time: 0.526s, 7783.04/s  (1.163s, 3521.27/s)  LR: 9.801e-05  Data: 0.000 (0.088)
2025-05-01 14:14:15,172 - train - INFO - Train: 19 [ 300/312 ( 96%)]  Loss:  3.040375 (3.0287)  Time: 2.984s, 1372.82/s  (1.161s, 3527.61/s)  LR: 9.801e-05  Data: 0.000 (0.073)
2025-05-01 14:14:25,301 - train - INFO - Train: 19 [ 311/312 (100%)]  Loss:  3.047358 (3.0310)  Time: 0.522s, 7852.04/s  (1.153s, 3553.55/s)  LR: 9.801e-05  Data: 0.000 (0.071)
2025-05-01 14:14:31,803 - train - INFO - Test: [   0/48]  Time: 6.331 (6.331)  Loss:  1.2979 (1.2979)  Acc@1: 74.7070 (74.7070)  Acc@5: 90.6250 (90.6250)
2025-05-01 14:15:28,366 - train - INFO - Test: [  48/48]  Time: 0.956 (1.284)  Loss:  1.0205 (1.7860)  Acc@1: 78.5377 (60.8960)  Acc@5: 91.9811 (83.6100)
2025-05-01 14:15:34,585 - train - INFO - Train: 20 [   0/312 (  0%)]  Loss:  3.058206 (3.0582)  Time: 5.890s,  695.39/s  (5.890s,  695.39/s)  LR: 9.780e-05  Data: 5.210 (5.210)
2025-05-01 14:16:30,084 - train - INFO - Train: 20 [  50/312 ( 16%)]  Loss:  3.051147 (3.0547)  Time: 0.525s, 7801.64/s  (1.204s, 3402.93/s)  LR: 9.780e-05  Data: 0.000 (0.573)
2025-05-01 14:17:28,383 - train - INFO - Train: 20 [ 100/312 ( 32%)]  Loss:  3.007890 (3.0391)  Time: 3.146s, 1301.86/s  (1.185s, 3456.53/s)  LR: 9.780e-05  Data: 0.312 (0.400)
2025-05-01 14:18:23,992 - train - INFO - Train: 20 [ 150/312 ( 48%)]  Loss:  2.956290 (3.0184)  Time: 0.525s, 7800.53/s  (1.161s, 3528.37/s)  LR: 9.780e-05  Data: 0.000 (0.268)
2025-05-01 14:19:23,323 - train - INFO - Train: 20 [ 200/312 ( 64%)]  Loss:  3.004539 (3.0156)  Time: 2.827s, 1448.95/s  (1.167s, 3509.04/s)  LR: 9.780e-05  Data: 0.000 (0.201)
2025-05-01 14:20:20,427 - train - INFO - Train: 20 [ 250/312 ( 80%)]  Loss:  3.018404 (3.0161)  Time: 0.525s, 7803.88/s  (1.162s, 3524.21/s)  LR: 9.780e-05  Data: 0.000 (0.161)
2025-05-01 14:21:19,587 - train - INFO - Train: 20 [ 300/312 ( 96%)]  Loss:  3.005623 (3.0146)  Time: 2.560s, 1600.07/s  (1.166s, 3513.73/s)  LR: 9.780e-05  Data: 0.000 (0.134)
2025-05-01 14:21:31,060 - train - INFO - Train: 20 [ 311/312 (100%)]  Loss:  3.026295 (3.0160)  Time: 0.529s, 7747.60/s  (1.161s, 3526.82/s)  LR: 9.780e-05  Data: 0.000 (0.130)
2025-05-01 14:21:37,831 - train - INFO - Test: [   0/48]  Time: 6.580 (6.580)  Loss:  1.4912 (1.4912)  Acc@1: 75.2930 (75.2930)  Acc@5: 91.2109 (91.2109)
2025-05-01 14:22:34,967 - train - INFO - Test: [  48/48]  Time: 1.549 (1.300)  Loss:  1.4199 (2.0164)  Acc@1: 75.0000 (60.5660)  Acc@5: 91.7453 (83.6460)
2025-05-01 14:22:41,371 - train - INFO - Train: 21 [   0/312 (  0%)]  Loss:  3.041304 (3.0413)  Time: 6.070s,  674.77/s  (6.070s,  674.77/s)  LR: 9.757e-05  Data: 5.544 (5.544)
2025-05-01 14:23:35,909 - train - INFO - Train: 21 [  50/312 ( 16%)]  Loss:  3.043799 (3.0426)  Time: 0.525s, 7797.88/s  (1.188s, 3446.71/s)  LR: 9.757e-05  Data: 0.000 (0.594)
2025-05-01 14:24:34,678 - train - INFO - Train: 21 [ 100/312 ( 32%)]  Loss:  3.020094 (3.0351)  Time: 2.978s, 1375.21/s  (1.182s, 3465.52/s)  LR: 9.757e-05  Data: 0.000 (0.343)
2025-05-01 14:25:30,881 - train - INFO - Train: 21 [ 150/312 ( 48%)]  Loss:  3.040686 (3.0365)  Time: 0.527s, 7775.22/s  (1.163s, 3522.65/s)  LR: 9.757e-05  Data: 0.000 (0.230)
2025-05-01 14:26:29,219 - train - INFO - Train: 21 [ 200/312 ( 64%)]  Loss:  3.097301 (3.0486)  Time: 2.876s, 1423.97/s  (1.164s, 3519.65/s)  LR: 9.757e-05  Data: 0.000 (0.173)
2025-05-01 14:27:25,186 - train - INFO - Train: 21 [ 250/312 ( 80%)]  Loss:  3.057128 (3.0501)  Time: 0.526s, 7794.05/s  (1.155s, 3546.62/s)  LR: 9.757e-05  Data: 0.000 (0.138)
2025-05-01 14:28:24,006 - train - INFO - Train: 21 [ 300/312 ( 96%)]  Loss:  3.071224 (3.0531)  Time: 2.892s, 1416.27/s  (1.158s, 3535.71/s)  LR: 9.757e-05  Data: 0.000 (0.115)
2025-05-01 14:28:34,525 - train - INFO - Train: 21 [ 311/312 (100%)]  Loss:  3.006136 (3.0472)  Time: 0.522s, 7845.10/s  (1.151s, 3557.61/s)  LR: 9.757e-05  Data: 0.000 (0.111)
2025-05-01 14:28:40,941 - train - INFO - Test: [   0/48]  Time: 6.242 (6.242)  Loss:  1.1230 (1.1230)  Acc@1: 75.8789 (75.8789)  Acc@5: 92.0898 (92.0898)
2025-05-01 14:29:38,897 - train - INFO - Test: [  48/48]  Time: 1.556 (1.310)  Loss:  1.2949 (1.8155)  Acc@1: 74.0566 (59.7240)  Acc@5: 88.7972 (83.0100)
2025-05-01 14:29:45,348 - train - INFO - Train: 22 [   0/312 (  0%)]  Loss:  3.007731 (3.0077)  Time: 6.113s,  670.03/s  (6.113s,  670.03/s)  LR: 9.734e-05  Data: 5.289 (5.289)
2025-05-01 14:30:40,943 - train - INFO - Train: 22 [  50/312 ( 16%)]  Loss:  3.019678 (3.0137)  Time: 0.530s, 7731.77/s  (1.210s, 3385.44/s)  LR: 9.734e-05  Data: 0.000 (0.679)
2025-05-01 14:31:37,204 - train - INFO - Train: 22 [ 100/312 ( 32%)]  Loss:  3.011414 (3.0129)  Time: 2.708s, 1512.80/s  (1.168s, 3507.09/s)  LR: 9.734e-05  Data: 1.860 (0.614)
2025-05-01 14:32:32,310 - train - INFO - Train: 22 [ 150/312 ( 48%)]  Loss:  3.051507 (3.0226)  Time: 0.533s, 7691.56/s  (1.146s, 3573.90/s)  LR: 9.734e-05  Data: 0.000 (0.535)
2025-05-01 14:33:30,939 - train - INFO - Train: 22 [ 200/312 ( 64%)]  Loss:  3.025264 (3.0231)  Time: 3.045s, 1345.13/s  (1.153s, 3553.57/s)  LR: 9.734e-05  Data: 0.000 (0.407)
2025-05-01 14:34:26,364 - train - INFO - Train: 22 [ 250/312 ( 80%)]  Loss:  3.036190 (3.0253)  Time: 0.523s, 7834.68/s  (1.144s, 3580.95/s)  LR: 9.734e-05  Data: 0.000 (0.326)
2025-05-01 14:35:24,122 - train - INFO - Train: 22 [ 300/312 ( 96%)]  Loss:  3.052682 (3.0292)  Time: 2.211s, 1852.73/s  (1.146s, 3575.10/s)  LR: 9.734e-05  Data: 0.000 (0.272)
2025-05-01 14:35:35,507 - train - INFO - Train: 22 [ 311/312 (100%)]  Loss:  3.067053 (3.0339)  Time: 0.528s, 7762.24/s  (1.142s, 3587.37/s)  LR: 9.734e-05  Data: 0.000 (0.262)
2025-05-01 14:35:41,964 - train - INFO - Test: [   0/48]  Time: 6.273 (6.273)  Loss:  1.0811 (1.0811)  Acc@1: 76.3672 (76.3672)  Acc@5: 92.7734 (92.7734)
2025-05-01 14:36:40,361 - train - INFO - Test: [  48/48]  Time: 2.735 (1.320)  Loss:  0.9785 (1.7269)  Acc@1: 79.5991 (61.3280)  Acc@5: 92.0991 (83.8260)
2025-05-01 14:36:47,062 - train - INFO - Train: 23 [   0/312 (  0%)]  Loss:  3.033253 (3.0333)  Time: 6.369s,  643.14/s  (6.369s,  643.14/s)  LR: 9.709e-05  Data: 5.845 (5.845)
2025-05-01 14:37:43,089 - train - INFO - Train: 23 [  50/312 ( 16%)]  Loss:  2.986794 (3.0100)  Time: 0.523s, 7837.11/s  (1.223s, 3348.14/s)  LR: 9.709e-05  Data: 0.000 (0.409)
2025-05-01 14:38:41,011 - train - INFO - Train: 23 [ 100/312 ( 32%)]  Loss:  3.058654 (3.0262)  Time: 2.884s, 1420.10/s  (1.191s, 3438.59/s)  LR: 9.709e-05  Data: 0.000 (0.216)
2025-05-01 14:39:37,274 - train - INFO - Train: 23 [ 150/312 ( 48%)]  Loss:  3.063795 (3.0356)  Time: 0.523s, 7829.05/s  (1.169s, 3502.86/s)  LR: 9.709e-05  Data: 0.000 (0.144)
2025-05-01 14:40:36,343 - train - INFO - Train: 23 [ 200/312 ( 64%)]  Loss:  3.045458 (3.0376)  Time: 2.923s, 1401.22/s  (1.172s, 3493.96/s)  LR: 9.709e-05  Data: 0.000 (0.109)
2025-05-01 14:41:32,330 - train - INFO - Train: 23 [ 250/312 ( 80%)]  Loss:  2.965140 (3.0255)  Time: 0.523s, 7831.03/s  (1.162s, 3525.50/s)  LR: 9.709e-05  Data: 0.000 (0.087)
2025-05-01 14:42:30,639 - train - INFO - Train: 23 [ 300/312 ( 96%)]  Loss:  3.021646 (3.0250)  Time: 2.892s, 1416.53/s  (1.163s, 3523.34/s)  LR: 9.709e-05  Data: 0.000 (0.073)
2025-05-01 14:42:41,768 - train - INFO - Train: 23 [ 311/312 (100%)]  Loss:  3.067072 (3.0302)  Time: 0.519s, 7888.90/s  (1.157s, 3539.58/s)  LR: 9.709e-05  Data: 0.000 (0.070)
2025-05-01 14:42:48,177 - train - INFO - Test: [   0/48]  Time: 6.210 (6.210)  Loss:  1.0273 (1.0273)  Acc@1: 77.6367 (77.6367)  Acc@5: 92.7734 (92.7734)
2025-05-01 14:43:46,097 - train - INFO - Test: [  48/48]  Time: 2.121 (1.309)  Loss:  1.1992 (1.8500)  Acc@1: 76.5330 (60.2080)  Acc@5: 91.3915 (83.1140)
2025-05-01 14:43:53,012 - train - INFO - Train: 24 [   0/312 (  0%)]  Loss:  3.024238 (3.0242)  Time: 6.573s,  623.19/s  (6.573s,  623.19/s)  LR: 9.684e-05  Data: 5.813 (5.813)
2025-05-01 14:44:49,574 - train - INFO - Train: 24 [  50/312 ( 16%)]  Loss:  3.031821 (3.0280)  Time: 0.531s, 7707.09/s  (1.238s, 3308.94/s)  LR: 9.684e-05  Data: 0.000 (0.329)
2025-05-01 14:45:49,030 - train - INFO - Train: 24 [ 100/312 ( 32%)]  Loss:  3.013166 (3.0231)  Time: 3.199s, 1280.52/s  (1.214s, 3374.90/s)  LR: 9.684e-05  Data: 0.000 (0.166)
2025-05-01 14:46:45,341 - train - INFO - Train: 24 [ 150/312 ( 48%)]  Loss:  3.021286 (3.0226)  Time: 0.535s, 7659.56/s  (1.185s, 3457.44/s)  LR: 9.684e-05  Data: 0.000 (0.111)
2025-05-01 14:47:44,368 - train - INFO - Train: 24 [ 200/312 ( 64%)]  Loss:  3.029065 (3.0239)  Time: 2.980s, 1374.62/s  (1.184s, 3460.47/s)  LR: 9.684e-05  Data: 0.000 (0.084)
2025-05-01 14:48:40,695 - train - INFO - Train: 24 [ 250/312 ( 80%)]  Loss:  3.089608 (3.0349)  Time: 0.530s, 7721.19/s  (1.172s, 3494.11/s)  LR: 9.684e-05  Data: 0.000 (0.067)
2025-05-01 14:49:40,881 - train - INFO - Train: 24 [ 300/312 ( 96%)]  Loss:  3.049606 (3.0370)  Time: 2.963s, 1382.43/s  (1.177s, 3478.65/s)  LR: 9.684e-05  Data: 0.000 (0.056)
2025-05-01 14:49:51,684 - train - INFO - Train: 24 [ 311/312 (100%)]  Loss:  3.051475 (3.0388)  Time: 0.526s, 7793.79/s  (1.171s, 3499.16/s)  LR: 9.684e-05  Data: 0.000 (0.054)
2025-05-01 14:49:58,092 - train - INFO - Test: [   0/48]  Time: 6.212 (6.212)  Loss:  1.0518 (1.0518)  Acc@1: 74.3164 (74.3164)  Acc@5: 91.0156 (91.0156)
2025-05-01 14:50:55,950 - train - INFO - Test: [  48/48]  Time: 2.376 (1.308)  Loss:  1.0469 (1.6982)  Acc@1: 77.0047 (60.5980)  Acc@5: 90.6840 (83.2940)
2025-05-01 14:51:02,224 - train - INFO - Train: 25 [   0/312 (  0%)]  Loss:  3.053081 (3.0531)  Time: 5.925s,  691.26/s  (5.925s,  691.26/s)  LR: 9.657e-05  Data: 5.392 (5.392)
2025-05-01 14:51:58,729 - train - INFO - Train: 25 [  50/312 ( 16%)]  Loss:  3.058142 (3.0556)  Time: 0.524s, 7818.33/s  (1.224s, 3346.16/s)  LR: 9.657e-05  Data: 0.000 (0.518)
2025-05-01 14:52:56,800 - train - INFO - Train: 25 [ 100/312 ( 32%)]  Loss:  3.022919 (3.0447)  Time: 2.836s, 1444.16/s  (1.193s, 3433.19/s)  LR: 9.657e-05  Data: 0.000 (0.298)
2025-05-01 14:53:53,347 - train - INFO - Train: 25 [ 150/312 ( 48%)]  Loss:  3.088631 (3.0557)  Time: 0.526s, 7788.22/s  (1.172s, 3493.44/s)  LR: 9.657e-05  Data: 0.000 (0.200)
2025-05-01 14:54:51,992 - train - INFO - Train: 25 [ 200/312 ( 64%)]  Loss:  3.093037 (3.0632)  Time: 2.491s, 1644.39/s  (1.173s, 3493.17/s)  LR: 9.657e-05  Data: 0.000 (0.150)
2025-05-01 14:55:49,191 - train - INFO - Train: 25 [ 250/312 ( 80%)]  Loss:  3.114372 (3.0717)  Time: 0.525s, 7795.80/s  (1.167s, 3510.25/s)  LR: 9.657e-05  Data: 0.000 (0.120)
2025-05-01 14:56:46,713 - train - INFO - Train: 25 [ 300/312 ( 96%)]  Loss:  3.037481 (3.0668)  Time: 1.593s, 2571.43/s  (1.164s, 3518.49/s)  LR: 9.657e-05  Data: 0.000 (0.100)
2025-05-01 14:56:58,537 - train - INFO - Train: 25 [ 311/312 (100%)]  Loss:  3.028494 (3.0620)  Time: 0.522s, 7845.84/s  (1.161s, 3528.03/s)  LR: 9.657e-05  Data: 0.000 (0.097)
2025-05-01 14:57:04,907 - train - INFO - Test: [   0/48]  Time: 6.173 (6.173)  Loss:  1.2451 (1.2451)  Acc@1: 75.9766 (75.9766)  Acc@5: 91.3086 (91.3086)
2025-05-01 14:58:03,246 - train - INFO - Test: [  48/48]  Time: 2.309 (1.317)  Loss:  1.1719 (1.8743)  Acc@1: 76.0613 (60.7260)  Acc@5: 92.4528 (83.3540)
2025-05-01 14:58:09,903 - train - INFO - Train: 26 [   0/312 (  0%)]  Loss:  3.013765 (3.0138)  Time: 6.118s,  669.51/s  (6.118s,  669.51/s)  LR: 9.630e-05  Data: 5.485 (5.485)
2025-05-01 14:59:06,037 - train - INFO - Train: 26 [  50/312 ( 16%)]  Loss:  3.016433 (3.0151)  Time: 0.525s, 7797.38/s  (1.221s, 3355.71/s)  LR: 9.630e-05  Data: 0.000 (0.647)
2025-05-01 15:00:04,351 - train - INFO - Train: 26 [ 100/312 ( 32%)]  Loss:  3.069782 (3.0333)  Time: 3.054s, 1341.35/s  (1.194s, 3431.37/s)  LR: 9.630e-05  Data: 0.859 (0.535)
2025-05-01 15:01:00,601 - train - INFO - Train: 26 [ 150/312 ( 48%)]  Loss:  3.110673 (3.0527)  Time: 0.532s, 7698.78/s  (1.171s, 3498.04/s)  LR: 9.630e-05  Data: 0.000 (0.401)
2025-05-01 15:01:59,513 - train - INFO - Train: 26 [ 200/312 ( 64%)]  Loss:  3.129512 (3.0680)  Time: 3.072s, 1333.28/s  (1.173s, 3492.66/s)  LR: 9.630e-05  Data: 0.001 (0.301)
2025-05-01 15:02:54,290 - train - INFO - Train: 26 [ 250/312 ( 80%)]  Loss:  3.114014 (3.0757)  Time: 0.537s, 7624.26/s  (1.157s, 3539.08/s)  LR: 9.630e-05  Data: 0.000 (0.241)
2025-05-01 15:03:52,814 - train - INFO - Train: 26 [ 300/312 ( 96%)]  Loss:  3.068929 (3.0747)  Time: 3.097s, 1322.45/s  (1.160s, 3532.46/s)  LR: 9.630e-05  Data: 0.000 (0.201)
2025-05-01 15:04:03,698 - train - INFO - Train: 26 [ 311/312 (100%)]  Loss:  3.021145 (3.0680)  Time: 0.529s, 7740.40/s  (1.154s, 3550.84/s)  LR: 9.630e-05  Data: 0.000 (0.194)
2025-05-01 15:04:10,140 - train - INFO - Test: [   0/48]  Time: 6.253 (6.253)  Loss:  1.3975 (1.3975)  Acc@1: 75.0977 (75.0977)  Acc@5: 90.2344 (90.2344)
2025-05-01 15:05:08,038 - train - INFO - Test: [  48/48]  Time: 2.321 (1.309)  Loss:  1.1152 (1.8780)  Acc@1: 77.2406 (60.0000)  Acc@5: 91.5094 (82.8700)
2025-05-01 15:05:14,435 - train - INFO - Train: 27 [   0/312 (  0%)]  Loss:  3.033101 (3.0331)  Time: 6.075s,  674.24/s  (6.075s,  674.24/s)  LR: 9.601e-05  Data: 5.030 (5.030)
2025-05-01 15:06:10,832 - train - INFO - Train: 27 [  50/312 ( 16%)]  Loss:  3.093552 (3.0633)  Time: 0.530s, 7726.05/s  (1.225s, 3343.97/s)  LR: 9.601e-05  Data: 0.000 (0.398)
2025-05-01 15:07:09,472 - train - INFO - Train: 27 [ 100/312 ( 32%)]  Loss:  3.047382 (3.0580)  Time: 2.951s, 1388.09/s  (1.199s, 3415.93/s)  LR: 9.601e-05  Data: 0.000 (0.225)
2025-05-01 15:08:03,978 - train - INFO - Train: 27 [ 150/312 ( 48%)]  Loss:  3.085027 (3.0648)  Time: 0.531s, 7709.33/s  (1.163s, 3521.96/s)  LR: 9.601e-05  Data: 0.000 (0.151)
2025-05-01 15:09:01,273 - train - INFO - Train: 27 [ 200/312 ( 64%)]  Loss:  3.086863 (3.0692)  Time: 2.888s, 1418.19/s  (1.159s, 3534.90/s)  LR: 9.601e-05  Data: 0.000 (0.113)
2025-05-01 15:09:56,644 - train - INFO - Train: 27 [ 250/312 ( 80%)]  Loss:  3.034498 (3.0634)  Time: 0.526s, 7789.15/s  (1.149s, 3566.37/s)  LR: 9.601e-05  Data: 0.000 (0.091)
2025-05-01 15:10:54,883 - train - INFO - Train: 27 [ 300/312 ( 96%)]  Loss:  3.084633 (3.0664)  Time: 2.701s, 1516.48/s  (1.151s, 3558.02/s)  LR: 9.601e-05  Data: 0.000 (0.076)
2025-05-01 15:11:05,246 - train - INFO - Train: 27 [ 311/312 (100%)]  Loss:  3.025027 (3.0613)  Time: 0.522s, 7850.33/s  (1.144s, 3580.97/s)  LR: 9.601e-05  Data: 0.000 (0.073)
2025-05-01 15:11:11,888 - train - INFO - Test: [   0/48]  Time: 6.460 (6.460)  Loss:  1.3555 (1.3555)  Acc@1: 76.1719 (76.1719)  Acc@5: 92.7734 (92.7734)
2025-05-01 15:12:08,719 - train - INFO - Test: [  48/48]  Time: 2.451 (1.292)  Loss:  1.4248 (2.0678)  Acc@1: 74.5283 (59.1900)  Acc@5: 91.8632 (82.1520)
2025-05-01 15:12:15,006 - train - INFO - Train: 28 [   0/312 (  0%)]  Loss:  3.066144 (3.0661)  Time: 5.914s,  692.56/s  (5.914s,  692.56/s)  LR: 9.572e-05  Data: 5.076 (5.076)
2025-05-01 15:13:10,058 - train - INFO - Train: 28 [  50/312 ( 16%)]  Loss:  3.069714 (3.0679)  Time: 0.527s, 7774.34/s  (1.195s, 3426.46/s)  LR: 9.572e-05  Data: 0.000 (0.413)
2025-05-01 15:14:06,600 - train - INFO - Train: 28 [ 100/312 ( 32%)]  Loss:  3.064543 (3.0668)  Time: 2.222s, 1843.39/s  (1.163s, 3520.65/s)  LR: 9.572e-05  Data: 0.000 (0.222)
2025-05-01 15:15:01,539 - train - INFO - Train: 28 [ 150/312 ( 48%)]  Loss:  3.062879 (3.0658)  Time: 0.529s, 7741.95/s  (1.142s, 3586.71/s)  LR: 9.572e-05  Data: 0.000 (0.149)
2025-05-01 15:15:59,288 - train - INFO - Train: 28 [ 200/312 ( 64%)]  Loss:  3.037234 (3.0601)  Time: 2.243s, 1826.12/s  (1.145s, 3576.62/s)  LR: 9.572e-05  Data: 0.000 (0.112)
2025-05-01 15:16:55,030 - train - INFO - Train: 28 [ 250/312 ( 80%)]  Loss:  3.107891 (3.0681)  Time: 0.764s, 5359.35/s  (1.139s, 3595.67/s)  LR: 9.572e-05  Data: 0.000 (0.089)
2025-05-01 15:17:53,388 - train - INFO - Train: 28 [ 300/312 ( 96%)]  Loss:  3.131691 (3.0772)  Time: 3.070s, 1334.38/s  (1.144s, 3581.07/s)  LR: 9.572e-05  Data: 0.000 (0.075)
2025-05-01 15:18:03,961 - train - INFO - Train: 28 [ 311/312 (100%)]  Loss:  3.123119 (3.0829)  Time: 0.530s, 7725.63/s  (1.137s, 3601.36/s)  LR: 9.572e-05  Data: 0.000 (0.072)
2025-05-01 15:18:10,302 - train - INFO - Test: [   0/48]  Time: 6.149 (6.149)  Loss:  1.0254 (1.0254)  Acc@1: 75.9766 (75.9766)  Acc@5: 91.1133 (91.1133)
2025-05-01 15:19:07,829 - train - INFO - Test: [  48/48]  Time: 1.964 (1.300)  Loss:  1.1455 (1.7381)  Acc@1: 74.1745 (60.1540)  Acc@5: 89.8585 (82.8740)
2025-05-01 15:19:14,343 - train - INFO - Train: 29 [   0/312 (  0%)]  Loss:  3.011890 (3.0119)  Time: 6.190s,  661.68/s  (6.190s,  661.68/s)  LR: 9.541e-05  Data: 5.012 (5.012)
2025-05-01 15:20:10,007 - train - INFO - Train: 29 [  50/312 ( 16%)]  Loss:  3.091535 (3.0517)  Time: 0.534s, 7673.13/s  (1.213s, 3377.28/s)  LR: 9.541e-05  Data: 0.000 (0.394)
2025-05-01 15:21:06,148 - train - INFO - Train: 29 [ 100/312 ( 32%)]  Loss:  3.050577 (3.0513)  Time: 2.709s, 1511.92/s  (1.168s, 3506.13/s)  LR: 9.541e-05  Data: 0.000 (0.199)
2025-05-01 15:22:01,179 - train - INFO - Train: 29 [ 150/312 ( 48%)]  Loss:  3.089879 (3.0610)  Time: 0.536s, 7639.88/s  (1.146s, 3574.65/s)  LR: 9.541e-05  Data: 0.000 (0.133)
2025-05-01 15:22:57,987 - train - INFO - Train: 29 [ 200/312 ( 64%)]  Loss:  3.058155 (3.0604)  Time: 2.975s, 1376.73/s  (1.143s, 3582.21/s)  LR: 9.541e-05  Data: 0.000 (0.100)
2025-05-01 15:23:53,033 - train - INFO - Train: 29 [ 250/312 ( 80%)]  Loss:  3.086305 (3.0647)  Time: 0.534s, 7668.01/s  (1.135s, 3608.96/s)  LR: 9.541e-05  Data: 0.000 (0.080)
2025-05-01 15:24:50,273 - train - INFO - Train: 29 [ 300/312 ( 96%)]  Loss:  3.074145 (3.0661)  Time: 2.937s, 1394.56/s  (1.137s, 3603.77/s)  LR: 9.541e-05  Data: 0.000 (0.067)
2025-05-01 15:25:00,949 - train - INFO - Train: 29 [ 311/312 (100%)]  Loss:  3.042154 (3.0631)  Time: 0.532s, 7705.52/s  (1.131s, 3622.44/s)  LR: 9.541e-05  Data: 0.000 (0.065)
2025-05-01 15:25:07,535 - train - INFO - Test: [   0/48]  Time: 6.387 (6.387)  Loss:  1.1641 (1.1641)  Acc@1: 77.0508 (77.0508)  Acc@5: 91.7969 (91.7969)
2025-05-01 15:26:04,522 - train - INFO - Test: [  48/48]  Time: 2.735 (1.293)  Loss:  1.1201 (1.7503)  Acc@1: 77.0047 (60.9180)  Acc@5: 90.9198 (83.6640)
2025-05-01 15:26:10,990 - train - INFO - Train: 30 [   0/312 (  0%)]  Loss:  3.084872 (3.0849)  Time: 6.146s,  666.40/s  (6.146s,  666.40/s)  LR: 9.510e-05  Data: 5.148 (5.148)
2025-05-01 15:27:06,937 - train - INFO - Train: 30 [  50/312 ( 16%)]  Loss:  3.018725 (3.0518)  Time: 0.537s, 7625.28/s  (1.217s, 3364.29/s)  LR: 9.510e-05  Data: 0.000 (0.351)
2025-05-01 15:28:04,708 - train - INFO - Train: 30 [ 100/312 ( 32%)]  Loss:  3.086664 (3.0634)  Time: 3.080s, 1329.72/s  (1.187s, 3451.48/s)  LR: 9.510e-05  Data: 0.000 (0.178)
2025-05-01 15:28:59,574 - train - INFO - Train: 30 [ 150/312 ( 48%)]  Loss:  3.066442 (3.0642)  Time: 0.527s, 7770.23/s  (1.157s, 3539.82/s)  LR: 9.510e-05  Data: 0.000 (0.119)
2025-05-01 15:29:56,062 - train - INFO - Train: 30 [ 200/312 ( 64%)]  Loss:  3.124611 (3.0763)  Time: 2.728s, 1501.41/s  (1.150s, 3560.79/s)  LR: 9.510e-05  Data: 0.000 (0.089)
2025-05-01 15:30:51,686 - train - INFO - Train: 30 [ 250/312 ( 80%)]  Loss:  3.061246 (3.0738)  Time: 0.536s, 7647.98/s  (1.143s, 3584.31/s)  LR: 9.510e-05  Data: 0.000 (0.072)
2025-05-01 15:31:48,204 - train - INFO - Train: 30 [ 300/312 ( 96%)]  Loss:  3.083278 (3.0751)  Time: 1.096s, 3736.69/s  (1.141s, 3590.79/s)  LR: 9.510e-05  Data: 0.000 (0.060)
2025-05-01 15:32:00,337 - train - INFO - Train: 30 [ 311/312 (100%)]  Loss:  3.079059 (3.0756)  Time: 0.522s, 7847.26/s  (1.139s, 3595.00/s)  LR: 9.510e-05  Data: 0.000 (0.058)
2025-05-01 15:32:06,519 - train - INFO - Test: [   0/48]  Time: 6.002 (6.002)  Loss:  1.2871 (1.2871)  Acc@1: 76.3672 (76.3672)  Acc@5: 91.6992 (91.6992)
2025-05-01 15:33:03,157 - train - INFO - Test: [  48/48]  Time: 2.003 (1.278)  Loss:  1.2744 (1.9440)  Acc@1: 77.2406 (59.2920)  Acc@5: 90.6840 (82.8200)
2025-05-01 15:33:09,606 - train - INFO - Train: 31 [   0/312 (  0%)]  Loss:  3.085552 (3.0856)  Time: 6.120s,  669.29/s  (6.120s,  669.29/s)  LR: 9.477e-05  Data: 5.587 (5.587)
2025-05-01 15:34:05,597 - train - INFO - Train: 31 [  50/312 ( 16%)]  Loss:  3.006160 (3.0459)  Time: 0.532s, 7701.85/s  (1.218s, 3363.38/s)  LR: 9.477e-05  Data: 0.000 (0.500)
2025-05-01 15:35:01,857 - train - INFO - Train: 31 [ 100/312 ( 32%)]  Loss:  3.109490 (3.0671)  Time: 0.546s, 7506.01/s  (1.172s, 3495.02/s)  LR: 9.477e-05  Data: 0.000 (0.285)
2025-05-01 15:36:00,197 - train - INFO - Train: 31 [ 150/312 ( 48%)]  Loss:  3.118009 (3.0798)  Time: 0.526s, 7790.41/s  (1.170s, 3500.14/s)  LR: 9.477e-05  Data: 0.000 (0.191)
2025-05-01 15:36:54,857 - train - INFO - Train: 31 [ 200/312 ( 64%)]  Loss:  3.051010 (3.0740)  Time: 0.526s, 7786.23/s  (1.151s, 3558.43/s)  LR: 9.477e-05  Data: 0.000 (0.143)
2025-05-01 15:37:52,522 - train - INFO - Train: 31 [ 250/312 ( 80%)]  Loss:  3.095646 (3.0776)  Time: 0.526s, 7793.36/s  (1.152s, 3557.07/s)  LR: 9.477e-05  Data: 0.000 (0.115)
2025-05-01 15:38:48,042 - train - INFO - Train: 31 [ 300/312 ( 96%)]  Loss:  3.058118 (3.0749)  Time: 0.525s, 7794.98/s  (1.145s, 3578.31/s)  LR: 9.477e-05  Data: 0.000 (0.096)
2025-05-01 15:39:00,832 - train - INFO - Train: 31 [ 311/312 (100%)]  Loss:  3.133207 (3.0821)  Time: 0.532s, 7695.94/s  (1.145s, 3576.33/s)  LR: 9.477e-05  Data: 0.000 (0.092)
2025-05-01 15:39:07,452 - train - INFO - Test: [   0/48]  Time: 6.423 (6.423)  Loss:  0.9526 (0.9526)  Acc@1: 79.2969 (79.2969)  Acc@5: 92.2852 (92.2852)
2025-05-01 15:40:04,859 - train - INFO - Test: [  48/48]  Time: 2.245 (1.303)  Loss:  1.0127 (1.7169)  Acc@1: 77.0047 (60.4560)  Acc@5: 91.0377 (83.2620)
2025-05-01 15:40:11,236 - train - INFO - Train: 32 [   0/312 (  0%)]  Loss:  3.036497 (3.0365)  Time: 6.056s,  676.40/s  (6.056s,  676.40/s)  LR: 9.443e-05  Data: 5.268 (5.268)
2025-05-01 15:41:06,797 - train - INFO - Train: 32 [  50/312 ( 16%)]  Loss:  3.036768 (3.0366)  Time: 0.525s, 7803.16/s  (1.208s, 3390.34/s)  LR: 9.443e-05  Data: 0.000 (0.546)
2025-05-01 15:42:04,963 - train - INFO - Train: 32 [ 100/312 ( 32%)]  Loss:  3.054810 (3.0427)  Time: 2.978s, 1375.40/s  (1.186s, 3453.78/s)  LR: 9.443e-05  Data: 0.000 (0.331)
2025-05-01 15:43:00,597 - train - INFO - Train: 32 [ 150/312 ( 48%)]  Loss:  3.094899 (3.0557)  Time: 0.527s, 7768.63/s  (1.162s, 3525.93/s)  LR: 9.443e-05  Data: 0.000 (0.221)
2025-05-01 15:43:57,683 - train - INFO - Train: 32 [ 200/312 ( 64%)]  Loss:  3.055700 (3.0557)  Time: 3.017s, 1357.60/s  (1.157s, 3541.09/s)  LR: 9.443e-05  Data: 0.000 (0.166)
2025-05-01 15:44:52,474 - train - INFO - Train: 32 [ 250/312 ( 80%)]  Loss:  3.131191 (3.0683)  Time: 0.526s, 7793.14/s  (1.145s, 3578.64/s)  LR: 9.443e-05  Data: 0.000 (0.133)
2025-05-01 15:45:49,100 - train - INFO - Train: 32 [ 300/312 ( 96%)]  Loss:  3.137409 (3.0782)  Time: 2.432s, 1684.19/s  (1.143s, 3584.92/s)  LR: 9.443e-05  Data: 0.000 (0.111)
2025-05-01 15:45:59,859 - train - INFO - Train: 32 [ 311/312 (100%)]  Loss:  3.074781 (3.0778)  Time: 0.522s, 7839.61/s  (1.137s, 3603.21/s)  LR: 9.443e-05  Data: 0.000 (0.107)
2025-05-01 15:46:06,312 - train - INFO - Test: [   0/48]  Time: 6.270 (6.270)  Loss:  1.3975 (1.3975)  Acc@1: 74.0234 (74.0234)  Acc@5: 91.3086 (91.3086)
2025-05-01 15:47:03,370 - train - INFO - Test: [  48/48]  Time: 1.511 (1.292)  Loss:  1.2461 (1.9003)  Acc@1: 75.2358 (59.8980)  Acc@5: 90.3302 (83.0660)
2025-05-01 15:47:10,409 - train - INFO - Train: 33 [   0/312 (  0%)]  Loss:  3.063974 (3.0640)  Time: 6.650s,  615.97/s  (6.650s,  615.97/s)  LR: 9.409e-05  Data: 5.640 (5.640)
2025-05-01 15:48:04,963 - train - INFO - Train: 33 [  50/312 ( 16%)]  Loss:  3.088393 (3.0762)  Time: 0.525s, 7800.51/s  (1.200s, 3413.22/s)  LR: 9.409e-05  Data: 0.000 (0.606)
2025-05-01 15:49:02,507 - train - INFO - Train: 33 [ 100/312 ( 32%)]  Loss:  3.018372 (3.0569)  Time: 2.969s, 1379.68/s  (1.176s, 3483.92/s)  LR: 9.409e-05  Data: 0.935 (0.509)
2025-05-01 15:49:57,753 - train - INFO - Train: 33 [ 150/312 ( 48%)]  Loss:  3.063264 (3.0585)  Time: 0.526s, 7793.25/s  (1.152s, 3554.80/s)  LR: 9.409e-05  Data: 0.000 (0.377)
2025-05-01 15:50:55,244 - train - INFO - Train: 33 [ 200/312 ( 64%)]  Loss:  3.125215 (3.0718)  Time: 2.853s, 1435.51/s  (1.152s, 3556.68/s)  LR: 9.409e-05  Data: 0.000 (0.283)
2025-05-01 15:51:50,963 - train - INFO - Train: 33 [ 250/312 ( 80%)]  Loss:  3.083821 (3.0738)  Time: 0.536s, 7648.89/s  (1.144s, 3579.77/s)  LR: 9.409e-05  Data: 0.000 (0.227)
2025-05-01 15:52:47,479 - train - INFO - Train: 33 [ 300/312 ( 96%)]  Loss:  3.097764 (3.0773)  Time: 2.679s, 1529.12/s  (1.142s, 3587.04/s)  LR: 9.409e-05  Data: 0.000 (0.189)
2025-05-01 15:52:58,163 - train - INFO - Train: 33 [ 311/312 (100%)]  Loss:  3.082685 (3.0779)  Time: 0.530s, 7726.02/s  (1.136s, 3606.05/s)  LR: 9.409e-05  Data: 0.000 (0.183)
2025-05-01 15:53:04,486 - train - INFO - Test: [   0/48]  Time: 6.142 (6.142)  Loss:  1.4902 (1.4902)  Acc@1: 76.3672 (76.3672)  Acc@5: 90.9180 (90.9180)
2025-05-01 15:54:01,784 - train - INFO - Test: [  48/48]  Time: 2.016 (1.295)  Loss:  1.4004 (1.9465)  Acc@1: 77.2406 (59.7260)  Acc@5: 89.8585 (83.0080)
2025-05-01 15:54:08,189 - train - INFO - Train: 34 [   0/312 (  0%)]  Loss:  3.050974 (3.0510)  Time: 6.091s,  672.46/s  (6.091s,  672.46/s)  LR: 9.373e-05  Data: 5.383 (5.383)
2025-05-01 15:55:04,170 - train - INFO - Train: 34 [  50/312 ( 16%)]  Loss:  3.060760 (3.0559)  Time: 0.533s, 7677.87/s  (1.217s, 3365.62/s)  LR: 9.373e-05  Data: 0.000 (0.643)
2025-05-01 15:56:01,830 - train - INFO - Train: 34 [ 100/312 ( 32%)]  Loss:  3.074204 (3.0620)  Time: 2.590s, 1581.59/s  (1.185s, 3455.36/s)  LR: 9.373e-05  Data: 1.967 (0.606)
2025-05-01 15:56:57,344 - train - INFO - Train: 34 [ 150/312 ( 48%)]  Loss:  3.143588 (3.0824)  Time: 0.537s, 7623.14/s  (1.161s, 3529.45/s)  LR: 9.373e-05  Data: 0.000 (0.559)
2025-05-01 15:57:54,480 - train - INFO - Train: 34 [ 200/312 ( 64%)]  Loss:  3.182561 (3.1024)  Time: 2.758s, 1485.13/s  (1.156s, 3542.98/s)  LR: 9.373e-05  Data: 0.641 (0.495)
2025-05-01 15:58:49,907 - train - INFO - Train: 34 [ 250/312 ( 80%)]  Loss:  3.080755 (3.0988)  Time: 0.533s, 7682.87/s  (1.147s, 3572.29/s)  LR: 9.373e-05  Data: 0.000 (0.435)
2025-05-01 15:59:46,564 - train - INFO - Train: 34 [ 300/312 ( 96%)]  Loss:  3.101373 (3.0992)  Time: 2.389s, 1714.77/s  (1.144s, 3579.29/s)  LR: 9.373e-05  Data: 0.219 (0.392)
2025-05-01 15:59:57,363 - train - INFO - Train: 34 [ 311/312 (100%)]  Loss:  3.107760 (3.1002)  Time: 0.522s, 7847.75/s  (1.139s, 3597.33/s)  LR: 9.373e-05  Data: 0.000 (0.385)
2025-05-01 16:00:03,867 - train - INFO - Test: [   0/48]  Time: 6.321 (6.321)  Loss:  1.2324 (1.2324)  Acc@1: 74.5117 (74.5117)  Acc@5: 92.0898 (92.0898)
2025-05-01 16:01:00,423 - train - INFO - Test: [  48/48]  Time: 1.956 (1.283)  Loss:  1.1406 (1.8416)  Acc@1: 76.8868 (59.5220)  Acc@5: 90.2123 (82.9420)
2025-05-01 16:01:07,009 - train - INFO - Train: 35 [   0/312 (  0%)]  Loss:  3.088403 (3.0884)  Time: 6.247s,  655.71/s  (6.247s,  655.71/s)  LR: 9.337e-05  Data: 5.595 (5.595)
2025-05-01 16:02:03,916 - train - INFO - Train: 35 [  50/312 ( 16%)]  Loss:  3.098228 (3.0933)  Time: 0.530s, 7733.95/s  (1.238s, 3307.84/s)  LR: 9.337e-05  Data: 0.000 (0.328)
2025-05-01 16:03:02,691 - train - INFO - Train: 35 [ 100/312 ( 32%)]  Loss:  3.059847 (3.0822)  Time: 2.756s, 1486.42/s  (1.207s, 3393.04/s)  LR: 9.337e-05  Data: 0.000 (0.169)
2025-05-01 16:03:58,504 - train - INFO - Train: 35 [ 150/312 ( 48%)]  Loss:  3.094353 (3.0852)  Time: 0.531s, 7713.63/s  (1.177s, 3479.89/s)  LR: 9.337e-05  Data: 0.000 (0.113)
2025-05-01 16:04:56,570 - train - INFO - Train: 35 [ 200/312 ( 64%)]  Loss:  3.096981 (3.0876)  Time: 2.484s, 1648.83/s  (1.173s, 3491.50/s)  LR: 9.337e-05  Data: 0.000 (0.085)
2025-05-01 16:05:54,178 - train - INFO - Train: 35 [ 250/312 ( 80%)]  Loss:  3.152431 (3.0984)  Time: 0.536s, 7645.54/s  (1.169s, 3504.03/s)  LR: 9.337e-05  Data: 0.000 (0.068)
2025-05-01 16:06:51,007 - train - INFO - Train: 35 [ 300/312 ( 96%)]  Loss:  3.086934 (3.0967)  Time: 1.666s, 2458.97/s  (1.164s, 3520.24/s)  LR: 9.337e-05  Data: 0.000 (0.057)
2025-05-01 16:07:03,389 - train - INFO - Train: 35 [ 311/312 (100%)]  Loss:  3.135535 (3.1016)  Time: 0.535s, 7660.89/s  (1.162s, 3524.30/s)  LR: 9.337e-05  Data: 0.000 (0.055)
2025-05-01 16:07:09,805 - train - INFO - Test: [   0/48]  Time: 6.218 (6.218)  Loss:  1.3828 (1.3828)  Acc@1: 75.7812 (75.7812)  Acc@5: 90.5273 (90.5273)
2025-05-01 16:08:06,761 - train - INFO - Test: [  48/48]  Time: 2.645 (1.289)  Loss:  1.2559 (1.8930)  Acc@1: 75.5896 (60.2460)  Acc@5: 91.1557 (83.4000)
2025-05-01 16:08:13,140 - train - INFO - Train: 36 [   0/312 (  0%)]  Loss:  3.031126 (3.0311)  Time: 6.043s,  677.82/s  (6.043s,  677.82/s)  LR: 9.299e-05  Data: 5.139 (5.139)
2025-05-01 16:09:08,890 - train - INFO - Train: 36 [  50/312 ( 16%)]  Loss:  3.041474 (3.0363)  Time: 0.526s, 7793.15/s  (1.212s, 3380.63/s)  LR: 9.299e-05  Data: 0.000 (0.485)
2025-05-01 16:10:06,682 - train - INFO - Train: 36 [ 100/312 ( 32%)]  Loss:  3.062778 (3.0451)  Time: 3.105s, 1319.34/s  (1.184s, 3459.51/s)  LR: 9.299e-05  Data: 0.000 (0.284)
2025-05-01 16:11:02,299 - train - INFO - Train: 36 [ 150/312 ( 48%)]  Loss:  3.115215 (3.0626)  Time: 0.525s, 7800.90/s  (1.160s, 3530.26/s)  LR: 9.299e-05  Data: 0.000 (0.190)
2025-05-01 16:11:59,962 - train - INFO - Train: 36 [ 200/312 ( 64%)]  Loss:  3.074627 (3.0650)  Time: 2.793s, 1466.76/s  (1.159s, 3535.57/s)  LR: 9.299e-05  Data: 0.000 (0.143)
2025-05-01 16:12:55,288 - train - INFO - Train: 36 [ 250/312 ( 80%)]  Loss:  3.054665 (3.0633)  Time: 0.527s, 7774.93/s  (1.148s, 3567.49/s)  LR: 9.299e-05  Data: 0.000 (0.114)
2025-05-01 16:13:52,678 - train - INFO - Train: 36 [ 300/312 ( 96%)]  Loss:  3.021728 (3.0574)  Time: 3.028s, 1352.53/s  (1.148s, 3567.70/s)  LR: 9.299e-05  Data: 0.000 (0.095)
2025-05-01 16:14:03,099 - train - INFO - Train: 36 [ 311/312 (100%)]  Loss:  3.080869 (3.0603)  Time: 0.521s, 7855.40/s  (1.141s, 3589.84/s)  LR: 9.299e-05  Data: 0.000 (0.092)
2025-05-01 16:14:09,502 - train - INFO - Test: [   0/48]  Time: 6.228 (6.228)  Loss:  1.3086 (1.3086)  Acc@1: 73.9258 (73.9258)  Acc@5: 90.8203 (90.8203)
2025-05-01 16:15:06,695 - train - INFO - Test: [  48/48]  Time: 2.215 (1.294)  Loss:  1.1982 (1.8427)  Acc@1: 76.5330 (59.3520)  Acc@5: 89.6226 (82.8140)
2025-05-01 16:15:13,249 - train - INFO - Train: 37 [   0/312 (  0%)]  Loss:  3.080468 (3.0805)  Time: 6.215s,  659.04/s  (6.215s,  659.04/s)  LR: 9.261e-05  Data: 5.271 (5.271)
2025-05-01 16:16:08,178 - train - INFO - Train: 37 [  50/312 ( 16%)]  Loss:  3.031808 (3.0561)  Time: 0.536s, 7641.30/s  (1.199s, 3416.51/s)  LR: 9.261e-05  Data: 0.000 (0.617)
2025-05-01 16:17:05,443 - train - INFO - Train: 37 [ 100/312 ( 32%)]  Loss:  3.114360 (3.0755)  Time: 2.917s, 1404.20/s  (1.172s, 3493.85/s)  LR: 9.261e-05  Data: 2.388 (0.607)
2025-05-01 16:18:00,722 - train - INFO - Train: 37 [ 150/312 ( 48%)]  Loss:  3.065712 (3.0731)  Time: 0.537s, 7624.07/s  (1.150s, 3561.04/s)  LR: 9.261e-05  Data: 0.000 (0.560)
2025-05-01 16:18:58,002 - train - INFO - Train: 37 [ 200/312 ( 64%)]  Loss:  3.105588 (3.0796)  Time: 2.861s, 1431.89/s  (1.149s, 3564.63/s)  LR: 9.261e-05  Data: 0.958 (0.503)
2025-05-01 16:19:52,283 - train - INFO - Train: 37 [ 250/312 ( 80%)]  Loss:  3.094405 (3.0821)  Time: 0.525s, 7796.71/s  (1.136s, 3604.28/s)  LR: 9.261e-05  Data: 0.000 (0.461)
2025-05-01 16:20:50,163 - train - INFO - Train: 37 [ 300/312 ( 96%)]  Loss:  3.112905 (3.0865)  Time: 2.969s, 1379.55/s  (1.140s, 3593.17/s)  LR: 9.261e-05  Data: 0.033 (0.420)
2025-05-01 16:21:00,497 - train - INFO - Train: 37 [ 311/312 (100%)]  Loss:  3.120503 (3.0907)  Time: 0.533s, 7688.11/s  (1.133s, 3615.62/s)  LR: 9.261e-05  Data: 0.000 (0.406)
2025-05-01 16:21:07,238 - train - INFO - Test: [   0/48]  Time: 6.554 (6.554)  Loss:  1.1572 (1.1572)  Acc@1: 76.7578 (76.7578)  Acc@5: 91.6992 (91.6992)
2025-05-01 16:22:03,702 - train - INFO - Test: [  48/48]  Time: 1.121 (1.286)  Loss:  1.1846 (1.8185)  Acc@1: 75.4717 (59.8460)  Acc@5: 91.7453 (82.8840)
2025-05-01 16:22:10,281 - train - INFO - Train: 38 [   0/312 (  0%)]  Loss:  3.092979 (3.0930)  Time: 6.253s,  655.09/s  (6.253s,  655.09/s)  LR: 9.222e-05  Data: 5.159 (5.159)
2025-05-01 16:23:05,456 - train - INFO - Train: 38 [  50/312 ( 16%)]  Loss:  3.105978 (3.0995)  Time: 0.525s, 7795.70/s  (1.204s, 3400.79/s)  LR: 9.222e-05  Data: 0.000 (0.414)
2025-05-01 16:24:03,130 - train - INFO - Train: 38 [ 100/312 ( 32%)]  Loss:  3.062468 (3.0871)  Time: 2.656s, 1542.31/s  (1.179s, 3473.56/s)  LR: 9.222e-05  Data: 0.000 (0.220)
2025-05-01 16:24:57,430 - train - INFO - Train: 38 [ 150/312 ( 48%)]  Loss:  3.069028 (3.0826)  Time: 0.525s, 7799.72/s  (1.148s, 3566.94/s)  LR: 9.222e-05  Data: 0.000 (0.147)
2025-05-01 16:25:54,221 - train - INFO - Train: 38 [ 200/312 ( 64%)]  Loss:  3.084341 (3.0830)  Time: 3.162s, 1295.26/s  (1.145s, 3576.66/s)  LR: 9.222e-05  Data: 0.000 (0.110)
2025-05-01 16:26:48,636 - train - INFO - Train: 38 [ 250/312 ( 80%)]  Loss:  3.056806 (3.0786)  Time: 0.763s, 5364.79/s  (1.134s, 3612.43/s)  LR: 9.222e-05  Data: 0.000 (0.088)
2025-05-01 16:27:44,770 - train - INFO - Train: 38 [ 300/312 ( 96%)]  Loss:  3.116521 (3.0840)  Time: 2.179s, 1879.70/s  (1.132s, 3618.38/s)  LR: 9.222e-05  Data: 0.000 (0.074)
2025-05-01 16:27:55,656 - train - INFO - Train: 38 [ 311/312 (100%)]  Loss:  3.056736 (3.0806)  Time: 0.523s, 7839.12/s  (1.127s, 3634.50/s)  LR: 9.222e-05  Data: 0.000 (0.071)
2025-05-01 16:28:02,158 - train - INFO - Test: [   0/48]  Time: 6.324 (6.324)  Loss:  1.2676 (1.2676)  Acc@1: 77.3438 (77.3438)  Acc@5: 91.7969 (91.7969)
2025-05-01 16:28:59,572 - train - INFO - Test: [  48/48]  Time: 2.040 (1.301)  Loss:  1.2656 (1.9299)  Acc@1: 77.0047 (59.8100)  Acc@5: 92.0991 (82.8440)
2025-05-01 16:29:06,348 - train - INFO - Train: 39 [   0/312 (  0%)]  Loss:  3.122782 (3.1228)  Time: 6.373s,  642.67/s  (6.373s,  642.67/s)  LR: 9.182e-05  Data: 5.849 (5.849)
2025-05-01 16:30:01,755 - train - INFO - Train: 39 [  50/312 ( 16%)]  Loss:  3.081506 (3.1021)  Time: 0.531s, 7708.25/s  (1.211s, 3381.41/s)  LR: 9.182e-05  Data: 0.000 (0.367)
2025-05-01 16:30:59,731 - train - INFO - Train: 39 [ 100/312 ( 32%)]  Loss:  3.047816 (3.0840)  Time: 2.933s, 1396.46/s  (1.186s, 3454.58/s)  LR: 9.182e-05  Data: 0.000 (0.185)
2025-05-01 16:31:54,598 - train - INFO - Train: 39 [ 150/312 ( 48%)]  Loss:  3.116791 (3.0922)  Time: 0.524s, 7815.64/s  (1.156s, 3541.97/s)  LR: 9.182e-05  Data: 0.000 (0.124)
2025-05-01 16:32:51,058 - train - INFO - Train: 39 [ 200/312 ( 64%)]  Loss:  3.122762 (3.0983)  Time: 2.779s, 1474.04/s  (1.150s, 3562.85/s)  LR: 9.182e-05  Data: 0.000 (0.093)
2025-05-01 16:33:46,315 - train - INFO - Train: 39 [ 250/312 ( 80%)]  Loss:  3.063233 (3.0925)  Time: 0.530s, 7721.37/s  (1.141s, 3590.56/s)  LR: 9.182e-05  Data: 0.000 (0.075)
2025-05-01 16:34:43,695 - train - INFO - Train: 39 [ 300/312 ( 96%)]  Loss:  3.167630 (3.1032)  Time: 2.858s, 1433.25/s  (1.142s, 3587.00/s)  LR: 9.182e-05  Data: 0.000 (0.062)
2025-05-01 16:34:53,979 - train - INFO - Train: 39 [ 311/312 (100%)]  Loss:  3.071564 (3.0993)  Time: 0.522s, 7845.15/s  (1.135s, 3610.08/s)  LR: 9.182e-05  Data: 0.000 (0.060)
2025-05-01 16:35:00,999 - train - INFO - Test: [   0/48]  Time: 6.850 (6.850)  Loss:  1.1787 (1.1787)  Acc@1: 74.7070 (74.7070)  Acc@5: 90.4297 (90.4297)
2025-05-01 16:35:57,404 - train - INFO - Test: [  48/48]  Time: 2.350 (1.291)  Loss:  1.0361 (1.8497)  Acc@1: 76.6509 (58.1480)  Acc@5: 91.2736 (82.0220)
2025-05-01 16:36:03,919 - train - INFO - Train: 40 [   0/312 (  0%)]  Loss:  3.073470 (3.0735)  Time: 6.203s,  660.37/s  (6.203s,  660.37/s)  LR: 9.141e-05  Data: 5.092 (5.092)
2025-05-01 16:36:59,259 - train - INFO - Train: 40 [  50/312 ( 16%)]  Loss:  3.115854 (3.0947)  Time: 0.527s, 7778.91/s  (1.207s, 3394.41/s)  LR: 9.141e-05  Data: 0.000 (0.488)
2025-05-01 16:37:55,583 - train - INFO - Train: 40 [ 100/312 ( 32%)]  Loss:  3.061071 (3.0835)  Time: 1.218s, 3362.70/s  (1.167s, 3509.94/s)  LR: 9.141e-05  Data: 0.000 (0.287)
2025-05-01 16:38:52,778 - train - INFO - Train: 40 [ 150/312 ( 48%)]  Loss:  3.108435 (3.0897)  Time: 0.527s, 7778.06/s  (1.159s, 3533.10/s)  LR: 9.141e-05  Data: 0.000 (0.192)
2025-05-01 16:39:47,932 - train - INFO - Train: 40 [ 200/312 ( 64%)]  Loss:  3.097044 (3.0912)  Time: 0.557s, 7359.28/s  (1.145s, 3576.27/s)  LR: 9.141e-05  Data: 0.000 (0.144)
2025-05-01 16:40:45,269 - train - INFO - Train: 40 [ 250/312 ( 80%)]  Loss:  3.016432 (3.0787)  Time: 0.526s, 7786.50/s  (1.146s, 3575.43/s)  LR: 9.141e-05  Data: 0.000 (0.116)
2025-05-01 16:41:40,219 - train - INFO - Train: 40 [ 300/312 ( 96%)]  Loss:  3.081861 (3.0792)  Time: 0.535s, 7650.84/s  (1.138s, 3599.77/s)  LR: 9.141e-05  Data: 0.000 (0.096)
2025-05-01 16:41:53,071 - train - INFO - Train: 40 [ 311/312 (100%)]  Loss:  3.094657 (3.0811)  Time: 0.528s, 7755.88/s  (1.139s, 3596.39/s)  LR: 9.141e-05  Data: 0.000 (0.093)
2025-05-01 16:41:59,606 - train - INFO - Test: [   0/48]  Time: 6.341 (6.341)  Loss:  1.2461 (1.2461)  Acc@1: 74.4141 (74.4141)  Acc@5: 92.2852 (92.2852)
2025-05-01 16:42:56,893 - train - INFO - Test: [  48/48]  Time: 2.324 (1.299)  Loss:  1.3066 (1.9142)  Acc@1: 74.6462 (58.5240)  Acc@5: 89.6226 (81.8060)
2025-05-01 16:43:03,434 - train - INFO - Train: 41 [   0/312 (  0%)]  Loss:  3.011524 (3.0115)  Time: 6.212s,  659.38/s  (6.212s,  659.38/s)  LR: 9.099e-05  Data: 5.679 (5.679)
2025-05-01 16:43:59,697 - train - INFO - Train: 41 [  50/312 ( 16%)]  Loss:  3.104961 (3.0582)  Time: 0.534s, 7667.23/s  (1.225s, 3343.79/s)  LR: 9.099e-05  Data: 0.000 (0.404)
2025-05-01 16:44:58,563 - train - INFO - Train: 41 [ 100/312 ( 32%)]  Loss:  3.067697 (3.0614)  Time: 3.096s, 1323.05/s  (1.201s, 3409.46/s)  LR: 9.099e-05  Data: 0.000 (0.206)
2025-05-01 16:45:53,602 - train - INFO - Train: 41 [ 150/312 ( 48%)]  Loss:  3.065784 (3.0625)  Time: 0.537s, 7629.08/s  (1.168s, 3506.74/s)  LR: 9.099e-05  Data: 0.000 (0.138)
2025-05-01 16:46:51,039 - train - INFO - Train: 41 [ 200/312 ( 64%)]  Loss:  3.058406 (3.0617)  Time: 2.764s, 1481.85/s  (1.163s, 3521.23/s)  LR: 9.099e-05  Data: 0.000 (0.104)
2025-05-01 16:47:45,671 - train - INFO - Train: 41 [ 250/312 ( 80%)]  Loss:  3.083231 (3.0653)  Time: 0.525s, 7808.27/s  (1.149s, 3564.33/s)  LR: 9.099e-05  Data: 0.000 (0.083)
2025-05-01 16:48:42,651 - train - INFO - Train: 41 [ 300/312 ( 96%)]  Loss:  3.112108 (3.0720)  Time: 2.994s, 1367.90/s  (1.148s, 3569.28/s)  LR: 9.099e-05  Data: 0.000 (0.069)
2025-05-01 16:48:53,207 - train - INFO - Train: 41 [ 311/312 (100%)]  Loss:  3.103849 (3.0759)  Time: 0.522s, 7844.30/s  (1.141s, 3590.02/s)  LR: 9.099e-05  Data: 0.000 (0.067)
2025-05-01 16:48:59,852 - train - INFO - Test: [   0/48]  Time: 6.466 (6.466)  Loss:  1.1875 (1.1875)  Acc@1: 75.2930 (75.2930)  Acc@5: 92.0898 (92.0898)
2025-05-01 16:49:57,018 - train - INFO - Test: [  48/48]  Time: 2.879 (1.299)  Loss:  1.0889 (1.8236)  Acc@1: 78.4198 (60.0120)  Acc@5: 91.1557 (82.8560)
2025-05-01 16:50:03,767 - train - INFO - Train: 42 [   0/312 (  0%)]  Loss:  3.087135 (3.0871)  Time: 6.372s,  642.80/s  (6.372s,  642.80/s)  LR: 9.056e-05  Data: 5.842 (5.842)
2025-05-01 16:50:59,395 - train - INFO - Train: 42 [  50/312 ( 16%)]  Loss:  3.085368 (3.0863)  Time: 0.526s, 7788.03/s  (1.216s, 3369.31/s)  LR: 9.056e-05  Data: 0.000 (0.435)
2025-05-01 16:51:57,408 - train - INFO - Train: 42 [ 100/312 ( 32%)]  Loss:  3.112537 (3.0950)  Time: 3.069s, 1334.80/s  (1.188s, 3447.15/s)  LR: 9.056e-05  Data: 0.000 (0.231)
2025-05-01 16:52:53,564 - train - INFO - Train: 42 [ 150/312 ( 48%)]  Loss:  3.062479 (3.0869)  Time: 0.525s, 7804.68/s  (1.167s, 3510.90/s)  LR: 9.056e-05  Data: 0.000 (0.155)
2025-05-01 16:53:51,782 - train - INFO - Train: 42 [ 200/312 ( 64%)]  Loss:  3.093314 (3.0882)  Time: 3.135s, 1306.68/s  (1.166s, 3512.63/s)  LR: 9.056e-05  Data: 0.000 (0.116)
2025-05-01 16:54:47,395 - train - INFO - Train: 42 [ 250/312 ( 80%)]  Loss:  3.124268 (3.0942)  Time: 0.526s, 7790.23/s  (1.155s, 3545.24/s)  LR: 9.056e-05  Data: 0.000 (0.093)
2025-05-01 16:55:45,605 - train - INFO - Train: 42 [ 300/312 ( 96%)]  Loss:  3.075457 (3.0915)  Time: 2.826s, 1449.21/s  (1.157s, 3540.75/s)  LR: 9.056e-05  Data: 0.000 (0.078)
2025-05-01 16:55:56,223 - train - INFO - Train: 42 [ 311/312 (100%)]  Loss:  3.144309 (3.0981)  Time: 0.523s, 7837.55/s  (1.150s, 3561.55/s)  LR: 9.056e-05  Data: 0.000 (0.075)
2025-05-01 16:56:02,539 - train - INFO - Test: [   0/48]  Time: 6.131 (6.131)  Loss:  0.9819 (0.9819)  Acc@1: 78.2227 (78.2227)  Acc@5: 93.0664 (93.0664)
2025-05-01 16:56:59,695 - train - INFO - Test: [  48/48]  Time: 2.741 (1.292)  Loss:  1.1104 (1.7812)  Acc@1: 76.7689 (59.8320)  Acc@5: 90.9198 (82.8760)
2025-05-01 16:57:06,208 - train - INFO - Train: 43 [   0/312 (  0%)]  Loss:  3.093181 (3.0932)  Time: 6.189s,  661.84/s  (6.189s,  661.84/s)  LR: 9.012e-05  Data: 5.296 (5.296)
2025-05-01 16:58:02,164 - train - INFO - Train: 43 [  50/312 ( 16%)]  Loss:  3.088665 (3.0909)  Time: 0.525s, 7795.74/s  (1.219s, 3361.48/s)  LR: 9.012e-05  Data: 0.000 (0.410)
2025-05-01 16:58:59,967 - train - INFO - Train: 43 [ 100/312 ( 32%)]  Loss:  3.086735 (3.0895)  Time: 2.864s, 1430.34/s  (1.188s, 3449.05/s)  LR: 9.012e-05  Data: 0.000 (0.217)
2025-05-01 16:59:55,864 - train - INFO - Train: 43 [ 150/312 ( 48%)]  Loss:  3.125882 (3.0986)  Time: 0.526s, 7792.09/s  (1.165s, 3517.37/s)  LR: 9.012e-05  Data: 0.000 (0.145)
2025-05-01 17:00:52,982 - train - INFO - Train: 43 [ 200/312 ( 64%)]  Loss:  3.101345 (3.0992)  Time: 2.764s, 1481.92/s  (1.159s, 3534.10/s)  LR: 9.012e-05  Data: 0.000 (0.109)
2025-05-01 17:01:46,926 - train - INFO - Train: 43 [ 250/312 ( 80%)]  Loss:  3.109161 (3.1008)  Time: 0.528s, 7757.97/s  (1.143s, 3583.46/s)  LR: 9.012e-05  Data: 0.000 (0.087)
2025-05-01 17:02:43,571 - train - INFO - Train: 43 [ 300/312 ( 96%)]  Loss:  3.089116 (3.0992)  Time: 2.845s, 1439.62/s  (1.141s, 3588.76/s)  LR: 9.012e-05  Data: 0.000 (0.073)
2025-05-01 17:02:53,984 - train - INFO - Train: 43 [ 311/312 (100%)]  Loss:  3.096598 (3.0988)  Time: 0.522s, 7840.43/s  (1.134s, 3610.47/s)  LR: 9.012e-05  Data: 0.000 (0.070)
2025-05-01 17:03:00,575 - train - INFO - Test: [   0/48]  Time: 6.423 (6.423)  Loss:  1.2979 (1.2979)  Acc@1: 72.9492 (72.9492)  Acc@5: 90.4297 (90.4297)
2025-05-01 17:03:57,130 - train - INFO - Test: [  48/48]  Time: 2.345 (1.285)  Loss:  1.2197 (1.9055)  Acc@1: 76.2972 (59.3520)  Acc@5: 89.1509 (82.4480)
2025-05-01 17:04:03,834 - train - INFO - Train: 44 [   0/312 (  0%)]  Loss:  3.099250 (3.0992)  Time: 6.355s,  644.55/s  (6.355s,  644.55/s)  LR: 8.967e-05  Data: 5.815 (5.815)
2025-05-01 17:04:58,864 - train - INFO - Train: 44 [  50/312 ( 16%)]  Loss:  3.067908 (3.0836)  Time: 0.525s, 7809.28/s  (1.204s, 3403.19/s)  LR: 8.967e-05  Data: 0.000 (0.576)
2025-05-01 17:05:56,345 - train - INFO - Train: 44 [ 100/312 ( 32%)]  Loss:  3.162740 (3.1100)  Time: 2.709s, 1512.25/s  (1.177s, 3480.50/s)  LR: 8.967e-05  Data: 0.000 (0.352)
2025-05-01 17:06:50,737 - train - INFO - Train: 44 [ 150/312 ( 48%)]  Loss:  3.157608 (3.1219)  Time: 0.526s, 7792.55/s  (1.147s, 3569.95/s)  LR: 8.967e-05  Data: 0.000 (0.237)
2025-05-01 17:07:48,016 - train - INFO - Train: 44 [ 200/312 ( 64%)]  Loss:  3.112802 (3.1201)  Time: 2.929s, 1398.29/s  (1.147s, 3571.33/s)  LR: 8.967e-05  Data: 0.000 (0.178)
2025-05-01 17:08:42,575 - train - INFO - Train: 44 [ 250/312 ( 80%)]  Loss:  3.082881 (3.1139)  Time: 0.525s, 7804.78/s  (1.136s, 3606.26/s)  LR: 8.967e-05  Data: 0.000 (0.143)
2025-05-01 17:09:40,232 - train - INFO - Train: 44 [ 300/312 ( 96%)]  Loss:  3.094149 (3.1110)  Time: 1.443s, 2837.87/s  (1.139s, 3597.16/s)  LR: 8.967e-05  Data: 0.000 (0.119)
2025-05-01 17:09:52,013 - train - INFO - Train: 44 [ 311/312 (100%)]  Loss:  3.073788 (3.1064)  Time: 2.104s, 1946.75/s  (1.136s, 3604.76/s)  LR: 8.967e-05  Data: 0.000 (0.115)
2025-05-01 17:09:58,414 - train - INFO - Test: [   0/48]  Time: 6.224 (6.224)  Loss:  1.1787 (1.1787)  Acc@1: 74.6094 (74.6094)  Acc@5: 91.6016 (91.6016)
2025-05-01 17:10:54,915 - train - INFO - Test: [  48/48]  Time: 1.957 (1.280)  Loss:  1.1230 (1.7924)  Acc@1: 77.0047 (60.0080)  Acc@5: 90.6840 (83.1700)
2025-05-01 17:11:01,368 - train - INFO - Train: 45 [   0/312 (  0%)]  Loss:  3.114327 (3.1143)  Time: 6.108s,  670.56/s  (6.108s,  670.56/s)  LR: 8.922e-05  Data: 5.575 (5.575)
2025-05-01 17:11:55,798 - train - INFO - Train: 45 [  50/312 ( 16%)]  Loss:  3.058588 (3.0865)  Time: 0.532s, 7699.14/s  (1.187s, 3450.84/s)  LR: 8.922e-05  Data: 0.000 (0.625)
2025-05-01 17:12:52,944 - train - INFO - Train: 45 [ 100/312 ( 32%)]  Loss:  3.053747 (3.0756)  Time: 2.944s, 1391.37/s  (1.165s, 3515.44/s)  LR: 8.922e-05  Data: 0.383 (0.478)
2025-05-01 17:13:48,563 - train - INFO - Train: 45 [ 150/312 ( 48%)]  Loss:  3.152236 (3.0947)  Time: 0.531s, 7707.44/s  (1.148s, 3568.98/s)  LR: 8.922e-05  Data: 0.000 (0.320)
2025-05-01 17:14:45,746 - train - INFO - Train: 45 [ 200/312 ( 64%)]  Loss:  3.026140 (3.0810)  Time: 2.738s, 1496.04/s  (1.147s, 3572.11/s)  LR: 8.922e-05  Data: 0.000 (0.241)
2025-05-01 17:15:40,762 - train - INFO - Train: 45 [ 250/312 ( 80%)]  Loss:  3.049962 (3.0758)  Time: 0.526s, 7789.78/s  (1.137s, 3601.11/s)  LR: 8.922e-05  Data: 0.000 (0.193)
2025-05-01 17:16:37,711 - train - INFO - Train: 45 [ 300/312 ( 96%)]  Loss:  3.051763 (3.0724)  Time: 2.918s, 1403.55/s  (1.138s, 3600.31/s)  LR: 8.922e-05  Data: 0.000 (0.161)
2025-05-01 17:16:47,977 - train - INFO - Train: 45 [ 311/312 (100%)]  Loss:  3.086654 (3.0742)  Time: 0.523s, 7827.52/s  (1.130s, 3623.26/s)  LR: 8.922e-05  Data: 0.000 (0.155)
2025-05-01 17:16:54,555 - train - INFO - Test: [   0/48]  Time: 6.380 (6.380)  Loss:  1.3027 (1.3027)  Acc@1: 77.2461 (77.2461)  Acc@5: 92.4805 (92.4805)
2025-05-01 17:17:52,161 - train - INFO - Test: [  48/48]  Time: 2.283 (1.306)  Loss:  1.3867 (2.0895)  Acc@1: 75.1179 (58.1740)  Acc@5: 91.6274 (81.6240)
2025-05-01 17:17:59,042 - train - INFO - Train: 46 [   0/312 (  0%)]  Loss:  3.077154 (3.0772)  Time: 6.477s,  632.38/s  (6.477s,  632.38/s)  LR: 8.875e-05  Data: 5.951 (5.951)
2025-05-01 17:18:54,936 - train - INFO - Train: 46 [  50/312 ( 16%)]  Loss:  3.097327 (3.0872)  Time: 0.526s, 7790.72/s  (1.223s, 3349.30/s)  LR: 8.875e-05  Data: 0.000 (0.697)
2025-05-01 17:19:52,475 - train - INFO - Train: 46 [ 100/312 ( 32%)]  Loss:  3.089032 (3.0878)  Time: 2.935s, 1395.50/s  (1.187s, 3450.13/s)  LR: 8.875e-05  Data: 2.420 (0.661)
2025-05-01 17:20:47,069 - train - INFO - Train: 46 [ 150/312 ( 48%)]  Loss:  3.106941 (3.0926)  Time: 0.527s, 7768.74/s  (1.156s, 3544.40/s)  LR: 8.875e-05  Data: 0.000 (0.629)
2025-05-01 17:21:44,202 - train - INFO - Train: 46 [ 200/312 ( 64%)]  Loss:  3.141044 (3.1023)  Time: 2.862s, 1431.27/s  (1.152s, 3554.35/s)  LR: 8.875e-05  Data: 2.347 (0.626)
2025-05-01 17:22:39,221 - train - INFO - Train: 46 [ 250/312 ( 80%)]  Loss:  3.086907 (3.0997)  Time: 0.527s, 7769.73/s  (1.142s, 3586.61/s)  LR: 8.875e-05  Data: 0.000 (0.616)
2025-05-01 17:23:35,814 - train - INFO - Train: 46 [ 300/312 ( 96%)]  Loss:  3.104816 (3.1005)  Time: 2.100s, 1950.73/s  (1.140s, 3591.94/s)  LR: 8.875e-05  Data: 1.586 (0.615)
2025-05-01 17:23:47,128 - train - INFO - Train: 46 [ 311/312 (100%)]  Loss:  3.149848 (3.1066)  Time: 0.532s, 7697.01/s  (1.136s, 3604.40/s)  LR: 8.875e-05  Data: 0.000 (0.611)
2025-05-01 17:23:53,537 - train - INFO - Test: [   0/48]  Time: 6.233 (6.233)  Loss:  1.4326 (1.4326)  Acc@1: 74.1211 (74.1211)  Acc@5: 90.0391 (90.0391)
2025-05-01 17:24:50,187 - train - INFO - Test: [  48/48]  Time: 2.393 (1.283)  Loss:  1.5029 (2.0180)  Acc@1: 72.7594 (58.0320)  Acc@5: 88.9151 (81.7640)
2025-05-01 17:24:56,673 - train - INFO - Train: 47 [   0/312 (  0%)]  Loss:  3.117353 (3.1174)  Time: 6.158s,  665.13/s  (6.158s,  665.13/s)  LR: 8.828e-05  Data: 4.955 (4.955)
2025-05-01 17:25:52,629 - train - INFO - Train: 47 [  50/312 ( 16%)]  Loss:  3.136028 (3.1267)  Time: 1.106s, 3703.63/s  (1.218s, 3363.27/s)  LR: 8.828e-05  Data: 0.000 (0.392)
2025-05-01 17:26:50,019 - train - INFO - Train: 47 [ 100/312 ( 32%)]  Loss:  3.101891 (3.1184)  Time: 1.938s, 2113.54/s  (1.183s, 3461.94/s)  LR: 8.828e-05  Data: 0.000 (0.206)
2025-05-01 17:27:45,888 - train - INFO - Train: 47 [ 150/312 ( 48%)]  Loss:  3.141936 (3.1243)  Time: 1.130s, 3624.84/s  (1.161s, 3526.89/s)  LR: 8.828e-05  Data: 0.000 (0.138)
2025-05-01 17:28:42,122 - train - INFO - Train: 47 [ 200/312 ( 64%)]  Loss:  3.106606 (3.1208)  Time: 2.161s, 1895.44/s  (1.152s, 3554.88/s)  LR: 8.828e-05  Data: 0.000 (0.103)
2025-05-01 17:29:37,659 - train - INFO - Train: 47 [ 250/312 ( 80%)]  Loss:  3.154241 (3.1263)  Time: 1.209s, 3389.25/s  (1.144s, 3580.58/s)  LR: 8.828e-05  Data: 0.000 (0.083)
2025-05-01 17:30:35,124 - train - INFO - Train: 47 [ 300/312 ( 96%)]  Loss:  3.117730 (3.1251)  Time: 2.685s, 1525.60/s  (1.145s, 3577.81/s)  LR: 8.828e-05  Data: 0.000 (0.069)
2025-05-01 17:30:45,521 - train - INFO - Train: 47 [ 311/312 (100%)]  Loss:  3.105537 (3.1227)  Time: 0.530s, 7733.77/s  (1.138s, 3599.96/s)  LR: 8.828e-05  Data: 0.000 (0.067)
2025-05-01 17:30:52,158 - train - INFO - Test: [   0/48]  Time: 6.451 (6.451)  Loss:  1.4961 (1.4961)  Acc@1: 72.5586 (72.5586)  Acc@5: 89.8438 (89.8438)
2025-05-01 17:31:49,452 - train - INFO - Test: [  48/48]  Time: 1.648 (1.301)  Loss:  1.2969 (2.0043)  Acc@1: 75.4717 (58.3420)  Acc@5: 91.3915 (81.7660)
2025-05-01 17:31:56,339 - train - INFO - Train: 48 [   0/312 (  0%)]  Loss:  3.075862 (3.0759)  Time: 6.469s,  633.17/s  (6.469s,  633.17/s)  LR: 8.780e-05  Data: 5.248 (5.248)
2025-05-01 17:32:52,524 - train - INFO - Train: 48 [  50/312 ( 16%)]  Loss:  3.083057 (3.0795)  Time: 0.526s, 7793.96/s  (1.228s, 3334.20/s)  LR: 8.780e-05  Data: 0.000 (0.654)
2025-05-01 17:33:50,229 - train - INFO - Train: 48 [ 100/312 ( 32%)]  Loss:  3.098741 (3.0859)  Time: 2.927s, 1399.18/s  (1.192s, 3437.26/s)  LR: 8.780e-05  Data: 0.987 (0.548)
2025-05-01 17:34:45,388 - train - INFO - Train: 48 [ 150/312 ( 48%)]  Loss:  3.109092 (3.0917)  Time: 0.526s, 7783.76/s  (1.162s, 3523.91/s)  LR: 8.780e-05  Data: 0.000 (0.449)
2025-05-01 17:35:42,958 - train - INFO - Train: 48 [ 200/312 ( 64%)]  Loss:  3.069723 (3.0873)  Time: 2.768s, 1479.87/s  (1.160s, 3532.20/s)  LR: 8.780e-05  Data: 0.000 (0.351)
2025-05-01 17:36:38,810 - train - INFO - Train: 48 [ 250/312 ( 80%)]  Loss:  3.110390 (3.0911)  Time: 0.533s, 7688.78/s  (1.151s, 3558.24/s)  LR: 8.780e-05  Data: 0.000 (0.281)
2025-05-01 17:37:35,689 - train - INFO - Train: 48 [ 300/312 ( 96%)]  Loss:  3.078547 (3.0893)  Time: 2.852s, 1436.17/s  (1.149s, 3565.23/s)  LR: 8.780e-05  Data: 0.000 (0.234)
2025-05-01 17:37:46,303 - train - INFO - Train: 48 [ 311/312 (100%)]  Loss:  3.052735 (3.0848)  Time: 0.545s, 7521.53/s  (1.142s, 3585.51/s)  LR: 8.780e-05  Data: 0.000 (0.226)
2025-05-01 17:37:52,791 - train - INFO - Test: [   0/48]  Time: 6.296 (6.296)  Loss:  1.1729 (1.1729)  Acc@1: 76.1719 (76.1719)  Acc@5: 92.4805 (92.4805)
2025-05-01 17:38:50,010 - train - INFO - Test: [  48/48]  Time: 2.409 (1.296)  Loss:  1.2715 (1.9100)  Acc@1: 74.0566 (58.7140)  Acc@5: 89.2689 (81.9040)
2025-05-01 17:38:56,212 - train - INFO - Train: 49 [   0/312 (  0%)]  Loss:  3.043598 (3.0436)  Time: 5.840s,  701.38/s  (5.840s,  701.38/s)  LR: 8.732e-05  Data: 5.030 (5.030)
2025-05-01 17:39:51,389 - train - INFO - Train: 49 [  50/312 ( 16%)]  Loss:  3.076723 (3.0602)  Time: 0.526s, 7785.89/s  (1.196s, 3423.65/s)  LR: 8.732e-05  Data: 0.000 (0.598)
2025-05-01 17:40:48,239 - train - INFO - Train: 49 [ 100/312 ( 32%)]  Loss:  3.056822 (3.0590)  Time: 2.779s, 1473.79/s  (1.167s, 3509.96/s)  LR: 8.732e-05  Data: 0.000 (0.378)
2025-05-01 17:41:43,573 - train - INFO - Train: 49 [ 150/312 ( 48%)]  Loss:  3.112514 (3.0724)  Time: 0.526s, 7790.01/s  (1.147s, 3571.09/s)  LR: 8.732e-05  Data: 0.000 (0.253)
2025-05-01 17:42:39,789 - train - INFO - Train: 49 [ 200/312 ( 64%)]  Loss:  3.103986 (3.0787)  Time: 1.722s, 2379.31/s  (1.141s, 3588.76/s)  LR: 8.732e-05  Data: 0.000 (0.190)
2025-05-01 17:43:36,454 - train - INFO - Train: 49 [ 250/312 ( 80%)]  Loss:  3.108678 (3.0837)  Time: 0.526s, 7792.17/s  (1.140s, 3593.81/s)  LR: 8.732e-05  Data: 0.000 (0.152)
2025-05-01 17:44:31,398 - train - INFO - Train: 49 [ 300/312 ( 96%)]  Loss:  3.080420 (3.0832)  Time: 0.525s, 7800.69/s  (1.133s, 3615.35/s)  LR: 8.732e-05  Data: 0.000 (0.127)
2025-05-01 17:44:44,411 - train - INFO - Train: 49 [ 311/312 (100%)]  Loss:  3.139103 (3.0902)  Time: 0.528s, 7755.74/s  (1.135s, 3609.75/s)  LR: 8.732e-05  Data: 0.000 (0.122)
2025-05-01 17:44:51,169 - train - INFO - Test: [   0/48]  Time: 6.569 (6.569)  Loss:  1.1152 (1.1152)  Acc@1: 77.0508 (77.0508)  Acc@5: 91.8945 (91.8945)
2025-05-01 17:45:47,290 - train - INFO - Test: [  48/48]  Time: 2.242 (1.279)  Loss:  1.2305 (1.8081)  Acc@1: 71.9340 (59.4440)  Acc@5: 89.8585 (82.6420)
2025-05-01 17:45:53,681 - train - INFO - Train: 50 [   0/312 (  0%)]  Loss:  3.098970 (3.0990)  Time: 6.059s,  675.99/s  (6.059s,  675.99/s)  LR: 8.682e-05  Data: 5.350 (5.350)
2025-05-01 17:46:49,170 - train - INFO - Train: 50 [  50/312 ( 16%)]  Loss:  3.100477 (3.0997)  Time: 0.524s, 7818.09/s  (1.207s, 3394.09/s)  LR: 8.682e-05  Data: 0.000 (0.663)
2025-05-01 17:47:47,327 - train - INFO - Train: 50 [ 100/312 ( 32%)]  Loss:  3.131987 (3.1105)  Time: 3.029s, 1352.37/s  (1.185s, 3456.09/s)  LR: 8.682e-05  Data: 0.735 (0.564)
2025-05-01 17:48:42,755 - train - INFO - Train: 50 [ 150/312 ( 48%)]  Loss:  3.054300 (3.0964)  Time: 0.527s, 7775.73/s  (1.160s, 3531.72/s)  LR: 8.682e-05  Data: 0.000 (0.388)
2025-05-01 17:49:41,194 - train - INFO - Train: 50 [ 200/312 ( 64%)]  Loss:  3.128857 (3.1029)  Time: 3.088s, 1326.34/s  (1.162s, 3524.98/s)  LR: 8.682e-05  Data: 0.000 (0.292)
2025-05-01 17:50:36,547 - train - INFO - Train: 50 [ 250/312 ( 80%)]  Loss:  3.111625 (3.1044)  Time: 0.537s, 7634.62/s  (1.151s, 3558.50/s)  LR: 8.682e-05  Data: 0.000 (0.234)
2025-05-01 17:51:33,305 - train - INFO - Train: 50 [ 300/312 ( 96%)]  Loss:  3.115548 (3.1060)  Time: 2.787s, 1469.59/s  (1.148s, 3566.71/s)  LR: 8.682e-05  Data: 0.000 (0.195)
2025-05-01 17:51:43,414 - train - INFO - Train: 50 [ 311/312 (100%)]  Loss:  3.116367 (3.1073)  Time: 0.523s, 7829.20/s  (1.140s, 3592.02/s)  LR: 8.682e-05  Data: 0.000 (0.188)
2025-05-01 17:51:49,625 - train - INFO - Test: [   0/48]  Time: 6.038 (6.038)  Loss:  1.1670 (1.1670)  Acc@1: 73.2422 (73.2422)  Acc@5: 91.9922 (91.9922)
2025-05-01 17:52:46,659 - train - INFO - Test: [  48/48]  Time: 2.335 (1.287)  Loss:  1.1572 (1.8228)  Acc@1: 74.5283 (59.2340)  Acc@5: 89.7406 (82.3220)
2025-05-01 17:52:52,861 - train - INFO - Train: 51 [   0/312 (  0%)]  Loss:  3.073497 (3.0735)  Time: 5.875s,  697.19/s  (5.875s,  697.19/s)  LR: 8.632e-05  Data: 5.227 (5.227)
2025-05-01 17:53:49,150 - train - INFO - Train: 51 [  50/312 ( 16%)]  Loss:  3.138446 (3.1060)  Time: 0.538s, 7620.36/s  (1.219s, 3360.47/s)  LR: 8.632e-05  Data: 0.000 (0.687)
2025-05-01 17:54:46,959 - train - INFO - Train: 51 [ 100/312 ( 32%)]  Loss:  3.115094 (3.1090)  Time: 2.848s, 1438.34/s  (1.188s, 3448.32/s)  LR: 8.632e-05  Data: 2.322 (0.659)
2025-05-01 17:55:41,804 - train - INFO - Train: 51 [ 150/312 ( 48%)]  Loss:  3.136858 (3.1160)  Time: 0.530s, 7723.00/s  (1.158s, 3538.06/s)  LR: 8.632e-05  Data: 0.000 (0.629)
2025-05-01 17:56:38,121 - train - INFO - Train: 51 [ 200/312 ( 64%)]  Loss:  3.115483 (3.1159)  Time: 2.946s, 1390.20/s  (1.150s, 3562.09/s)  LR: 8.632e-05  Data: 2.422 (0.622)
2025-05-01 17:57:32,943 - train - INFO - Train: 51 [ 250/312 ( 80%)]  Loss:  3.066939 (3.1077)  Time: 0.527s, 7775.41/s  (1.139s, 3595.40/s)  LR: 8.632e-05  Data: 0.000 (0.612)
2025-05-01 17:58:29,628 - train - INFO - Train: 51 [ 300/312 ( 96%)]  Loss:  3.084004 (3.1043)  Time: 2.834s, 1445.45/s  (1.138s, 3598.32/s)  LR: 8.632e-05  Data: 2.319 (0.611)
2025-05-01 17:58:40,251 - train - INFO - Train: 51 [ 311/312 (100%)]  Loss:  3.136951 (3.1084)  Time: 0.522s, 7839.71/s  (1.132s, 3617.66/s)  LR: 8.632e-05  Data: 0.000 (0.605)
2025-05-01 17:58:46,694 - train - INFO - Test: [   0/48]  Time: 6.248 (6.248)  Loss:  1.3652 (1.3652)  Acc@1: 75.1953 (75.1953)  Acc@5: 91.0156 (91.0156)
2025-05-01 17:59:43,841 - train - INFO - Test: [  48/48]  Time: 2.230 (1.294)  Loss:  1.2871 (1.9737)  Acc@1: 75.0000 (58.7600)  Acc@5: 91.3915 (82.1920)
2025-05-01 17:59:50,832 - train - INFO - Train: 52 [   0/312 (  0%)]  Loss:  3.040499 (3.0405)  Time: 6.323s,  647.82/s  (6.323s,  647.82/s)  LR: 8.580e-05  Data: 5.785 (5.785)
2025-05-01 18:00:46,572 - train - INFO - Train: 52 [  50/312 ( 16%)]  Loss:  3.057549 (3.0490)  Time: 0.531s, 7719.47/s  (1.217s, 3365.94/s)  LR: 8.580e-05  Data: 0.000 (0.689)
2025-05-01 18:01:45,121 - train - INFO - Train: 52 [ 100/312 ( 32%)]  Loss:  3.098011 (3.0654)  Time: 2.929s, 1398.45/s  (1.194s, 3430.04/s)  LR: 8.580e-05  Data: 0.534 (0.545)
2025-05-01 18:02:40,335 - train - INFO - Train: 52 [ 150/312 ( 48%)]  Loss:  3.083779 (3.0700)  Time: 0.535s, 7659.88/s  (1.164s, 3517.73/s)  LR: 8.580e-05  Data: 0.000 (0.371)
2025-05-01 18:03:38,436 - train - INFO - Train: 52 [ 200/312 ( 64%)]  Loss:  3.125336 (3.0810)  Time: 2.888s, 1418.10/s  (1.164s, 3519.53/s)  LR: 8.580e-05  Data: 0.000 (0.279)
2025-05-01 18:04:34,599 - train - INFO - Train: 52 [ 250/312 ( 80%)]  Loss:  3.104379 (3.0849)  Time: 0.531s, 7718.33/s  (1.156s, 3544.14/s)  LR: 8.580e-05  Data: 0.000 (0.223)
2025-05-01 18:05:33,221 - train - INFO - Train: 52 [ 300/312 ( 96%)]  Loss:  3.103582 (3.0876)  Time: 2.992s, 1368.90/s  (1.158s, 3535.67/s)  LR: 8.580e-05  Data: 0.000 (0.186)
2025-05-01 18:05:43,555 - train - INFO - Train: 52 [ 311/312 (100%)]  Loss:  3.094724 (3.0885)  Time: 0.522s, 7849.30/s  (1.151s, 3559.40/s)  LR: 8.580e-05  Data: 0.000 (0.180)
2025-05-01 18:05:49,926 - train - INFO - Test: [   0/48]  Time: 6.192 (6.192)  Loss:  1.2295 (1.2295)  Acc@1: 75.2930 (75.2930)  Acc@5: 91.6016 (91.6016)
2025-05-01 18:06:47,683 - train - INFO - Test: [  48/48]  Time: 2.646 (1.305)  Loss:  1.3135 (1.9293)  Acc@1: 75.9434 (58.5840)  Acc@5: 90.5660 (82.1440)
2025-05-01 18:06:54,021 - train - INFO - Train: 53 [   0/312 (  0%)]  Loss:  3.103703 (3.1037)  Time: 6.014s,  681.03/s  (6.014s,  681.03/s)  LR: 8.529e-05  Data: 5.224 (5.224)
2025-05-01 18:07:50,416 - train - INFO - Train: 53 [  50/312 ( 16%)]  Loss:  3.074444 (3.0891)  Time: 0.531s, 7707.49/s  (1.224s, 3347.29/s)  LR: 8.529e-05  Data: 0.000 (0.320)
2025-05-01 18:08:48,172 - train - INFO - Train: 53 [ 100/312 ( 32%)]  Loss:  3.052862 (3.0770)  Time: 3.677s, 1113.96/s  (1.190s, 3442.81/s)  LR: 8.529e-05  Data: 0.000 (0.165)
2025-05-01 18:09:42,455 - train - INFO - Train: 53 [ 150/312 ( 48%)]  Loss:  3.038944 (3.0675)  Time: 0.533s, 7683.75/s  (1.155s, 3545.52/s)  LR: 8.529e-05  Data: 0.000 (0.110)
2025-05-01 18:10:40,019 - train - INFO - Train: 53 [ 200/312 ( 64%)]  Loss:  3.086884 (3.0714)  Time: 2.820s, 1452.73/s  (1.154s, 3548.64/s)  LR: 8.529e-05  Data: 0.000 (0.083)
2025-05-01 18:11:35,014 - train - INFO - Train: 53 [ 250/312 ( 80%)]  Loss:  3.071803 (3.0714)  Time: 0.532s, 7698.17/s  (1.143s, 3582.30/s)  LR: 8.529e-05  Data: 0.000 (0.066)
2025-05-01 18:12:31,200 - train - INFO - Train: 53 [ 300/312 ( 96%)]  Loss:  3.088732 (3.0739)  Time: 2.578s, 1588.78/s  (1.140s, 3592.59/s)  LR: 8.529e-05  Data: 0.000 (0.055)
2025-05-01 18:12:41,801 - train - INFO - Train: 53 [ 311/312 (100%)]  Loss:  3.099976 (3.0772)  Time: 0.529s, 7742.93/s  (1.134s, 3612.32/s)  LR: 8.529e-05  Data: 0.000 (0.053)
2025-05-01 18:12:48,135 - train - INFO - Test: [   0/48]  Time: 6.141 (6.141)  Loss:  1.1221 (1.1221)  Acc@1: 76.7578 (76.7578)  Acc@5: 93.3594 (93.3594)
2025-05-01 18:13:44,713 - train - INFO - Test: [  48/48]  Time: 2.138 (1.280)  Loss:  1.2041 (1.8606)  Acc@1: 76.5330 (59.5420)  Acc@5: 91.1557 (82.6380)
2025-05-01 18:13:51,287 - train - INFO - Train: 54 [   0/312 (  0%)]  Loss:  3.087525 (3.0875)  Time: 6.237s,  656.75/s  (6.237s,  656.75/s)  LR: 8.476e-05  Data: 5.192 (5.192)
2025-05-01 18:14:46,685 - train - INFO - Train: 54 [  50/312 ( 16%)]  Loss:  3.069474 (3.0785)  Time: 0.532s, 7697.44/s  (1.208s, 3389.41/s)  LR: 8.476e-05  Data: 0.000 (0.657)
2025-05-01 18:15:43,895 - train - INFO - Train: 54 [ 100/312 ( 32%)]  Loss:  3.012820 (3.0566)  Time: 3.217s, 1273.19/s  (1.177s, 3481.18/s)  LR: 8.476e-05  Data: 2.695 (0.638)
2025-05-01 18:16:38,595 - train - INFO - Train: 54 [ 150/312 ( 48%)]  Loss:  3.097473 (3.0668)  Time: 0.533s, 7685.76/s  (1.149s, 3564.07/s)  LR: 8.476e-05  Data: 0.000 (0.615)
2025-05-01 18:17:35,190 - train - INFO - Train: 54 [ 200/312 ( 64%)]  Loss:  3.097998 (3.0731)  Time: 2.797s, 1464.49/s  (1.145s, 3577.58/s)  LR: 8.476e-05  Data: 2.274 (0.612)
2025-05-01 18:18:29,430 - train - INFO - Train: 54 [ 250/312 ( 80%)]  Loss:  3.012614 (3.0630)  Time: 0.532s, 7692.67/s  (1.133s, 3615.41/s)  LR: 8.476e-05  Data: 0.001 (0.602)
2025-05-01 18:19:25,869 - train - INFO - Train: 54 [ 300/312 ( 96%)]  Loss:  3.093978 (3.0674)  Time: 2.880s, 1422.26/s  (1.132s, 3617.66/s)  LR: 8.476e-05  Data: 2.358 (0.602)
2025-05-01 18:19:36,491 - train - INFO - Train: 54 [ 311/312 (100%)]  Loss:  3.084091 (3.0695)  Time: 0.533s, 7681.79/s  (1.126s, 3636.53/s)  LR: 8.476e-05  Data: 0.000 (0.596)
2025-05-01 18:19:43,130 - train - INFO - Test: [   0/48]  Time: 6.456 (6.456)  Loss:  1.1055 (1.1055)  Acc@1: 77.5391 (77.5391)  Acc@5: 92.4805 (92.4805)
2025-05-01 18:20:38,676 - train - INFO - Test: [  48/48]  Time: 1.767 (1.265)  Loss:  1.2773 (1.8929)  Acc@1: 76.0613 (58.7920)  Acc@5: 89.9764 (82.5340)
2025-05-01 18:20:45,285 - train - INFO - Train: 55 [   0/312 (  0%)]  Loss:  3.092496 (3.0925)  Time: 6.285s,  651.69/s  (6.285s,  651.69/s)  LR: 8.423e-05  Data: 5.061 (5.061)
2025-05-01 18:21:40,134 - train - INFO - Train: 55 [  50/312 ( 16%)]  Loss:  3.056426 (3.0745)  Time: 0.544s, 7527.97/s  (1.199s, 3417.39/s)  LR: 8.423e-05  Data: 0.000 (0.578)
2025-05-01 18:22:37,744 - train - INFO - Train: 55 [ 100/312 ( 32%)]  Loss:  3.079257 (3.0761)  Time: 3.101s, 1320.66/s  (1.176s, 3484.18/s)  LR: 8.423e-05  Data: 1.761 (0.541)
2025-05-01 18:23:32,107 - train - INFO - Train: 55 [ 150/312 ( 48%)]  Loss:  3.133849 (3.0905)  Time: 0.524s, 7811.72/s  (1.146s, 3573.11/s)  LR: 8.423e-05  Data: 0.000 (0.466)
2025-05-01 18:24:29,025 - train - INFO - Train: 55 [ 200/312 ( 64%)]  Loss:  3.081832 (3.0888)  Time: 1.343s, 3049.06/s  (1.144s, 3579.34/s)  LR: 8.423e-05  Data: 0.000 (0.379)
2025-05-01 18:25:23,865 - train - INFO - Train: 55 [ 250/312 ( 80%)]  Loss:  3.049890 (3.0823)  Time: 0.532s, 7698.80/s  (1.135s, 3609.23/s)  LR: 8.423e-05  Data: 0.000 (0.305)
2025-05-01 18:26:21,329 - train - INFO - Train: 55 [ 300/312 ( 96%)]  Loss:  3.112968 (3.0867)  Time: 0.526s, 7789.72/s  (1.137s, 3601.65/s)  LR: 8.423e-05  Data: 0.000 (0.254)
2025-05-01 18:26:34,258 - train - INFO - Train: 55 [ 311/312 (100%)]  Loss:  3.119750 (3.0908)  Time: 2.887s, 1418.92/s  (1.139s, 3597.40/s)  LR: 8.423e-05  Data: 0.000 (0.245)
2025-05-01 18:26:41,022 - train - INFO - Test: [   0/48]  Time: 6.585 (6.585)  Loss:  1.2432 (1.2432)  Acc@1: 73.8281 (73.8281)  Acc@5: 90.5273 (90.5273)
2025-05-01 18:27:37,230 - train - INFO - Test: [  48/48]  Time: 1.232 (1.281)  Loss:  1.1504 (1.8511)  Acc@1: 77.0047 (59.1780)  Acc@5: 91.1557 (82.2420)
2025-05-01 18:27:43,433 - train - INFO - Train: 56 [   0/312 (  0%)]  Loss:  3.042556 (3.0426)  Time: 5.836s,  701.89/s  (5.836s,  701.89/s)  LR: 8.368e-05  Data: 5.203 (5.203)
2025-05-01 18:28:39,009 - train - INFO - Train: 56 [  50/312 ( 16%)]  Loss:  3.086503 (3.0645)  Time: 0.525s, 7808.08/s  (1.204s, 3401.64/s)  LR: 8.368e-05  Data: 0.000 (0.675)
2025-05-01 18:29:35,911 - train - INFO - Train: 56 [ 100/312 ( 32%)]  Loss:  3.096230 (3.0751)  Time: 3.088s, 1326.47/s  (1.171s, 3496.72/s)  LR: 8.368e-05  Data: 2.573 (0.644)
2025-05-01 18:30:31,238 - train - INFO - Train: 56 [ 150/312 ( 48%)]  Loss:  3.098081 (3.0808)  Time: 0.527s, 7777.91/s  (1.150s, 3562.03/s)  LR: 8.368e-05  Data: 0.000 (0.623)
2025-05-01 18:31:28,179 - train - INFO - Train: 56 [ 200/312 ( 64%)]  Loss:  3.095120 (3.0837)  Time: 2.343s, 1747.82/s  (1.147s, 3570.72/s)  LR: 8.368e-05  Data: 1.482 (0.589)
2025-05-01 18:32:23,926 - train - INFO - Train: 56 [ 250/312 ( 80%)]  Loss:  3.102267 (3.0868)  Time: 1.554s, 2636.30/s  (1.141s, 3590.79/s)  LR: 8.368e-05  Data: 0.000 (0.514)
2025-05-01 18:33:20,331 - train - INFO - Train: 56 [ 300/312 ( 96%)]  Loss:  3.061067 (3.0831)  Time: 1.738s, 2356.95/s  (1.139s, 3597.40/s)  LR: 8.368e-05  Data: 0.000 (0.436)
2025-05-01 18:33:31,972 - train - INFO - Train: 56 [ 311/312 (100%)]  Loss:  3.073645 (3.0819)  Time: 0.522s, 7841.61/s  (1.136s, 3606.39/s)  LR: 8.368e-05  Data: 0.000 (0.420)
2025-05-01 18:33:38,360 - train - INFO - Test: [   0/48]  Time: 6.212 (6.212)  Loss:  1.0479 (1.0479)  Acc@1: 76.4648 (76.4648)  Acc@5: 92.0898 (92.0898)
2025-05-01 18:34:34,908 - train - INFO - Test: [  48/48]  Time: 2.196 (1.281)  Loss:  1.1924 (1.8508)  Acc@1: 73.4670 (58.2120)  Acc@5: 90.0943 (81.7460)
2025-05-01 18:34:41,617 - train - INFO - Train: 57 [   0/312 (  0%)]  Loss:  3.061417 (3.0614)  Time: 6.381s,  641.92/s  (6.381s,  641.92/s)  LR: 8.314e-05  Data: 5.601 (5.601)
2025-05-01 18:35:37,449 - train - INFO - Train: 57 [  50/312 ( 16%)]  Loss:  3.085756 (3.0736)  Time: 0.533s, 7685.05/s  (1.220s, 3357.83/s)  LR: 8.314e-05  Data: 0.000 (0.687)
2025-05-01 18:36:35,074 - train - INFO - Train: 57 [ 100/312 ( 32%)]  Loss:  3.082828 (3.0767)  Time: 2.812s, 1456.53/s  (1.186s, 3452.19/s)  LR: 8.314e-05  Data: 2.285 (0.656)
2025-05-01 18:37:30,474 - train - INFO - Train: 57 [ 150/312 ( 48%)]  Loss:  3.101092 (3.0828)  Time: 0.535s, 7657.37/s  (1.160s, 3529.59/s)  LR: 8.314e-05  Data: 0.000 (0.582)
2025-05-01 18:38:27,620 - train - INFO - Train: 57 [ 200/312 ( 64%)]  Loss:  3.069176 (3.0801)  Time: 2.981s, 1373.81/s  (1.156s, 3542.94/s)  LR: 8.314e-05  Data: 2.458 (0.549)
2025-05-01 18:39:22,187 - train - INFO - Train: 57 [ 250/312 ( 80%)]  Loss:  3.092296 (3.0821)  Time: 0.525s, 7795.66/s  (1.143s, 3582.94/s)  LR: 8.314e-05  Data: 0.000 (0.552)
2025-05-01 18:40:18,766 - train - INFO - Train: 57 [ 300/312 ( 96%)]  Loss:  3.065564 (3.0797)  Time: 3.055s, 1340.54/s  (1.141s, 3589.01/s)  LR: 8.314e-05  Data: 2.540 (0.561)
2025-05-01 18:40:29,085 - train - INFO - Train: 57 [ 311/312 (100%)]  Loss:  3.152405 (3.0888)  Time: 0.522s, 7847.90/s  (1.134s, 3611.69/s)  LR: 8.314e-05  Data: 0.000 (0.556)
2025-05-01 18:40:35,260 - train - INFO - Test: [   0/48]  Time: 5.989 (5.989)  Loss:  1.1680 (1.1680)  Acc@1: 77.7344 (77.7344)  Acc@5: 91.6016 (91.6016)
2025-05-01 18:41:32,482 - train - INFO - Test: [  48/48]  Time: 1.900 (1.290)  Loss:  1.2012 (1.8890)  Acc@1: 75.0000 (58.3520)  Acc@5: 91.0377 (81.9840)
2025-05-01 18:41:39,370 - train - INFO - Train: 58 [   0/312 (  0%)]  Loss:  3.077852 (3.0779)  Time: 6.525s,  627.76/s  (6.525s,  627.76/s)  LR: 8.258e-05  Data: 5.038 (5.038)
2025-05-01 18:42:34,410 - train - INFO - Train: 58 [  50/312 ( 16%)]  Loss:  3.105877 (3.0919)  Time: 0.525s, 7797.99/s  (1.207s, 3393.14/s)  LR: 8.258e-05  Data: 0.000 (0.600)
2025-05-01 18:43:30,875 - train - INFO - Train: 58 [ 100/312 ( 32%)]  Loss:  3.075691 (3.0865)  Time: 2.842s, 1441.37/s  (1.169s, 3505.09/s)  LR: 8.258e-05  Data: 2.328 (0.600)
2025-05-01 18:44:25,098 - train - INFO - Train: 58 [ 150/312 ( 48%)]  Loss:  3.093626 (3.0883)  Time: 0.524s, 7813.18/s  (1.141s, 3590.70/s)  LR: 8.258e-05  Data: 0.000 (0.567)
2025-05-01 18:45:20,785 - train - INFO - Train: 58 [ 200/312 ( 64%)]  Loss:  3.091022 (3.0888)  Time: 2.773s, 1477.16/s  (1.134s, 3611.98/s)  LR: 8.258e-05  Data: 2.159 (0.560)
2025-05-01 18:46:15,191 - train - INFO - Train: 58 [ 250/312 ( 80%)]  Loss:  3.102895 (3.0912)  Time: 0.533s, 7680.59/s  (1.125s, 3641.35/s)  LR: 8.258e-05  Data: 0.000 (0.540)
2025-05-01 18:47:11,182 - train - INFO - Train: 58 [ 300/312 ( 96%)]  Loss:  3.119488 (3.0952)  Time: 1.920s, 2133.46/s  (1.124s, 3644.07/s)  LR: 8.258e-05  Data: 1.327 (0.531)
2025-05-01 18:47:22,454 - train - INFO - Train: 58 [ 311/312 (100%)]  Loss:  3.054885 (3.0902)  Time: 1.021s, 4010.28/s  (1.121s, 3655.46/s)  LR: 8.258e-05  Data: 0.000 (0.521)
2025-05-01 18:47:28,998 - train - INFO - Test: [   0/48]  Time: 6.362 (6.362)  Loss:  1.1055 (1.1055)  Acc@1: 77.3438 (77.3438)  Acc@5: 91.9922 (91.9922)
2025-05-01 18:48:26,212 - train - INFO - Test: [  48/48]  Time: 2.438 (1.297)  Loss:  1.1221 (1.8310)  Acc@1: 76.7689 (59.0300)  Acc@5: 91.0377 (82.3680)
2025-05-01 18:48:32,686 - train - INFO - Train: 59 [   0/312 (  0%)]  Loss:  3.075109 (3.0751)  Time: 6.143s,  666.79/s  (6.143s,  666.79/s)  LR: 8.202e-05  Data: 5.099 (5.099)
2025-05-01 18:49:27,921 - train - INFO - Train: 59 [  50/312 ( 16%)]  Loss:  3.053022 (3.0641)  Time: 0.533s, 7680.29/s  (1.203s, 3403.53/s)  LR: 8.202e-05  Data: 0.000 (0.550)
2025-05-01 18:50:25,550 - train - INFO - Train: 59 [ 100/312 ( 32%)]  Loss:  3.067983 (3.0654)  Time: 2.672s, 1533.04/s  (1.178s, 3476.33/s)  LR: 8.202e-05  Data: 0.443 (0.409)
2025-05-01 18:51:20,725 - train - INFO - Train: 59 [ 150/312 ( 48%)]  Loss:  3.106060 (3.0755)  Time: 0.530s, 7726.22/s  (1.153s, 3550.97/s)  LR: 8.202e-05  Data: 0.000 (0.316)
2025-05-01 18:52:17,846 - train - INFO - Train: 59 [ 200/312 ( 64%)]  Loss:  3.092422 (3.0789)  Time: 1.741s, 2353.18/s  (1.151s, 3559.54/s)  LR: 8.202e-05  Data: 0.000 (0.247)
2025-05-01 18:53:14,609 - train - INFO - Train: 59 [ 250/312 ( 80%)]  Loss:  3.081734 (3.0794)  Time: 0.537s, 7633.86/s  (1.148s, 3569.10/s)  LR: 8.202e-05  Data: 0.000 (0.198)
2025-05-01 18:54:10,776 - train - INFO - Train: 59 [ 300/312 ( 96%)]  Loss:  3.067525 (3.0777)  Time: 0.833s, 4915.47/s  (1.144s, 3581.73/s)  LR: 8.202e-05  Data: 0.000 (0.165)
2025-05-01 18:54:23,617 - train - INFO - Train: 59 [ 311/312 (100%)]  Loss:  3.084870 (3.0786)  Time: 0.532s, 7705.85/s  (1.144s, 3579.11/s)  LR: 8.202e-05  Data: 0.000 (0.159)
2025-05-01 18:54:29,807 - train - INFO - Test: [   0/48]  Time: 5.989 (5.989)  Loss:  1.2598 (1.2598)  Acc@1: 75.2930 (75.2930)  Acc@5: 89.6484 (89.6484)
2025-05-01 18:55:26,490 - train - INFO - Test: [  48/48]  Time: 1.553 (1.279)  Loss:  1.2715 (1.8887)  Acc@1: 72.4057 (58.3080)  Acc@5: 90.4481 (81.8340)
2025-05-01 18:55:32,696 - train - INFO - Train: 60 [   0/312 (  0%)]  Loss:  3.062015 (3.0620)  Time: 5.868s,  698.03/s  (5.868s,  698.03/s)  LR: 8.145e-05  Data: 5.262 (5.262)
2025-05-01 18:56:29,170 - train - INFO - Train: 60 [  50/312 ( 16%)]  Loss:  3.073703 (3.0679)  Time: 0.532s, 7692.49/s  (1.222s, 3351.02/s)  LR: 8.145e-05  Data: 0.000 (0.459)
2025-05-01 18:57:26,842 - train - INFO - Train: 60 [ 100/312 ( 32%)]  Loss:  3.033088 (3.0563)  Time: 3.463s, 1182.67/s  (1.188s, 3447.33/s)  LR: 8.145e-05  Data: 0.506 (0.306)
2025-05-01 18:58:21,389 - train - INFO - Train: 60 [ 150/312 ( 48%)]  Loss:  3.058802 (3.0569)  Time: 0.535s, 7661.26/s  (1.156s, 3543.39/s)  LR: 8.145e-05  Data: 0.000 (0.205)
2025-05-01 18:59:19,343 - train - INFO - Train: 60 [ 200/312 ( 64%)]  Loss:  3.074799 (3.0605)  Time: 3.004s, 1363.74/s  (1.157s, 3541.05/s)  LR: 8.145e-05  Data: 0.000 (0.154)
2025-05-01 19:00:15,261 - train - INFO - Train: 60 [ 250/312 ( 80%)]  Loss:  3.058303 (3.0601)  Time: 1.785s, 2294.96/s  (1.149s, 3564.63/s)  LR: 8.145e-05  Data: 0.000 (0.123)
2025-05-01 19:01:11,574 - train - INFO - Train: 60 [ 300/312 ( 96%)]  Loss:  3.111636 (3.0675)  Time: 2.471s, 1657.62/s  (1.145s, 3576.45/s)  LR: 8.145e-05  Data: 0.000 (0.103)
2025-05-01 19:01:22,442 - train - INFO - Train: 60 [ 311/312 (100%)]  Loss:  3.103117 (3.0719)  Time: 0.523s, 7830.90/s  (1.140s, 3593.86/s)  LR: 8.145e-05  Data: 0.000 (0.099)
2025-05-01 19:01:29,155 - train - INFO - Test: [   0/48]  Time: 6.533 (6.533)  Loss:  1.0264 (1.0264)  Acc@1: 78.9062 (78.9062)  Acc@5: 92.8711 (92.8711)
2025-05-01 19:02:25,435 - train - INFO - Test: [  48/48]  Time: 2.274 (1.282)  Loss:  1.1826 (1.8136)  Acc@1: 76.2972 (59.2920)  Acc@5: 89.8585 (82.6040)
2025-05-01 19:02:31,950 - train - INFO - Train: 61 [   0/312 (  0%)]  Loss:  3.087247 (3.0872)  Time: 6.177s,  663.14/s  (6.177s,  663.14/s)  LR: 8.088e-05  Data: 5.491 (5.491)
2025-05-01 19:03:27,599 - train - INFO - Train: 61 [  50/312 ( 16%)]  Loss:  3.093493 (3.0904)  Time: 0.531s, 7714.68/s  (1.212s, 3378.92/s)  LR: 8.088e-05  Data: 0.000 (0.677)
2025-05-01 19:04:25,538 - train - INFO - Train: 61 [ 100/312 ( 32%)]  Loss:  3.041272 (3.0740)  Time: 2.856s, 1434.06/s  (1.186s, 3454.33/s)  LR: 8.088e-05  Data: 2.329 (0.654)
2025-05-01 19:05:20,615 - train - INFO - Train: 61 [ 150/312 ( 48%)]  Loss:  3.054726 (3.0692)  Time: 0.539s, 7601.29/s  (1.158s, 3537.59/s)  LR: 8.088e-05  Data: 0.000 (0.627)
2025-05-01 19:06:17,352 - train - INFO - Train: 61 [ 200/312 ( 64%)]  Loss:  3.050352 (3.0654)  Time: 2.926s, 1399.89/s  (1.152s, 3555.27/s)  LR: 8.088e-05  Data: 2.399 (0.623)
2025-05-01 19:07:11,940 - train - INFO - Train: 61 [ 250/312 ( 80%)]  Loss:  3.102368 (3.0716)  Time: 0.535s, 7656.33/s  (1.140s, 3592.77/s)  LR: 8.088e-05  Data: 0.000 (0.611)
2025-05-01 19:08:08,495 - train - INFO - Train: 61 [ 300/312 ( 96%)]  Loss:  3.118534 (3.0783)  Time: 2.746s, 1491.58/s  (1.139s, 3597.48/s)  LR: 8.088e-05  Data: 2.229 (0.610)
2025-05-01 19:08:19,112 - train - INFO - Train: 61 [ 311/312 (100%)]  Loss:  3.092045 (3.0800)  Time: 0.521s, 7855.64/s  (1.132s, 3616.91/s)  LR: 8.088e-05  Data: 0.000 (0.604)
2025-05-01 19:08:25,461 - train - INFO - Test: [   0/48]  Time: 6.173 (6.173)  Loss:  1.3027 (1.3027)  Acc@1: 75.0977 (75.0977)  Acc@5: 91.0156 (91.0156)
2025-05-01 19:09:22,314 - train - INFO - Test: [  48/48]  Time: 1.933 (1.286)  Loss:  1.3496 (1.9618)  Acc@1: 73.5849 (57.6500)  Acc@5: 90.8019 (81.4860)
2025-05-01 19:09:28,771 - train - INFO - Train: 62 [   0/312 (  0%)]  Loss:  3.097673 (3.0977)  Time: 6.065s,  675.37/s  (6.065s,  675.37/s)  LR: 8.029e-05  Data: 5.508 (5.508)
2025-05-01 19:10:23,549 - train - INFO - Train: 62 [  50/312 ( 16%)]  Loss:  3.080770 (3.0892)  Time: 0.525s, 7796.15/s  (1.193s, 3433.42/s)  LR: 8.029e-05  Data: 0.000 (0.529)
2025-05-01 19:11:20,716 - train - INFO - Train: 62 [ 100/312 ( 32%)]  Loss:  3.094502 (3.0910)  Time: 2.878s, 1423.42/s  (1.168s, 3505.70/s)  LR: 8.029e-05  Data: 0.592 (0.409)
2025-05-01 19:12:15,506 - train - INFO - Train: 62 [ 150/312 ( 48%)]  Loss:  3.042042 (3.0787)  Time: 0.532s, 7703.52/s  (1.144s, 3579.35/s)  LR: 8.029e-05  Data: 0.000 (0.306)
2025-05-01 19:13:12,112 - train - INFO - Train: 62 [ 200/312 ( 64%)]  Loss:  3.069418 (3.0769)  Time: 2.870s, 1427.21/s  (1.141s, 3588.90/s)  LR: 8.029e-05  Data: 0.000 (0.230)
2025-05-01 19:14:06,308 - train - INFO - Train: 62 [ 250/312 ( 80%)]  Loss:  3.086400 (3.0785)  Time: 0.525s, 7808.01/s  (1.130s, 3625.23/s)  LR: 8.029e-05  Data: 0.000 (0.184)
2025-05-01 19:15:03,189 - train - INFO - Train: 62 [ 300/312 ( 96%)]  Loss:  3.074674 (3.0779)  Time: 2.725s, 1503.26/s  (1.131s, 3621.11/s)  LR: 8.029e-05  Data: 0.000 (0.154)
2025-05-01 19:15:13,719 - train - INFO - Train: 62 [ 311/312 (100%)]  Loss:  3.102844 (3.0810)  Time: 0.523s, 7827.30/s  (1.125s, 3640.84/s)  LR: 8.029e-05  Data: 0.000 (0.149)
2025-05-01 19:15:20,261 - train - INFO - Test: [   0/48]  Time: 6.382 (6.382)  Loss:  1.0898 (1.0898)  Acc@1: 75.8789 (75.8789)  Acc@5: 91.6992 (91.6992)
2025-05-01 19:16:17,479 - train - INFO - Test: [  48/48]  Time: 2.658 (1.298)  Loss:  1.1855 (1.8902)  Acc@1: 76.1792 (57.8520)  Acc@5: 90.5660 (81.6460)
2025-05-01 19:16:23,997 - train - INFO - Train: 63 [   0/312 (  0%)]  Loss:  3.062547 (3.0625)  Time: 6.179s,  662.86/s  (6.179s,  662.86/s)  LR: 7.971e-05  Data: 5.460 (5.460)
2025-05-01 19:17:19,613 - train - INFO - Train: 63 [  50/312 ( 16%)]  Loss:  3.098733 (3.0806)  Time: 0.524s, 7810.00/s  (1.212s, 3380.49/s)  LR: 7.971e-05  Data: 0.000 (0.670)
2025-05-01 19:18:17,663 - train - INFO - Train: 63 [ 100/312 ( 32%)]  Loss:  3.130138 (3.0971)  Time: 3.174s, 1290.33/s  (1.187s, 3451.97/s)  LR: 7.971e-05  Data: 1.853 (0.575)
2025-05-01 19:19:12,485 - train - INFO - Train: 63 [ 150/312 ( 48%)]  Loss:  3.095270 (3.0967)  Time: 0.534s, 7667.62/s  (1.157s, 3541.07/s)  LR: 7.971e-05  Data: 0.001 (0.442)
2025-05-01 19:20:09,955 - train - INFO - Train: 63 [ 200/312 ( 64%)]  Loss:  3.085824 (3.0945)  Time: 2.812s, 1456.70/s  (1.155s, 3546.67/s)  LR: 7.971e-05  Data: 0.000 (0.341)
2025-05-01 19:21:05,542 - train - INFO - Train: 63 [ 250/312 ( 80%)]  Loss:  3.065546 (3.0897)  Time: 0.526s, 7782.64/s  (1.146s, 3573.29/s)  LR: 7.971e-05  Data: 0.000 (0.273)
2025-05-01 19:22:02,895 - train - INFO - Train: 63 [ 300/312 ( 96%)]  Loss:  3.049020 (3.0839)  Time: 2.919s, 1403.18/s  (1.146s, 3572.89/s)  LR: 7.971e-05  Data: 0.000 (0.228)
2025-05-01 19:22:13,381 - train - INFO - Train: 63 [ 311/312 (100%)]  Loss:  3.065485 (3.0816)  Time: 0.523s, 7834.73/s  (1.140s, 3594.25/s)  LR: 7.971e-05  Data: 0.000 (0.220)
2025-05-01 19:22:19,861 - train - INFO - Test: [   0/48]  Time: 6.304 (6.304)  Loss:  1.1953 (1.1953)  Acc@1: 77.0508 (77.0508)  Acc@5: 91.6016 (91.6016)
2025-05-01 19:23:16,906 - train - INFO - Test: [  48/48]  Time: 1.781 (1.293)  Loss:  1.2354 (1.8265)  Acc@1: 74.2925 (59.5980)  Acc@5: 89.1509 (82.8460)
2025-05-01 19:23:23,601 - train - INFO - Train: 64 [   0/312 (  0%)]  Loss:  3.041075 (3.0411)  Time: 6.260s,  654.32/s  (6.260s,  654.32/s)  LR: 7.911e-05  Data: 5.460 (5.460)
2025-05-01 19:24:19,415 - train - INFO - Train: 64 [  50/312 ( 16%)]  Loss:  2.982179 (3.0116)  Time: 0.539s, 7595.01/s  (1.217s, 3365.38/s)  LR: 7.911e-05  Data: 0.000 (0.647)
2025-05-01 19:25:17,685 - train - INFO - Train: 64 [ 100/312 ( 32%)]  Loss:  3.073868 (3.0324)  Time: 3.025s, 1354.16/s  (1.191s, 3437.72/s)  LR: 7.911e-05  Data: 0.450 (0.475)
2025-05-01 19:26:13,565 - train - INFO - Train: 64 [ 150/312 ( 48%)]  Loss:  3.123601 (3.0552)  Time: 0.531s, 7713.22/s  (1.167s, 3509.87/s)  LR: 7.911e-05  Data: 0.000 (0.319)
2025-05-01 19:27:11,895 - train - INFO - Train: 64 [ 200/312 ( 64%)]  Loss:  3.095075 (3.0632)  Time: 2.932s, 1397.19/s  (1.167s, 3510.19/s)  LR: 7.911e-05  Data: 0.000 (0.240)
2025-05-01 19:28:07,247 - train - INFO - Train: 64 [ 250/312 ( 80%)]  Loss:  3.087834 (3.0673)  Time: 0.525s, 7802.41/s  (1.155s, 3546.42/s)  LR: 7.911e-05  Data: 0.000 (0.192)
2025-05-01 19:29:05,081 - train - INFO - Train: 64 [ 300/312 ( 96%)]  Loss:  3.056798 (3.0658)  Time: 2.926s, 1399.83/s  (1.155s, 3545.57/s)  LR: 7.911e-05  Data: 0.000 (0.160)
2025-05-01 19:29:15,724 - train - INFO - Train: 64 [ 311/312 (100%)]  Loss:  3.055259 (3.0645)  Time: 0.527s, 7767.63/s  (1.149s, 3566.03/s)  LR: 7.911e-05  Data: 0.000 (0.155)
2025-05-01 19:29:22,414 - train - INFO - Test: [   0/48]  Time: 6.497 (6.497)  Loss:  1.1738 (1.1738)  Acc@1: 73.7305 (73.7305)  Acc@5: 90.6250 (90.6250)
2025-05-01 19:30:18,397 - train - INFO - Test: [  48/48]  Time: 1.946 (1.275)  Loss:  1.3320 (1.8630)  Acc@1: 70.7547 (58.1460)  Acc@5: 89.5047 (81.7820)
2025-05-01 19:30:24,840 - train - INFO - Train: 65 [   0/312 (  0%)]  Loss:  3.082492 (3.0825)  Time: 6.123s,  668.91/s  (6.123s,  668.91/s)  LR: 7.851e-05  Data: 5.310 (5.310)
2025-05-01 19:31:19,629 - train - INFO - Train: 65 [  50/312 ( 16%)]  Loss:  3.033389 (3.0579)  Time: 0.525s, 7795.03/s  (1.194s, 3429.51/s)  LR: 7.851e-05  Data: 0.000 (0.651)
2025-05-01 19:32:16,675 - train - INFO - Train: 65 [ 100/312 ( 32%)]  Loss:  3.081176 (3.0657)  Time: 2.384s, 1718.36/s  (1.168s, 3507.20/s)  LR: 7.851e-05  Data: 1.869 (0.594)
2025-05-01 19:33:11,924 - train - INFO - Train: 65 [ 150/312 ( 48%)]  Loss:  3.095617 (3.0732)  Time: 0.535s, 7657.49/s  (1.147s, 3570.92/s)  LR: 7.851e-05  Data: 0.000 (0.517)
2025-05-01 19:34:08,776 - train - INFO - Train: 65 [ 200/312 ( 64%)]  Loss:  3.056286 (3.0698)  Time: 1.220s, 3357.29/s  (1.145s, 3578.70/s)  LR: 7.851e-05  Data: 0.000 (0.424)
2025-05-01 19:35:05,092 - train - INFO - Train: 65 [ 250/312 ( 80%)]  Loss:  3.070232 (3.0699)  Time: 0.531s, 7710.25/s  (1.141s, 3590.11/s)  LR: 7.851e-05  Data: 0.000 (0.339)
2025-05-01 19:36:00,823 - train - INFO - Train: 65 [ 300/312 ( 96%)]  Loss:  3.076153 (3.0708)  Time: 0.534s, 7667.28/s  (1.137s, 3603.92/s)  LR: 7.851e-05  Data: 0.000 (0.283)
2025-05-01 19:36:13,773 - train - INFO - Train: 65 [ 311/312 (100%)]  Loss:  3.044107 (3.0674)  Time: 0.521s, 7856.29/s  (1.138s, 3599.39/s)  LR: 7.851e-05  Data: 0.000 (0.273)
2025-05-01 19:36:19,949 - train - INFO - Test: [   0/48]  Time: 5.990 (5.990)  Loss:  1.0791 (1.0791)  Acc@1: 75.6836 (75.6836)  Acc@5: 91.0156 (91.0156)
2025-05-01 19:37:16,582 - train - INFO - Test: [  48/48]  Time: 2.425 (1.278)  Loss:  1.2920 (1.8400)  Acc@1: 71.6981 (58.4060)  Acc@5: 90.0943 (81.8940)
2025-05-01 19:37:23,061 - train - INFO - Train: 66 [   0/312 (  0%)]  Loss:  3.065542 (3.0655)  Time: 6.157s,  665.25/s  (6.157s,  665.25/s)  LR: 7.791e-05  Data: 5.574 (5.574)
2025-05-01 19:38:20,229 - train - INFO - Train: 66 [  50/312 ( 16%)]  Loss:  3.055543 (3.0605)  Time: 0.529s, 7745.01/s  (1.242s, 3298.92/s)  LR: 7.791e-05  Data: 0.000 (0.713)
2025-05-01 19:39:16,396 - train - INFO - Train: 66 [ 100/312 ( 32%)]  Loss:  3.055080 (3.0587)  Time: 1.479s, 2769.32/s  (1.183s, 3462.30/s)  LR: 7.791e-05  Data: 0.954 (0.657)
2025-05-01 19:40:13,438 - train - INFO - Train: 66 [ 150/312 ( 48%)]  Loss:  3.071702 (3.0620)  Time: 0.531s, 7709.19/s  (1.169s, 3503.74/s)  LR: 7.791e-05  Data: 0.000 (0.643)
2025-05-01 19:41:08,718 - train - INFO - Train: 66 [ 200/312 ( 64%)]  Loss:  3.313785 (3.1123)  Time: 0.537s, 7626.94/s  (1.153s, 3551.70/s)  LR: 7.791e-05  Data: 0.000 (0.627)
2025-05-01 19:42:06,725 - train - INFO - Train: 66 [ 250/312 ( 80%)]  Loss:  3.065353 (3.1045)  Time: 0.528s, 7752.09/s  (1.155s, 3547.49/s)  LR: 7.791e-05  Data: 0.000 (0.628)
2025-05-01 19:43:02,164 - train - INFO - Train: 66 [ 300/312 ( 96%)]  Loss:  3.030849 (3.0940)  Time: 0.532s, 7700.67/s  (1.147s, 3571.07/s)  LR: 7.791e-05  Data: 0.000 (0.621)
2025-05-01 19:43:14,797 - train - INFO - Train: 66 [ 311/312 (100%)]  Loss:  3.129386 (3.0984)  Time: 0.533s, 7688.73/s  (1.147s, 3570.92/s)  LR: 7.791e-05  Data: 0.000 (0.621)
2025-05-01 19:43:21,253 - train - INFO - Test: [   0/48]  Time: 6.268 (6.268)  Loss:  1.2051 (1.2051)  Acc@1: 75.5859 (75.5859)  Acc@5: 91.0156 (91.0156)
2025-05-01 19:44:17,827 - train - INFO - Test: [  48/48]  Time: 1.798 (1.282)  Loss:  1.3281 (1.8869)  Acc@1: 73.5849 (58.7480)  Acc@5: 88.7972 (81.7600)
2025-05-01 19:44:24,629 - train - INFO - Train: 67 [   0/312 (  0%)]  Loss:  3.064297 (3.0643)  Time: 6.465s,  633.59/s  (6.465s,  633.59/s)  LR: 7.730e-05  Data: 5.224 (5.224)
2025-05-01 19:45:20,273 - train - INFO - Train: 67 [  50/312 ( 16%)]  Loss:  3.052885 (3.0586)  Time: 0.528s, 7754.44/s  (1.218s, 3363.42/s)  LR: 7.730e-05  Data: 0.000 (0.547)
2025-05-01 19:46:16,209 - train - INFO - Train: 67 [ 100/312 ( 32%)]  Loss:  3.117165 (3.0781)  Time: 2.501s, 1637.79/s  (1.169s, 3504.61/s)  LR: 7.730e-05  Data: 1.696 (0.437)
2025-05-01 19:47:11,366 - train - INFO - Train: 67 [ 150/312 ( 48%)]  Loss:  3.117471 (3.0880)  Time: 0.536s, 7635.53/s  (1.147s, 3571.03/s)  LR: 7.730e-05  Data: 0.000 (0.473)
2025-05-01 19:48:07,159 - train - INFO - Train: 67 [ 200/312 ( 64%)]  Loss:  3.116528 (3.0937)  Time: 2.422s, 1691.27/s  (1.139s, 3595.33/s)  LR: 7.730e-05  Data: 1.527 (0.478)
2025-05-01 19:49:01,600 - train - INFO - Train: 67 [ 250/312 ( 80%)]  Loss:  3.065310 (3.0889)  Time: 0.525s, 7801.99/s  (1.129s, 3627.34/s)  LR: 7.730e-05  Data: 0.000 (0.480)
2025-05-01 19:49:58,009 - train - INFO - Train: 67 [ 300/312 ( 96%)]  Loss:  3.025680 (3.0799)  Time: 2.402s, 1705.59/s  (1.129s, 3627.90/s)  LR: 7.730e-05  Data: 0.684 (0.460)
2025-05-01 19:50:08,932 - train - INFO - Train: 67 [ 311/312 (100%)]  Loss:  3.110886 (3.0838)  Time: 0.528s, 7752.69/s  (1.124s, 3643.39/s)  LR: 7.730e-05  Data: 0.000 (0.452)
2025-05-01 19:50:15,542 - train - INFO - Test: [   0/48]  Time: 6.422 (6.422)  Loss:  1.6191 (1.6191)  Acc@1: 74.0234 (74.0234)  Acc@5: 90.2344 (90.2344)
2025-05-01 19:51:12,433 - train - INFO - Test: [  48/48]  Time: 2.372 (1.292)  Loss:  1.6133 (2.2327)  Acc@1: 71.4623 (56.1060)  Acc@5: 87.5000 (80.0420)
2025-05-01 19:51:19,098 - train - INFO - Train: 68 [   0/312 (  0%)]  Loss:  3.132378 (3.1324)  Time: 6.332s,  646.91/s  (6.332s,  646.91/s)  LR: 7.668e-05  Data: 5.800 (5.800)
2025-05-01 19:52:15,090 - train - INFO - Train: 68 [  50/312 ( 16%)]  Loss:  3.063054 (3.0977)  Time: 0.525s, 7806.24/s  (1.222s, 3351.90/s)  LR: 7.668e-05  Data: 0.000 (0.428)
2025-05-01 19:53:12,578 - train - INFO - Train: 68 [ 100/312 ( 32%)]  Loss:  3.037625 (3.0777)  Time: 2.978s, 1375.25/s  (1.186s, 3452.98/s)  LR: 7.668e-05  Data: 0.081 (0.245)
2025-05-01 19:54:07,511 - train - INFO - Train: 68 [ 150/312 ( 48%)]  Loss:  3.036650 (3.0674)  Time: 0.526s, 7784.09/s  (1.157s, 3539.51/s)  LR: 7.668e-05  Data: 0.000 (0.168)
2025-05-01 19:55:04,293 - train - INFO - Train: 68 [ 200/312 ( 64%)]  Loss:  3.083803 (3.0707)  Time: 2.552s, 1604.77/s  (1.152s, 3556.04/s)  LR: 7.668e-05  Data: 0.000 (0.126)
2025-05-01 19:55:59,225 - train - INFO - Train: 68 [ 250/312 ( 80%)]  Loss:  3.066865 (3.0701)  Time: 0.525s, 7798.51/s  (1.141s, 3589.09/s)  LR: 7.668e-05  Data: 0.000 (0.101)
2025-05-01 19:56:56,881 - train - INFO - Train: 68 [ 300/312 ( 96%)]  Loss:  3.007083 (3.0611)  Time: 2.900s, 1412.49/s  (1.143s, 3582.93/s)  LR: 7.668e-05  Data: 0.000 (0.084)
2025-05-01 19:57:07,790 - train - INFO - Train: 68 [ 311/312 (100%)]  Loss:  3.023129 (3.0563)  Time: 1.064s, 3850.58/s  (1.138s, 3599.76/s)  LR: 7.668e-05  Data: 0.000 (0.082)
2025-05-01 19:57:14,384 - train - INFO - Test: [   0/48]  Time: 6.411 (6.411)  Loss:  1.2021 (1.2021)  Acc@1: 73.5352 (73.5352)  Acc@5: 91.3086 (91.3086)
2025-05-01 19:58:11,105 - train - INFO - Test: [  48/48]  Time: 2.443 (1.288)  Loss:  1.1611 (1.8352)  Acc@1: 76.0613 (58.6440)  Acc@5: 90.3302 (82.2240)
2025-05-01 19:58:17,793 - train - INFO - Train: 69 [   0/312 (  0%)]  Loss:  3.077803 (3.0778)  Time: 6.357s,  644.37/s  (6.357s,  644.37/s)  LR: 7.606e-05  Data: 4.931 (4.931)
2025-05-01 19:59:13,079 - train - INFO - Train: 69 [  50/312 ( 16%)]  Loss:  3.065949 (3.0719)  Time: 0.532s, 7700.53/s  (1.209s, 3388.88/s)  LR: 7.606e-05  Data: 0.000 (0.391)
2025-05-01 20:00:09,887 - train - INFO - Train: 69 [ 100/312 ( 32%)]  Loss:  3.059294 (3.0677)  Time: 3.046s, 1344.51/s  (1.173s, 3492.72/s)  LR: 7.606e-05  Data: 0.000 (0.212)
2025-05-01 20:01:04,946 - train - INFO - Train: 69 [ 150/312 ( 48%)]  Loss:  3.076642 (3.0699)  Time: 0.541s, 7569.95/s  (1.149s, 3564.84/s)  LR: 7.606e-05  Data: 0.000 (0.142)
2025-05-01 20:02:03,631 - train - INFO - Train: 69 [ 200/312 ( 64%)]  Loss:  3.089378 (3.0738)  Time: 3.095s, 1323.55/s  (1.155s, 3545.93/s)  LR: 7.606e-05  Data: 0.000 (0.107)
2025-05-01 20:02:58,841 - train - INFO - Train: 69 [ 250/312 ( 80%)]  Loss:  3.070622 (3.0733)  Time: 0.526s, 7784.83/s  (1.145s, 3577.36/s)  LR: 7.606e-05  Data: 0.000 (0.085)
2025-05-01 20:03:56,022 - train - INFO - Train: 69 [ 300/312 ( 96%)]  Loss:  3.063592 (3.0719)  Time: 2.934s, 1396.06/s  (1.145s, 3578.08/s)  LR: 7.606e-05  Data: 0.000 (0.071)
2025-05-01 20:04:06,120 - train - INFO - Train: 69 [ 311/312 (100%)]  Loss:  3.062816 (3.0708)  Time: 0.522s, 7850.84/s  (1.137s, 3603.26/s)  LR: 7.606e-05  Data: 0.000 (0.069)
2025-05-01 20:04:12,593 - train - INFO - Test: [   0/48]  Time: 6.298 (6.298)  Loss:  1.2744 (1.2744)  Acc@1: 71.9727 (71.9727)  Acc@5: 89.8438 (89.8438)
2025-05-01 20:05:09,936 - train - INFO - Test: [  48/48]  Time: 2.304 (1.299)  Loss:  1.1748 (1.9227)  Acc@1: 75.4717 (57.4980)  Acc@5: 89.2689 (80.9960)
2025-05-01 20:05:16,472 - train - INFO - Train: 70 [   0/312 (  0%)]  Loss:  3.058675 (3.0587)  Time: 6.133s,  667.90/s  (6.133s,  667.90/s)  LR: 7.543e-05  Data: 5.592 (5.592)
2025-05-01 20:06:10,663 - train - INFO - Train: 70 [  50/312 ( 16%)]  Loss:  3.097085 (3.0779)  Time: 0.585s, 6998.18/s  (1.183s, 3463.00/s)  LR: 7.543e-05  Data: 0.000 (0.595)
2025-05-01 20:07:08,103 - train - INFO - Train: 70 [ 100/312 ( 32%)]  Loss:  3.055248 (3.0703)  Time: 1.629s, 2514.22/s  (1.166s, 3512.99/s)  LR: 7.543e-05  Data: 0.000 (0.366)
2025-05-01 20:08:02,366 - train - INFO - Train: 70 [ 150/312 ( 48%)]  Loss:  3.011564 (3.0556)  Time: 0.590s, 6941.72/s  (1.139s, 3595.42/s)  LR: 7.543e-05  Data: 0.000 (0.245)
2025-05-01 20:08:57,882 - train - INFO - Train: 70 [ 200/312 ( 64%)]  Loss:  3.057465 (3.0560)  Time: 1.362s, 3007.02/s  (1.132s, 3618.28/s)  LR: 7.543e-05  Data: 0.000 (0.184)
2025-05-01 20:09:53,552 - train - INFO - Train: 70 [ 250/312 ( 80%)]  Loss:  3.018851 (3.0498)  Time: 0.525s, 7795.16/s  (1.128s, 3630.20/s)  LR: 7.543e-05  Data: 0.000 (0.148)
2025-05-01 20:11:21,095 - train - INFO - Namespace(data_dir='/data/dataset/imagenet/', dataset='image_folder', train_split='train', val_split='validation', model='ResNet18', pretrained=False, initial_checkpoint='output/train/20250501-115119-ResNet18-224/best.pth.tar.pth', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=224, input_size=None, crop_pct=None, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], interpolation='', batch_size=1024, validation_batch_size_multiplier=1, gpu=0, opt='sgd', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.0001, clip_grad=None, clip_mode='norm', sched='step', lr=0.0001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=0.0001, min_lr=1e-06, epochs=200, epoch_repeats=0.0, start_epoch=None, decay_epochs=30, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0, vflip=0.0, color_jitter=None, aa='rand-m9-mstd0.5-inc1', aug_splits=0, jsd=False, reprob=0, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0, cutmix_minmax=None, mixup_prob=0.0, mixup_switch_prob=0.0, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=True, dist_bn='', split_bn=False, log_interval=50, recovery_interval=0, checkpoint_hist=1, save_images=False, amp=False, apex_amp=False, native_amp=False, channels_last=False, pin_mem=True, output='', experiment='', eval_metric='top1', tta=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False, wq_enable=True, wq_mode='LSQ', wq_bitw=32, wq_pos=None, wq_neg=None, wq_per_channel=True, wq_asym=False, aq_enable=True, aq_mode='LSQ', aq_bitw=32, aq_pos=None, aq_neg=None, aq_asym=True, qmodules=['convbn_first;wq:bit:8;aq:bit:8', 'layer1.0.convbn1', 'layer1.0.convbn2', 'layer1.1.convbn1', 'layer1.1.convbn2', 'layer2.0.convbn1', 'layer2.0.convbn2', 'layer2.1.convbn1', 'layer2.1.convbn2', 'layer3.0.convbn1', 'layer3.0.convbn2', 'layer3.1.convbn1', 'layer3.1.convbn2', 'layer4.0.convbn1', 'layer4.0.convbn2', 'layer4.1.convbn1', 'layer4.1.convbn2', 'fc;wq:bit:8;aq:bit:8'], resq_modules=['relu', 'layer1.0.relu2', 'layer1.1.relu2', 'layer2.0.relu2', 'layer3.0.downsample', 'layer2.1.relu2', 'layer3.0.relu2', 'layer3.0.downsample', 'layer3.1.relu2', 'layer4.0.downsample', 'layer4.0.relu2', 'layer4.1.relu2'], resq_enable=True, resq_mode='LSQ', resq_bitw=12, resq_pos=None, resq_neg=None, resq_asym=False, aq_per_channel=False, powerof2=True, world_size=4, local_rank=-1, dist_on_itp=False, dist_url='env://', device='cuda', seed=0, dist_eval=False, use_kd=False, kd_alpha=1.0, teacher='ResNet18', teacher_checkpoint='output/train/20250501-115119-ResNet18-224/best.pth.tar.pth', log_name='resnet18_imagenet_avgpool_acc15_adam', budget=1, bw_list='5, 5, 5, 5, 5, 4, 5, 3, 5, 4, 3, 3, 3, 2, 2, 2', ba_list='4, 4, 4, 4, 4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3', workers=4, multiprocessing_distributed=True, rank=0, distributed=True, dist_backend='nccl', **{'weight-decay': '1e-4'})
