2025-06-01 11:16:09,482 - train - INFO - Namespace(data_dir='/data/dataset/imagenet', dataset='image_folder', train_split='train', val_split='validation', model='ResNet18', pretrained=False, initial_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=224, input_size=None, crop_pct=None, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], interpolation='', batch_size=1024, validation_batch_size_multiplier=1, gpu=0, opt='sgd', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.0001, clip_grad=None, clip_mode='norm', sched='cosine', lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=0.0001, min_lr=1e-05, epochs=300, epoch_repeats=0.0, start_epoch=None, decay_epochs=30, warmup_epochs=0, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0, vflip=0.0, color_jitter=None, aa='rand-m9-mstd0.5-inc1', aug_splits=0, jsd=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=True, dist_bn='', split_bn=False, log_interval=50, recovery_interval=0, checkpoint_hist=1, save_images=False, amp=False, apex_amp=False, native_amp=False, channels_last=False, pin_mem=True, output='', experiment='', eval_metric='top1', tta=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False, wq_enable=True, wq_mode='LSQ', wq_bitw=32, wq_pos=None, wq_neg=None, wq_per_channel=True, wq_asym=True, aq_enable=True, aq_mode='LSQ', aq_bitw=32, aq_pos=None, aq_neg=None, aq_asym=True, qmodules=['convbn_first;wq:bit:8;aq:bit:8', 'layer1.0.convbn1', 'layer1.0.convbn2', 'layer1.1.convbn1', 'layer1.1.convbn2', 'layer2.0.convbn1', 'layer2.0.convbn2', 'layer2.1.convbn1', 'layer2.1.convbn2', 'layer3.0.convbn1', 'layer3.0.convbn2', 'layer3.1.convbn1', 'layer3.1.convbn2', 'layer4.0.convbn1', 'layer4.0.convbn2', 'layer4.1.convbn1', 'layer4.1.convbn2', 'fc;wq:bit:8;aq:bit:8'], resq_modules=['relu', 'layer1.0.relu2', 'layer1.1.relu2', 'layer2.0.relu2', 'layer3.0.downsample', 'layer2.1.relu2', 'layer3.0.relu2', 'layer3.0.downsample', 'layer3.1.relu2', 'layer4.0.downsample', 'layer4.0.relu2', 'layer4.1.relu2'], resq_enable=True, resq_mode='LSQ', resq_bitw=16, resq_pos=None, resq_neg=None, resq_asym=False, aq_per_channel=False, powerof2=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', device='cuda', seed=0, dist_eval=False, use_kd=True, kd_alpha=4, teacher='ResNet18', teacher_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', log_name='resnet18_imagenet_avgpool_acc15_kd', budget=1, bw_list='5, 5, 5, 5, 5, 4, 4, 3, 4, 3, 3, 3, 3, 2, 2, 2', ba_list='4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3', workers=4, multiprocessing_distributed=True, rank=0, distributed=True, dist_backend='nccl', **{'weight-decay': '5e-3'})
2025-06-01 11:16:10,965 - train - INFO - Model ResNet18 created, param count:11689512
2025-06-01 11:16:12,573 - train - INFO - Converted model to use Synchronized BatchNorm. WARNING: You may have issues if using zero initialized BN layers (enabled by default for ResNets) while sync-bn enabled.
2025-06-01 11:16:12,574 - train - INFO - Using native Torch AMP. Training in mixed precision.
2025-06-01 11:16:12,574 - train - INFO - Scheduled epochs: 310
2025-06-01 11:16:12,574 - train - INFO - Verifying teacher model
2025-06-01 11:21:00,145 - train - INFO - Namespace(data_dir='/data/dataset/imagenet', dataset='image_folder', train_split='train', val_split='validation', model='ResNet18', pretrained=False, initial_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=224, input_size=None, crop_pct=None, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], interpolation='', batch_size=1024, validation_batch_size_multiplier=1, gpu=0, opt='sgd', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.0001, clip_grad=None, clip_mode='norm', sched='cosine', lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=0.0001, min_lr=1e-05, epochs=300, epoch_repeats=0.0, start_epoch=None, decay_epochs=30, warmup_epochs=0, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0, vflip=0.0, color_jitter=None, aa='rand-m9-mstd0.5-inc1', aug_splits=0, jsd=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=True, dist_bn='', split_bn=False, log_interval=50, recovery_interval=0, checkpoint_hist=1, save_images=False, amp=False, apex_amp=False, native_amp=False, channels_last=False, pin_mem=True, output='', experiment='', eval_metric='top1', tta=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False, wq_enable=True, wq_mode='LSQ', wq_bitw=32, wq_pos=None, wq_neg=None, wq_per_channel=True, wq_asym=True, aq_enable=True, aq_mode='LSQ', aq_bitw=32, aq_pos=None, aq_neg=None, aq_asym=True, qmodules=['convbn_first;wq:bit:8;aq:bit:8', 'layer1.0.convbn1', 'layer1.0.convbn2', 'layer1.1.convbn1', 'layer1.1.convbn2', 'layer2.0.convbn1', 'layer2.0.convbn2', 'layer2.1.convbn1', 'layer2.1.convbn2', 'layer3.0.convbn1', 'layer3.0.convbn2', 'layer3.1.convbn1', 'layer3.1.convbn2', 'layer4.0.convbn1', 'layer4.0.convbn2', 'layer4.1.convbn1', 'layer4.1.convbn2', 'fc;wq:bit:8;aq:bit:8'], resq_modules=['relu', 'layer1.0.relu2', 'layer1.1.relu2', 'layer2.0.relu2', 'layer3.0.downsample', 'layer2.1.relu2', 'layer3.0.relu2', 'layer3.0.downsample', 'layer3.1.relu2', 'layer4.0.downsample', 'layer4.0.relu2', 'layer4.1.relu2'], resq_enable=True, resq_mode='LSQ', resq_bitw=16, resq_pos=None, resq_neg=None, resq_asym=False, aq_per_channel=False, powerof2=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', device='cuda', seed=0, dist_eval=False, use_kd=True, kd_alpha=4, teacher='ResNet18', teacher_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', log_name='resnet18_imagenet_avgpool_acc15_kd', budget=1, bw_list='5, 5, 5, 5, 5, 4, 4, 3, 4, 3, 3, 3, 3, 2, 2, 2', ba_list='4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3', workers=4, multiprocessing_distributed=True, rank=0, distributed=True, dist_backend='nccl', **{'weight-decay': '5e-3'})
2025-06-01 11:21:03,006 - train - INFO - Model ResNet18 created, param count:11689512
2025-06-01 11:21:03,428 - train - INFO - Converted model to use Synchronized BatchNorm. WARNING: You may have issues if using zero initialized BN layers (enabled by default for ResNets) while sync-bn enabled.
2025-06-01 11:21:03,430 - train - INFO - Using native Torch AMP. Training in mixed precision.
2025-06-01 11:21:03,430 - train - INFO - Scheduled epochs: 310
2025-06-01 11:21:03,431 - train - INFO - Verifying teacher model
2025-06-01 12:10:15,273 - train - INFO - Namespace(data_dir='/data/dataset/imagenet', dataset='image_folder', train_split='train', val_split='validation', model='ResNet18', pretrained=False, initial_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=224, input_size=None, crop_pct=None, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], interpolation='', batch_size=1024, validation_batch_size_multiplier=1, gpu=0, opt='sgd', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.0001, clip_grad=None, clip_mode='norm', sched='cosine', lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=0.0001, min_lr=1e-05, epochs=300, epoch_repeats=0.0, start_epoch=None, decay_epochs=30, warmup_epochs=0, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0, vflip=0.0, color_jitter=None, aa='rand-m9-mstd0.5-inc1', aug_splits=0, jsd=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=True, dist_bn='', split_bn=False, log_interval=50, recovery_interval=0, checkpoint_hist=1, save_images=False, amp=False, apex_amp=False, native_amp=False, channels_last=False, pin_mem=True, output='', experiment='', eval_metric='top1', tta=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False, wq_enable=True, wq_mode='LSQ', wq_bitw=32, wq_pos=None, wq_neg=None, wq_per_channel=True, wq_asym=True, aq_enable=True, aq_mode='LSQ', aq_bitw=32, aq_pos=None, aq_neg=None, aq_asym=True, qmodules=['convbn_first;wq:bit:8;aq:bit:8', 'layer1.0.convbn1', 'layer1.0.convbn2', 'layer1.1.convbn1', 'layer1.1.convbn2', 'layer2.0.convbn1', 'layer2.0.convbn2', 'layer2.1.convbn1', 'layer2.1.convbn2', 'layer3.0.convbn1', 'layer3.0.convbn2', 'layer3.1.convbn1', 'layer3.1.convbn2', 'layer4.0.convbn1', 'layer4.0.convbn2', 'layer4.1.convbn1', 'layer4.1.convbn2', 'fc;wq:bit:8;aq:bit:8'], resq_modules=['relu', 'layer1.0.relu2', 'layer1.1.relu2', 'layer2.0.relu2', 'layer3.0.downsample', 'layer2.1.relu2', 'layer3.0.relu2', 'layer3.0.downsample', 'layer3.1.relu2', 'layer4.0.downsample', 'layer4.0.relu2', 'layer4.1.relu2'], resq_enable=True, resq_mode='LSQ', resq_bitw=16, resq_pos=None, resq_neg=None, resq_asym=False, aq_per_channel=False, powerof2=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', device='cuda', seed=0, dist_eval=False, use_kd=True, kd_alpha=4, teacher='ResNet18', teacher_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', log_name='resnet18_imagenet_avgpool_acc15_kd', budget=1, bw_list='5, 5, 5, 5, 5, 4, 4, 3, 4, 3, 3, 3, 3, 2, 2, 2', ba_list='4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3', workers=4, multiprocessing_distributed=True, rank=0, distributed=True, dist_backend='nccl', **{'weight-decay': '5e-3'})
2025-06-01 12:10:16,771 - train - INFO - Model ResNet18 created, param count:11689512
2025-06-01 12:10:18,310 - train - INFO - Converted model to use Synchronized BatchNorm. WARNING: You may have issues if using zero initialized BN layers (enabled by default for ResNets) while sync-bn enabled.
2025-06-01 12:10:18,311 - train - INFO - Using native Torch AMP. Training in mixed precision.
2025-06-01 12:10:18,311 - train - INFO - Scheduled epochs: 310
2025-06-01 12:10:18,311 - train - INFO - Verifying teacher model
2025-06-01 12:10:27,060 - train - INFO - Test: [   0/48]  Time: 8.748 (8.748)  Loss:  6.3672 (6.3672)  Acc@1:  0.4883 ( 0.4883)  Acc@5:  4.6875 ( 4.6875)
2025-06-01 12:11:21,608 - train - INFO - Test: [  48/48]  Time: 2.908 (1.292)  Loss:  6.6523 (6.6250)  Acc@1:  2.7123 ( 1.5520)  Acc@5:  8.4906 ( 4.5060)
2025-06-01 12:11:21,785 - train - INFO - Verifying initial model in test dataset
2025-06-01 12:11:21,785 - train - INFO - cuda:0
2025-06-01 12:11:28,041 - train - INFO - Test: [   0/48]  Time: 6.255 (6.255)  Loss:  6.5078 (6.5078)  Acc@1:  0.3906 ( 0.3906)  Acc@5:  2.5391 ( 2.5391)
2025-06-01 12:11:45,137 - train - INFO - Namespace(data_dir='/data/dataset/imagenet', dataset='image_folder', train_split='train', val_split='validation', model='ResNet18', pretrained=False, initial_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=224, input_size=None, crop_pct=None, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], interpolation='', batch_size=1024, validation_batch_size_multiplier=1, gpu=0, opt='sgd', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.0001, clip_grad=None, clip_mode='norm', sched='cosine', lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=0.0001, min_lr=1e-05, epochs=300, epoch_repeats=0.0, start_epoch=None, decay_epochs=30, warmup_epochs=0, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0, vflip=0.0, color_jitter=None, aa='rand-m9-mstd0.5-inc1', aug_splits=0, jsd=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=True, dist_bn='', split_bn=False, log_interval=50, recovery_interval=0, checkpoint_hist=1, save_images=False, amp=False, apex_amp=False, native_amp=False, channels_last=False, pin_mem=True, output='', experiment='', eval_metric='top1', tta=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False, wq_enable=True, wq_mode='LSQ', wq_bitw=32, wq_pos=None, wq_neg=None, wq_per_channel=True, wq_asym=True, aq_enable=True, aq_mode='LSQ', aq_bitw=32, aq_pos=None, aq_neg=None, aq_asym=True, qmodules=['convbn_first;wq:bit:8;aq:bit:8', 'layer1.0.convbn1', 'layer1.0.convbn2', 'layer1.1.convbn1', 'layer1.1.convbn2', 'layer2.0.convbn1', 'layer2.0.convbn2', 'layer2.1.convbn1', 'layer2.1.convbn2', 'layer3.0.convbn1', 'layer3.0.convbn2', 'layer3.1.convbn1', 'layer3.1.convbn2', 'layer4.0.convbn1', 'layer4.0.convbn2', 'layer4.1.convbn1', 'layer4.1.convbn2', 'fc;wq:bit:8;aq:bit:8'], resq_modules=['relu', 'layer1.0.relu2', 'layer1.1.relu2', 'layer2.0.relu2', 'layer3.0.downsample', 'layer2.1.relu2', 'layer3.0.relu2', 'layer3.0.downsample', 'layer3.1.relu2', 'layer4.0.downsample', 'layer4.0.relu2', 'layer4.1.relu2'], resq_enable=True, resq_mode='LSQ', resq_bitw=16, resq_pos=None, resq_neg=None, resq_asym=False, aq_per_channel=False, powerof2=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', device='cuda', seed=0, dist_eval=False, use_kd=True, kd_alpha=4, teacher='ResNet18', teacher_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', log_name='resnet18_imagenet_avgpool_acc15_kd', budget=1, bw_list='5, 5, 5, 5, 5, 4, 4, 3, 4, 3, 3, 3, 3, 2, 2, 2', ba_list='4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3', workers=4, multiprocessing_distributed=True, rank=0, distributed=True, dist_backend='nccl', **{'weight-decay': '5e-3'})
2025-06-01 12:11:47,174 - train - INFO - Model ResNet18 created, param count:11689512
2025-06-01 12:13:39,088 - train - INFO - Namespace(data_dir='/data/dataset/imagenet', dataset='image_folder', train_split='train', val_split='validation', model='ResNet18', pretrained=False, initial_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=224, input_size=None, crop_pct=None, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], interpolation='', batch_size=1024, validation_batch_size_multiplier=1, gpu=0, opt='sgd', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.0001, clip_grad=None, clip_mode='norm', sched='cosine', lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=0.0001, min_lr=1e-05, epochs=300, epoch_repeats=0.0, start_epoch=None, decay_epochs=30, warmup_epochs=0, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0, vflip=0.0, color_jitter=None, aa='rand-m9-mstd0.5-inc1', aug_splits=0, jsd=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=True, dist_bn='', split_bn=False, log_interval=50, recovery_interval=0, checkpoint_hist=1, save_images=False, amp=False, apex_amp=False, native_amp=False, channels_last=False, pin_mem=True, output='', experiment='', eval_metric='top1', tta=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False, wq_enable=True, wq_mode='LSQ', wq_bitw=32, wq_pos=None, wq_neg=None, wq_per_channel=True, wq_asym=True, aq_enable=True, aq_mode='LSQ', aq_bitw=32, aq_pos=None, aq_neg=None, aq_asym=True, qmodules=['convbn_first;wq:bit:8;aq:bit:8', 'layer1.0.convbn1', 'layer1.0.convbn2', 'layer1.1.convbn1', 'layer1.1.convbn2', 'layer2.0.convbn1', 'layer2.0.convbn2', 'layer2.1.convbn1', 'layer2.1.convbn2', 'layer3.0.convbn1', 'layer3.0.convbn2', 'layer3.1.convbn1', 'layer3.1.convbn2', 'layer4.0.convbn1', 'layer4.0.convbn2', 'layer4.1.convbn1', 'layer4.1.convbn2', 'fc;wq:bit:8;aq:bit:8'], resq_modules=['relu', 'layer1.0.relu2', 'layer1.1.relu2', 'layer2.0.relu2', 'layer3.0.downsample', 'layer2.1.relu2', 'layer3.0.relu2', 'layer3.0.downsample', 'layer3.1.relu2', 'layer4.0.downsample', 'layer4.0.relu2', 'layer4.1.relu2'], resq_enable=True, resq_mode='LSQ', resq_bitw=16, resq_pos=None, resq_neg=None, resq_asym=False, aq_per_channel=False, powerof2=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', device='cuda', seed=0, dist_eval=False, use_kd=True, kd_alpha=4, teacher='ResNet18', teacher_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', log_name='resnet18_imagenet_avgpool_acc15_kd', budget=1, bw_list='5, 5, 5, 5, 5, 4, 4, 3, 4, 3, 3, 3, 3, 2, 2, 2', ba_list='4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3', workers=4, multiprocessing_distributed=True, rank=0, distributed=True, dist_backend='nccl', **{'weight-decay': '5e-3'})
2025-06-01 12:13:40,765 - train - INFO - Model ResNet18 created, param count:11689512
2025-06-01 12:14:35,519 - train - INFO - Namespace(data_dir='/data/dataset/imagenet', dataset='image_folder', train_split='train', val_split='validation', model='ResNet18', pretrained=False, initial_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=224, input_size=None, crop_pct=None, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], interpolation='', batch_size=1024, validation_batch_size_multiplier=1, gpu=0, opt='sgd', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.0001, clip_grad=None, clip_mode='norm', sched='cosine', lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=0.0001, min_lr=1e-05, epochs=300, epoch_repeats=0.0, start_epoch=None, decay_epochs=30, warmup_epochs=0, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0, vflip=0.0, color_jitter=None, aa='rand-m9-mstd0.5-inc1', aug_splits=0, jsd=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=True, dist_bn='', split_bn=False, log_interval=50, recovery_interval=0, checkpoint_hist=1, save_images=False, amp=False, apex_amp=False, native_amp=False, channels_last=False, pin_mem=True, output='', experiment='', eval_metric='top1', tta=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False, wq_enable=True, wq_mode='LSQ', wq_bitw=32, wq_pos=None, wq_neg=None, wq_per_channel=True, wq_asym=True, aq_enable=True, aq_mode='LSQ', aq_bitw=32, aq_pos=None, aq_neg=None, aq_asym=True, qmodules=['convbn_first;wq:bit:8;aq:bit:8', 'layer1.0.convbn1', 'layer1.0.convbn2', 'layer1.1.convbn1', 'layer1.1.convbn2', 'layer2.0.convbn1', 'layer2.0.convbn2', 'layer2.1.convbn1', 'layer2.1.convbn2', 'layer3.0.convbn1', 'layer3.0.convbn2', 'layer3.1.convbn1', 'layer3.1.convbn2', 'layer4.0.convbn1', 'layer4.0.convbn2', 'layer4.1.convbn1', 'layer4.1.convbn2', 'fc;wq:bit:8;aq:bit:8'], resq_modules=['relu', 'layer1.0.relu2', 'layer1.1.relu2', 'layer2.0.relu2', 'layer3.0.downsample', 'layer2.1.relu2', 'layer3.0.relu2', 'layer3.0.downsample', 'layer3.1.relu2', 'layer4.0.downsample', 'layer4.0.relu2', 'layer4.1.relu2'], resq_enable=True, resq_mode='LSQ', resq_bitw=16, resq_pos=None, resq_neg=None, resq_asym=False, aq_per_channel=False, powerof2=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', device='cuda', seed=0, dist_eval=False, use_kd=True, kd_alpha=4, teacher='ResNet18', teacher_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', log_name='resnet18_imagenet_avgpool_acc15_kd', budget=1, bw_list='5, 5, 5, 5, 5, 4, 4, 3, 4, 3, 3, 3, 3, 2, 2, 2', ba_list='4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3', workers=4, multiprocessing_distributed=True, rank=0, distributed=True, dist_backend='nccl', **{'weight-decay': '5e-3'})
2025-06-01 12:14:37,796 - train - INFO - Model ResNet18 created, param count:11689512
2025-06-01 12:21:15,140 - train - INFO - Namespace(data_dir='/data/dataset/imagenet', dataset='image_folder', train_split='train', val_split='validation', model='ResNet18', pretrained=False, initial_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=224, input_size=None, crop_pct=None, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], interpolation='', batch_size=1024, validation_batch_size_multiplier=1, gpu=0, opt='sgd', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.0001, clip_grad=None, clip_mode='norm', sched='cosine', lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=0.0001, min_lr=1e-05, epochs=300, epoch_repeats=0.0, start_epoch=None, decay_epochs=30, warmup_epochs=0, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0, vflip=0.0, color_jitter=None, aa='rand-m9-mstd0.5-inc1', aug_splits=0, jsd=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=True, dist_bn='', split_bn=False, log_interval=50, recovery_interval=0, checkpoint_hist=1, save_images=False, amp=False, apex_amp=False, native_amp=False, channels_last=False, pin_mem=True, output='', experiment='', eval_metric='top1', tta=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False, wq_enable=True, wq_mode='LSQ', wq_bitw=32, wq_pos=None, wq_neg=None, wq_per_channel=True, wq_asym=True, aq_enable=True, aq_mode='LSQ', aq_bitw=32, aq_pos=None, aq_neg=None, aq_asym=True, qmodules=['convbn_first;wq:bit:8;aq:bit:8', 'layer1.0.convbn1', 'layer1.0.convbn2', 'layer1.1.convbn1', 'layer1.1.convbn2', 'layer2.0.convbn1', 'layer2.0.convbn2', 'layer2.1.convbn1', 'layer2.1.convbn2', 'layer3.0.convbn1', 'layer3.0.convbn2', 'layer3.1.convbn1', 'layer3.1.convbn2', 'layer4.0.convbn1', 'layer4.0.convbn2', 'layer4.1.convbn1', 'layer4.1.convbn2', 'fc;wq:bit:8;aq:bit:8'], resq_modules=['relu', 'layer1.0.relu2', 'layer1.1.relu2', 'layer2.0.relu2', 'layer3.0.downsample', 'layer2.1.relu2', 'layer3.0.relu2', 'layer3.0.downsample', 'layer3.1.relu2', 'layer4.0.downsample', 'layer4.0.relu2', 'layer4.1.relu2'], resq_enable=True, resq_mode='LSQ', resq_bitw=16, resq_pos=None, resq_neg=None, resq_asym=False, aq_per_channel=False, powerof2=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', device='cuda', seed=0, dist_eval=False, use_kd=True, kd_alpha=4, teacher='ResNet18', teacher_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', log_name='resnet18_imagenet_avgpool_acc15_kd', budget=1, bw_list='5, 5, 5, 5, 5, 4, 4, 3, 4, 3, 3, 3, 3, 2, 2, 2', ba_list='4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3', workers=4, multiprocessing_distributed=True, rank=0, distributed=True, dist_backend='nccl', **{'weight-decay': '5e-3'})
2025-06-01 12:21:17,347 - train - INFO - Model ResNet18 created, param count:11689512
2025-06-01 12:21:18,281 - train - INFO - Converted model to use Synchronized BatchNorm. WARNING: You may have issues if using zero initialized BN layers (enabled by default for ResNets) while sync-bn enabled.
2025-06-01 12:21:18,283 - train - INFO - Using native Torch AMP. Training in mixed precision.
2025-06-01 12:21:18,283 - train - INFO - Scheduled epochs: 310
2025-06-01 12:21:18,283 - train - INFO - Verifying teacher model
2025-06-01 12:21:26,980 - train - INFO - Test: [   0/48]  Time: 8.697 (8.697)  Loss:  0.7266 (0.7266)  Acc@1: 84.4727 (84.4727)  Acc@5: 95.8008 (95.8008)
2025-06-01 12:22:23,876 - train - INFO - Test: [  48/48]  Time: 2.486 (1.339)  Loss:  0.8047 (1.3031)  Acc@1: 82.4293 (71.0160)  Acc@5: 94.6934 (89.6920)
2025-06-01 12:22:24,112 - train - INFO - Verifying initial model in test dataset
2025-06-01 12:22:24,112 - train - INFO - cuda:0
2025-06-01 12:22:31,087 - train - INFO - Test: [   0/48]  Time: 6.974 (6.974)  Loss:  6.5078 (6.5078)  Acc@1:  0.3906 ( 0.3906)  Acc@5:  2.5391 ( 2.5391)
2025-06-01 12:23:28,931 - train - INFO - Test: [  48/48]  Time: 2.268 (1.323)  Loss:  6.1562 (6.6466)  Acc@1:  4.0094 ( 1.2660)  Acc@5: 10.2594 ( 4.0520)
2025-06-01 12:23:29,168 - train - INFO - DistributedDataParallel(
  (module): ResNet(
    (relu): ReLU(
      (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
    )
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (maxpool): AvgPool2d(kernel_size=3, stride=2, padding=1)
    (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (convbn_first): QConvBn2d(
      3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
      (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
      (quan_a_fn): LsqQuantizer(bit=8, pos=127, neg=-127, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
      (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (quan_a_fn): LsqQuantizer(bit=16, pos=32767, neg=-32767, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (quan_a_fn): LsqQuantizer(bit=16, pos=32767, neg=-32767, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): QLinear(
      in_features=512, out_features=1000, bias=True
      (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
      (quan_a_fn): LsqQuantizer(bit=8, pos=255, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
    )
  )
)
2025-06-01 12:30:31,419 - train - INFO - Namespace(data_dir='/data/dataset/imagenet', dataset='image_folder', train_split='train', val_split='validation', model='ResNet18', pretrained=False, initial_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=224, input_size=None, crop_pct=None, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], interpolation='', batch_size=856, validation_batch_size_multiplier=1, gpu=0, opt='sgd', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.0001, clip_grad=None, clip_mode='norm', sched='cosine', lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=0.0001, min_lr=1e-05, epochs=300, epoch_repeats=0.0, start_epoch=None, decay_epochs=30, warmup_epochs=0, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0, vflip=0.0, color_jitter=None, aa='rand-m9-mstd0.5-inc1', aug_splits=0, jsd=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=True, dist_bn='', split_bn=False, log_interval=50, recovery_interval=0, checkpoint_hist=1, save_images=False, amp=False, apex_amp=False, native_amp=False, channels_last=False, pin_mem=True, output='', experiment='', eval_metric='top1', tta=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False, wq_enable=True, wq_mode='LSQ', wq_bitw=32, wq_pos=None, wq_neg=None, wq_per_channel=True, wq_asym=True, aq_enable=True, aq_mode='LSQ', aq_bitw=32, aq_pos=None, aq_neg=None, aq_asym=True, qmodules=['convbn_first;wq:bit:8;aq:bit:8', 'layer1.0.convbn1', 'layer1.0.convbn2', 'layer1.1.convbn1', 'layer1.1.convbn2', 'layer2.0.convbn1', 'layer2.0.convbn2', 'layer2.1.convbn1', 'layer2.1.convbn2', 'layer3.0.convbn1', 'layer3.0.convbn2', 'layer3.1.convbn1', 'layer3.1.convbn2', 'layer4.0.convbn1', 'layer4.0.convbn2', 'layer4.1.convbn1', 'layer4.1.convbn2', 'fc;wq:bit:8;aq:bit:8'], resq_modules=['relu', 'layer1.0.relu2', 'layer1.1.relu2', 'layer2.0.relu2', 'layer3.0.downsample', 'layer2.1.relu2', 'layer3.0.relu2', 'layer3.0.downsample', 'layer3.1.relu2', 'layer4.0.downsample', 'layer4.0.relu2', 'layer4.1.relu2'], resq_enable=True, resq_mode='LSQ', resq_bitw=16, resq_pos=None, resq_neg=None, resq_asym=False, aq_per_channel=False, powerof2=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', device='cuda', seed=0, dist_eval=False, use_kd=True, kd_alpha=4, teacher='ResNet18', teacher_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', log_name='resnet18_imagenet_avgpool_acc15_kd', budget=1, bw_list='5, 5, 5, 5, 5, 4, 4, 3, 4, 3, 3, 3, 3, 2, 2, 2', ba_list='4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3', workers=4, multiprocessing_distributed=True, rank=0, distributed=True, dist_backend='nccl', **{'weight-decay': '5e-3'})
2025-06-01 12:30:34,041 - train - INFO - Model ResNet18 created, param count:11689512
2025-06-01 12:30:34,579 - train - INFO - Converted model to use Synchronized BatchNorm. WARNING: You may have issues if using zero initialized BN layers (enabled by default for ResNets) while sync-bn enabled.
2025-06-01 12:30:34,581 - train - INFO - Using native Torch AMP. Training in mixed precision.
2025-06-01 12:30:34,581 - train - INFO - Scheduled epochs: 310
2025-06-01 12:30:34,581 - train - INFO - Verifying teacher model
2025-06-01 12:30:41,495 - train - INFO - Test: [   0/58]  Time: 6.913 (6.913)  Loss:  0.7388 (0.7388)  Acc@1: 83.4112 (83.4112)  Acc@5: 95.6776 (95.6776)
2025-06-01 12:31:30,172 - train - INFO - Test: [  50/58]  Time: 1.315 (1.090)  Loss:  1.6182 (1.2988)  Acc@1: 63.7850 (71.2067)  Acc@5: 85.6308 (89.7769)
2025-06-01 12:31:37,189 - train - INFO - Test: [  58/58]  Time: 0.241 (1.061)  Loss:  1.0713 (1.3033)  Acc@1: 73.8636 (71.0160)  Acc@5: 91.1932 (89.6920)
2025-06-01 12:31:37,355 - train - INFO - Verifying initial model in test dataset
2025-06-01 12:31:37,355 - train - INFO - cuda:0
2025-06-01 12:31:43,043 - train - INFO - Test: [   0/58]  Time: 5.687 (5.687)  Loss:  6.3828 (6.3828)  Acc@1:  0.4673 ( 0.4673)  Acc@5:  3.0374 ( 3.0374)
2025-06-01 12:32:33,963 - train - INFO - Test: [  50/58]  Time: 1.304 (1.110)  Loss:  6.8711 (6.6806)  Acc@1:  0.1168 ( 1.0583)  Acc@5:  0.4673 ( 3.5207)
2025-06-01 12:32:40,545 - train - INFO - Test: [  58/58]  Time: 0.064 (1.071)  Loss:  6.1836 (6.6469)  Acc@1:  4.8295 ( 1.2660)  Acc@5:  9.9432 ( 4.0520)
2025-06-01 12:32:40,732 - train - INFO - DistributedDataParallel(
  (module): ResNet(
    (relu): ReLU(
      (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
    )
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (maxpool): AvgPool2d(kernel_size=3, stride=2, padding=1)
    (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (convbn_first): QConvBn2d(
      3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
      (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
      (quan_a_fn): LsqQuantizer(bit=8, pos=127, neg=-127, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
      (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (quan_a_fn): LsqQuantizer(bit=16, pos=32767, neg=-32767, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (quan_a_fn): LsqQuantizer(bit=16, pos=32767, neg=-32767, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): QLinear(
      in_features=512, out_features=1000, bias=True
      (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
      (quan_a_fn): LsqQuantizer(bit=8, pos=255, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
    )
  )
)
2025-06-01 12:37:13,833 - train - INFO - Namespace(data_dir='/data/dataset/imagenet', dataset='image_folder', train_split='train', val_split='validation', model='ResNet18', pretrained=False, initial_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=224, input_size=None, crop_pct=None, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], interpolation='', batch_size=792, validation_batch_size_multiplier=1, gpu=0, opt='sgd', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.0001, clip_grad=None, clip_mode='norm', sched='cosine', lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=0.0001, min_lr=1e-05, epochs=300, epoch_repeats=0.0, start_epoch=None, decay_epochs=30, warmup_epochs=0, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0, vflip=0.0, color_jitter=None, aa='rand-m9-mstd0.5-inc1', aug_splits=0, jsd=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=True, dist_bn='', split_bn=False, log_interval=50, recovery_interval=0, checkpoint_hist=1, save_images=False, amp=False, apex_amp=False, native_amp=False, channels_last=False, pin_mem=True, output='', experiment='', eval_metric='top1', tta=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False, wq_enable=True, wq_mode='LSQ', wq_bitw=32, wq_pos=None, wq_neg=None, wq_per_channel=True, wq_asym=True, aq_enable=True, aq_mode='LSQ', aq_bitw=32, aq_pos=None, aq_neg=None, aq_asym=True, qmodules=['convbn_first;wq:bit:8;aq:bit:8', 'layer1.0.convbn1', 'layer1.0.convbn2', 'layer1.1.convbn1', 'layer1.1.convbn2', 'layer2.0.convbn1', 'layer2.0.convbn2', 'layer2.1.convbn1', 'layer2.1.convbn2', 'layer3.0.convbn1', 'layer3.0.convbn2', 'layer3.1.convbn1', 'layer3.1.convbn2', 'layer4.0.convbn1', 'layer4.0.convbn2', 'layer4.1.convbn1', 'layer4.1.convbn2', 'fc;wq:bit:8;aq:bit:8'], resq_modules=['relu', 'layer1.0.relu2', 'layer1.1.relu2', 'layer2.0.relu2', 'layer3.0.downsample', 'layer2.1.relu2', 'layer3.0.relu2', 'layer3.0.downsample', 'layer3.1.relu2', 'layer4.0.downsample', 'layer4.0.relu2', 'layer4.1.relu2'], resq_enable=True, resq_mode='LSQ', resq_bitw=16, resq_pos=None, resq_neg=None, resq_asym=False, aq_per_channel=False, powerof2=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', device='cuda', seed=0, dist_eval=False, use_kd=True, kd_alpha=4, teacher='ResNet18', teacher_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', log_name='resnet18_imagenet_avgpool_acc15_kd', budget=1, bw_list='5, 5, 5, 5, 5, 4, 4, 3, 4, 3, 3, 3, 3, 2, 2, 2', ba_list='4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3', workers=4, multiprocessing_distributed=True, rank=0, distributed=True, dist_backend='nccl', **{'weight-decay': '5e-3'})
2025-06-01 12:37:16,409 - train - INFO - Model ResNet18 created, param count:11689512
2025-06-01 12:37:16,938 - train - INFO - Converted model to use Synchronized BatchNorm. WARNING: You may have issues if using zero initialized BN layers (enabled by default for ResNets) while sync-bn enabled.
2025-06-01 12:37:16,939 - train - INFO - Using native Torch AMP. Training in mixed precision.
2025-06-01 12:37:16,939 - train - INFO - Scheduled epochs: 310
2025-06-01 12:37:16,939 - train - INFO - Verifying teacher model
2025-06-01 12:37:23,545 - train - INFO - Test: [   0/63]  Time: 6.606 (6.606)  Loss:  0.7432 (0.7432)  Acc@1: 83.3333 (83.3333)  Acc@5: 95.4545 (95.4545)
2025-06-01 12:38:09,065 - train - INFO - Test: [  50/63]  Time: 0.067 (1.022)  Loss:  1.4990 (1.2692)  Acc@1: 69.6970 (71.9078)  Acc@5: 86.8687 (90.1268)
2025-06-01 12:38:19,898 - train - INFO - Test: [  63/63]  Time: 0.161 (0.984)  Loss:  2.0137 (1.3032)  Acc@1: 47.1154 (71.0160)  Acc@5: 82.6923 (89.6920)
2025-06-01 12:38:20,073 - train - INFO - Verifying initial model in test dataset
2025-06-01 12:38:20,073 - train - INFO - cuda:0
2025-06-01 12:38:25,173 - train - INFO - Test: [   0/63]  Time: 5.100 (5.100)  Loss:  6.4023 (6.4023)  Acc@1:  0.5051 ( 0.5051)  Acc@5:  3.1566 ( 3.1566)
2025-06-01 12:39:12,804 - train - INFO - Test: [  50/63]  Time: 0.136 (1.034)  Loss:  6.4102 (6.6767)  Acc@1:  4.7980 ( 1.0621)  Acc@5:  8.3333 ( 3.4982)
2025-06-01 12:39:23,531 - train - INFO - Test: [  63/63]  Time: 0.025 (0.992)  Loss:  6.0586 (6.6452)  Acc@1:  0.0000 ( 1.2660)  Acc@5:  2.8846 ( 4.0520)
2025-06-01 12:39:23,728 - train - INFO - DistributedDataParallel(
  (module): ResNet(
    (relu): ReLU(
      (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
    )
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (maxpool): AvgPool2d(kernel_size=3, stride=2, padding=1)
    (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (convbn_first): QConvBn2d(
      3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
      (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
      (quan_a_fn): LsqQuantizer(bit=8, pos=127, neg=-127, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
      (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (quan_a_fn): LsqQuantizer(bit=16, pos=32767, neg=-32767, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (quan_a_fn): LsqQuantizer(bit=16, pos=32767, neg=-32767, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): QLinear(
      in_features=512, out_features=1000, bias=True
      (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
      (quan_a_fn): LsqQuantizer(bit=8, pos=255, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
    )
  )
)
2025-06-01 12:40:16,854 - train - INFO - Namespace(data_dir='/data/dataset/imagenet', dataset='image_folder', train_split='train', val_split='validation', model='ResNet18', pretrained=False, initial_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=224, input_size=None, crop_pct=None, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], interpolation='', batch_size=512, validation_batch_size_multiplier=1, gpu=0, opt='sgd', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.0001, clip_grad=None, clip_mode='norm', sched='cosine', lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=0.0001, min_lr=1e-05, epochs=300, epoch_repeats=0.0, start_epoch=None, decay_epochs=30, warmup_epochs=0, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0, vflip=0.0, color_jitter=None, aa='rand-m9-mstd0.5-inc1', aug_splits=0, jsd=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=True, dist_bn='', split_bn=False, log_interval=50, recovery_interval=0, checkpoint_hist=1, save_images=False, amp=False, apex_amp=False, native_amp=False, channels_last=False, pin_mem=True, output='', experiment='', eval_metric='top1', tta=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False, wq_enable=True, wq_mode='LSQ', wq_bitw=32, wq_pos=None, wq_neg=None, wq_per_channel=True, wq_asym=True, aq_enable=True, aq_mode='LSQ', aq_bitw=32, aq_pos=None, aq_neg=None, aq_asym=True, qmodules=['convbn_first;wq:bit:8;aq:bit:8', 'layer1.0.convbn1', 'layer1.0.convbn2', 'layer1.1.convbn1', 'layer1.1.convbn2', 'layer2.0.convbn1', 'layer2.0.convbn2', 'layer2.1.convbn1', 'layer2.1.convbn2', 'layer3.0.convbn1', 'layer3.0.convbn2', 'layer3.1.convbn1', 'layer3.1.convbn2', 'layer4.0.convbn1', 'layer4.0.convbn2', 'layer4.1.convbn1', 'layer4.1.convbn2', 'fc;wq:bit:8;aq:bit:8'], resq_modules=['relu', 'layer1.0.relu2', 'layer1.1.relu2', 'layer2.0.relu2', 'layer3.0.downsample', 'layer2.1.relu2', 'layer3.0.relu2', 'layer3.0.downsample', 'layer3.1.relu2', 'layer4.0.downsample', 'layer4.0.relu2', 'layer4.1.relu2'], resq_enable=True, resq_mode='LSQ', resq_bitw=16, resq_pos=None, resq_neg=None, resq_asym=False, aq_per_channel=False, powerof2=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', device='cuda', seed=0, dist_eval=False, use_kd=True, kd_alpha=4, teacher='ResNet18', teacher_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', log_name='resnet18_imagenet_avgpool_acc15_kd', budget=1, bw_list='5, 5, 5, 5, 5, 4, 4, 3, 4, 3, 3, 3, 3, 2, 2, 2', ba_list='4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3', workers=4, multiprocessing_distributed=True, rank=0, distributed=True, dist_backend='nccl', **{'weight-decay': '5e-3'})
2025-06-01 12:40:19,500 - train - INFO - Model ResNet18 created, param count:11689512
2025-06-01 12:40:20,009 - train - INFO - Converted model to use Synchronized BatchNorm. WARNING: You may have issues if using zero initialized BN layers (enabled by default for ResNets) while sync-bn enabled.
2025-06-01 12:40:20,011 - train - INFO - Using native Torch AMP. Training in mixed precision.
2025-06-01 12:40:20,011 - train - INFO - Scheduled epochs: 310
2025-06-01 12:40:20,011 - train - INFO - Verifying teacher model
2025-06-01 12:40:20,012 - train - INFO - Verifying initial model in test dataset
2025-06-01 12:40:20,012 - train - INFO - cuda:0
2025-06-01 12:40:20,014 - train - INFO - DistributedDataParallel(
  (module): ResNet(
    (relu): ReLU(
      (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
    )
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (maxpool): AvgPool2d(kernel_size=3, stride=2, padding=1)
    (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (convbn_first): QConvBn2d(
      3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
      (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
      (quan_a_fn): LsqQuantizer(bit=8, pos=127, neg=-127, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
      (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (quan_a_fn): LsqQuantizer(bit=16, pos=32767, neg=-32767, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (quan_a_fn): LsqQuantizer(bit=16, pos=32767, neg=-32767, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): QLinear(
      in_features=512, out_features=1000, bias=True
      (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
      (quan_a_fn): LsqQuantizer(bit=8, pos=255, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
    )
  )
)
2025-06-01 12:40:28,422 - train - INFO - Train: 0 [   0/312 (  0%)]  Loss:  5.299526 (5.2995)  Time: 8.403s,  487.45/s  (8.403s,  487.45/s)  LR: 1.000e-02  Data: 3.626 (3.626)
2025-06-01 12:41:04,335 - train - INFO - Namespace(data_dir='/data/dataset/imagenet', dataset='image_folder', train_split='train', val_split='validation', model='ResNet18', pretrained=False, initial_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=224, input_size=None, crop_pct=None, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], interpolation='', batch_size=712, validation_batch_size_multiplier=1, gpu=0, opt='sgd', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.0001, clip_grad=None, clip_mode='norm', sched='cosine', lr=0.01, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=0.0001, min_lr=1e-05, epochs=300, epoch_repeats=0.0, start_epoch=None, decay_epochs=30, warmup_epochs=0, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0, vflip=0.0, color_jitter=None, aa='rand-m9-mstd0.5-inc1', aug_splits=0, jsd=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=True, dist_bn='', split_bn=False, log_interval=50, recovery_interval=0, checkpoint_hist=1, save_images=False, amp=False, apex_amp=False, native_amp=False, channels_last=False, pin_mem=True, output='', experiment='', eval_metric='top1', tta=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False, wq_enable=True, wq_mode='LSQ', wq_bitw=32, wq_pos=None, wq_neg=None, wq_per_channel=True, wq_asym=True, aq_enable=True, aq_mode='LSQ', aq_bitw=32, aq_pos=None, aq_neg=None, aq_asym=True, qmodules=['convbn_first;wq:bit:8;aq:bit:8', 'layer1.0.convbn1', 'layer1.0.convbn2', 'layer1.1.convbn1', 'layer1.1.convbn2', 'layer2.0.convbn1', 'layer2.0.convbn2', 'layer2.1.convbn1', 'layer2.1.convbn2', 'layer3.0.convbn1', 'layer3.0.convbn2', 'layer3.1.convbn1', 'layer3.1.convbn2', 'layer4.0.convbn1', 'layer4.0.convbn2', 'layer4.1.convbn1', 'layer4.1.convbn2', 'fc;wq:bit:8;aq:bit:8'], resq_modules=['relu', 'layer1.0.relu2', 'layer1.1.relu2', 'layer2.0.relu2', 'layer3.0.downsample', 'layer2.1.relu2', 'layer3.0.relu2', 'layer3.0.downsample', 'layer3.1.relu2', 'layer4.0.downsample', 'layer4.0.relu2', 'layer4.1.relu2'], resq_enable=True, resq_mode='LSQ', resq_bitw=16, resq_pos=None, resq_neg=None, resq_asym=False, aq_per_channel=False, powerof2=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', device='cuda', seed=0, dist_eval=False, use_kd=True, kd_alpha=4, teacher='ResNet18', teacher_checkpoint='output/train/20250427-184912-ResNet18-224/best.pth.tar.pth', log_name='resnet18_imagenet_avgpool_acc15_kd', budget=1, bw_list='5, 5, 5, 5, 5, 4, 4, 3, 4, 3, 3, 3, 3, 2, 2, 2', ba_list='4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3', workers=4, multiprocessing_distributed=True, rank=0, distributed=True, dist_backend='nccl', **{'weight-decay': '5e-3'})
2025-06-01 12:41:05,818 - train - INFO - Model ResNet18 created, param count:11689512
2025-06-01 12:41:07,482 - train - INFO - Converted model to use Synchronized BatchNorm. WARNING: You may have issues if using zero initialized BN layers (enabled by default for ResNets) while sync-bn enabled.
2025-06-01 12:41:07,483 - train - INFO - Using native Torch AMP. Training in mixed precision.
2025-06-01 12:41:07,483 - train - INFO - Scheduled epochs: 310
2025-06-01 12:41:07,483 - train - INFO - Verifying teacher model
2025-06-01 12:41:07,484 - train - INFO - Verifying initial model in test dataset
2025-06-01 12:41:07,484 - train - INFO - cuda:0
2025-06-01 12:41:07,485 - train - INFO - DistributedDataParallel(
  (module): ResNet(
    (relu): ReLU(
      (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
    )
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (maxpool): AvgPool2d(kernel_size=3, stride=2, padding=1)
    (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (convbn_first): QConvBn2d(
      3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
      (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
      (quan_a_fn): LsqQuantizer(bit=8, pos=127, neg=-127, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
      (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=5, pos=15, neg=-16, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=4, pos=7, neg=-8, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=4, pos=15, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (quan_a_fn): LsqQuantizer(bit=16, pos=32767, neg=-32767, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=3, pos=3, neg=-4, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (quan_a_fn): LsqQuantizer(bit=16, pos=32767, neg=-32767, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False, apot=False )
        )
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn1): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convbn2): QConvBn2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (quan_w_fn): LsqQuantizer(bit=2, pos=1, neg=-2, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
          (quan_a_fn): LsqQuantizer(bit=3, pos=7, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential()
        (relu2): ReLU(
          (quan_a_fn): LsqQuantizer(bit=16, pos=65535, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
        )
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): QLinear(
      in_features=512, out_features=1000, bias=True
      (quan_w_fn): LsqQuantizer(bit=8, pos=127, neg=-128, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=False, per_channel=True, apot=False )
      (quan_a_fn): LsqQuantizer(bit=8, pos=255, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False, apot=False )
    )
  )
)
2025-06-01 12:41:16,162 - train - INFO - Train: 0 [   0/224 (  0%)]  Loss:  5.289166 (5.2892)  Time: 8.660s,  657.73/s  (8.660s,  657.73/s)  LR: 1.000e-02  Data: 3.797 (3.797)
2025-06-01 12:41:54,228 - train - INFO - Train: 0 [  50/224 ( 22%)]  Loss:  4.079849 (4.6845)  Time: 0.552s, 10312.94/s  (0.916s, 6217.62/s)  LR: 1.000e-02  Data: 0.000 (0.121)
2025-06-01 12:42:35,892 - train - INFO - Train: 0 [ 100/224 ( 45%)]  Loss:  3.864565 (4.4112)  Time: 0.551s, 10340.52/s  (0.875s, 6509.05/s)  LR: 1.000e-02  Data: 0.000 (0.130)
2025-06-01 12:43:17,191 - train - INFO - Train: 0 [ 150/224 ( 67%)]  Loss:  3.697816 (4.2328)  Time: 0.548s, 10392.23/s  (0.859s, 6632.39/s)  LR: 1.000e-02  Data: 0.000 (0.177)
2025-06-01 12:43:59,074 - train - INFO - Train: 0 [ 200/224 ( 90%)]  Loss:  3.589373 (4.1042)  Time: 0.549s, 10376.57/s  (0.854s, 6673.33/s)  LR: 1.000e-02  Data: 0.000 (0.205)
2025-06-01 12:44:18,156 - train - INFO - Train: 0 [ 223/224 (100%)]  Loss:  3.553037 (4.0123)  Time: 1.298s, 4387.70/s  (0.851s, 6692.63/s)  LR: 1.000e-02  Data: 0.760 (0.213)
2025-06-01 12:44:23,065 - train - INFO - Test: [   0/70]  Time: 4.677 (4.677)  Loss:  1.4678 (1.4678)  Acc@1: 67.7669 (67.7669)  Acc@5: 90.0105 (90.0105)
2025-06-01 12:45:05,171 - train - INFO - Test: [  50/70]  Time: 0.120 (0.917)  Loss:  2.1016 (1.9853)  Acc@1: 55.9691 (57.1801)  Acc@5: 79.7402 (81.3836)
2025-06-01 12:45:21,790 - train - INFO - Test: [  70/70]  Time: 0.396 (0.893)  Loss:  2.7227 (2.0574)  Acc@1: 42.9688 (56.0005)  Acc@5: 69.2969 (80.0728)
2025-06-01 12:45:26,840 - train - INFO - Train: 1 [   0/224 (  0%)]  Loss:  3.579729 (3.5797)  Time: 4.681s, 1216.79/s  (4.681s, 1216.79/s)  LR: 1.000e-02  Data: 3.744 (3.744)
2025-06-01 12:46:07,580 - train - INFO - Train: 1 [  50/224 ( 22%)]  Loss:  3.566122 (3.5729)  Time: 0.548s, 10399.67/s  (0.891s, 6395.85/s)  LR: 1.000e-02  Data: 0.000 (0.240)
2025-06-01 12:46:49,095 - train - INFO - Train: 1 [ 100/224 ( 45%)]  Loss:  3.551277 (3.5657)  Time: 1.336s, 4262.64/s  (0.861s, 6617.70/s)  LR: 1.000e-02  Data: 0.000 (0.157)
2025-06-01 12:47:29,882 - train - INFO - Train: 1 [ 150/224 ( 67%)]  Loss:  3.518439 (3.5539)  Time: 0.550s, 10359.11/s  (0.846s, 6734.35/s)  LR: 1.000e-02  Data: 0.000 (0.105)
2025-06-01 12:48:10,499 - train - INFO - Train: 1 [ 200/224 ( 90%)]  Loss:  3.610004 (3.5651)  Time: 1.416s, 4022.75/s  (0.837s, 6801.44/s)  LR: 1.000e-02  Data: 0.000 (0.079)
2025-06-01 12:48:28,537 - train - INFO - Train: 1 [ 223/224 (100%)]  Loss:  3.559228 (3.5641)  Time: 0.553s, 10303.06/s  (0.832s, 6846.21/s)  LR: 1.000e-02  Data: 0.000 (0.071)
2025-06-01 12:48:33,513 - train - INFO - Test: [   0/70]  Time: 4.730 (4.730)  Loss:  1.4775 (1.4775)  Acc@1: 66.8013 (66.8013)  Acc@5: 89.7121 (89.7121)
2025-06-01 12:49:15,572 - train - INFO - Test: [  50/70]  Time: 0.629 (0.917)  Loss:  1.9971 (2.0331)  Acc@1: 58.4270 (55.5209)  Acc@5: 81.4431 (80.2121)
2025-06-01 12:49:31,722 - train - INFO - Test: [  70/70]  Time: 0.035 (0.886)  Loss:  2.7539 (2.1065)  Acc@1: 45.0000 (54.3113)  Acc@5: 70.0781 (78.8338)
2025-06-01 12:49:36,753 - train - INFO - Train: 2 [   0/224 (  0%)]  Loss:  3.576424 (3.5764)  Time: 4.730s, 1204.25/s  (4.730s, 1204.25/s)  LR: 9.999e-03  Data: 3.851 (3.851)
2025-06-01 12:50:17,894 - train - INFO - Train: 2 [  50/224 ( 22%)]  Loss:  3.505270 (3.5408)  Time: 0.554s, 10275.57/s  (0.899s, 6333.07/s)  LR: 9.999e-03  Data: 0.000 (0.191)
2025-06-01 12:50:59,481 - train - INFO - Train: 2 [ 100/224 ( 45%)]  Loss:  3.554976 (3.5456)  Time: 1.666s, 3418.92/s  (0.866s, 6578.20/s)  LR: 9.999e-03  Data: 0.000 (0.096)
2025-06-01 12:51:40,185 - train - INFO - Train: 2 [ 150/224 ( 67%)]  Loss:  3.488614 (3.5313)  Time: 0.556s, 10243.38/s  (0.849s, 6711.28/s)  LR: 9.999e-03  Data: 0.000 (0.065)
2025-06-01 12:52:21,813 - train - INFO - Train: 2 [ 200/224 ( 90%)]  Loss:  3.461417 (3.5173)  Time: 1.638s, 3478.38/s  (0.845s, 6743.33/s)  LR: 9.999e-03  Data: 0.000 (0.049)
2025-06-01 12:52:39,950 - train - INFO - Train: 2 [ 223/224 (100%)]  Loss:  3.460843 (3.5079)  Time: 0.554s, 10275.93/s  (0.839s, 6789.68/s)  LR: 9.999e-03  Data: 0.000 (0.044)
2025-06-01 12:52:44,695 - train - INFO - Test: [   0/70]  Time: 4.508 (4.508)  Loss:  1.4043 (1.4043)  Acc@1: 71.9628 (71.9628)  Acc@5: 91.0112 (91.0112)
2025-06-01 12:53:27,670 - train - INFO - Test: [  50/70]  Time: 0.121 (0.931)  Loss:  1.9121 (1.8559)  Acc@1: 62.5702 (60.5341)  Acc@5: 82.7072 (83.4734)
2025-06-01 12:53:44,523 - train - INFO - Test: [  70/70]  Time: 0.035 (0.906)  Loss:  2.5000 (1.9342)  Acc@1: 41.0938 (59.0863)  Acc@5: 74.0625 (82.1370)
2025-06-01 12:53:49,301 - train - INFO - Train: 3 [   0/224 (  0%)]  Loss:  3.430814 (3.4308)  Time: 4.346s, 1310.49/s  (4.346s, 1310.49/s)  LR: 9.998e-03  Data: 3.745 (3.745)
2025-06-01 12:54:30,493 - train - INFO - Train: 3 [  50/224 ( 22%)]  Loss:  3.451308 (3.4411)  Time: 0.550s, 10353.46/s  (0.893s, 6379.26/s)  LR: 9.998e-03  Data: 0.000 (0.177)
2025-06-01 12:55:12,571 - train - INFO - Train: 3 [ 100/224 ( 45%)]  Loss:  3.429672 (3.4373)  Time: 1.503s, 3789.85/s  (0.867s, 6566.29/s)  LR: 9.998e-03  Data: 0.000 (0.089)
2025-06-01 12:55:53,472 - train - INFO - Train: 3 [ 150/224 ( 67%)]  Loss:  3.422081 (3.4335)  Time: 0.550s, 10358.15/s  (0.851s, 6692.69/s)  LR: 9.998e-03  Data: 0.000 (0.060)
2025-06-01 12:56:34,987 - train - INFO - Train: 3 [ 200/224 ( 90%)]  Loss:  3.407978 (3.4284)  Time: 1.648s, 3455.91/s  (0.846s, 6733.61/s)  LR: 9.998e-03  Data: 0.000 (0.045)
2025-06-01 12:56:52,869 - train - INFO - Train: 3 [ 223/224 (100%)]  Loss:  3.422197 (3.4273)  Time: 0.544s, 10475.97/s  (0.839s, 6790.12/s)  LR: 9.998e-03  Data: 0.000 (0.040)
2025-06-01 12:56:57,699 - train - INFO - Test: [   0/70]  Time: 4.573 (4.573)  Loss:  1.1963 (1.1963)  Acc@1: 75.2458 (75.2458)  Acc@5: 91.2395 (91.2395)
2025-06-01 12:57:39,268 - train - INFO - Test: [  50/70]  Time: 0.120 (0.905)  Loss:  1.8066 (1.7326)  Acc@1: 60.8322 (61.5344)  Acc@5: 83.3567 (84.1375)
2025-06-01 12:57:55,576 - train - INFO - Test: [  70/70]  Time: 0.039 (0.880)  Loss:  2.3281 (1.8006)  Acc@1: 41.7188 (60.1380)  Acc@5: 79.2969 (82.9888)
2025-06-01 12:58:00,795 - train - INFO - Train: 4 [   0/224 (  0%)]  Loss:  3.373387 (3.3734)  Time: 4.674s, 1218.72/s  (4.674s, 1218.72/s)  LR: 9.996e-03  Data: 4.121 (4.121)
2025-06-01 12:58:41,524 - train - INFO - Train: 4 [  50/224 ( 22%)]  Loss:  3.428145 (3.4008)  Time: 0.549s, 10383.24/s  (0.890s, 6398.35/s)  LR: 9.996e-03  Data: 0.000 (0.341)
2025-06-01 12:59:22,286 - train - INFO - Train: 4 [ 100/224 ( 45%)]  Loss:  3.446140 (3.4159)  Time: 1.512s, 3766.04/s  (0.853s, 6676.91/s)  LR: 9.996e-03  Data: 0.910 (0.304)
2025-06-01 13:00:03,065 - train - INFO - Train: 4 [ 150/224 ( 67%)]  Loss:  3.458379 (3.4265)  Time: 0.555s, 10257.77/s  (0.841s, 6775.63/s)  LR: 9.996e-03  Data: 0.000 (0.237)
2025-06-01 13:00:44,201 - train - INFO - Train: 4 [ 200/224 ( 90%)]  Loss:  3.406373 (3.4225)  Time: 0.909s, 6262.94/s  (0.836s, 6811.82/s)  LR: 9.996e-03  Data: 0.000 (0.186)
2025-06-01 13:01:02,663 - train - INFO - Train: 4 [ 223/224 (100%)]  Loss:  3.370067 (3.4137)  Time: 0.545s, 10446.62/s  (0.833s, 6839.97/s)  LR: 9.996e-03  Data: 0.000 (0.171)
2025-06-01 13:01:07,956 - train - INFO - Test: [   0/70]  Time: 5.057 (5.057)  Loss:  1.0596 (1.0596)  Acc@1: 74.4558 (74.4558)  Acc@5: 92.9951 (92.9951)
2025-06-01 13:01:50,035 - train - INFO - Test: [  50/70]  Time: 0.126 (0.924)  Loss:  1.8008 (1.7317)  Acc@1: 60.2528 (60.6153)  Acc@5: 81.3729 (83.4579)
2025-06-01 13:02:06,565 - train - INFO - Test: [  70/70]  Time: 0.034 (0.897)  Loss:  2.1094 (1.8136)  Acc@1: 48.9844 (58.9480)  Acc@5: 79.7656 (82.0865)
2025-06-01 13:02:11,457 - train - INFO - Train: 5 [   0/224 (  0%)]  Loss:  3.432265 (3.4323)  Time: 4.586s, 1241.99/s  (4.586s, 1241.99/s)  LR: 9.993e-03  Data: 3.783 (3.783)
2025-06-01 13:02:51,667 - train - INFO - Train: 5 [  50/224 ( 22%)]  Loss:  3.432089 (3.4322)  Time: 0.554s, 10277.91/s  (0.878s, 6485.15/s)  LR: 9.993e-03  Data: 0.000 (0.222)
2025-06-01 13:03:33,091 - train - INFO - Train: 5 [ 100/224 ( 45%)]  Loss:  3.457224 (3.4405)  Time: 1.728s, 3295.46/s  (0.854s, 6672.70/s)  LR: 9.993e-03  Data: 0.000 (0.122)
2025-06-01 13:04:13,354 - train - INFO - Train: 5 [ 150/224 ( 67%)]  Loss:  3.373751 (3.4238)  Time: 0.554s, 10284.18/s  (0.838s, 6800.41/s)  LR: 9.993e-03  Data: 0.000 (0.082)
2025-06-01 13:04:55,052 - train - INFO - Train: 5 [ 200/224 ( 90%)]  Loss:  3.439234 (3.4269)  Time: 1.504s, 3786.80/s  (0.837s, 6807.82/s)  LR: 9.993e-03  Data: 0.000 (0.062)
2025-06-01 13:05:12,980 - train - INFO - Train: 5 [ 223/224 (100%)]  Loss:  3.373981 (3.4181)  Time: 0.547s, 10406.48/s  (0.831s, 6856.02/s)  LR: 9.993e-03  Data: 0.000 (0.055)
2025-06-01 13:05:17,860 - train - INFO - Test: [   0/70]  Time: 4.633 (4.633)  Loss:  1.1523 (1.1523)  Acc@1: 74.6840 (74.6840)  Acc@5: 92.0295 (92.0295)
2025-06-01 13:05:59,808 - train - INFO - Test: [  50/70]  Time: 0.120 (0.913)  Loss:  1.7236 (1.7120)  Acc@1: 62.3596 (61.8064)  Acc@5: 83.4796 (84.3537)
2025-06-01 13:06:16,296 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.1641 (1.7838)  Acc@1: 47.8125 (60.3363)  Acc@5: 77.1875 (83.1545)
2025-06-01 13:06:20,967 - train - INFO - Train: 6 [   0/224 (  0%)]  Loss:  3.354261 (3.3543)  Time: 4.246s, 1341.64/s  (4.246s, 1341.64/s)  LR: 9.990e-03  Data: 3.591 (3.591)
2025-06-01 13:07:01,726 - train - INFO - Train: 6 [  50/224 ( 22%)]  Loss:  3.359341 (3.3568)  Time: 0.555s, 10260.89/s  (0.882s, 6454.99/s)  LR: 9.990e-03  Data: 0.000 (0.269)
2025-06-01 13:07:43,941 - train - INFO - Train: 6 [ 100/224 ( 45%)]  Loss:  3.367407 (3.3603)  Time: 1.719s, 3314.10/s  (0.864s, 6596.16/s)  LR: 9.990e-03  Data: 0.000 (0.146)
2025-06-01 13:08:24,808 - train - INFO - Train: 6 [ 150/224 ( 67%)]  Loss:  3.371516 (3.3631)  Time: 0.555s, 10262.18/s  (0.848s, 6715.26/s)  LR: 9.990e-03  Data: 0.000 (0.097)
2025-06-01 13:09:06,913 - train - INFO - Train: 6 [ 200/224 ( 90%)]  Loss:  3.354850 (3.3615)  Time: 1.600s, 3560.66/s  (0.847s, 6727.35/s)  LR: 9.990e-03  Data: 0.000 (0.073)
2025-06-01 13:09:24,695 - train - INFO - Train: 6 [ 223/224 (100%)]  Loss:  3.358617 (3.3610)  Time: 0.544s, 10464.51/s  (0.839s, 6787.99/s)  LR: 9.990e-03  Data: 0.000 (0.066)
2025-06-01 13:09:29,569 - train - INFO - Test: [   0/70]  Time: 4.631 (4.631)  Loss:  1.1455 (1.1455)  Acc@1: 73.6833 (73.6833)  Acc@5: 92.0997 (92.0997)
2025-06-01 13:10:12,007 - train - INFO - Test: [  50/70]  Time: 0.120 (0.923)  Loss:  1.7471 (1.6746)  Acc@1: 61.8855 (62.7616)  Acc@5: 82.6369 (84.8476)
2025-06-01 13:10:28,465 - train - INFO - Test: [  70/70]  Time: 0.034 (0.895)  Loss:  2.1406 (1.7433)  Acc@1: 44.5312 (61.4063)  Acc@5: 81.0938 (83.7313)
2025-06-01 13:10:33,522 - train - INFO - Train: 7 [   0/224 (  0%)]  Loss:  3.340668 (3.3407)  Time: 4.615s, 1234.20/s  (4.615s, 1234.20/s)  LR: 9.987e-03  Data: 3.678 (3.678)
2025-06-01 13:11:14,380 - train - INFO - Train: 7 [  50/224 ( 22%)]  Loss:  3.339835 (3.3403)  Time: 0.549s, 10369.58/s  (0.892s, 6388.49/s)  LR: 9.987e-03  Data: 0.000 (0.139)
2025-06-01 13:11:55,908 - train - INFO - Train: 7 [ 100/224 ( 45%)]  Loss:  3.334327 (3.3383)  Time: 1.609s, 3540.43/s  (0.861s, 6612.80/s)  LR: 9.987e-03  Data: 0.000 (0.070)
2025-06-01 13:12:36,372 - train - INFO - Train: 7 [ 150/224 ( 67%)]  Loss:  3.291625 (3.3266)  Time: 0.548s, 10390.36/s  (0.844s, 6747.95/s)  LR: 9.987e-03  Data: 0.000 (0.047)
2025-06-01 13:13:18,223 - train - INFO - Train: 7 [ 200/224 ( 90%)]  Loss:  3.316965 (3.3247)  Time: 1.531s, 3721.10/s  (0.842s, 6762.18/s)  LR: 9.987e-03  Data: 0.000 (0.035)
2025-06-01 13:13:35,854 - train - INFO - Train: 7 [ 223/224 (100%)]  Loss:  3.312946 (3.3227)  Time: 0.546s, 10437.52/s  (0.835s, 6825.25/s)  LR: 9.987e-03  Data: 0.000 (0.032)
2025-06-01 13:13:40,662 - train - INFO - Test: [   0/70]  Time: 4.572 (4.572)  Loss:  1.1465 (1.1465)  Acc@1: 74.5435 (74.5435)  Acc@5: 91.6433 (91.6433)
2025-06-01 13:14:23,420 - train - INFO - Test: [  50/70]  Time: 0.120 (0.928)  Loss:  1.8027 (1.7238)  Acc@1: 61.9733 (61.0318)  Acc@5: 82.3912 (83.8962)
2025-06-01 13:14:40,174 - train - INFO - Test: [  70/70]  Time: 0.034 (0.903)  Loss:  2.1406 (1.7806)  Acc@1: 47.0312 (59.9533)  Acc@5: 80.2344 (82.9245)
2025-06-01 13:14:45,294 - train - INFO - Train: 8 [   0/224 (  0%)]  Loss:  3.312232 (3.3122)  Time: 4.827s, 1179.93/s  (4.827s, 1179.93/s)  LR: 9.982e-03  Data: 3.633 (3.633)
2025-06-01 13:15:26,301 - train - INFO - Train: 8 [  50/224 ( 22%)]  Loss:  3.311393 (3.3118)  Time: 0.549s, 10383.53/s  (0.899s, 6338.18/s)  LR: 9.982e-03  Data: 0.000 (0.075)
2025-06-01 13:16:07,929 - train - INFO - Train: 8 [ 100/224 ( 45%)]  Loss:  3.304845 (3.3095)  Time: 1.483s, 3842.05/s  (0.866s, 6577.86/s)  LR: 9.982e-03  Data: 0.000 (0.038)
2025-06-01 13:16:49,142 - train - INFO - Train: 8 [ 150/224 ( 67%)]  Loss:  3.306034 (3.3086)  Time: 0.556s, 10242.51/s  (0.852s, 6684.44/s)  LR: 9.982e-03  Data: 0.000 (0.026)
2025-06-01 13:17:30,686 - train - INFO - Train: 8 [ 200/224 ( 90%)]  Loss:  3.261995 (3.2993)  Time: 1.321s, 4311.16/s  (0.847s, 6726.23/s)  LR: 9.982e-03  Data: 0.000 (0.019)
2025-06-01 13:17:48,792 - train - INFO - Train: 8 [ 223/224 (100%)]  Loss:  3.302239 (3.2998)  Time: 0.551s, 10336.66/s  (0.841s, 6775.26/s)  LR: 9.982e-03  Data: 0.000 (0.017)
2025-06-01 13:17:53,499 - train - INFO - Test: [   0/70]  Time: 4.431 (4.431)  Loss:  1.2363 (1.2363)  Acc@1: 72.5597 (72.5597)  Acc@5: 90.8884 (90.8884)
2025-06-01 13:18:36,153 - train - INFO - Test: [  50/70]  Time: 0.120 (0.923)  Loss:  1.7568 (1.7478)  Acc@1: 61.2886 (60.9172)  Acc@5: 82.2507 (83.5877)
2025-06-01 13:18:53,098 - train - INFO - Test: [  70/70]  Time: 0.034 (0.902)  Loss:  2.1367 (1.8025)  Acc@1: 49.2969 (59.6740)  Acc@5: 79.4531 (82.6363)
2025-06-01 13:18:58,065 - train - INFO - Train: 9 [   0/224 (  0%)]  Loss:  3.298296 (3.2983)  Time: 4.650s, 1224.99/s  (4.650s, 1224.99/s)  LR: 9.978e-03  Data: 3.821 (3.821)
2025-06-01 13:19:39,287 - train - INFO - Train: 9 [  50/224 ( 22%)]  Loss:  3.279332 (3.2888)  Time: 0.550s, 10362.76/s  (0.899s, 6332.99/s)  LR: 9.978e-03  Data: 0.000 (0.128)
2025-06-01 13:20:20,196 - train - INFO - Train: 9 [ 100/224 ( 45%)]  Loss:  3.269849 (3.2825)  Time: 1.682s, 3386.87/s  (0.859s, 6629.48/s)  LR: 9.978e-03  Data: 0.000 (0.065)
2025-06-01 13:21:01,527 - train - INFO - Train: 9 [ 150/224 ( 67%)]  Loss:  3.305931 (3.2884)  Time: 0.549s, 10369.76/s  (0.848s, 6713.90/s)  LR: 9.978e-03  Data: 0.000 (0.044)
2025-06-01 13:21:41,482 - train - INFO - Train: 9 [ 200/224 ( 90%)]  Loss:  3.304305 (3.2915)  Time: 0.604s, 9436.24/s  (0.836s, 6812.41/s)  LR: 9.978e-03  Data: 0.000 (0.033)
2025-06-01 13:22:00,457 - train - INFO - Train: 9 [ 223/224 (100%)]  Loss:  3.314246 (3.2953)  Time: 0.544s, 10470.37/s  (0.835s, 6821.77/s)  LR: 9.978e-03  Data: 0.000 (0.030)
2025-06-01 13:22:05,219 - train - INFO - Test: [   0/70]  Time: 4.495 (4.495)  Loss:  1.0967 (1.0967)  Acc@1: 74.3855 (74.3855)  Acc@5: 92.2402 (92.2402)
2025-06-01 13:22:47,352 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  1.6494 (1.6162)  Acc@1: 63.9747 (63.1551)  Acc@5: 83.6552 (85.4201)
2025-06-01 13:23:03,957 - train - INFO - Test: [  70/70]  Time: 0.035 (0.891)  Loss:  2.0840 (1.6886)  Acc@1: 48.8281 (61.7715)  Acc@5: 78.4375 (84.2153)
2025-06-01 13:23:08,899 - train - INFO - Train: 10 [   0/224 (  0%)]  Loss:  3.297634 (3.2976)  Time: 4.494s, 1267.43/s  (4.494s, 1267.43/s)  LR: 9.973e-03  Data: 3.594 (3.594)
2025-06-01 13:23:50,251 - train - INFO - Train: 10 [  50/224 ( 22%)]  Loss:  3.280678 (3.2892)  Time: 0.550s, 10357.23/s  (0.899s, 6336.72/s)  LR: 9.973e-03  Data: 0.000 (0.126)
2025-06-01 13:24:31,313 - train - INFO - Train: 10 [ 100/224 ( 45%)]  Loss:  3.290843 (3.2897)  Time: 0.797s, 7151.22/s  (0.860s, 6619.86/s)  LR: 9.973e-03  Data: 0.000 (0.064)
2025-06-01 13:25:12,915 - train - INFO - Train: 10 [ 150/224 ( 67%)]  Loss:  3.265005 (3.2835)  Time: 0.551s, 10344.04/s  (0.851s, 6693.15/s)  LR: 9.973e-03  Data: 0.000 (0.043)
2025-06-01 13:25:53,980 - train - INFO - Train: 10 [ 200/224 ( 90%)]  Loss:  3.290231 (3.2849)  Time: 1.587s, 3588.20/s  (0.844s, 6751.86/s)  LR: 9.973e-03  Data: 0.000 (0.032)
2025-06-01 13:26:11,743 - train - INFO - Train: 10 [ 223/224 (100%)]  Loss:  3.295385 (3.2866)  Time: 0.546s, 10438.05/s  (0.836s, 6811.01/s)  LR: 9.973e-03  Data: 0.000 (0.029)
2025-06-01 13:26:16,295 - train - INFO - Test: [   0/70]  Time: 4.303 (4.303)  Loss:  1.0996 (1.0996)  Acc@1: 75.7900 (75.7900)  Acc@5: 92.7318 (92.7318)
2025-06-01 13:26:58,526 - train - INFO - Test: [  50/70]  Time: 0.122 (0.912)  Loss:  1.7363 (1.6718)  Acc@1: 62.3771 (62.6312)  Acc@5: 83.0934 (85.0532)
2025-06-01 13:27:14,742 - train - INFO - Test: [  70/70]  Time: 0.034 (0.884)  Loss:  2.1758 (1.7254)  Acc@1: 48.6719 (61.5378)  Acc@5: 78.1250 (84.0900)
2025-06-01 13:27:19,606 - train - INFO - Train: 11 [   0/224 (  0%)]  Loss:  3.331620 (3.3316)  Time: 4.554s, 1250.88/s  (4.554s, 1250.88/s)  LR: 9.967e-03  Data: 3.993 (3.993)
2025-06-01 13:28:00,389 - train - INFO - Train: 11 [  50/224 ( 22%)]  Loss:  3.295557 (3.3136)  Time: 0.549s, 10377.09/s  (0.889s, 6407.72/s)  LR: 9.967e-03  Data: 0.000 (0.115)
2025-06-01 13:28:41,501 - train - INFO - Train: 11 [ 100/224 ( 45%)]  Loss:  3.332045 (3.3197)  Time: 1.321s, 4310.44/s  (0.856s, 6655.11/s)  LR: 9.967e-03  Data: 0.000 (0.058)
2025-06-01 13:29:21,692 - train - INFO - Train: 11 [ 150/224 ( 67%)]  Loss:  3.299663 (3.3147)  Time: 0.555s, 10255.51/s  (0.839s, 6792.00/s)  LR: 9.967e-03  Data: 0.000 (0.039)
2025-06-01 13:30:02,749 - train - INFO - Train: 11 [ 200/224 ( 90%)]  Loss:  3.259241 (3.3036)  Time: 1.434s, 3971.87/s  (0.834s, 6827.48/s)  LR: 9.967e-03  Data: 0.000 (0.029)
2025-06-01 13:30:20,650 - train - INFO - Train: 11 [ 223/224 (100%)]  Loss:  3.260004 (3.2964)  Time: 0.544s, 10466.92/s  (0.829s, 6874.89/s)  LR: 9.967e-03  Data: 0.000 (0.026)
2025-06-01 13:30:25,462 - train - INFO - Test: [   0/70]  Time: 4.585 (4.585)  Loss:  0.9854 (0.9854)  Acc@1: 77.7037 (77.7037)  Acc@5: 94.5225 (94.5225)
2025-06-01 13:31:07,407 - train - INFO - Test: [  50/70]  Time: 0.126 (0.912)  Loss:  1.7559 (1.6043)  Acc@1: 61.8680 (63.8804)  Acc@5: 82.8827 (85.8156)
2025-06-01 13:31:24,091 - train - INFO - Test: [  70/70]  Time: 0.034 (0.890)  Loss:  2.0449 (1.6822)  Acc@1: 49.8438 (62.4363)  Acc@5: 78.8281 (84.5733)
2025-06-01 13:31:29,048 - train - INFO - Train: 12 [   0/224 (  0%)]  Loss:  3.256100 (3.2561)  Time: 4.514s, 1261.91/s  (4.514s, 1261.91/s)  LR: 9.961e-03  Data: 3.796 (3.796)
2025-06-01 13:32:10,250 - train - INFO - Train: 12 [  50/224 ( 22%)]  Loss:  3.217898 (3.2370)  Time: 0.554s, 10284.66/s  (0.896s, 6354.93/s)  LR: 9.961e-03  Data: 0.000 (0.346)
2025-06-01 13:32:51,857 - train - INFO - Train: 12 [ 100/224 ( 45%)]  Loss:  3.280760 (3.2516)  Time: 1.785s, 3191.17/s  (0.865s, 6588.70/s)  LR: 9.961e-03  Data: 0.147 (0.271)
2025-06-01 13:33:31,983 - train - INFO - Train: 12 [ 150/224 ( 67%)]  Loss:  3.284874 (3.2599)  Time: 0.551s, 10346.13/s  (0.844s, 6749.19/s)  LR: 9.961e-03  Data: 0.000 (0.181)
2025-06-01 13:34:13,924 - train - INFO - Train: 12 [ 200/224 ( 90%)]  Loss:  3.275788 (3.2631)  Time: 1.641s, 3471.74/s  (0.843s, 6759.46/s)  LR: 9.961e-03  Data: 0.000 (0.136)
2025-06-01 13:34:31,926 - train - INFO - Train: 12 [ 223/224 (100%)]  Loss:  3.233894 (3.2582)  Time: 0.544s, 10480.18/s  (0.837s, 6809.31/s)  LR: 9.961e-03  Data: 0.000 (0.122)
2025-06-01 13:34:36,878 - train - INFO - Test: [   0/70]  Time: 4.725 (4.725)  Loss:  1.1709 (1.1709)  Acc@1: 73.7008 (73.7008)  Acc@5: 91.7662 (91.7662)
2025-06-01 13:35:19,867 - train - INFO - Test: [  50/70]  Time: 0.121 (0.936)  Loss:  1.8750 (1.6442)  Acc@1: 60.3055 (62.9523)  Acc@5: 80.5302 (85.0335)
2025-06-01 13:35:36,487 - train - INFO - Test: [  70/70]  Time: 0.035 (0.906)  Loss:  1.9531 (1.7202)  Acc@1: 52.9688 (61.5598)  Acc@5: 80.8594 (83.7565)
2025-06-01 13:35:41,474 - train - INFO - Train: 13 [   0/224 (  0%)]  Loss:  3.264398 (3.2644)  Time: 4.665s, 1220.98/s  (4.665s, 1220.98/s)  LR: 9.954e-03  Data: 4.119 (4.119)
2025-06-01 13:36:22,839 - train - INFO - Train: 13 [  50/224 ( 22%)]  Loss:  3.231218 (3.2478)  Time: 0.548s, 10402.30/s  (0.903s, 6311.14/s)  LR: 9.954e-03  Data: 0.000 (0.329)
2025-06-01 13:37:05,312 - train - INFO - Train: 13 [ 100/224 ( 45%)]  Loss:  3.288881 (3.2615)  Time: 1.660s, 3431.92/s  (0.876s, 6500.50/s)  LR: 9.954e-03  Data: 0.000 (0.179)
2025-06-01 13:37:45,210 - train - INFO - Train: 13 [ 150/224 ( 67%)]  Loss:  3.275960 (3.2651)  Time: 0.554s, 10286.25/s  (0.850s, 6698.78/s)  LR: 9.954e-03  Data: 0.000 (0.120)
2025-06-01 13:38:26,684 - train - INFO - Train: 13 [ 200/224 ( 90%)]  Loss:  3.283700 (3.2688)  Time: 1.627s, 3501.08/s  (0.845s, 6739.98/s)  LR: 9.954e-03  Data: 0.000 (0.090)
2025-06-01 13:38:44,498 - train - INFO - Train: 13 [ 223/224 (100%)]  Loss:  3.214212 (3.2597)  Time: 0.551s, 10340.71/s  (0.838s, 6798.35/s)  LR: 9.954e-03  Data: 0.000 (0.081)
2025-06-01 13:38:49,203 - train - INFO - Test: [   0/70]  Time: 4.463 (4.463)  Loss:  1.0664 (1.0664)  Acc@1: 76.0007 (76.0007)  Acc@5: 93.7324 (93.7324)
2025-06-01 13:39:32,219 - train - INFO - Test: [  50/70]  Time: 0.563 (0.931)  Loss:  1.7871 (1.6505)  Acc@1: 62.0435 (63.3169)  Acc@5: 82.3209 (85.3433)
2025-06-01 13:39:48,651 - train - INFO - Test: [  70/70]  Time: 0.035 (0.900)  Loss:  2.3730 (1.7208)  Acc@1: 39.9219 (61.7495)  Acc@5: 76.6406 (84.0838)
2025-06-01 13:39:53,532 - train - INFO - Train: 14 [   0/224 (  0%)]  Loss:  3.318493 (3.3185)  Time: 4.580s, 1243.76/s  (4.580s, 1243.76/s)  LR: 9.946e-03  Data: 3.782 (3.782)
2025-06-01 13:40:35,937 - train - INFO - Train: 14 [  50/224 ( 22%)]  Loss:  3.284739 (3.3016)  Time: 0.556s, 10248.66/s  (0.921s, 6183.00/s)  LR: 9.946e-03  Data: 0.000 (0.125)
2025-06-01 13:41:17,226 - train - INFO - Train: 14 [ 100/224 ( 45%)]  Loss:  3.244939 (3.2827)  Time: 1.576s, 3613.39/s  (0.874s, 6517.61/s)  LR: 9.946e-03  Data: 0.000 (0.063)
2025-06-01 13:41:58,159 - train - INFO - Train: 14 [ 150/224 ( 67%)]  Loss:  3.218200 (3.2666)  Time: 0.555s, 10261.46/s  (0.856s, 6657.19/s)  LR: 9.946e-03  Data: 0.000 (0.042)
2025-06-01 13:42:39,880 - train - INFO - Train: 14 [ 200/224 ( 90%)]  Loss:  3.260386 (3.2654)  Time: 1.915s, 2974.32/s  (0.850s, 6698.59/s)  LR: 9.946e-03  Data: 0.000 (0.032)
2025-06-01 13:42:57,720 - train - INFO - Train: 14 [ 223/224 (100%)]  Loss:  3.239382 (3.2610)  Time: 0.546s, 10441.70/s  (0.843s, 6759.69/s)  LR: 9.946e-03  Data: 0.000 (0.029)
2025-06-01 13:43:02,589 - train - INFO - Test: [   0/70]  Time: 4.598 (4.598)  Loss:  1.2666 (1.2666)  Acc@1: 72.4368 (72.4368)  Acc@5: 91.0990 (91.0990)
2025-06-01 13:43:44,702 - train - INFO - Test: [  50/70]  Time: 0.120 (0.916)  Loss:  1.8848 (1.7220)  Acc@1: 59.7261 (61.1819)  Acc@5: 81.2325 (83.9726)
2025-06-01 13:44:01,265 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.5078 (1.7800)  Acc@1: 42.5781 (60.0345)  Acc@5: 73.5156 (82.9363)
2025-06-01 13:44:06,270 - train - INFO - Train: 15 [   0/224 (  0%)]  Loss:  3.198726 (3.1987)  Time: 4.713s, 1208.45/s  (4.713s, 1208.45/s)  LR: 9.939e-03  Data: 4.168 (4.168)
2025-06-01 13:44:47,942 - train - INFO - Train: 15 [  50/224 ( 22%)]  Loss:  3.239832 (3.2193)  Time: 0.556s, 10246.34/s  (0.909s, 6262.86/s)  LR: 9.939e-03  Data: 0.000 (0.193)
2025-06-01 13:45:30,280 - train - INFO - Train: 15 [ 100/224 ( 45%)]  Loss:  3.187535 (3.2087)  Time: 1.613s, 3531.19/s  (0.878s, 6484.41/s)  LR: 9.939e-03  Data: 0.000 (0.098)
2025-06-01 13:46:11,196 - train - INFO - Train: 15 [ 150/224 ( 67%)]  Loss:  3.238745 (3.2162)  Time: 0.556s, 10250.77/s  (0.859s, 6634.80/s)  LR: 9.939e-03  Data: 0.000 (0.065)
2025-06-01 13:46:53,131 - train - INFO - Train: 15 [ 200/224 ( 90%)]  Loss:  3.245057 (3.2220)  Time: 1.560s, 3651.60/s  (0.854s, 6673.12/s)  LR: 9.939e-03  Data: 0.000 (0.049)
2025-06-01 13:47:11,615 - train - INFO - Train: 15 [ 223/224 (100%)]  Loss:  3.239394 (3.2249)  Time: 0.552s, 10317.11/s  (0.848s, 6713.51/s)  LR: 9.939e-03  Data: 0.000 (0.044)
2025-06-01 13:47:16,266 - train - INFO - Test: [   0/70]  Time: 4.419 (4.419)  Loss:  1.1611 (1.1611)  Acc@1: 76.8961 (76.8961)  Acc@5: 91.5379 (91.5379)
2025-06-01 13:47:59,609 - train - INFO - Test: [  50/70]  Time: 0.120 (0.936)  Loss:  1.7119 (1.6733)  Acc@1: 63.1320 (63.1028)  Acc@5: 83.9537 (85.1248)
2025-06-01 13:48:16,498 - train - INFO - Test: [  70/70]  Time: 0.034 (0.911)  Loss:  2.3086 (1.7509)  Acc@1: 45.7812 (61.6198)  Acc@5: 77.5781 (83.9503)
2025-06-01 13:48:21,933 - train - INFO - Train: 16 [   0/224 (  0%)]  Loss:  3.302345 (3.3023)  Time: 5.137s, 1108.72/s  (5.137s, 1108.72/s)  LR: 9.930e-03  Data: 4.206 (4.206)
2025-06-01 13:49:03,385 - train - INFO - Train: 16 [  50/224 ( 22%)]  Loss:  3.258370 (3.2804)  Time: 0.551s, 10338.16/s  (0.913s, 6235.48/s)  LR: 9.930e-03  Data: 0.000 (0.158)
2025-06-01 13:49:45,568 - train - INFO - Train: 16 [ 100/224 ( 45%)]  Loss:  3.237590 (3.2661)  Time: 1.439s, 3957.31/s  (0.879s, 6480.81/s)  LR: 9.930e-03  Data: 0.000 (0.091)
2025-06-01 13:50:26,414 - train - INFO - Train: 16 [ 150/224 ( 67%)]  Loss:  3.292410 (3.2727)  Time: 0.550s, 10347.56/s  (0.858s, 6635.83/s)  LR: 9.930e-03  Data: 0.000 (0.061)
2025-06-01 13:51:07,867 - train - INFO - Train: 16 [ 200/224 ( 90%)]  Loss:  3.230770 (3.2643)  Time: 1.646s, 3461.05/s  (0.851s, 6692.79/s)  LR: 9.930e-03  Data: 0.000 (0.046)
2025-06-01 13:51:26,295 - train - INFO - Train: 16 [ 223/224 (100%)]  Loss:  3.226392 (3.2580)  Time: 0.545s, 10447.10/s  (0.846s, 6733.30/s)  LR: 9.930e-03  Data: 0.000 (0.041)
2025-06-01 13:51:31,724 - train - INFO - Test: [   0/70]  Time: 5.193 (5.193)  Loss:  1.0723 (1.0723)  Acc@1: 76.0183 (76.0183)  Acc@5: 92.8722 (92.8722)
2025-06-01 13:52:14,176 - train - INFO - Test: [  50/70]  Time: 0.120 (0.934)  Loss:  1.8760 (1.6670)  Acc@1: 60.0421 (62.4322)  Acc@5: 81.0393 (84.6841)
2025-06-01 13:52:30,881 - train - INFO - Test: [  70/70]  Time: 0.034 (0.906)  Loss:  2.3242 (1.7391)  Acc@1: 40.7812 (61.0650)  Acc@5: 75.3906 (83.5265)
2025-06-01 13:52:35,961 - train - INFO - Train: 17 [   0/224 (  0%)]  Loss:  3.268443 (3.2684)  Time: 4.777s, 1192.39/s  (4.777s, 1192.39/s)  LR: 9.921e-03  Data: 3.524 (3.524)
2025-06-01 13:53:17,116 - train - INFO - Train: 17 [  50/224 ( 22%)]  Loss:  3.205806 (3.2371)  Time: 0.549s, 10373.13/s  (0.901s, 6324.50/s)  LR: 9.921e-03  Data: 0.000 (0.212)
2025-06-01 13:53:59,612 - train - INFO - Train: 17 [ 100/224 ( 45%)]  Loss:  3.265918 (3.2467)  Time: 1.753s, 3249.99/s  (0.875s, 6506.21/s)  LR: 9.921e-03  Data: 0.000 (0.107)
2025-06-01 13:54:40,776 - train - INFO - Train: 17 [ 150/224 ( 67%)]  Loss:  3.286290 (3.2566)  Time: 0.550s, 10362.01/s  (0.858s, 6637.41/s)  LR: 9.921e-03  Data: 0.000 (0.072)
2025-06-01 13:55:22,819 - train - INFO - Train: 17 [ 200/224 ( 90%)]  Loss:  3.237530 (3.2528)  Time: 1.564s, 3641.07/s  (0.854s, 6671.01/s)  LR: 9.921e-03  Data: 0.000 (0.054)
2025-06-01 13:55:40,604 - train - INFO - Train: 17 [ 223/224 (100%)]  Loss:  3.241298 (3.2509)  Time: 0.546s, 10436.60/s  (0.846s, 6736.33/s)  LR: 9.921e-03  Data: 0.000 (0.049)
2025-06-01 13:55:45,463 - train - INFO - Test: [   0/70]  Time: 4.627 (4.627)  Loss:  0.9912 (0.9912)  Acc@1: 76.2992 (76.2992)  Acc@5: 94.2591 (94.2591)
2025-06-01 13:56:27,570 - train - INFO - Test: [  50/70]  Time: 0.120 (0.916)  Loss:  1.7402 (1.6789)  Acc@1: 63.0618 (62.9713)  Acc@5: 83.4796 (85.0125)
2025-06-01 13:56:44,307 - train - INFO - Test: [  70/70]  Time: 0.034 (0.894)  Loss:  2.3535 (1.7501)  Acc@1: 38.9062 (61.5918)  Acc@5: 77.2656 (83.8600)
2025-06-01 13:56:49,262 - train - INFO - Train: 18 [   0/224 (  0%)]  Loss:  3.322438 (3.3224)  Time: 4.660s, 1222.27/s  (4.660s, 1222.27/s)  LR: 9.912e-03  Data: 4.096 (4.096)
2025-06-01 13:57:30,122 - train - INFO - Train: 18 [  50/224 ( 22%)]  Loss:  3.249872 (3.2862)  Time: 0.597s, 9541.06/s  (0.892s, 6382.16/s)  LR: 9.912e-03  Data: 0.000 (0.190)
2025-06-01 13:58:12,129 - train - INFO - Train: 18 [ 100/224 ( 45%)]  Loss:  3.216133 (3.2628)  Time: 1.556s, 3661.09/s  (0.867s, 6573.15/s)  LR: 9.912e-03  Data: 0.000 (0.096)
2025-06-01 13:58:53,089 - train - INFO - Train: 18 [ 150/224 ( 67%)]  Loss:  3.238512 (3.2567)  Time: 0.556s, 10250.42/s  (0.851s, 6694.40/s)  LR: 9.912e-03  Data: 0.000 (0.064)
2025-06-01 13:59:34,506 - train - INFO - Train: 18 [ 200/224 ( 90%)]  Loss:  3.257276 (3.2568)  Time: 0.859s, 6633.76/s  (0.845s, 6738.83/s)  LR: 9.912e-03  Data: 0.000 (0.048)
2025-06-01 13:59:53,292 - train - INFO - Train: 18 [ 223/224 (100%)]  Loss:  3.245569 (3.2550)  Time: 0.552s, 10325.61/s  (0.842s, 6762.23/s)  LR: 9.912e-03  Data: 0.000 (0.044)
2025-06-01 13:59:58,130 - train - INFO - Test: [   0/70]  Time: 4.597 (4.597)  Loss:  1.2832 (1.2832)  Acc@1: 74.8420 (74.8420)  Acc@5: 92.4860 (92.4860)
2025-06-01 14:00:40,198 - train - INFO - Test: [  50/70]  Time: 0.120 (0.915)  Loss:  1.8926 (1.8507)  Acc@1: 62.4298 (61.5523)  Acc@5: 82.9881 (84.2359)
2025-06-01 14:00:57,099 - train - INFO - Test: [  70/70]  Time: 0.034 (0.895)  Loss:  2.2637 (1.9310)  Acc@1: 48.3594 (60.0508)  Acc@5: 80.5469 (82.8603)
2025-06-01 14:01:01,892 - train - INFO - Train: 19 [   0/224 (  0%)]  Loss:  3.255093 (3.2551)  Time: 4.488s, 1269.09/s  (4.488s, 1269.09/s)  LR: 9.901e-03  Data: 3.786 (3.786)
2025-06-01 14:01:43,293 - train - INFO - Train: 19 [  50/224 ( 22%)]  Loss:  3.201565 (3.2283)  Time: 0.558s, 10205.32/s  (0.900s, 6330.83/s)  LR: 9.901e-03  Data: 0.000 (0.129)
2025-06-01 14:02:25,657 - train - INFO - Train: 19 [ 100/224 ( 45%)]  Loss:  3.175960 (3.2109)  Time: 1.632s, 3490.44/s  (0.874s, 6519.25/s)  LR: 9.901e-03  Data: 0.000 (0.065)
2025-06-01 14:03:06,459 - train - INFO - Train: 19 [ 150/224 ( 67%)]  Loss:  3.166725 (3.1998)  Time: 0.549s, 10378.25/s  (0.855s, 6665.20/s)  LR: 9.901e-03  Data: 0.000 (0.044)
2025-06-01 14:03:47,575 - train - INFO - Train: 19 [ 200/224 ( 90%)]  Loss:  3.250708 (3.2100)  Time: 1.497s, 3803.98/s  (0.847s, 6728.54/s)  LR: 9.901e-03  Data: 0.000 (0.033)
2025-06-01 14:04:06,104 - train - INFO - Train: 19 [ 223/224 (100%)]  Loss:  3.212831 (3.2105)  Time: 0.546s, 10437.74/s  (0.842s, 6762.26/s)  LR: 9.901e-03  Data: 0.000 (0.029)
2025-06-01 14:04:11,042 - train - INFO - Test: [   0/70]  Time: 4.682 (4.682)  Loss:  1.2969 (1.2969)  Acc@1: 72.1735 (72.1735)  Acc@5: 91.1517 (91.1517)
2025-06-01 14:04:53,895 - train - INFO - Test: [  50/70]  Time: 0.120 (0.932)  Loss:  1.8164 (1.7767)  Acc@1: 60.7444 (60.7495)  Acc@5: 82.9529 (83.5901)
2025-06-01 14:05:10,646 - train - INFO - Test: [  70/70]  Time: 0.034 (0.905)  Loss:  2.3750 (1.8497)  Acc@1: 45.2344 (59.3948)  Acc@5: 74.9219 (82.4000)
2025-06-01 14:05:15,733 - train - INFO - Train: 20 [   0/224 (  0%)]  Loss:  3.220276 (3.2203)  Time: 4.777s, 1192.41/s  (4.777s, 1192.41/s)  LR: 9.891e-03  Data: 3.890 (3.890)
2025-06-01 14:05:56,957 - train - INFO - Train: 20 [  50/224 ( 22%)]  Loss:  3.239384 (3.2298)  Time: 0.555s, 10269.16/s  (0.902s, 6315.46/s)  LR: 9.891e-03  Data: 0.000 (0.257)
2025-06-01 14:06:39,071 - train - INFO - Train: 20 [ 100/224 ( 45%)]  Loss:  3.236379 (3.2320)  Time: 1.737s, 3279.83/s  (0.872s, 6529.45/s)  LR: 9.891e-03  Data: 0.000 (0.181)
2025-06-01 14:07:20,105 - train - INFO - Train: 20 [ 150/224 ( 67%)]  Loss:  3.196661 (3.2232)  Time: 0.557s, 10234.72/s  (0.855s, 6660.31/s)  LR: 9.891e-03  Data: 0.000 (0.121)
2025-06-01 14:08:01,844 - train - INFO - Train: 20 [ 200/224 ( 90%)]  Loss:  3.471997 (3.2729)  Time: 1.488s, 3827.97/s  (0.850s, 6700.24/s)  LR: 9.891e-03  Data: 0.000 (0.091)
2025-06-01 14:08:19,814 - train - INFO - Train: 20 [ 223/224 (100%)]  Loss:  3.317532 (3.2804)  Time: 0.545s, 10449.72/s  (0.843s, 6756.57/s)  LR: 9.891e-03  Data: 0.000 (0.082)
2025-06-01 14:08:24,434 - train - INFO - Test: [   0/70]  Time: 4.381 (4.381)  Loss:  1.5264 (1.5264)  Acc@1: 71.0323 (71.0323)  Acc@5: 89.2907 (89.2907)
2025-06-01 14:09:06,344 - train - INFO - Test: [  50/70]  Time: 0.120 (0.908)  Loss:  2.0566 (1.9548)  Acc@1: 58.1812 (59.0738)  Acc@5: 79.4066 (82.4542)
2025-06-01 14:09:22,755 - train - INFO - Test: [  70/70]  Time: 0.034 (0.883)  Loss:  2.4980 (2.0189)  Acc@1: 38.3594 (57.8375)  Acc@5: 75.2344 (81.2725)
2025-06-01 14:09:27,768 - train - INFO - Train: 21 [   0/224 (  0%)]  Loss:  3.287797 (3.2878)  Time: 4.718s, 1207.33/s  (4.718s, 1207.33/s)  LR: 9.880e-03  Data: 3.545 (3.545)
2025-06-01 14:10:10,101 - train - INFO - Train: 21 [  50/224 ( 22%)]  Loss:  3.274370 (3.2811)  Time: 0.550s, 10359.41/s  (0.923s, 6174.27/s)  LR: 9.880e-03  Data: 0.000 (0.072)
2025-06-01 14:10:51,744 - train - INFO - Train: 21 [ 100/224 ( 45%)]  Loss:  3.248489 (3.2702)  Time: 1.243s, 4580.82/s  (0.878s, 6486.46/s)  LR: 9.880e-03  Data: 0.000 (0.037)
2025-06-01 14:11:33,572 - train - INFO - Train: 21 [ 150/224 ( 67%)]  Loss:  3.266309 (3.2692)  Time: 0.548s, 10385.58/s  (0.864s, 6589.88/s)  LR: 9.880e-03  Data: 0.000 (0.025)
2025-06-01 14:12:13,965 - train - INFO - Train: 21 [ 200/224 ( 90%)]  Loss:  3.236306 (3.2627)  Time: 0.550s, 10356.50/s  (0.850s, 6698.80/s)  LR: 9.880e-03  Data: 0.000 (0.018)
2025-06-01 14:12:32,742 - train - INFO - Train: 21 [ 223/224 (100%)]  Loss:  3.211998 (3.2542)  Time: 0.545s, 10454.19/s  (0.847s, 6726.43/s)  LR: 9.880e-03  Data: 0.000 (0.017)
2025-06-01 14:12:37,737 - train - INFO - Test: [   0/70]  Time: 4.743 (4.743)  Loss:  1.1348 (1.1348)  Acc@1: 75.8954 (75.8954)  Acc@5: 92.5913 (92.5913)
2025-06-01 14:13:19,864 - train - INFO - Test: [  50/70]  Time: 0.121 (0.919)  Loss:  1.6934 (1.7021)  Acc@1: 66.5379 (62.9764)  Acc@5: 83.2338 (84.7392)
2025-06-01 14:13:36,352 - train - INFO - Test: [  70/70]  Time: 0.034 (0.892)  Loss:  1.9697 (1.7720)  Acc@1: 50.1562 (61.4935)  Acc@5: 83.8281 (83.6378)
2025-06-01 14:13:41,200 - train - INFO - Train: 22 [   0/224 (  0%)]  Loss:  3.264819 (3.2648)  Time: 4.546s, 1253.06/s  (4.546s, 1253.06/s)  LR: 9.868e-03  Data: 3.994 (3.994)
2025-06-01 14:14:22,254 - train - INFO - Train: 22 [  50/224 ( 22%)]  Loss:  3.228626 (3.2467)  Time: 0.564s, 10094.27/s  (0.894s, 6371.12/s)  LR: 9.868e-03  Data: 0.000 (0.143)
2025-06-01 14:15:03,970 - train - INFO - Train: 22 [ 100/224 ( 45%)]  Loss:  3.218635 (3.2374)  Time: 1.613s, 3531.21/s  (0.864s, 6589.01/s)  LR: 9.868e-03  Data: 0.000 (0.072)
2025-06-01 14:15:46,496 - train - INFO - Train: 22 [ 150/224 ( 67%)]  Loss:  3.258494 (3.2426)  Time: 0.552s, 10322.44/s  (0.860s, 6624.51/s)  LR: 9.868e-03  Data: 0.000 (0.048)
2025-06-01 14:16:27,480 - train - INFO - Train: 22 [ 200/224 ( 90%)]  Loss:  3.207844 (3.2357)  Time: 1.529s, 3725.12/s  (0.850s, 6702.41/s)  LR: 9.868e-03  Data: 0.000 (0.036)
2025-06-01 14:16:45,477 - train - INFO - Train: 22 [ 223/224 (100%)]  Loss:  3.266648 (3.2408)  Time: 0.545s, 10447.67/s  (0.843s, 6757.45/s)  LR: 9.868e-03  Data: 0.000 (0.033)
2025-06-01 14:16:50,352 - train - INFO - Test: [   0/70]  Time: 4.644 (4.644)  Loss:  1.1377 (1.1377)  Acc@1: 75.5267 (75.5267)  Acc@5: 92.3455 (92.3455)
2025-06-01 14:17:32,359 - train - INFO - Test: [  50/70]  Time: 0.120 (0.915)  Loss:  1.7344 (1.6354)  Acc@1: 62.2191 (63.5093)  Acc@5: 82.3736 (85.5664)
2025-06-01 14:17:48,708 - train - INFO - Test: [  70/70]  Time: 0.034 (0.887)  Loss:  2.3848 (1.7070)  Acc@1: 44.6094 (62.0048)  Acc@5: 76.3281 (84.3503)
2025-06-01 14:17:53,644 - train - INFO - Train: 23 [   0/224 (  0%)]  Loss:  3.207374 (3.2074)  Time: 4.642s, 1226.96/s  (4.642s, 1226.96/s)  LR: 9.856e-03  Data: 4.095 (4.095)
2025-06-01 14:18:34,295 - train - INFO - Train: 23 [  50/224 ( 22%)]  Loss:  3.211536 (3.2095)  Time: 0.550s, 10352.85/s  (0.888s, 6413.84/s)  LR: 9.856e-03  Data: 0.000 (0.220)
2025-06-01 14:19:15,749 - train - INFO - Train: 23 [ 100/224 ( 45%)]  Loss:  3.205604 (3.2082)  Time: 1.085s, 5251.09/s  (0.859s, 6632.05/s)  LR: 9.856e-03  Data: 0.000 (0.121)
2025-06-01 14:19:56,515 - train - INFO - Train: 23 [ 150/224 ( 67%)]  Loss:  3.281381 (3.2265)  Time: 0.549s, 10371.12/s  (0.844s, 6745.34/s)  LR: 9.856e-03  Data: 0.000 (0.081)
2025-06-01 14:20:37,711 - train - INFO - Train: 23 [ 200/224 ( 90%)]  Loss:  3.228478 (3.2269)  Time: 1.032s, 5520.89/s  (0.839s, 6786.45/s)  LR: 9.856e-03  Data: 0.000 (0.061)
2025-06-01 14:20:56,131 - train - INFO - Train: 23 [ 223/224 (100%)]  Loss:  3.235244 (3.2283)  Time: 0.552s, 10320.01/s  (0.835s, 6818.55/s)  LR: 9.856e-03  Data: 0.000 (0.055)
2025-06-01 14:21:00,968 - train - INFO - Test: [   0/70]  Time: 4.580 (4.580)  Loss:  1.1885 (1.1885)  Acc@1: 76.2289 (76.2289)  Acc@5: 92.0471 (92.0471)
2025-06-01 14:21:43,273 - train - INFO - Test: [  50/70]  Time: 0.120 (0.919)  Loss:  1.9893 (1.6716)  Acc@1: 57.5492 (62.9620)  Acc@5: 79.4066 (85.1089)
2025-06-01 14:22:00,020 - train - INFO - Test: [  70/70]  Time: 0.035 (0.896)  Loss:  2.3320 (1.7444)  Acc@1: 43.0469 (61.6533)  Acc@5: 78.6719 (83.9825)
2025-06-01 14:22:04,922 - train - INFO - Train: 24 [   0/224 (  0%)]  Loss:  3.226875 (3.2269)  Time: 4.605s, 1236.96/s  (4.605s, 1236.96/s)  LR: 9.843e-03  Data: 3.985 (3.985)
2025-06-01 14:22:46,397 - train - INFO - Train: 24 [  50/224 ( 22%)]  Loss:  3.197653 (3.2123)  Time: 0.548s, 10387.85/s  (0.903s, 6304.39/s)  LR: 9.843e-03  Data: 0.000 (0.188)
2025-06-01 14:23:27,437 - train - INFO - Train: 24 [ 100/224 ( 45%)]  Loss:  3.244200 (3.2229)  Time: 1.578s, 3609.21/s  (0.863s, 6603.66/s)  LR: 9.843e-03  Data: 0.000 (0.095)
2025-06-01 14:24:07,751 - train - INFO - Train: 24 [ 150/224 ( 67%)]  Loss:  3.222735 (3.2229)  Time: 0.767s, 7428.16/s  (0.844s, 6749.55/s)  LR: 9.843e-03  Data: 0.000 (0.064)
2025-06-01 14:24:48,926 - train - INFO - Train: 24 [ 200/224 ( 90%)]  Loss:  3.246495 (3.2276)  Time: 1.023s, 5567.54/s  (0.839s, 6790.40/s)  LR: 9.843e-03  Data: 0.000 (0.048)
2025-06-01 14:25:07,355 - train - INFO - Train: 24 [ 223/224 (100%)]  Loss:  3.251782 (3.2316)  Time: 0.546s, 10436.74/s  (0.835s, 6821.85/s)  LR: 9.843e-03  Data: 0.000 (0.043)
2025-06-01 14:25:12,044 - train - INFO - Test: [   0/70]  Time: 4.452 (4.452)  Loss:  1.1406 (1.1406)  Acc@1: 75.8954 (75.8954)  Acc@5: 92.2753 (92.2753)
2025-06-01 14:25:53,970 - train - INFO - Test: [  50/70]  Time: 0.120 (0.909)  Loss:  1.7744 (1.6677)  Acc@1: 62.7985 (63.1916)  Acc@5: 84.0063 (85.4470)
2025-06-01 14:26:10,600 - train - INFO - Test: [  70/70]  Time: 0.034 (0.887)  Loss:  1.8916 (1.7416)  Acc@1: 54.8438 (61.6018)  Acc@5: 82.9688 (84.1503)
2025-06-01 14:26:15,526 - train - INFO - Train: 25 [   0/224 (  0%)]  Loss:  3.211047 (3.2110)  Time: 4.606s, 1236.70/s  (4.606s, 1236.70/s)  LR: 9.830e-03  Data: 3.652 (3.652)
2025-06-01 14:26:56,924 - train - INFO - Train: 25 [  50/224 ( 22%)]  Loss:  3.203409 (3.2072)  Time: 0.551s, 10342.19/s  (0.902s, 6314.75/s)  LR: 9.830e-03  Data: 0.000 (0.077)
2025-06-01 14:27:38,848 - train - INFO - Train: 25 [ 100/224 ( 45%)]  Loss:  3.217376 (3.2106)  Time: 1.718s, 3316.34/s  (0.871s, 6543.00/s)  LR: 9.830e-03  Data: 0.000 (0.039)
2025-06-01 14:28:19,936 - train - INFO - Train: 25 [ 150/224 ( 67%)]  Loss:  3.229505 (3.2153)  Time: 0.549s, 10370.94/s  (0.854s, 6666.73/s)  LR: 9.830e-03  Data: 0.000 (0.026)
2025-06-01 14:29:01,921 - train - INFO - Train: 25 [ 200/224 ( 90%)]  Loss:  3.225620 (3.2174)  Time: 1.589s, 3584.43/s  (0.851s, 6695.44/s)  LR: 9.830e-03  Data: 0.000 (0.020)
2025-06-01 14:29:19,728 - train - INFO - Train: 25 [ 223/224 (100%)]  Loss:  3.215464 (3.2171)  Time: 0.547s, 10413.65/s  (0.843s, 6757.86/s)  LR: 9.830e-03  Data: 0.000 (0.018)
2025-06-01 14:29:24,601 - train - INFO - Test: [   0/70]  Time: 4.614 (4.614)  Loss:  1.2227 (1.2227)  Acc@1: 75.7900 (75.7900)  Acc@5: 92.3631 (92.3631)
2025-06-01 14:30:06,202 - train - INFO - Test: [  50/70]  Time: 0.120 (0.906)  Loss:  1.8965 (1.7287)  Acc@1: 63.1496 (63.7269)  Acc@5: 83.7956 (85.7034)
2025-06-01 14:30:22,650 - train - INFO - Test: [  70/70]  Time: 0.034 (0.883)  Loss:  2.1582 (1.7971)  Acc@1: 44.2969 (62.3828)  Acc@5: 82.8906 (84.5348)
2025-06-01 14:30:27,628 - train - INFO - Train: 26 [   0/224 (  0%)]  Loss:  3.232449 (3.2324)  Time: 4.665s, 1221.08/s  (4.665s, 1221.08/s)  LR: 9.816e-03  Data: 3.932 (3.932)
2025-06-01 14:31:08,527 - train - INFO - Train: 26 [  50/224 ( 22%)]  Loss:  3.192104 (3.2123)  Time: 0.548s, 10387.89/s  (0.893s, 6375.66/s)  LR: 9.816e-03  Data: 0.000 (0.186)
2025-06-01 14:31:50,087 - train - INFO - Train: 26 [ 100/224 ( 45%)]  Loss:  3.183446 (3.2027)  Time: 1.649s, 3453.36/s  (0.863s, 6603.32/s)  LR: 9.816e-03  Data: 0.000 (0.094)
2025-06-01 14:32:31,071 - train - INFO - Train: 26 [ 150/224 ( 67%)]  Loss:  3.240768 (3.2122)  Time: 0.556s, 10244.32/s  (0.848s, 6714.01/s)  LR: 9.816e-03  Data: 0.000 (0.063)
2025-06-01 14:33:13,168 - train - INFO - Train: 26 [ 200/224 ( 90%)]  Loss:  3.214190 (3.2126)  Time: 1.894s, 3007.71/s  (0.847s, 6726.80/s)  LR: 9.816e-03  Data: 0.000 (0.047)
2025-06-01 14:33:30,988 - train - INFO - Train: 26 [ 223/224 (100%)]  Loss:  3.207332 (3.2117)  Time: 0.552s, 10323.51/s  (0.839s, 6786.11/s)  LR: 9.816e-03  Data: 0.000 (0.042)
2025-06-01 14:33:35,900 - train - INFO - Test: [   0/70]  Time: 4.670 (4.670)  Loss:  0.9814 (0.9814)  Acc@1: 76.9136 (76.9136)  Acc@5: 93.9607 (93.9607)
2025-06-01 14:34:17,564 - train - INFO - Test: [  50/70]  Time: 0.120 (0.909)  Loss:  1.8281 (1.6773)  Acc@1: 61.2535 (63.1072)  Acc@5: 81.6362 (85.2022)
2025-06-01 14:34:33,731 - train - INFO - Test: [  70/70]  Time: 0.034 (0.880)  Loss:  2.2363 (1.7536)  Acc@1: 46.4844 (61.5740)  Acc@5: 79.4531 (83.8865)
2025-06-01 14:34:38,567 - train - INFO - Train: 27 [   0/224 (  0%)]  Loss:  3.219108 (3.2191)  Time: 4.534s, 1256.17/s  (4.534s, 1256.17/s)  LR: 9.802e-03  Data: 3.887 (3.887)
2025-06-01 14:35:19,210 - train - INFO - Train: 27 [  50/224 ( 22%)]  Loss:  3.278275 (3.2487)  Time: 0.547s, 10415.35/s  (0.886s, 6430.16/s)  LR: 9.802e-03  Data: 0.000 (0.201)
2025-06-01 14:36:01,139 - train - INFO - Train: 27 [ 100/224 ( 45%)]  Loss:  3.228546 (3.2420)  Time: 1.589s, 3583.68/s  (0.862s, 6604.74/s)  LR: 9.802e-03  Data: 0.000 (0.106)
2025-06-01 14:36:40,618 - train - INFO - Train: 27 [ 150/224 ( 67%)]  Loss:  3.236794 (3.2407)  Time: 0.550s, 10363.15/s  (0.838s, 6794.85/s)  LR: 9.802e-03  Data: 0.000 (0.071)
2025-06-01 14:37:22,104 - train - INFO - Train: 27 [ 200/224 ( 90%)]  Loss:  3.258765 (3.2443)  Time: 1.629s, 3496.92/s  (0.836s, 6812.23/s)  LR: 9.802e-03  Data: 0.000 (0.054)
2025-06-01 14:37:39,808 - train - INFO - Train: 27 [ 223/224 (100%)]  Loss:  3.221550 (3.2405)  Time: 0.546s, 10435.90/s  (0.829s, 6868.27/s)  LR: 9.802e-03  Data: 0.000 (0.048)
2025-06-01 14:37:44,665 - train - INFO - Test: [   0/70]  Time: 4.615 (4.615)  Loss:  1.2334 (1.2334)  Acc@1: 74.9649 (74.9649)  Acc@5: 92.2753 (92.2753)
2025-06-01 14:38:26,552 - train - INFO - Test: [  50/70]  Time: 0.120 (0.912)  Loss:  1.7607 (1.7588)  Acc@1: 64.8525 (62.3361)  Acc@5: 83.9537 (84.5354)
2025-06-01 14:38:42,932 - train - INFO - Test: [  70/70]  Time: 0.034 (0.886)  Loss:  2.5742 (1.8437)  Acc@1: 41.6406 (60.5748)  Acc@5: 73.7500 (83.0265)
2025-06-01 14:38:47,660 - train - INFO - Train: 28 [   0/224 (  0%)]  Loss:  3.246459 (3.2465)  Time: 4.421s, 1288.51/s  (4.421s, 1288.51/s)  LR: 9.787e-03  Data: 3.619 (3.619)
2025-06-01 14:39:27,959 - train - INFO - Train: 28 [  50/224 ( 22%)]  Loss:  3.198541 (3.2225)  Time: 0.548s, 10386.19/s  (0.877s, 6496.04/s)  LR: 9.787e-03  Data: 0.000 (0.232)
2025-06-01 14:40:08,865 - train - INFO - Train: 28 [ 100/224 ( 45%)]  Loss:  3.219071 (3.2214)  Time: 1.619s, 3517.92/s  (0.848s, 6718.87/s)  LR: 9.787e-03  Data: 0.001 (0.126)
2025-06-01 14:40:49,163 - train - INFO - Train: 28 [ 150/224 ( 67%)]  Loss:  3.175196 (3.2098)  Time: 0.689s, 8263.95/s  (0.834s, 6830.55/s)  LR: 9.787e-03  Data: 0.000 (0.085)
2025-06-01 14:41:30,324 - train - INFO - Train: 28 [ 200/224 ( 90%)]  Loss:  3.227296 (3.2133)  Time: 1.325s, 4298.45/s  (0.831s, 6852.43/s)  LR: 9.787e-03  Data: 0.000 (0.064)
2025-06-01 14:41:48,547 - train - INFO - Train: 28 [ 223/224 (100%)]  Loss:  3.213031 (3.2133)  Time: 0.546s, 10425.60/s  (0.827s, 6885.57/s)  LR: 9.787e-03  Data: 0.000 (0.057)
2025-06-01 14:41:53,301 - train - INFO - Test: [   0/70]  Time: 4.513 (4.513)  Loss:  1.0342 (1.0342)  Acc@1: 77.2999 (77.2999)  Acc@5: 92.9249 (92.9249)
2025-06-01 14:42:35,038 - train - INFO - Test: [  50/70]  Time: 0.121 (0.907)  Loss:  1.7002 (1.6335)  Acc@1: 63.1496 (62.9847)  Acc@5: 82.7247 (85.2029)
2025-06-01 14:42:51,366 - train - INFO - Test: [  70/70]  Time: 0.034 (0.881)  Loss:  2.3965 (1.6961)  Acc@1: 37.9688 (61.7613)  Acc@5: 74.7656 (84.0858)
2025-06-01 14:42:56,240 - train - INFO - Train: 29 [   0/224 (  0%)]  Loss:  3.225122 (3.2251)  Time: 4.580s, 1243.55/s  (4.580s, 1243.55/s)  LR: 9.771e-03  Data: 4.022 (4.022)
2025-06-01 14:43:37,369 - train - INFO - Train: 29 [  50/224 ( 22%)]  Loss:  3.237231 (3.2312)  Time: 0.549s, 10369.40/s  (0.896s, 6355.79/s)  LR: 9.771e-03  Data: 0.000 (0.179)
2025-06-01 14:44:17,777 - train - INFO - Train: 29 [ 100/224 ( 45%)]  Loss:  3.216284 (3.2262)  Time: 0.551s, 10329.10/s  (0.853s, 6680.81/s)  LR: 9.771e-03  Data: 0.000 (0.090)
2025-06-01 14:44:59,237 - train - INFO - Train: 29 [ 150/224 ( 67%)]  Loss:  3.258624 (3.2343)  Time: 0.550s, 10353.12/s  (0.845s, 6742.11/s)  LR: 9.771e-03  Data: 0.000 (0.061)
2025-06-01 14:45:40,773 - train - INFO - Train: 29 [ 200/224 ( 90%)]  Loss:  3.209143 (3.2293)  Time: 1.061s, 5369.47/s  (0.841s, 6770.31/s)  LR: 9.771e-03  Data: 0.000 (0.046)
2025-06-01 14:45:59,355 - train - INFO - Train: 29 [ 223/224 (100%)]  Loss:  3.248264 (3.2324)  Time: 0.547s, 10422.54/s  (0.838s, 6798.05/s)  LR: 9.771e-03  Data: 0.000 (0.041)
2025-06-01 14:46:04,252 - train - INFO - Test: [   0/70]  Time: 4.650 (4.650)  Loss:  1.0684 (1.0684)  Acc@1: 75.4565 (75.4565)  Acc@5: 92.5737 (92.5737)
2025-06-01 14:46:46,341 - train - INFO - Test: [  50/70]  Time: 0.120 (0.916)  Loss:  1.6348 (1.6376)  Acc@1: 63.9572 (62.8549)  Acc@5: 84.3223 (85.0711)
2025-06-01 14:47:02,618 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.2266 (1.7073)  Acc@1: 43.2031 (61.5048)  Acc@5: 78.1250 (83.9493)
2025-06-01 14:47:07,521 - train - INFO - Train: 30 [   0/224 (  0%)]  Loss:  3.239278 (3.2393)  Time: 4.612s, 1234.99/s  (4.612s, 1234.99/s)  LR: 9.756e-03  Data: 3.945 (3.945)
2025-06-01 14:47:48,215 - train - INFO - Train: 30 [  50/224 ( 22%)]  Loss:  3.229184 (3.2342)  Time: 0.548s, 10394.02/s  (0.888s, 6411.92/s)  LR: 9.756e-03  Data: 0.000 (0.257)
2025-06-01 14:48:29,973 - train - INFO - Train: 30 [ 100/224 ( 45%)]  Loss:  3.184117 (3.2175)  Time: 1.575s, 3616.90/s  (0.862s, 6608.03/s)  LR: 9.756e-03  Data: 0.860 (0.247)
2025-06-01 14:49:10,815 - train - INFO - Train: 30 [ 150/224 ( 67%)]  Loss:  3.263152 (3.2289)  Time: 0.909s, 6266.42/s  (0.847s, 6724.68/s)  LR: 9.756e-03  Data: 0.000 (0.223)
2025-06-01 14:49:52,199 - train - INFO - Train: 30 [ 200/224 ( 90%)]  Loss:  3.194389 (3.2220)  Time: 1.138s, 5005.05/s  (0.842s, 6763.14/s)  LR: 9.756e-03  Data: 0.338 (0.204)
2025-06-01 14:50:10,522 - train - INFO - Train: 30 [ 223/224 (100%)]  Loss:  3.243139 (3.2255)  Time: 0.544s, 10461.27/s  (0.838s, 6801.00/s)  LR: 9.756e-03  Data: 0.000 (0.188)
2025-06-01 14:50:15,180 - train - INFO - Test: [   0/70]  Time: 4.411 (4.411)  Loss:  1.1914 (1.1914)  Acc@1: 73.5955 (73.5955)  Acc@5: 91.6959 (91.6959)
2025-06-01 14:50:57,058 - train - INFO - Test: [  50/70]  Time: 0.120 (0.908)  Loss:  1.8252 (1.6997)  Acc@1: 62.0084 (62.7358)  Acc@5: 81.3905 (84.9578)
2025-06-01 14:51:13,549 - train - INFO - Test: [  70/70]  Time: 0.035 (0.884)  Loss:  2.1367 (1.7804)  Acc@1: 51.5625 (61.1005)  Acc@5: 78.5938 (83.5048)
2025-06-01 14:51:18,562 - train - INFO - Train: 31 [   0/224 (  0%)]  Loss:  3.217918 (3.2179)  Time: 4.712s, 1208.75/s  (4.712s, 1208.75/s)  LR: 9.739e-03  Data: 4.167 (4.167)
2025-06-01 14:51:59,541 - train - INFO - Train: 31 [  50/224 ( 22%)]  Loss:  3.206393 (3.2122)  Time: 0.554s, 10290.58/s  (0.896s, 6358.24/s)  LR: 9.739e-03  Data: 0.000 (0.173)
2025-06-01 14:52:40,893 - train - INFO - Train: 31 [ 100/224 ( 45%)]  Loss:  3.202168 (3.2088)  Time: 1.508s, 3778.36/s  (0.862s, 6609.73/s)  LR: 9.739e-03  Data: 0.000 (0.087)
2025-06-01 14:53:21,585 - train - INFO - Train: 31 [ 150/224 ( 67%)]  Loss:  3.186720 (3.2033)  Time: 0.556s, 10252.94/s  (0.846s, 6733.80/s)  LR: 9.739e-03  Data: 0.000 (0.059)
2025-06-01 14:54:02,657 - train - INFO - Train: 31 [ 200/224 ( 90%)]  Loss:  3.182153 (3.1991)  Time: 0.556s, 10239.44/s  (0.840s, 6782.57/s)  LR: 9.739e-03  Data: 0.000 (0.044)
2025-06-01 14:54:21,382 - train - INFO - Train: 31 [ 223/224 (100%)]  Loss:  3.242403 (3.2063)  Time: 0.553s, 10301.34/s  (0.837s, 6803.95/s)  LR: 9.739e-03  Data: 0.000 (0.040)
2025-06-01 14:54:26,247 - train - INFO - Test: [   0/70]  Time: 4.618 (4.618)  Loss:  1.3105 (1.3105)  Acc@1: 73.0337 (73.0337)  Acc@5: 91.1166 (91.1166)
2025-06-01 14:55:08,261 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  1.7588 (1.6757)  Acc@1: 61.3062 (63.6670)  Acc@5: 83.0056 (85.6205)
2025-06-01 14:55:24,933 - train - INFO - Test: [  70/70]  Time: 0.034 (0.892)  Loss:  1.9883 (1.7509)  Acc@1: 49.5312 (62.1470)  Acc@5: 83.4375 (84.4735)
2025-06-01 14:55:29,801 - train - INFO - Train: 32 [   0/224 (  0%)]  Loss:  3.162932 (3.1629)  Time: 4.566s, 1247.48/s  (4.566s, 1247.48/s)  LR: 9.722e-03  Data: 4.010 (4.010)
2025-06-01 14:56:10,799 - train - INFO - Train: 32 [  50/224 ( 22%)]  Loss:  3.174603 (3.1688)  Time: 0.551s, 10335.96/s  (0.893s, 6375.83/s)  LR: 9.722e-03  Data: 0.000 (0.312)
2025-06-01 14:56:52,221 - train - INFO - Train: 32 [ 100/224 ( 45%)]  Loss:  3.255722 (3.1978)  Time: 0.973s, 5856.01/s  (0.861s, 6613.87/s)  LR: 9.722e-03  Data: 0.013 (0.238)
2025-06-01 14:57:33,215 - train - INFO - Train: 32 [ 150/224 ( 67%)]  Loss:  3.238984 (3.2081)  Time: 0.550s, 10358.94/s  (0.848s, 6720.78/s)  LR: 9.722e-03  Data: 0.000 (0.184)
2025-06-01 14:58:15,119 - train - INFO - Train: 32 [ 200/224 ( 90%)]  Loss:  3.251913 (3.2168)  Time: 1.637s, 3480.50/s  (0.845s, 6739.48/s)  LR: 9.722e-03  Data: 0.000 (0.142)
2025-06-01 14:58:33,266 - train - INFO - Train: 32 [ 223/224 (100%)]  Loss:  3.207262 (3.2152)  Time: 0.547s, 10413.70/s  (0.839s, 6785.82/s)  LR: 9.722e-03  Data: 0.000 (0.127)
2025-06-01 14:58:38,076 - train - INFO - Test: [   0/70]  Time: 4.559 (4.559)  Loss:  1.1699 (1.1699)  Acc@1: 73.8413 (73.8413)  Acc@5: 91.1868 (91.1868)
2025-06-01 14:59:19,657 - train - INFO - Test: [  50/70]  Time: 0.120 (0.905)  Loss:  1.7295 (1.6737)  Acc@1: 63.6763 (62.1836)  Acc@5: 82.3034 (84.7024)
2025-06-01 14:59:35,866 - train - INFO - Test: [  70/70]  Time: 0.034 (0.878)  Loss:  2.2793 (1.7480)  Acc@1: 47.0312 (60.7870)  Acc@5: 75.1562 (83.4535)
2025-06-01 14:59:40,642 - train - INFO - Train: 33 [   0/224 (  0%)]  Loss:  3.248892 (3.2489)  Time: 4.464s, 1276.09/s  (4.464s, 1276.09/s)  LR: 9.705e-03  Data: 3.601 (3.601)
2025-06-01 15:00:22,377 - train - INFO - Train: 33 [  50/224 ( 22%)]  Loss:  3.245016 (3.2470)  Time: 0.550s, 10363.65/s  (0.906s, 6288.11/s)  LR: 9.705e-03  Data: 0.000 (0.079)
2025-06-01 15:01:02,869 - train - INFO - Train: 33 [ 100/224 ( 45%)]  Loss:  3.193603 (3.2292)  Time: 0.783s, 7274.13/s  (0.858s, 6636.41/s)  LR: 9.705e-03  Data: 0.000 (0.040)
2025-06-01 15:01:44,099 - train - INFO - Train: 33 [ 150/224 ( 67%)]  Loss:  3.210129 (3.2244)  Time: 0.556s, 10248.77/s  (0.847s, 6723.97/s)  LR: 9.705e-03  Data: 0.000 (0.027)
2025-06-01 15:02:24,608 - train - INFO - Train: 33 [ 200/224 ( 90%)]  Loss:  3.207566 (3.2210)  Time: 0.595s, 9580.81/s  (0.838s, 6797.80/s)  LR: 9.705e-03  Data: 0.000 (0.020)
2025-06-01 15:02:43,096 - train - INFO - Train: 33 [ 223/224 (100%)]  Loss:  3.200579 (3.2176)  Time: 0.546s, 10427.08/s  (0.834s, 6826.32/s)  LR: 9.705e-03  Data: 0.000 (0.018)
2025-06-01 15:02:47,838 - train - INFO - Test: [   0/70]  Time: 4.492 (4.492)  Loss:  1.1787 (1.1787)  Acc@1: 76.2114 (76.2114)  Acc@5: 92.5913 (92.5913)
2025-06-01 15:03:30,150 - train - INFO - Test: [  50/70]  Time: 0.120 (0.918)  Loss:  1.7939 (1.6994)  Acc@1: 62.8862 (63.2236)  Acc@5: 82.9178 (85.3375)
2025-06-01 15:03:46,576 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.4219 (1.7617)  Acc@1: 37.8125 (61.8388)  Acc@5: 77.4219 (84.2715)
2025-06-01 15:03:51,428 - train - INFO - Train: 34 [   0/224 (  0%)]  Loss:  3.175873 (3.1759)  Time: 4.552s, 1251.41/s  (4.552s, 1251.41/s)  LR: 9.687e-03  Data: 3.497 (3.497)
2025-06-01 15:04:32,238 - train - INFO - Train: 34 [  50/224 ( 22%)]  Loss:  3.183746 (3.1798)  Time: 0.551s, 10336.55/s  (0.889s, 6404.30/s)  LR: 9.687e-03  Data: 0.000 (0.179)
2025-06-01 15:05:13,800 - train - INFO - Train: 34 [ 100/224 ( 45%)]  Loss:  3.231764 (3.1971)  Time: 1.737s, 3279.62/s  (0.861s, 6618.76/s)  LR: 9.687e-03  Data: 0.000 (0.093)
2025-06-01 15:05:54,262 - train - INFO - Train: 34 [ 150/224 ( 67%)]  Loss:  3.206306 (3.1994)  Time: 0.550s, 10358.07/s  (0.844s, 6752.20/s)  LR: 9.687e-03  Data: 0.001 (0.062)
2025-06-01 15:06:35,596 - train - INFO - Train: 34 [ 200/224 ( 90%)]  Loss:  3.198800 (3.1993)  Time: 1.506s, 3782.35/s  (0.839s, 6786.06/s)  LR: 9.687e-03  Data: 0.000 (0.047)
2025-06-01 15:06:53,211 - train - INFO - Train: 34 [ 223/224 (100%)]  Loss:  3.172976 (3.1949)  Time: 0.545s, 10449.72/s  (0.832s, 6847.63/s)  LR: 9.687e-03  Data: 0.000 (0.042)
2025-06-01 15:06:57,807 - train - INFO - Test: [   0/70]  Time: 4.360 (4.360)  Loss:  1.1094 (1.1094)  Acc@1: 75.1053 (75.1053)  Acc@5: 93.3638 (93.3638)
2025-06-01 15:07:39,608 - train - INFO - Test: [  50/70]  Time: 0.120 (0.905)  Loss:  1.6025 (1.7525)  Acc@1: 64.4663 (62.2026)  Acc@5: 85.5161 (84.5347)
2025-06-01 15:07:55,806 - train - INFO - Test: [  70/70]  Time: 0.034 (0.878)  Loss:  1.9434 (1.8116)  Acc@1: 51.7188 (60.8813)  Acc@5: 81.9531 (83.3283)
2025-06-01 15:08:01,134 - train - INFO - Train: 35 [   0/224 (  0%)]  Loss:  3.176574 (3.1766)  Time: 5.008s, 1137.41/s  (5.008s, 1137.41/s)  LR: 9.668e-03  Data: 4.465 (4.465)
2025-06-01 15:08:41,943 - train - INFO - Train: 35 [  50/224 ( 22%)]  Loss:  3.228742 (3.2027)  Time: 0.549s, 10383.05/s  (0.898s, 6340.47/s)  LR: 9.668e-03  Data: 0.000 (0.301)
2025-06-01 15:09:24,539 - train - INFO - Train: 35 [ 100/224 ( 45%)]  Loss:  3.240466 (3.2153)  Time: 1.557s, 3657.91/s  (0.875s, 6507.07/s)  LR: 9.668e-03  Data: 0.000 (0.157)
2025-06-01 15:10:04,827 - train - INFO - Train: 35 [ 150/224 ( 67%)]  Loss:  3.189875 (3.2089)  Time: 0.555s, 10269.23/s  (0.852s, 6683.08/s)  LR: 9.668e-03  Data: 0.000 (0.105)
2025-06-01 15:10:45,171 - train - INFO - Train: 35 [ 200/224 ( 90%)]  Loss:  3.208859 (3.2089)  Time: 1.124s, 5065.38/s  (0.841s, 6772.93/s)  LR: 9.668e-03  Data: 0.000 (0.079)
2025-06-01 15:11:03,199 - train - INFO - Train: 35 [ 223/224 (100%)]  Loss:  3.222292 (3.2111)  Time: 0.676s, 8432.00/s  (0.835s, 6820.55/s)  LR: 9.668e-03  Data: 0.000 (0.071)
2025-06-01 15:11:07,870 - train - INFO - Test: [   0/70]  Time: 4.415 (4.415)  Loss:  1.1113 (1.1113)  Acc@1: 75.7374 (75.7374)  Acc@5: 92.3279 (92.3279)
2025-06-01 15:11:49,463 - train - INFO - Test: [  50/70]  Time: 0.120 (0.902)  Loss:  1.7402 (1.6549)  Acc@1: 62.2191 (62.7062)  Acc@5: 83.1987 (85.2118)
2025-06-01 15:12:05,653 - train - INFO - Test: [  70/70]  Time: 0.034 (0.876)  Loss:  2.3633 (1.7317)  Acc@1: 44.9219 (61.1280)  Acc@5: 76.7188 (83.8863)
2025-06-01 15:12:10,689 - train - INFO - Train: 36 [   0/224 (  0%)]  Loss:  3.203122 (3.2031)  Time: 4.727s, 1204.92/s  (4.727s, 1204.92/s)  LR: 9.649e-03  Data: 4.104 (4.104)
2025-06-01 15:12:52,192 - train - INFO - Train: 36 [  50/224 ( 22%)]  Loss:  3.261119 (3.2321)  Time: 0.550s, 10349.19/s  (0.906s, 6283.84/s)  LR: 9.649e-03  Data: 0.000 (0.147)
2025-06-01 15:13:34,144 - train - INFO - Train: 36 [ 100/224 ( 45%)]  Loss:  3.239050 (3.2344)  Time: 1.456s, 3912.65/s  (0.873s, 6524.14/s)  LR: 9.649e-03  Data: 0.000 (0.075)
2025-06-01 15:14:14,565 - train - INFO - Train: 36 [ 150/224 ( 67%)]  Loss:  3.204508 (3.2269)  Time: 0.550s, 10350.02/s  (0.852s, 6688.17/s)  LR: 9.649e-03  Data: 0.000 (0.050)
2025-06-01 15:14:55,664 - train - INFO - Train: 36 [ 200/224 ( 90%)]  Loss:  3.191985 (3.2200)  Time: 1.629s, 3497.53/s  (0.844s, 6746.71/s)  LR: 9.649e-03  Data: 0.000 (0.038)
2025-06-01 15:15:13,446 - train - INFO - Train: 36 [ 223/224 (100%)]  Loss:  3.203800 (3.2173)  Time: 0.545s, 10455.31/s  (0.837s, 6805.66/s)  LR: 9.649e-03  Data: 0.000 (0.034)
2025-06-01 15:15:18,171 - train - INFO - Test: [   0/70]  Time: 4.478 (4.478)  Loss:  1.4541 (1.4541)  Acc@1: 74.8596 (74.8596)  Acc@5: 90.2563 (90.2563)
2025-06-01 15:15:59,580 - train - INFO - Test: [  50/70]  Time: 0.120 (0.900)  Loss:  1.7568 (1.8801)  Acc@1: 65.0632 (61.1809)  Acc@5: 83.7430 (83.8752)
2025-06-01 15:16:15,814 - train - INFO - Test: [  70/70]  Time: 0.034 (0.875)  Loss:  2.3906 (1.9359)  Acc@1: 40.3906 (59.9240)  Acc@5: 80.0000 (82.8345)
2025-06-01 15:16:20,689 - train - INFO - Train: 37 [   0/224 (  0%)]  Loss:  3.210974 (3.2110)  Time: 4.578s, 1244.27/s  (4.578s, 1244.27/s)  LR: 9.630e-03  Data: 4.017 (4.017)
2025-06-01 15:17:01,554 - train - INFO - Train: 37 [  50/224 ( 22%)]  Loss:  3.192286 (3.2016)  Time: 0.552s, 10325.77/s  (0.891s, 6392.73/s)  LR: 9.630e-03  Data: 0.000 (0.341)
2025-06-01 15:17:43,304 - train - INFO - Train: 37 [ 100/224 ( 45%)]  Loss:  3.239461 (3.2142)  Time: 1.805s, 3155.17/s  (0.863s, 6598.17/s)  LR: 9.630e-03  Data: 0.435 (0.269)
2025-06-01 15:18:22,994 - train - INFO - Train: 37 [ 150/224 ( 67%)]  Loss:  3.188002 (3.2077)  Time: 0.549s, 10372.23/s  (0.840s, 6778.86/s)  LR: 9.630e-03  Data: 0.000 (0.182)
2025-06-01 15:19:03,874 - train - INFO - Train: 37 [ 200/224 ( 90%)]  Loss:  3.219227 (3.2100)  Time: 1.648s, 3457.08/s  (0.835s, 6824.71/s)  LR: 9.630e-03  Data: 0.000 (0.137)
2025-06-01 15:19:21,822 - train - INFO - Train: 37 [ 223/224 (100%)]  Loss:  3.131082 (3.1968)  Time: 0.546s, 10440.50/s  (0.829s, 6870.63/s)  LR: 9.630e-03  Data: 0.000 (0.123)
2025-06-01 15:19:26,608 - train - INFO - Test: [   0/70]  Time: 4.543 (4.543)  Loss:  1.4131 (1.4131)  Acc@1: 71.9803 (71.9803)  Acc@5: 89.6945 (89.6945)
2025-06-01 15:20:08,456 - train - INFO - Test: [  50/70]  Time: 0.120 (0.910)  Loss:  1.8184 (1.8145)  Acc@1: 62.5527 (60.6597)  Acc@5: 82.9881 (83.6425)
2025-06-01 15:20:24,790 - train - INFO - Test: [  70/70]  Time: 0.034 (0.883)  Loss:  2.3828 (1.8785)  Acc@1: 43.6719 (59.5540)  Acc@5: 78.2812 (82.5275)
2025-06-01 15:20:29,723 - train - INFO - Train: 38 [   0/224 (  0%)]  Loss:  3.228336 (3.2283)  Time: 4.632s, 1229.58/s  (4.632s, 1229.58/s)  LR: 9.610e-03  Data: 4.040 (4.040)
2025-06-01 15:21:10,887 - train - INFO - Train: 38 [  50/224 ( 22%)]  Loss:  3.199311 (3.2138)  Time: 0.548s, 10389.80/s  (0.898s, 6343.42/s)  LR: 9.610e-03  Data: 0.000 (0.209)
2025-06-01 15:21:52,496 - train - INFO - Train: 38 [ 100/224 ( 45%)]  Loss:  3.185779 (3.2045)  Time: 1.913s, 2977.20/s  (0.865s, 6582.15/s)  LR: 9.610e-03  Data: 0.000 (0.105)
2025-06-01 15:22:33,584 - train - INFO - Train: 38 [ 150/224 ( 67%)]  Loss:  3.205221 (3.2047)  Time: 0.550s, 10359.60/s  (0.851s, 6693.91/s)  LR: 9.610e-03  Data: 0.000 (0.071)
2025-06-01 15:23:15,097 - train - INFO - Train: 38 [ 200/224 ( 90%)]  Loss:  3.208115 (3.2054)  Time: 1.626s, 3503.80/s  (0.846s, 6734.64/s)  LR: 9.610e-03  Data: 0.000 (0.053)
2025-06-01 15:23:33,036 - train - INFO - Train: 38 [ 223/224 (100%)]  Loss:  3.233278 (3.2100)  Time: 0.544s, 10472.92/s  (0.839s, 6788.96/s)  LR: 9.610e-03  Data: 0.000 (0.048)
2025-06-01 15:23:38,023 - train - INFO - Test: [   0/70]  Time: 4.752 (4.752)  Loss:  1.4834 (1.4834)  Acc@1: 71.8574 (71.8574)  Acc@5: 89.2907 (89.2907)
2025-06-01 15:24:19,729 - train - INFO - Test: [  50/70]  Time: 0.120 (0.911)  Loss:  2.0000 (1.9439)  Acc@1: 59.7788 (59.5753)  Acc@5: 81.0042 (82.6142)
2025-06-01 15:24:36,063 - train - INFO - Test: [  70/70]  Time: 0.034 (0.884)  Loss:  3.1738 (2.0076)  Acc@1: 28.5156 (58.2250)  Acc@5: 62.8125 (81.2625)
2025-06-01 15:24:41,165 - train - INFO - Train: 39 [   0/224 (  0%)]  Loss:  3.202015 (3.2020)  Time: 4.793s, 1188.35/s  (4.793s, 1188.35/s)  LR: 9.589e-03  Data: 4.248 (4.248)
2025-06-01 15:25:21,789 - train - INFO - Train: 39 [  50/224 ( 22%)]  Loss:  3.194320 (3.1982)  Time: 0.550s, 10357.57/s  (0.891s, 6396.24/s)  LR: 9.589e-03  Data: 0.000 (0.335)
2025-06-01 15:26:03,064 - train - INFO - Train: 39 [ 100/224 ( 45%)]  Loss:  3.221199 (3.2058)  Time: 1.529s, 3724.19/s  (0.858s, 6636.26/s)  LR: 9.589e-03  Data: 0.878 (0.298)
2025-06-01 15:26:43,322 - train - INFO - Train: 39 [ 150/224 ( 67%)]  Loss:  3.176560 (3.1985)  Time: 0.552s, 10318.31/s  (0.841s, 6775.25/s)  LR: 9.589e-03  Data: 0.000 (0.281)
2025-06-01 15:27:24,992 - train - INFO - Train: 39 [ 200/224 ( 90%)]  Loss:  3.165444 (3.1919)  Time: 1.490s, 3824.10/s  (0.839s, 6789.97/s)  LR: 9.589e-03  Data: 0.445 (0.244)
2025-06-01 15:27:43,162 - train - INFO - Train: 39 [ 223/224 (100%)]  Loss:  3.167152 (3.1878)  Time: 0.545s, 10454.50/s  (0.834s, 6830.92/s)  LR: 9.589e-03  Data: 0.000 (0.222)
2025-06-01 15:27:48,006 - train - INFO - Test: [   0/70]  Time: 4.584 (4.584)  Loss:  1.1543 (1.1543)  Acc@1: 73.7184 (73.7184)  Acc@5: 91.5028 (91.5028)
2025-06-01 15:28:29,972 - train - INFO - Test: [  50/70]  Time: 0.120 (0.913)  Loss:  1.7539 (1.6738)  Acc@1: 61.4993 (62.0373)  Acc@5: 81.7240 (84.6607)
2025-06-01 15:28:46,189 - train - INFO - Test: [  70/70]  Time: 0.034 (0.884)  Loss:  2.3262 (1.7382)  Acc@1: 43.6719 (60.8538)  Acc@5: 77.5000 (83.6325)
2025-06-01 15:28:51,160 - train - INFO - Train: 40 [   0/224 (  0%)]  Loss:  3.185745 (3.1857)  Time: 4.643s, 1226.88/s  (4.643s, 1226.88/s)  LR: 9.568e-03  Data: 3.696 (3.696)
2025-06-01 15:29:32,657 - train - INFO - Train: 40 [  50/224 ( 22%)]  Loss:  3.189097 (3.1874)  Time: 0.550s, 10349.52/s  (0.905s, 6296.27/s)  LR: 9.568e-03  Data: 0.000 (0.226)
2025-06-01 15:30:15,114 - train - INFO - Train: 40 [ 100/224 ( 45%)]  Loss:  3.203623 (3.1928)  Time: 1.791s, 3181.02/s  (0.877s, 6493.76/s)  LR: 9.568e-03  Data: 0.087 (0.143)
2025-06-01 15:30:56,288 - train - INFO - Train: 40 [ 150/224 ( 67%)]  Loss:  3.196532 (3.1937)  Time: 0.571s, 9967.77/s  (0.859s, 6628.09/s)  LR: 9.568e-03  Data: 0.000 (0.099)
2025-06-01 15:31:37,656 - train - INFO - Train: 40 [ 200/224 ( 90%)]  Loss:  3.167332 (3.1885)  Time: 1.564s, 3642.22/s  (0.851s, 6690.12/s)  LR: 9.568e-03  Data: 0.000 (0.074)
2025-06-01 15:31:55,317 - train - INFO - Train: 40 [ 223/224 (100%)]  Loss:  3.222901 (3.1942)  Time: 0.547s, 10414.96/s  (0.843s, 6758.24/s)  LR: 9.568e-03  Data: 0.000 (0.067)
2025-06-01 15:32:00,198 - train - INFO - Test: [   0/70]  Time: 4.623 (4.623)  Loss:  1.4883 (1.4883)  Acc@1: 69.1538 (69.1538)  Acc@5: 87.7984 (87.7984)
2025-06-01 15:32:42,507 - train - INFO - Test: [  50/70]  Time: 0.120 (0.920)  Loss:  1.8223 (1.8299)  Acc@1: 60.9726 (61.2518)  Acc@5: 83.2338 (83.9392)
2025-06-01 15:32:59,072 - train - INFO - Test: [  70/70]  Time: 0.034 (0.894)  Loss:  2.8145 (1.9129)  Acc@1: 34.9219 (59.6185)  Acc@5: 68.1250 (82.3578)
2025-06-01 15:33:04,215 - train - INFO - Train: 41 [   0/224 (  0%)]  Loss:  3.206450 (3.2064)  Time: 4.824s, 1180.65/s  (4.824s, 1180.65/s)  LR: 9.547e-03  Data: 4.281 (4.281)
2025-06-01 15:33:44,422 - train - INFO - Train: 41 [  50/224 ( 22%)]  Loss:  3.205397 (3.2059)  Time: 0.550s, 10356.02/s  (0.883s, 6451.08/s)  LR: 9.547e-03  Data: 0.000 (0.241)
2025-06-01 15:34:25,791 - train - INFO - Train: 41 [ 100/224 ( 45%)]  Loss:  3.239465 (3.2171)  Time: 1.240s, 4592.41/s  (0.855s, 6658.69/s)  LR: 9.547e-03  Data: 0.000 (0.171)
2025-06-01 15:35:07,171 - train - INFO - Train: 41 [ 150/224 ( 67%)]  Loss:  3.193666 (3.2112)  Time: 0.550s, 10353.49/s  (0.846s, 6731.28/s)  LR: 9.547e-03  Data: 0.000 (0.148)
2025-06-01 15:35:48,116 - train - INFO - Train: 41 [ 200/224 ( 90%)]  Loss:  3.263854 (3.2218)  Time: 1.738s, 3276.81/s  (0.839s, 6785.80/s)  LR: 9.547e-03  Data: 0.000 (0.133)
2025-06-01 15:36:05,826 - train - INFO - Train: 41 [ 223/224 (100%)]  Loss:  3.215186 (3.2207)  Time: 0.548s, 10403.51/s  (0.832s, 6843.91/s)  LR: 9.547e-03  Data: 0.000 (0.120)
2025-06-01 15:36:10,823 - train - INFO - Test: [   0/70]  Time: 4.724 (4.724)  Loss:  1.3809 (1.3809)  Acc@1: 73.9993 (73.9993)  Acc@5: 90.5021 (90.5021)
2025-06-01 15:36:52,955 - train - INFO - Test: [  50/70]  Time: 0.501 (0.919)  Loss:  1.9199 (1.8215)  Acc@1: 60.8322 (61.3564)  Acc@5: 80.9867 (84.0218)
2025-06-01 15:37:09,102 - train - INFO - Test: [  70/70]  Time: 0.034 (0.887)  Loss:  2.4570 (1.8995)  Acc@1: 38.5156 (59.6733)  Acc@5: 75.3906 (82.5015)
2025-06-01 15:37:13,905 - train - INFO - Train: 42 [   0/224 (  0%)]  Loss:  3.195127 (3.1951)  Time: 4.489s, 1268.82/s  (4.489s, 1268.82/s)  LR: 9.525e-03  Data: 3.449 (3.449)
2025-06-01 15:37:55,238 - train - INFO - Train: 42 [  50/224 ( 22%)]  Loss:  3.226205 (3.2107)  Time: 0.548s, 10394.07/s  (0.898s, 6339.83/s)  LR: 9.525e-03  Data: 0.000 (0.150)
2025-06-01 15:38:36,926 - train - INFO - Train: 42 [ 100/224 ( 45%)]  Loss:  3.175519 (3.1990)  Time: 1.569s, 3630.21/s  (0.866s, 6574.19/s)  LR: 9.525e-03  Data: 0.000 (0.076)
2025-06-01 15:39:17,218 - train - INFO - Train: 42 [ 150/224 ( 67%)]  Loss:  3.306007 (3.2257)  Time: 0.548s, 10384.86/s  (0.846s, 6730.08/s)  LR: 9.525e-03  Data: 0.000 (0.051)
2025-06-01 15:39:58,017 - train - INFO - Train: 42 [ 200/224 ( 90%)]  Loss:  3.221429 (3.2249)  Time: 1.136s, 5012.67/s  (0.839s, 6790.73/s)  LR: 9.525e-03  Data: 0.000 (0.038)
2025-06-01 15:40:16,409 - train - INFO - Train: 42 [ 223/224 (100%)]  Loss:  3.199756 (3.2207)  Time: 0.544s, 10463.29/s  (0.835s, 6823.50/s)  LR: 9.525e-03  Data: 0.000 (0.034)
2025-06-01 15:40:21,171 - train - INFO - Test: [   0/70]  Time: 4.511 (4.511)  Loss:  1.2275 (1.2275)  Acc@1: 73.9115 (73.9115)  Acc@5: 91.9593 (91.9593)
2025-06-01 15:41:02,804 - train - INFO - Test: [  50/70]  Time: 0.120 (0.905)  Loss:  2.0488 (1.8298)  Acc@1: 56.4958 (60.1550)  Acc@5: 78.8799 (83.2156)
2025-06-01 15:41:19,317 - train - INFO - Test: [  70/70]  Time: 0.034 (0.882)  Loss:  2.2988 (1.8833)  Acc@1: 45.2344 (59.0885)  Acc@5: 74.1406 (82.1953)
2025-06-01 15:41:24,116 - train - INFO - Train: 43 [   0/224 (  0%)]  Loss:  3.192885 (3.1929)  Time: 4.498s, 1266.44/s  (4.498s, 1266.44/s)  LR: 9.502e-03  Data: 3.745 (3.745)
2025-06-01 15:42:05,079 - train - INFO - Train: 43 [  50/224 ( 22%)]  Loss:  3.198634 (3.1958)  Time: 0.549s, 10370.29/s  (0.891s, 6390.13/s)  LR: 9.502e-03  Data: 0.000 (0.208)
2025-06-01 15:42:46,954 - train - INFO - Train: 43 [ 100/224 ( 45%)]  Loss:  3.259626 (3.2170)  Time: 1.741s, 3272.07/s  (0.865s, 6587.35/s)  LR: 9.502e-03  Data: 0.000 (0.108)
2025-06-01 15:43:27,437 - train - INFO - Train: 43 [ 150/224 ( 67%)]  Loss:  3.255918 (3.2268)  Time: 0.550s, 10358.75/s  (0.846s, 6729.20/s)  LR: 9.502e-03  Data: 0.000 (0.072)
2025-06-01 15:44:09,283 - train - INFO - Train: 43 [ 200/224 ( 90%)]  Loss:  3.215790 (3.2246)  Time: 1.604s, 3550.13/s  (0.844s, 6748.14/s)  LR: 9.502e-03  Data: 0.000 (0.054)
2025-06-01 15:44:26,823 - train - INFO - Train: 43 [ 223/224 (100%)]  Loss:  3.201054 (3.2207)  Time: 0.544s, 10465.54/s  (0.836s, 6815.78/s)  LR: 9.502e-03  Data: 0.000 (0.049)
2025-06-01 15:44:31,546 - train - INFO - Test: [   0/70]  Time: 4.481 (4.481)  Loss:  1.6572 (1.6572)  Acc@1: 70.3125 (70.3125)  Acc@5: 89.7823 (89.7823)
2025-06-01 15:45:12,971 - train - INFO - Test: [  50/70]  Time: 0.182 (0.900)  Loss:  2.1816 (2.1455)  Acc@1: 55.5829 (57.6287)  Acc@5: 78.7746 (81.2252)
2025-06-01 15:45:29,331 - train - INFO - Test: [  70/70]  Time: 0.034 (0.877)  Loss:  2.6562 (2.2083)  Acc@1: 34.0625 (56.1258)  Acc@5: 75.1562 (79.9803)
2025-06-01 15:45:34,390 - train - INFO - Train: 44 [   0/224 (  0%)]  Loss:  3.237184 (3.2372)  Time: 4.753s, 1198.39/s  (4.753s, 1198.39/s)  LR: 9.479e-03  Data: 3.975 (3.975)
2025-06-01 15:46:15,248 - train - INFO - Train: 44 [  50/224 ( 22%)]  Loss:  3.217365 (3.2273)  Time: 0.550s, 10353.80/s  (0.894s, 6369.12/s)  LR: 9.479e-03  Data: 0.000 (0.205)
2025-06-01 15:46:56,680 - train - INFO - Train: 44 [ 100/224 ( 45%)]  Loss:  3.176999 (3.2105)  Time: 1.001s, 5687.51/s  (0.862s, 6609.45/s)  LR: 9.479e-03  Data: 0.000 (0.103)
2025-06-01 15:47:37,815 - train - INFO - Train: 44 [ 150/224 ( 67%)]  Loss:  3.159875 (3.1979)  Time: 0.549s, 10382.70/s  (0.849s, 6710.31/s)  LR: 9.479e-03  Data: 0.000 (0.069)
2025-06-01 15:48:18,546 - train - INFO - Train: 44 [ 200/224 ( 90%)]  Loss:  3.222988 (3.2029)  Time: 0.567s, 10041.37/s  (0.840s, 6778.38/s)  LR: 9.479e-03  Data: 0.000 (0.052)
2025-06-01 15:48:37,637 - train - INFO - Train: 44 [ 223/224 (100%)]  Loss:  3.176181 (3.1984)  Time: 0.544s, 10472.37/s  (0.839s, 6786.95/s)  LR: 9.479e-03  Data: 0.000 (0.047)
2025-06-01 15:48:42,601 - train - INFO - Test: [   0/70]  Time: 4.718 (4.718)  Loss:  1.3262 (1.3262)  Acc@1: 71.7170 (71.7170)  Acc@5: 89.6067 (89.6067)
2025-06-01 15:49:24,520 - train - INFO - Test: [  50/70]  Time: 0.124 (0.914)  Loss:  1.8545 (1.8031)  Acc@1: 57.7072 (59.2955)  Acc@5: 81.4958 (82.2676)
2025-06-01 15:49:40,849 - train - INFO - Test: [  70/70]  Time: 0.034 (0.887)  Loss:  2.9395 (1.8705)  Acc@1: 33.8281 (57.9325)  Acc@5: 68.9844 (81.1740)
2025-06-01 15:49:45,821 - train - INFO - Train: 45 [   0/224 (  0%)]  Loss:  3.208690 (3.2087)  Time: 4.663s, 1221.58/s  (4.663s, 1221.58/s)  LR: 9.456e-03  Data: 3.784 (3.784)
2025-06-01 15:50:26,509 - train - INFO - Train: 45 [  50/224 ( 22%)]  Loss:  3.195758 (3.2022)  Time: 0.550s, 10361.55/s  (0.889s, 6405.75/s)  LR: 9.456e-03  Data: 0.000 (0.172)
2025-06-01 15:51:08,169 - train - INFO - Train: 45 [ 100/224 ( 45%)]  Loss:  3.194774 (3.1997)  Time: 1.326s, 4295.14/s  (0.861s, 6612.04/s)  LR: 9.456e-03  Data: 0.000 (0.087)
2025-06-01 15:51:49,414 - train - INFO - Train: 45 [ 150/224 ( 67%)]  Loss:  3.232759 (3.2080)  Time: 0.549s, 10384.10/s  (0.849s, 6706.37/s)  LR: 9.456e-03  Data: 0.000 (0.058)
2025-06-01 15:52:30,222 - train - INFO - Train: 45 [ 200/224 ( 90%)]  Loss:  3.190744 (3.2045)  Time: 1.121s, 5080.99/s  (0.841s, 6772.23/s)  LR: 9.456e-03  Data: 0.000 (0.044)
2025-06-01 15:52:48,491 - train - INFO - Train: 45 [ 223/224 (100%)]  Loss:  3.250863 (3.2123)  Time: 0.546s, 10424.96/s  (0.836s, 6811.20/s)  LR: 9.456e-03  Data: 0.000 (0.039)
2025-06-01 15:52:53,497 - train - INFO - Test: [   0/70]  Time: 4.759 (4.759)  Loss:  1.2578 (1.2578)  Acc@1: 73.1039 (73.1039)  Acc@5: 91.5730 (91.5730)
2025-06-01 15:53:35,485 - train - INFO - Test: [  50/70]  Time: 0.120 (0.917)  Loss:  1.8438 (1.7912)  Acc@1: 59.2170 (61.1795)  Acc@5: 82.4263 (84.1210)
2025-06-01 15:53:51,860 - train - INFO - Test: [  70/70]  Time: 0.034 (0.889)  Loss:  2.4258 (1.8714)  Acc@1: 42.9688 (59.3850)  Acc@5: 75.7812 (82.7018)
2025-06-01 15:53:56,723 - train - INFO - Train: 46 [   0/224 (  0%)]  Loss:  3.187365 (3.1874)  Time: 4.554s, 1250.90/s  (4.554s, 1250.90/s)  LR: 9.432e-03  Data: 3.701 (3.701)
2025-06-01 15:54:37,937 - train - INFO - Train: 46 [  50/224 ( 22%)]  Loss:  3.222262 (3.2048)  Time: 0.548s, 10396.60/s  (0.897s, 6347.42/s)  LR: 9.432e-03  Data: 0.000 (0.159)
2025-06-01 15:55:19,919 - train - INFO - Train: 46 [ 100/224 ( 45%)]  Loss:  3.235020 (3.2149)  Time: 1.652s, 3447.79/s  (0.869s, 6556.38/s)  LR: 9.432e-03  Data: 0.000 (0.080)
2025-06-01 15:56:00,518 - train - INFO - Train: 46 [ 150/224 ( 67%)]  Loss:  3.324079 (3.2422)  Time: 0.549s, 10375.97/s  (0.850s, 6701.52/s)  LR: 9.432e-03  Data: 0.000 (0.054)
2025-06-01 15:56:41,461 - train - INFO - Train: 46 [ 200/224 ( 90%)]  Loss:  3.205149 (3.2348)  Time: 1.562s, 3647.07/s  (0.842s, 6763.11/s)  LR: 9.432e-03  Data: 0.217 (0.043)
2025-06-01 15:56:59,318 - train - INFO - Train: 46 [ 223/224 (100%)]  Loss:  3.212657 (3.2311)  Time: 0.545s, 10449.09/s  (0.835s, 6817.87/s)  LR: 9.432e-03  Data: 0.000 (0.045)
2025-06-01 15:57:04,122 - train - INFO - Test: [   0/70]  Time: 4.548 (4.548)  Loss:  1.4258 (1.4258)  Acc@1: 71.2956 (71.2956)  Acc@5: 89.5190 (89.5190)
2025-06-01 15:57:45,637 - train - INFO - Test: [  50/70]  Time: 0.120 (0.903)  Loss:  2.0703 (1.8629)  Acc@1: 55.5829 (60.0872)  Acc@5: 79.0906 (83.1430)
2025-06-01 15:58:01,858 - train - INFO - Test: [  70/70]  Time: 0.034 (0.877)  Loss:  2.6738 (1.9475)  Acc@1: 38.6719 (58.3940)  Acc@5: 71.2500 (81.6893)
2025-06-01 15:58:06,868 - train - INFO - Train: 47 [   0/224 (  0%)]  Loss:  3.234575 (3.2346)  Time: 4.685s, 1215.88/s  (4.685s, 1215.88/s)  LR: 9.407e-03  Data: 3.838 (3.838)
2025-06-01 15:58:48,403 - train - INFO - Train: 47 [  50/224 ( 22%)]  Loss:  3.230893 (3.2327)  Time: 0.556s, 10239.88/s  (0.906s, 6285.43/s)  LR: 9.407e-03  Data: 0.000 (0.155)
2025-06-01 15:59:30,525 - train - INFO - Train: 47 [ 100/224 ( 45%)]  Loss:  3.206028 (3.2238)  Time: 1.798s, 3168.25/s  (0.875s, 6512.38/s)  LR: 9.407e-03  Data: 0.000 (0.078)
2025-06-01 16:00:11,058 - train - INFO - Train: 47 [ 150/224 ( 67%)]  Loss:  3.225559 (3.2243)  Time: 0.554s, 10282.98/s  (0.853s, 6674.19/s)  LR: 9.407e-03  Data: 0.000 (0.052)
2025-06-01 16:00:53,080 - train - INFO - Train: 47 [ 200/224 ( 90%)]  Loss:  3.199619 (3.2193)  Time: 1.615s, 3527.29/s  (0.850s, 6699.62/s)  LR: 9.407e-03  Data: 0.000 (0.039)
2025-06-01 16:01:10,932 - train - INFO - Train: 47 [ 223/224 (100%)]  Loss:  3.224077 (3.2201)  Time: 0.550s, 10349.39/s  (0.843s, 6760.18/s)  LR: 9.407e-03  Data: 0.000 (0.035)
2025-06-01 16:01:15,829 - train - INFO - Test: [   0/70]  Time: 4.660 (4.660)  Loss:  1.3076 (1.3076)  Acc@1: 73.8413 (73.8413)  Acc@5: 89.9228 (89.9228)
2025-06-01 16:01:57,880 - train - INFO - Test: [  50/70]  Time: 0.120 (0.916)  Loss:  2.0781 (1.8975)  Acc@1: 56.7240 (58.3753)  Acc@5: 79.5646 (82.0493)
2025-06-01 16:02:14,279 - train - INFO - Test: [  70/70]  Time: 0.034 (0.889)  Loss:  2.6777 (1.9642)  Acc@1: 34.4531 (57.1078)  Acc@5: 73.5156 (80.8968)
2025-06-01 16:02:19,311 - train - INFO - Train: 48 [   0/224 (  0%)]  Loss:  3.206631 (3.2066)  Time: 4.723s, 1205.90/s  (4.723s, 1205.90/s)  LR: 9.382e-03  Data: 3.644 (3.644)
2025-06-01 16:03:00,381 - train - INFO - Train: 48 [  50/224 ( 22%)]  Loss:  3.189950 (3.1983)  Time: 0.554s, 10282.64/s  (0.898s, 6344.00/s)  LR: 9.382e-03  Data: 0.000 (0.112)
2025-06-01 16:03:41,776 - train - INFO - Train: 48 [ 100/224 ( 45%)]  Loss:  3.203914 (3.2002)  Time: 1.596s, 3569.75/s  (0.863s, 6598.70/s)  LR: 9.382e-03  Data: 0.000 (0.057)
2025-06-01 16:04:22,634 - train - INFO - Train: 48 [ 150/224 ( 67%)]  Loss:  3.207614 (3.2020)  Time: 0.565s, 10075.74/s  (0.848s, 6717.39/s)  LR: 9.382e-03  Data: 0.000 (0.038)
2025-06-01 16:05:03,957 - train - INFO - Train: 48 [ 200/224 ( 90%)]  Loss:  3.196886 (3.2010)  Time: 0.925s, 6158.98/s  (0.843s, 6760.08/s)  LR: 9.382e-03  Data: 0.000 (0.029)
2025-06-01 16:05:22,877 - train - INFO - Train: 48 [ 223/224 (100%)]  Loss:  3.207640 (3.2021)  Time: 0.546s, 10430.18/s  (0.841s, 6776.60/s)  LR: 9.382e-03  Data: 0.000 (0.026)
2025-06-01 16:05:27,759 - train - INFO - Test: [   0/70]  Time: 4.643 (4.643)  Loss:  1.6270 (1.6270)  Acc@1: 69.8209 (69.8209)  Acc@5: 86.4466 (86.4466)
2025-06-01 16:06:09,544 - train - INFO - Test: [  50/70]  Time: 0.120 (0.910)  Loss:  2.2500 (1.9065)  Acc@1: 53.5815 (59.6769)  Acc@5: 77.7388 (82.5774)
2025-06-01 16:06:25,648 - train - INFO - Test: [  70/70]  Time: 0.034 (0.881)  Loss:  2.6621 (1.9692)  Acc@1: 44.0625 (58.4408)  Acc@5: 71.4062 (81.5740)
2025-06-01 16:06:30,421 - train - INFO - Train: 49 [   0/224 (  0%)]  Loss:  3.200402 (3.2004)  Time: 4.480s, 1271.35/s  (4.480s, 1271.35/s)  LR: 9.357e-03  Data: 3.853 (3.853)
2025-06-01 16:07:12,037 - train - INFO - Train: 49 [  50/224 ( 22%)]  Loss:  3.191500 (3.1960)  Time: 0.550s, 10358.04/s  (0.904s, 6302.31/s)  LR: 9.357e-03  Data: 0.000 (0.189)
2025-06-01 16:07:53,654 - train - INFO - Train: 49 [ 100/224 ( 45%)]  Loss:  3.214894 (3.2023)  Time: 1.669s, 3413.02/s  (0.868s, 6559.17/s)  LR: 9.357e-03  Data: 0.000 (0.095)
2025-06-01 16:08:33,777 - train - INFO - Train: 49 [ 150/224 ( 67%)]  Loss:  3.232167 (3.2097)  Time: 0.548s, 10385.41/s  (0.847s, 6728.42/s)  LR: 9.357e-03  Data: 0.000 (0.064)
2025-06-01 16:09:14,586 - train - INFO - Train: 49 [ 200/224 ( 90%)]  Loss:  3.209841 (3.2098)  Time: 1.412s, 4033.20/s  (0.839s, 6789.09/s)  LR: 9.357e-03  Data: 0.000 (0.048)
2025-06-01 16:09:32,327 - train - INFO - Train: 49 [ 223/224 (100%)]  Loss:  3.238157 (3.2145)  Time: 0.544s, 10463.11/s  (0.832s, 6845.85/s)  LR: 9.357e-03  Data: 0.000 (0.043)
2025-06-01 16:09:37,502 - train - INFO - Test: [   0/70]  Time: 4.933 (4.933)  Loss:  1.4531 (1.4531)  Acc@1: 69.3469 (69.3469)  Acc@5: 88.8869 (88.8869)
2025-06-01 16:10:19,326 - train - INFO - Test: [  50/70]  Time: 0.120 (0.917)  Loss:  1.8193 (1.9285)  Acc@1: 61.3588 (58.0263)  Acc@5: 83.0583 (81.7123)
2025-06-01 16:10:35,586 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.2188 (2.0014)  Acc@1: 51.6406 (56.6028)  Acc@5: 76.6406 (80.3475)
2025-06-01 16:10:40,564 - train - INFO - Train: 50 [   0/224 (  0%)]  Loss:  3.226424 (3.2264)  Time: 4.681s, 1216.96/s  (4.681s, 1216.96/s)  LR: 9.331e-03  Data: 3.486 (3.486)
2025-06-01 16:11:21,331 - train - INFO - Train: 50 [  50/224 ( 22%)]  Loss:  3.215684 (3.2211)  Time: 0.550s, 10362.69/s  (0.891s, 6392.00/s)  LR: 9.331e-03  Data: 0.000 (0.097)
2025-06-01 16:12:02,953 - train - INFO - Train: 50 [ 100/224 ( 45%)]  Loss:  3.235044 (3.2257)  Time: 1.601s, 3558.43/s  (0.862s, 6607.44/s)  LR: 9.331e-03  Data: 0.000 (0.049)
2025-06-01 16:12:43,084 - train - INFO - Train: 50 [ 150/224 ( 67%)]  Loss:  3.222272 (3.2249)  Time: 0.551s, 10346.30/s  (0.842s, 6761.88/s)  LR: 9.331e-03  Data: 0.000 (0.033)
2025-06-01 16:13:24,920 - train - INFO - Train: 50 [ 200/224 ( 90%)]  Loss:  3.173308 (3.2145)  Time: 1.597s, 3566.64/s  (0.841s, 6773.24/s)  LR: 9.331e-03  Data: 0.000 (0.025)
2025-06-01 16:13:42,372 - train - INFO - Train: 50 [ 223/224 (100%)]  Loss:  3.189694 (3.2104)  Time: 0.546s, 10428.31/s  (0.833s, 6841.91/s)  LR: 9.331e-03  Data: 0.000 (0.022)
2025-06-01 16:13:46,946 - train - INFO - Test: [   0/70]  Time: 4.331 (4.331)  Loss:  1.5576 (1.5576)  Acc@1: 66.9944 (66.9944)  Acc@5: 86.7626 (86.7626)
2025-06-01 16:14:28,776 - train - INFO - Test: [  50/70]  Time: 0.120 (0.905)  Loss:  2.2148 (1.9208)  Acc@1: 53.0197 (56.7695)  Acc@5: 75.0527 (81.0996)
2025-06-01 16:14:45,511 - train - INFO - Test: [  70/70]  Time: 0.035 (0.886)  Loss:  2.6133 (2.0097)  Acc@1: 42.1094 (55.3180)  Acc@5: 71.3281 (79.5180)
2025-06-01 16:14:50,395 - train - INFO - Train: 51 [   0/224 (  0%)]  Loss:  3.176551 (3.1766)  Time: 4.575s, 1244.98/s  (4.575s, 1244.98/s)  LR: 9.304e-03  Data: 3.513 (3.513)
2025-06-01 16:15:31,761 - train - INFO - Train: 51 [  50/224 ( 22%)]  Loss:  3.205374 (3.1910)  Time: 0.551s, 10331.28/s  (0.901s, 6323.34/s)  LR: 9.304e-03  Data: 0.000 (0.140)
2025-06-01 16:16:13,579 - train - INFO - Train: 51 [ 100/224 ( 45%)]  Loss:  3.209095 (3.1970)  Time: 1.709s, 3333.44/s  (0.869s, 6555.50/s)  LR: 9.304e-03  Data: 0.000 (0.071)
2025-06-01 16:16:53,864 - train - INFO - Train: 51 [ 150/224 ( 67%)]  Loss:  3.209426 (3.2001)  Time: 0.555s, 10254.75/s  (0.848s, 6717.42/s)  LR: 9.304e-03  Data: 0.000 (0.047)
2025-06-01 16:17:35,222 - train - INFO - Train: 51 [ 200/224 ( 90%)]  Loss:  3.207193 (3.2015)  Time: 1.573s, 3620.53/s  (0.843s, 6758.70/s)  LR: 9.304e-03  Data: 0.000 (0.036)
2025-06-01 16:17:53,260 - train - INFO - Train: 51 [ 223/224 (100%)]  Loss:  3.226373 (3.2057)  Time: 0.544s, 10467.44/s  (0.837s, 6807.30/s)  LR: 9.304e-03  Data: 0.000 (0.032)
2025-06-01 16:17:57,886 - train - INFO - Test: [   0/70]  Time: 4.372 (4.372)  Loss:  1.2422 (1.2422)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.3982 (92.3982)
2025-06-01 16:18:40,263 - train - INFO - Test: [  50/70]  Time: 0.120 (0.917)  Loss:  1.7852 (1.9185)  Acc@1: 63.8694 (59.6356)  Acc@5: 83.1636 (82.9643)
2025-06-01 16:18:56,824 - train - INFO - Test: [  70/70]  Time: 0.034 (0.892)  Loss:  2.4590 (1.9925)  Acc@1: 43.5938 (58.0735)  Acc@5: 76.4844 (81.5103)
2025-06-01 16:19:01,885 - train - INFO - Train: 52 [   0/224 (  0%)]  Loss:  3.177858 (3.1779)  Time: 4.761s, 1196.44/s  (4.761s, 1196.44/s)  LR: 9.278e-03  Data: 4.208 (4.208)
2025-06-01 16:19:42,415 - train - INFO - Train: 52 [  50/224 ( 22%)]  Loss:  3.234044 (3.2060)  Time: 0.553s, 10296.58/s  (0.888s, 6414.38/s)  LR: 9.278e-03  Data: 0.000 (0.330)
2025-06-01 16:20:24,535 - train - INFO - Train: 52 [ 100/224 ( 45%)]  Loss:  3.236458 (3.2161)  Time: 1.676s, 3397.89/s  (0.865s, 6581.80/s)  LR: 9.278e-03  Data: 0.000 (0.224)
2025-06-01 16:21:05,194 - train - INFO - Train: 52 [ 150/224 ( 67%)]  Loss:  3.173034 (3.2053)  Time: 0.549s, 10381.81/s  (0.848s, 6716.12/s)  LR: 9.278e-03  Data: 0.000 (0.150)
2025-06-01 16:21:46,906 - train - INFO - Train: 52 [ 200/224 ( 90%)]  Loss:  3.209280 (3.2061)  Time: 1.586s, 3591.91/s  (0.845s, 6743.63/s)  LR: 9.278e-03  Data: 0.000 (0.113)
2025-06-01 16:22:04,383 - train - INFO - Train: 52 [ 223/224 (100%)]  Loss:  3.243951 (3.2124)  Time: 0.544s, 10469.48/s  (0.836s, 6813.88/s)  LR: 9.278e-03  Data: 0.000 (0.101)
2025-06-01 16:22:09,105 - train - INFO - Test: [   0/70]  Time: 4.462 (4.462)  Loss:  1.3223 (1.3223)  Acc@1: 72.2261 (72.2261)  Acc@5: 90.9235 (90.9235)
2025-06-01 16:22:51,029 - train - INFO - Test: [  50/70]  Time: 0.120 (0.910)  Loss:  1.8867 (1.8715)  Acc@1: 60.0948 (59.8235)  Acc@5: 81.5134 (83.0741)
2025-06-01 16:23:07,583 - train - INFO - Test: [  70/70]  Time: 0.034 (0.886)  Loss:  2.1230 (1.9541)  Acc@1: 46.5625 (58.1098)  Acc@5: 83.9062 (81.5035)
2025-06-01 16:23:12,415 - train - INFO - Train: 53 [   0/224 (  0%)]  Loss:  3.235163 (3.2352)  Time: 4.522s, 1259.74/s  (4.522s, 1259.74/s)  LR: 9.250e-03  Data: 3.705 (3.705)
2025-06-01 16:23:53,227 - train - INFO - Train: 53 [  50/224 ( 22%)]  Loss:  3.186399 (3.2108)  Time: 0.552s, 10327.99/s  (0.889s, 6408.14/s)  LR: 9.250e-03  Data: 0.000 (0.112)
2025-06-01 16:24:34,683 - train - INFO - Train: 53 [ 100/224 ( 45%)]  Loss:  3.198558 (3.2067)  Time: 1.512s, 3767.57/s  (0.859s, 6628.84/s)  LR: 9.250e-03  Data: 0.000 (0.057)
2025-06-01 16:25:14,571 - train - INFO - Train: 53 [ 150/224 ( 67%)]  Loss:  3.143177 (3.1908)  Time: 0.550s, 10352.02/s  (0.839s, 6789.87/s)  LR: 9.250e-03  Data: 0.000 (0.038)
2025-06-01 16:25:55,886 - train - INFO - Train: 53 [ 200/224 ( 90%)]  Loss:  3.233593 (3.1994)  Time: 1.628s, 3498.06/s  (0.836s, 6815.41/s)  LR: 9.250e-03  Data: 0.000 (0.029)
2025-06-01 16:26:13,564 - train - INFO - Train: 53 [ 223/224 (100%)]  Loss:  3.224497 (3.2036)  Time: 0.545s, 10447.93/s  (0.829s, 6872.17/s)  LR: 9.250e-03  Data: 0.000 (0.026)
2025-06-01 16:26:18,443 - train - INFO - Test: [   0/70]  Time: 4.637 (4.637)  Loss:  1.4014 (1.4014)  Acc@1: 69.9263 (69.9263)  Acc@5: 87.8160 (87.8160)
2025-06-01 16:27:00,144 - train - INFO - Test: [  50/70]  Time: 0.120 (0.909)  Loss:  2.0703 (1.8059)  Acc@1: 54.9860 (59.3358)  Acc@5: 78.8448 (82.8865)
2025-06-01 16:27:16,298 - train - INFO - Test: [  70/70]  Time: 0.034 (0.880)  Loss:  1.9209 (1.8895)  Acc@1: 48.7500 (57.6518)  Acc@5: 82.1875 (81.4098)
2025-06-01 16:27:21,135 - train - INFO - Train: 54 [   0/224 (  0%)]  Loss:  3.168688 (3.1687)  Time: 4.527s, 1258.19/s  (4.527s, 1258.19/s)  LR: 9.222e-03  Data: 3.887 (3.887)
2025-06-01 16:28:02,690 - train - INFO - Train: 54 [  50/224 ( 22%)]  Loss:  3.208501 (3.1886)  Time: 0.548s, 10399.85/s  (0.904s, 6304.32/s)  LR: 9.222e-03  Data: 0.000 (0.187)
2025-06-01 16:28:45,059 - train - INFO - Train: 54 [ 100/224 ( 45%)]  Loss:  3.184857 (3.1873)  Time: 1.833s, 3107.53/s  (0.876s, 6504.51/s)  LR: 9.222e-03  Data: 0.000 (0.095)
2025-06-01 16:29:26,401 - train - INFO - Train: 54 [ 150/224 ( 67%)]  Loss:  3.217243 (3.1948)  Time: 0.555s, 10257.10/s  (0.860s, 6626.98/s)  LR: 9.222e-03  Data: 0.000 (0.063)
2025-06-01 16:30:08,012 - train - INFO - Train: 54 [ 200/224 ( 90%)]  Loss:  3.226306 (3.2011)  Time: 1.874s, 3039.01/s  (0.853s, 6679.88/s)  LR: 9.222e-03  Data: 0.000 (0.048)
2025-06-01 16:30:25,889 - train - INFO - Train: 54 [ 223/224 (100%)]  Loss:  3.233289 (3.2065)  Time: 0.550s, 10363.48/s  (0.845s, 6741.15/s)  LR: 9.222e-03  Data: 0.000 (0.043)
2025-06-01 16:30:30,793 - train - INFO - Test: [   0/70]  Time: 4.660 (4.660)  Loss:  1.5059 (1.5059)  Acc@1: 69.0309 (69.0309)  Acc@5: 88.5358 (88.5358)
2025-06-01 16:31:12,740 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  2.0859 (1.8745)  Acc@1: 56.5485 (58.9271)  Acc@5: 79.1784 (82.6276)
2025-06-01 16:31:29,232 - train - INFO - Test: [  70/70]  Time: 0.034 (0.889)  Loss:  2.7402 (1.9394)  Acc@1: 39.3750 (57.6425)  Acc@5: 72.8906 (81.4025)
2025-06-01 16:31:34,095 - train - INFO - Train: 55 [   0/224 (  0%)]  Loss:  3.191393 (3.1914)  Time: 4.554s, 1250.90/s  (4.554s, 1250.90/s)  LR: 9.194e-03  Data: 4.004 (4.004)
2025-06-01 16:32:15,202 - train - INFO - Train: 55 [  50/224 ( 22%)]  Loss:  3.216307 (3.2038)  Time: 0.557s, 10232.39/s  (0.895s, 6362.35/s)  LR: 9.194e-03  Data: 0.000 (0.342)
2025-06-01 16:32:57,016 - train - INFO - Train: 55 [ 100/224 ( 45%)]  Loss:  3.212808 (3.2068)  Time: 1.609s, 3541.09/s  (0.866s, 6576.90/s)  LR: 9.194e-03  Data: 1.068 (0.315)
2025-06-01 16:33:37,888 - train - INFO - Train: 55 [ 150/224 ( 67%)]  Loss:  3.232386 (3.2132)  Time: 0.548s, 10385.49/s  (0.850s, 6701.71/s)  LR: 9.194e-03  Data: 0.000 (0.300)
2025-06-01 16:34:19,149 - train - INFO - Train: 55 [ 200/224 ( 90%)]  Loss:  3.190140 (3.2086)  Time: 1.607s, 3545.51/s  (0.844s, 6750.57/s)  LR: 9.194e-03  Data: 1.066 (0.294)
2025-06-01 16:34:37,029 - train - INFO - Train: 55 [ 223/224 (100%)]  Loss:  3.162577 (3.2009)  Time: 0.544s, 10464.76/s  (0.837s, 6805.59/s)  LR: 9.194e-03  Data: 0.000 (0.287)
2025-06-01 16:34:41,813 - train - INFO - Test: [   0/70]  Time: 4.546 (4.546)  Loss:  1.7070 (1.7070)  Acc@1: 70.6987 (70.6987)  Acc@5: 90.2037 (90.2037)
2025-06-01 16:35:23,464 - train - INFO - Test: [  50/70]  Time: 0.120 (0.906)  Loss:  2.1855 (2.0710)  Acc@1: 59.0239 (60.9943)  Acc@5: 82.5843 (83.8080)
2025-06-01 16:35:39,823 - train - INFO - Test: [  70/70]  Time: 0.038 (0.881)  Loss:  2.8418 (2.1452)  Acc@1: 50.6250 (59.6288)  Acc@5: 72.8906 (82.4495)
2025-06-01 16:35:45,156 - train - INFO - Train: 56 [   0/224 (  0%)]  Loss:  3.202308 (3.2023)  Time: 4.975s, 1144.88/s  (4.975s, 1144.88/s)  LR: 9.165e-03  Data: 3.719 (3.719)
2025-06-01 16:36:25,642 - train - INFO - Train: 56 [  50/224 ( 22%)]  Loss:  3.211380 (3.2068)  Time: 0.555s, 10261.43/s  (0.891s, 6390.03/s)  LR: 9.165e-03  Data: 0.000 (0.084)
2025-06-01 16:37:07,487 - train - INFO - Train: 56 [ 100/224 ( 45%)]  Loss:  3.200511 (3.2047)  Time: 1.366s, 4168.74/s  (0.864s, 6589.58/s)  LR: 9.165e-03  Data: 0.000 (0.042)
2025-06-01 16:37:48,264 - train - INFO - Train: 56 [ 150/224 ( 67%)]  Loss:  3.197738 (3.2030)  Time: 0.549s, 10367.26/s  (0.848s, 6715.35/s)  LR: 9.165e-03  Data: 0.000 (0.028)
2025-06-01 16:38:29,240 - train - INFO - Train: 56 [ 200/224 ( 90%)]  Loss:  3.211613 (3.2047)  Time: 0.898s, 6345.77/s  (0.841s, 6772.40/s)  LR: 9.165e-03  Data: 0.000 (0.021)
2025-06-01 16:38:47,809 - train - INFO - Train: 56 [ 223/224 (100%)]  Loss:  3.184030 (3.2013)  Time: 0.552s, 10312.45/s  (0.838s, 6800.41/s)  LR: 9.165e-03  Data: 0.000 (0.019)
2025-06-01 16:38:52,816 - train - INFO - Test: [   0/70]  Time: 4.751 (4.751)  Loss:  1.4062 (1.4062)  Acc@1: 75.2985 (75.2985)  Acc@5: 93.4164 (93.4164)
2025-06-01 16:39:34,966 - train - INFO - Test: [  50/70]  Time: 0.125 (0.920)  Loss:  1.8867 (2.0299)  Acc@1: 63.9396 (61.4081)  Acc@5: 84.5330 (84.2438)
2025-06-01 16:39:51,349 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.3750 (2.1086)  Acc@1: 52.5781 (59.5623)  Acc@5: 79.6094 (82.5895)
2025-06-01 16:39:56,209 - train - INFO - Train: 57 [   0/224 (  0%)]  Loss:  3.174622 (3.1746)  Time: 4.520s, 1260.13/s  (4.520s, 1260.13/s)  LR: 9.136e-03  Data: 3.962 (3.962)
2025-06-01 16:40:37,410 - train - INFO - Train: 57 [  50/224 ( 22%)]  Loss:  3.145794 (3.1602)  Time: 0.550s, 10347.01/s  (0.896s, 6353.85/s)  LR: 9.136e-03  Data: 0.000 (0.140)
2025-06-01 16:41:18,641 - train - INFO - Train: 57 [ 100/224 ( 45%)]  Loss:  3.194819 (3.1717)  Time: 1.476s, 3859.09/s  (0.861s, 6616.47/s)  LR: 9.136e-03  Data: 0.000 (0.071)
2025-06-01 16:41:59,701 - train - INFO - Train: 57 [ 150/224 ( 67%)]  Loss:  3.225590 (3.1852)  Time: 0.555s, 10256.35/s  (0.848s, 6719.13/s)  LR: 9.136e-03  Data: 0.000 (0.047)
2025-06-01 16:42:41,166 - train - INFO - Train: 57 [ 200/224 ( 90%)]  Loss:  3.192555 (3.1867)  Time: 0.555s, 10269.57/s  (0.843s, 6755.71/s)  LR: 9.136e-03  Data: 0.000 (0.036)
2025-06-01 16:43:00,087 - train - INFO - Train: 57 [ 223/224 (100%)]  Loss:  3.191559 (3.1875)  Time: 0.552s, 10311.67/s  (0.841s, 6772.67/s)  LR: 9.136e-03  Data: 0.000 (0.032)
2025-06-01 16:43:05,005 - train - INFO - Test: [   0/70]  Time: 4.669 (4.669)  Loss:  1.5908 (1.5908)  Acc@1: 67.5035 (67.5035)  Acc@5: 87.7984 (87.7984)
2025-06-01 16:43:47,195 - train - INFO - Test: [  50/70]  Time: 0.120 (0.919)  Loss:  1.9707 (1.9070)  Acc@1: 60.4635 (58.9777)  Acc@5: 80.6531 (82.4004)
2025-06-01 16:44:03,828 - train - INFO - Test: [  70/70]  Time: 0.034 (0.894)  Loss:  2.3242 (1.9452)  Acc@1: 44.2188 (57.9435)  Acc@5: 75.8594 (81.5005)
2025-06-01 16:44:08,859 - train - INFO - Train: 58 [   0/224 (  0%)]  Loss:  3.205847 (3.2058)  Time: 4.716s, 1207.89/s  (4.716s, 1207.89/s)  LR: 9.107e-03  Data: 4.131 (4.131)
2025-06-01 16:44:49,681 - train - INFO - Train: 58 [  50/224 ( 22%)]  Loss:  3.196873 (3.2014)  Time: 0.548s, 10392.06/s  (0.893s, 6379.51/s)  LR: 9.107e-03  Data: 0.000 (0.212)
2025-06-01 16:45:31,420 - train - INFO - Train: 58 [ 100/224 ( 45%)]  Loss:  3.214957 (3.2059)  Time: 1.530s, 3722.46/s  (0.864s, 6591.93/s)  LR: 9.107e-03  Data: 0.131 (0.136)
2025-06-01 16:46:11,680 - train - INFO - Train: 58 [ 150/224 ( 67%)]  Loss:  3.196899 (3.2036)  Time: 0.549s, 10376.44/s  (0.845s, 6744.22/s)  LR: 9.107e-03  Data: 0.000 (0.096)
2025-06-01 16:46:52,606 - train - INFO - Train: 58 [ 200/224 ( 90%)]  Loss:  3.146203 (3.1922)  Time: 1.517s, 3754.77/s  (0.838s, 6796.43/s)  LR: 9.107e-03  Data: 0.568 (0.091)
2025-06-01 16:47:10,430 - train - INFO - Train: 58 [ 223/224 (100%)]  Loss:  3.223407 (3.1974)  Time: 0.546s, 10441.48/s  (0.832s, 6849.43/s)  LR: 9.107e-03  Data: 0.000 (0.090)
2025-06-01 16:47:15,343 - train - INFO - Test: [   0/70]  Time: 4.671 (4.671)  Loss:  1.1133 (1.1133)  Acc@1: 75.5794 (75.5794)  Acc@5: 92.7142 (92.7142)
2025-06-01 16:47:57,306 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  2.0996 (1.8228)  Acc@1: 56.7065 (60.1816)  Acc@5: 79.4944 (82.9908)
2025-06-01 16:48:13,908 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.3594 (1.9071)  Acc@1: 44.5312 (58.5358)  Acc@5: 74.4531 (81.5850)
2025-06-01 16:48:19,092 - train - INFO - Train: 59 [   0/224 (  0%)]  Loss:  3.216433 (3.2164)  Time: 4.869s, 1169.79/s  (4.869s, 1169.79/s)  LR: 9.077e-03  Data: 3.985 (3.985)
2025-06-01 16:48:59,737 - train - INFO - Train: 59 [  50/224 ( 22%)]  Loss:  3.183819 (3.2001)  Time: 0.550s, 10351.49/s  (0.892s, 6382.69/s)  LR: 9.077e-03  Data: 0.000 (0.210)
2025-06-01 16:49:41,387 - train - INFO - Train: 59 [ 100/224 ( 45%)]  Loss:  3.195745 (3.1987)  Time: 1.755s, 3246.50/s  (0.863s, 6600.46/s)  LR: 9.077e-03  Data: 0.536 (0.152)
2025-06-01 16:50:22,298 - train - INFO - Train: 59 [ 150/224 ( 67%)]  Loss:  3.214127 (3.2025)  Time: 0.555s, 10254.55/s  (0.848s, 6715.84/s)  LR: 9.077e-03  Data: 0.000 (0.110)
2025-06-01 16:51:03,165 - train - INFO - Train: 59 [ 200/224 ( 90%)]  Loss:  3.232960 (3.2086)  Time: 0.894s, 6372.82/s  (0.840s, 6777.13/s)  LR: 9.077e-03  Data: 0.000 (0.083)
2025-06-01 16:51:21,880 - train - INFO - Train: 59 [ 223/224 (100%)]  Loss:  3.233642 (3.2128)  Time: 0.551s, 10337.41/s  (0.838s, 6799.42/s)  LR: 9.077e-03  Data: 0.000 (0.074)
2025-06-01 16:51:26,767 - train - INFO - Test: [   0/70]  Time: 4.637 (4.637)  Loss:  1.4219 (1.4219)  Acc@1: 72.4544 (72.4544)  Acc@5: 89.6243 (89.6243)
2025-06-01 16:52:08,464 - train - INFO - Test: [  50/70]  Time: 0.120 (0.908)  Loss:  1.7314 (1.7832)  Acc@1: 63.1496 (61.8432)  Acc@5: 83.7079 (84.2473)
2025-06-01 16:52:24,976 - train - INFO - Test: [  70/70]  Time: 0.034 (0.885)  Loss:  2.7637 (1.8484)  Acc@1: 38.2812 (60.3690)  Acc@5: 71.2500 (82.8125)
2025-06-01 16:52:29,843 - train - INFO - Train: 60 [   0/224 (  0%)]  Loss:  3.184332 (3.1843)  Time: 4.545s, 1253.18/s  (4.545s, 1253.18/s)  LR: 9.046e-03  Data: 3.640 (3.640)
2025-06-01 16:53:10,771 - train - INFO - Train: 60 [  50/224 ( 22%)]  Loss:  3.196706 (3.1905)  Time: 0.550s, 10364.74/s  (0.892s, 6388.50/s)  LR: 9.046e-03  Data: 0.000 (0.132)
2025-06-01 16:53:52,150 - train - INFO - Train: 60 [ 100/224 ( 45%)]  Loss:  3.229362 (3.2035)  Time: 1.656s, 3438.93/s  (0.860s, 6624.19/s)  LR: 9.046e-03  Data: 0.000 (0.067)
2025-06-01 16:54:33,016 - train - INFO - Train: 60 [ 150/224 ( 67%)]  Loss:  3.254447 (3.2162)  Time: 0.549s, 10376.99/s  (0.846s, 6734.60/s)  LR: 9.046e-03  Data: 0.000 (0.045)
2025-06-01 16:55:14,302 - train - INFO - Train: 60 [ 200/224 ( 90%)]  Loss:  3.168435 (3.2067)  Time: 1.774s, 3210.73/s  (0.841s, 6774.65/s)  LR: 9.046e-03  Data: 0.000 (0.034)
2025-06-01 16:55:31,836 - train - INFO - Train: 60 [ 223/224 (100%)]  Loss:  3.187721 (3.2035)  Time: 0.549s, 10378.81/s  (0.833s, 6840.16/s)  LR: 9.046e-03  Data: 0.000 (0.030)
2025-06-01 16:55:36,594 - train - INFO - Test: [   0/70]  Time: 4.505 (4.505)  Loss:  1.4844 (1.4844)  Acc@1: 68.3462 (68.3462)  Acc@5: 89.2029 (89.2029)
2025-06-01 16:56:19,238 - train - INFO - Test: [  50/70]  Time: 0.120 (0.924)  Loss:  1.7500 (1.9566)  Acc@1: 64.6067 (57.6242)  Acc@5: 82.7598 (81.5168)
2025-06-01 16:56:36,116 - train - INFO - Test: [  70/70]  Time: 0.034 (0.902)  Loss:  2.7852 (2.0208)  Acc@1: 31.4062 (56.3445)  Acc@5: 72.3438 (80.2800)
2025-06-01 16:56:41,145 - train - INFO - Train: 61 [   0/224 (  0%)]  Loss:  3.215148 (3.2151)  Time: 4.725s, 1205.61/s  (4.725s, 1205.61/s)  LR: 9.015e-03  Data: 3.861 (3.861)
2025-06-01 16:57:22,178 - train - INFO - Train: 61 [  50/224 ( 22%)]  Loss:  3.204355 (3.2098)  Time: 0.555s, 10257.87/s  (0.897s, 6348.74/s)  LR: 9.015e-03  Data: 0.000 (0.102)
2025-06-01 16:58:03,177 - train - INFO - Train: 61 [ 100/224 ( 45%)]  Loss:  3.180376 (3.2000)  Time: 0.863s, 6602.29/s  (0.859s, 6631.34/s)  LR: 9.015e-03  Data: 0.000 (0.051)
2025-06-01 16:58:44,647 - train - INFO - Train: 61 [ 150/224 ( 67%)]  Loss:  3.165926 (3.1915)  Time: 1.689s, 3373.23/s  (0.849s, 6707.84/s)  LR: 9.015e-03  Data: 0.000 (0.034)
2025-06-01 16:59:25,106 - train - INFO - Train: 61 [ 200/224 ( 90%)]  Loss:  3.192124 (3.1916)  Time: 0.556s, 10251.10/s  (0.839s, 6787.37/s)  LR: 9.015e-03  Data: 0.000 (0.026)
2025-06-01 16:59:44,055 - train - INFO - Train: 61 [ 223/224 (100%)]  Loss:  3.207200 (3.1942)  Time: 0.545s, 10457.08/s  (0.838s, 6800.15/s)  LR: 9.015e-03  Data: 0.000 (0.023)
2025-06-01 16:59:48,939 - train - INFO - Test: [   0/70]  Time: 4.650 (4.650)  Loss:  1.3477 (1.3477)  Acc@1: 72.7528 (72.7528)  Acc@5: 89.8876 (89.8876)
2025-06-01 17:00:30,962 - train - INFO - Test: [  50/70]  Time: 0.127 (0.915)  Loss:  2.0605 (1.9012)  Acc@1: 56.3553 (58.6483)  Acc@5: 77.9670 (81.9113)
2025-06-01 17:00:47,682 - train - INFO - Test: [  70/70]  Time: 0.036 (0.893)  Loss:  2.1484 (1.9672)  Acc@1: 46.0938 (57.2378)  Acc@5: 81.7969 (80.7740)
2025-06-01 17:00:52,532 - train - INFO - Train: 62 [   0/224 (  0%)]  Loss:  3.226515 (3.2265)  Time: 4.545s, 1253.17/s  (4.545s, 1253.17/s)  LR: 8.984e-03  Data: 3.857 (3.857)
2025-06-01 17:01:33,315 - train - INFO - Train: 62 [  50/224 ( 22%)]  Loss:  3.226282 (3.2264)  Time: 0.548s, 10386.21/s  (0.889s, 6408.85/s)  LR: 8.984e-03  Data: 0.000 (0.336)
2025-06-01 17:02:14,321 - train - INFO - Train: 62 [ 100/224 ( 45%)]  Loss:  3.188514 (3.2138)  Time: 1.384s, 4114.15/s  (0.855s, 6663.78/s)  LR: 8.984e-03  Data: 0.842 (0.304)
2025-06-01 17:02:54,916 - train - INFO - Train: 62 [ 150/224 ( 67%)]  Loss:  3.165314 (3.2017)  Time: 0.942s, 6045.65/s  (0.841s, 6776.37/s)  LR: 8.984e-03  Data: 0.000 (0.270)
2025-06-01 17:03:36,208 - train - INFO - Train: 62 [ 200/224 ( 90%)]  Loss:  3.206499 (3.2026)  Time: 1.568s, 3631.57/s  (0.837s, 6806.07/s)  LR: 8.984e-03  Data: 1.020 (0.264)
2025-06-01 17:03:54,081 - train - INFO - Train: 62 [ 223/224 (100%)]  Loss:  3.190878 (3.2007)  Time: 1.076s, 5294.37/s  (0.831s, 6856.41/s)  LR: 8.984e-03  Data: 0.000 (0.254)
2025-06-01 17:03:59,072 - train - INFO - Test: [   0/70]  Time: 4.745 (4.745)  Loss:  1.4102 (1.4102)  Acc@1: 71.9803 (71.9803)  Acc@5: 90.3090 (90.3090)
2025-06-01 17:04:41,783 - train - INFO - Test: [  50/70]  Time: 0.120 (0.931)  Loss:  1.9346 (1.8601)  Acc@1: 60.3581 (60.6876)  Acc@5: 80.3195 (83.4294)
2025-06-01 17:04:58,324 - train - INFO - Test: [  70/70]  Time: 0.034 (0.901)  Loss:  2.6035 (1.9230)  Acc@1: 36.5625 (59.0330)  Acc@5: 73.7500 (82.1828)
2025-06-01 17:05:03,272 - train - INFO - Train: 63 [   0/224 (  0%)]  Loss:  3.185660 (3.1857)  Time: 4.622s, 1232.45/s  (4.622s, 1232.45/s)  LR: 8.952e-03  Data: 3.676 (3.676)
2025-06-01 17:05:44,298 - train - INFO - Train: 63 [  50/224 ( 22%)]  Loss:  3.198325 (3.1920)  Time: 0.555s, 10265.32/s  (0.895s, 6364.42/s)  LR: 8.952e-03  Data: 0.000 (0.212)
2025-06-01 17:06:25,886 - train - INFO - Train: 63 [ 100/224 ( 45%)]  Loss:  3.216123 (3.2000)  Time: 1.448s, 3934.62/s  (0.864s, 6595.20/s)  LR: 8.952e-03  Data: 0.000 (0.107)
2025-06-01 17:07:06,836 - train - INFO - Train: 63 [ 150/224 ( 67%)]  Loss:  3.199056 (3.1998)  Time: 0.556s, 10251.39/s  (0.849s, 6710.22/s)  LR: 8.952e-03  Data: 0.000 (0.072)
2025-06-01 17:07:48,549 - train - INFO - Train: 63 [ 200/224 ( 90%)]  Loss:  3.217772 (3.2034)  Time: 1.762s, 3233.09/s  (0.845s, 6739.16/s)  LR: 8.952e-03  Data: 0.000 (0.054)
2025-06-01 17:08:06,746 - train - INFO - Train: 63 [ 223/224 (100%)]  Loss:  3.138928 (3.1926)  Time: 0.553s, 10306.70/s  (0.840s, 6783.73/s)  LR: 8.952e-03  Data: 0.000 (0.048)
2025-06-01 17:08:11,612 - train - INFO - Test: [   0/70]  Time: 4.629 (4.629)  Loss:  1.2529 (1.2529)  Acc@1: 69.9087 (69.9087)  Acc@5: 90.5548 (90.5548)
2025-06-01 17:08:54,051 - train - INFO - Test: [  50/70]  Time: 0.120 (0.923)  Loss:  1.7930 (1.8374)  Acc@1: 58.4270 (57.7547)  Acc@5: 82.0049 (81.6559)
2025-06-01 17:09:10,222 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.2109 (1.9102)  Acc@1: 39.2969 (56.3503)  Acc@5: 79.5312 (80.4363)
2025-06-01 17:09:15,166 - train - INFO - Train: 64 [   0/224 (  0%)]  Loss:  3.199001 (3.1990)  Time: 4.623s, 1231.98/s  (4.623s, 1231.98/s)  LR: 8.920e-03  Data: 4.075 (4.075)
2025-06-01 17:09:56,281 - train - INFO - Train: 64 [  50/224 ( 22%)]  Loss:  3.197085 (3.1980)  Time: 0.549s, 10367.08/s  (0.897s, 6351.37/s)  LR: 8.920e-03  Data: 0.000 (0.271)
2025-06-01 17:10:38,139 - train - INFO - Train: 64 [ 100/224 ( 45%)]  Loss:  3.229678 (3.2086)  Time: 1.232s, 4622.51/s  (0.867s, 6567.84/s)  LR: 8.920e-03  Data: 0.000 (0.137)
2025-06-01 17:11:19,836 - train - INFO - Train: 64 [ 150/224 ( 67%)]  Loss:  3.188080 (3.2035)  Time: 0.557s, 10231.15/s  (0.856s, 6652.52/s)  LR: 8.920e-03  Data: 0.000 (0.092)
2025-06-01 17:12:01,230 - train - INFO - Train: 64 [ 200/224 ( 90%)]  Loss:  3.162348 (3.1952)  Time: 0.556s, 10249.73/s  (0.849s, 6707.80/s)  LR: 8.920e-03  Data: 0.000 (0.069)
2025-06-01 17:12:20,219 - train - INFO - Train: 64 [ 223/224 (100%)]  Loss:  3.176600 (3.1921)  Time: 0.554s, 10288.50/s  (0.847s, 6727.07/s)  LR: 8.920e-03  Data: 0.000 (0.062)
2025-06-01 17:12:25,248 - train - INFO - Test: [   0/70]  Time: 4.771 (4.771)  Loss:  1.1631 (1.1631)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.7317 (92.7317)
2025-06-01 17:13:07,248 - train - INFO - Test: [  50/70]  Time: 0.120 (0.917)  Loss:  1.9209 (1.8236)  Acc@1: 58.5499 (60.6759)  Acc@5: 82.8301 (83.4259)
2025-06-01 17:13:23,644 - train - INFO - Test: [  70/70]  Time: 0.034 (0.890)  Loss:  2.3418 (1.9030)  Acc@1: 43.5938 (59.1033)  Acc@5: 76.8750 (81.9618)
2025-06-01 17:13:29,219 - train - INFO - Train: 65 [   0/224 (  0%)]  Loss:  3.171791 (3.1718)  Time: 5.265s, 1081.95/s  (5.265s, 1081.95/s)  LR: 8.887e-03  Data: 4.102 (4.102)
2025-06-01 17:14:10,244 - train - INFO - Train: 65 [  50/224 ( 22%)]  Loss:  3.206626 (3.1892)  Time: 0.556s, 10243.23/s  (0.908s, 6275.75/s)  LR: 8.887e-03  Data: 0.000 (0.103)
2025-06-01 17:14:51,608 - train - INFO - Train: 65 [ 100/224 ( 45%)]  Loss:  3.205156 (3.1945)  Time: 1.663s, 3424.61/s  (0.868s, 6563.62/s)  LR: 8.887e-03  Data: 0.000 (0.052)
2025-06-01 17:15:31,644 - train - INFO - Train: 65 [ 150/224 ( 67%)]  Loss:  3.191986 (3.1939)  Time: 0.555s, 10269.72/s  (0.846s, 6736.15/s)  LR: 8.887e-03  Data: 0.000 (0.035)
2025-06-01 17:16:12,694 - train - INFO - Train: 65 [ 200/224 ( 90%)]  Loss:  3.209627 (3.1970)  Time: 1.201s, 4742.96/s  (0.839s, 6785.29/s)  LR: 8.887e-03  Data: 0.000 (0.026)
2025-06-01 17:16:30,900 - train - INFO - Train: 65 [ 223/224 (100%)]  Loss:  3.166422 (3.1919)  Time: 0.545s, 10460.06/s  (0.835s, 6825.32/s)  LR: 8.887e-03  Data: 0.000 (0.024)
2025-06-01 17:16:35,736 - train - INFO - Test: [   0/70]  Time: 4.585 (4.585)  Loss:  1.3232 (1.3232)  Acc@1: 72.6826 (72.6826)  Acc@5: 90.6426 (90.6426)
2025-06-01 17:17:18,012 - train - INFO - Test: [  50/70]  Time: 0.120 (0.919)  Loss:  1.9219 (1.9263)  Acc@1: 59.2170 (58.4989)  Acc@5: 82.8301 (81.8707)
2025-06-01 17:17:34,474 - train - INFO - Test: [  70/70]  Time: 0.034 (0.892)  Loss:  1.9629 (2.0019)  Acc@1: 43.0469 (57.0500)  Acc@5: 82.8906 (80.5400)
2025-06-01 17:17:39,264 - train - INFO - Train: 66 [   0/224 (  0%)]  Loss:  3.199598 (3.1996)  Time: 4.491s, 1268.21/s  (4.491s, 1268.21/s)  LR: 8.854e-03  Data: 3.936 (3.936)
2025-06-01 17:18:19,887 - train - INFO - Train: 66 [  50/224 ( 22%)]  Loss:  3.233452 (3.2165)  Time: 0.549s, 10378.01/s  (0.885s, 6439.60/s)  LR: 8.854e-03  Data: 0.000 (0.337)
2025-06-01 17:19:01,666 - train - INFO - Train: 66 [ 100/224 ( 45%)]  Loss:  3.192584 (3.2085)  Time: 1.640s, 3472.71/s  (0.860s, 6621.09/s)  LR: 8.854e-03  Data: 0.777 (0.296)
2025-06-01 17:19:42,091 - train - INFO - Train: 66 [ 150/224 ( 67%)]  Loss:  3.165442 (3.1978)  Time: 0.557s, 10226.93/s  (0.843s, 6755.75/s)  LR: 8.854e-03  Data: 0.000 (0.261)
2025-06-01 17:20:23,659 - train - INFO - Train: 66 [ 200/224 ( 90%)]  Loss:  3.171573 (3.1925)  Time: 1.767s, 3222.83/s  (0.840s, 6779.45/s)  LR: 8.854e-03  Data: 0.903 (0.253)
2025-06-01 17:20:41,398 - train - INFO - Train: 66 [ 223/224 (100%)]  Loss:  3.221122 (3.1973)  Time: 0.552s, 10321.14/s  (0.833s, 6837.12/s)  LR: 8.854e-03  Data: 0.000 (0.242)
2025-06-01 17:20:46,174 - train - INFO - Test: [   0/70]  Time: 4.545 (4.545)  Loss:  1.2139 (1.2139)  Acc@1: 74.1046 (74.1046)  Acc@5: 91.8539 (91.8539)
2025-06-01 17:21:28,283 - train - INFO - Test: [  50/70]  Time: 0.120 (0.915)  Loss:  1.8867 (1.8808)  Acc@1: 60.3055 (59.7712)  Acc@5: 81.7065 (82.8452)
2025-06-01 17:21:44,835 - train - INFO - Test: [  70/70]  Time: 0.034 (0.890)  Loss:  2.6387 (1.9516)  Acc@1: 34.6094 (58.1533)  Acc@5: 71.5625 (81.5003)
2025-06-01 17:21:49,776 - train - INFO - Train: 67 [   0/224 (  0%)]  Loss:  3.239334 (3.2393)  Time: 4.637s, 1228.30/s  (4.637s, 1228.30/s)  LR: 8.820e-03  Data: 3.529 (3.529)
2025-06-01 17:22:30,683 - train - INFO - Train: 67 [  50/224 ( 22%)]  Loss:  3.189815 (3.2146)  Time: 0.548s, 10396.38/s  (0.893s, 6378.53/s)  LR: 8.820e-03  Data: 0.000 (0.306)
2025-06-01 17:23:11,427 - train - INFO - Train: 67 [ 100/224 ( 45%)]  Loss:  3.206565 (3.2119)  Time: 1.376s, 4138.80/s  (0.854s, 6667.38/s)  LR: 8.820e-03  Data: 0.429 (0.272)
2025-06-01 17:23:51,899 - train - INFO - Train: 67 [ 150/224 ( 67%)]  Loss:  3.174920 (3.2027)  Time: 0.556s, 10247.04/s  (0.839s, 6785.51/s)  LR: 8.820e-03  Data: 0.000 (0.256)
2025-06-01 17:24:32,789 - train - INFO - Train: 67 [ 200/224 ( 90%)]  Loss:  3.193331 (3.2008)  Time: 1.472s, 3870.05/s  (0.834s, 6829.42/s)  LR: 8.820e-03  Data: 0.869 (0.245)
2025-06-01 17:24:51,007 - train - INFO - Train: 67 [ 223/224 (100%)]  Loss:  3.231570 (3.2059)  Time: 0.545s, 10457.80/s  (0.830s, 6864.92/s)  LR: 8.820e-03  Data: 0.000 (0.243)
2025-06-01 17:24:55,858 - train - INFO - Test: [   0/70]  Time: 4.599 (4.599)  Loss:  1.1982 (1.1982)  Acc@1: 73.4550 (73.4550)  Acc@5: 90.8006 (90.8006)
2025-06-01 17:25:38,065 - train - INFO - Test: [  50/70]  Time: 0.212 (0.918)  Loss:  2.2930 (1.7782)  Acc@1: 50.6145 (59.6607)  Acc@5: 75.4565 (82.9719)
2025-06-01 17:25:54,530 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.7578 (1.8660)  Acc@1: 40.7812 (58.1070)  Acc@5: 69.6875 (81.5370)
2025-06-01 17:25:59,257 - train - INFO - Train: 68 [   0/224 (  0%)]  Loss:  3.213059 (3.2131)  Time: 4.422s, 1288.04/s  (4.422s, 1288.04/s)  LR: 8.786e-03  Data: 3.872 (3.872)
2025-06-01 17:26:40,390 - train - INFO - Train: 68 [  50/224 ( 22%)]  Loss:  3.163325 (3.1882)  Time: 0.551s, 10329.45/s  (0.893s, 6376.96/s)  LR: 8.786e-03  Data: 0.000 (0.245)
2025-06-01 17:27:22,308 - train - INFO - Train: 68 [ 100/224 ( 45%)]  Loss:  3.181306 (3.1859)  Time: 1.611s, 3535.66/s  (0.866s, 6577.04/s)  LR: 8.786e-03  Data: 0.000 (0.144)
2025-06-01 17:28:02,513 - train - INFO - Train: 68 [ 150/224 ( 67%)]  Loss:  3.212240 (3.1925)  Time: 0.555s, 10256.16/s  (0.846s, 6736.71/s)  LR: 8.786e-03  Data: 0.000 (0.096)
2025-06-01 17:28:44,616 - train - INFO - Train: 68 [ 200/224 ( 90%)]  Loss:  3.209617 (3.1959)  Time: 1.959s, 2908.01/s  (0.845s, 6743.62/s)  LR: 8.786e-03  Data: 0.000 (0.072)
2025-06-01 17:29:02,254 - train - INFO - Train: 68 [ 223/224 (100%)]  Loss:  3.176518 (3.1927)  Time: 0.555s, 10266.00/s  (0.837s, 6808.03/s)  LR: 8.786e-03  Data: 0.000 (0.065)
2025-06-01 17:29:07,128 - train - INFO - Test: [   0/70]  Time: 4.616 (4.616)  Loss:  1.3926 (1.3926)  Acc@1: 69.8912 (69.8912)  Acc@5: 89.1854 (89.1854)
2025-06-01 17:29:49,940 - train - INFO - Test: [  50/70]  Time: 0.120 (0.930)  Loss:  1.9932 (1.9228)  Acc@1: 56.9171 (59.0098)  Acc@5: 80.5653 (82.4442)
2025-06-01 17:30:06,614 - train - INFO - Test: [  70/70]  Time: 0.036 (0.903)  Loss:  2.8008 (1.9973)  Acc@1: 32.9688 (57.5178)  Acc@5: 70.4688 (81.0753)
2025-06-01 17:30:11,661 - train - INFO - Train: 69 [   0/224 (  0%)]  Loss:  3.237081 (3.2371)  Time: 4.724s, 1205.74/s  (4.724s, 1205.74/s)  LR: 8.752e-03  Data: 3.769 (3.769)
2025-06-01 17:30:53,149 - train - INFO - Train: 69 [  50/224 ( 22%)]  Loss:  3.166495 (3.2018)  Time: 0.563s, 10112.45/s  (0.906s, 6286.52/s)  LR: 8.752e-03  Data: 0.000 (0.104)
2025-06-01 17:31:35,317 - train - INFO - Train: 69 [ 100/224 ( 45%)]  Loss:  3.211902 (3.2052)  Time: 1.705s, 3341.41/s  (0.875s, 6509.68/s)  LR: 8.752e-03  Data: 0.000 (0.052)
2025-06-01 17:32:15,562 - train - INFO - Train: 69 [ 150/224 ( 67%)]  Loss:  3.174691 (3.1975)  Time: 0.556s, 10238.19/s  (0.852s, 6687.12/s)  LR: 8.752e-03  Data: 0.000 (0.035)
2025-06-01 17:32:57,460 - train - INFO - Train: 69 [ 200/224 ( 90%)]  Loss:  3.208646 (3.1998)  Time: 1.656s, 3439.20/s  (0.848s, 6714.26/s)  LR: 8.752e-03  Data: 0.000 (0.026)
2025-06-01 17:33:15,341 - train - INFO - Train: 69 [ 223/224 (100%)]  Loss:  3.182665 (3.1969)  Time: 0.552s, 10322.87/s  (0.841s, 6772.44/s)  LR: 8.752e-03  Data: 0.000 (0.024)
2025-06-01 17:33:20,027 - train - INFO - Test: [   0/70]  Time: 4.441 (4.441)  Loss:  1.2168 (1.2168)  Acc@1: 73.0337 (73.0337)  Acc@5: 91.1517 (91.1517)
2025-06-01 17:34:02,676 - train - INFO - Test: [  50/70]  Time: 0.124 (0.923)  Loss:  1.9199 (1.8051)  Acc@1: 59.1292 (60.0717)  Acc@5: 80.7409 (83.2817)
2025-06-01 17:34:19,898 - train - INFO - Test: [  70/70]  Time: 0.035 (0.906)  Loss:  2.0801 (1.8771)  Acc@1: 49.0625 (58.7650)  Acc@5: 81.4062 (82.0608)
2025-06-01 17:34:24,943 - train - INFO - Train: 70 [   0/224 (  0%)]  Loss:  3.148669 (3.1487)  Time: 4.742s, 1201.20/s  (4.742s, 1201.20/s)  LR: 8.717e-03  Data: 3.965 (3.965)
2025-06-01 17:35:05,860 - train - INFO - Train: 70 [  50/224 ( 22%)]  Loss:  3.163079 (3.1559)  Time: 0.555s, 10258.99/s  (0.895s, 6362.56/s)  LR: 8.717e-03  Data: 0.000 (0.146)
2025-06-01 17:35:47,220 - train - INFO - Train: 70 [ 100/224 ( 45%)]  Loss:  3.208754 (3.1735)  Time: 1.390s, 4096.89/s  (0.862s, 6611.47/s)  LR: 8.717e-03  Data: 0.001 (0.074)
2025-06-01 17:36:28,092 - train - INFO - Train: 70 [ 150/224 ( 67%)]  Loss:  3.236294 (3.1892)  Time: 0.808s, 7050.89/s  (0.847s, 6725.52/s)  LR: 8.717e-03  Data: 0.000 (0.050)
2025-06-01 17:37:09,390 - train - INFO - Train: 70 [ 200/224 ( 90%)]  Loss:  3.207159 (3.1928)  Time: 0.821s, 6935.92/s  (0.842s, 6767.21/s)  LR: 8.717e-03  Data: 0.000 (0.037)
2025-06-01 17:37:28,026 - train - INFO - Train: 70 [ 223/224 (100%)]  Loss:  3.150066 (3.1857)  Time: 0.546s, 10438.45/s  (0.838s, 6793.33/s)  LR: 8.717e-03  Data: 0.000 (0.034)
2025-06-01 17:37:32,999 - train - INFO - Test: [   0/70]  Time: 4.723 (4.723)  Loss:  1.8408 (1.8408)  Acc@1: 67.3279 (67.3279)  Acc@5: 85.9199 (85.9199)
2025-06-01 17:38:15,459 - train - INFO - Test: [  50/70]  Time: 0.120 (0.925)  Loss:  2.2168 (2.1288)  Acc@1: 52.7739 (57.1774)  Acc@5: 78.7921 (80.6527)
2025-06-01 17:38:32,221 - train - INFO - Test: [  70/70]  Time: 0.034 (0.901)  Loss:  2.1914 (2.1689)  Acc@1: 51.5625 (55.7850)  Acc@5: 77.8906 (79.5135)
2025-06-01 17:38:37,176 - train - INFO - Train: 71 [   0/224 (  0%)]  Loss:  3.191601 (3.1916)  Time: 4.647s, 1225.81/s  (4.647s, 1225.81/s)  LR: 8.682e-03  Data: 3.454 (3.454)
2025-06-01 17:39:18,148 - train - INFO - Train: 71 [  50/224 ( 22%)]  Loss:  3.185245 (3.1884)  Time: 0.546s, 10429.05/s  (0.894s, 6368.30/s)  LR: 8.682e-03  Data: 0.000 (0.146)
2025-06-01 17:40:00,426 - train - INFO - Train: 71 [ 100/224 ( 45%)]  Loss:  3.180406 (3.1858)  Time: 1.806s, 3154.60/s  (0.870s, 6545.43/s)  LR: 8.682e-03  Data: 0.000 (0.074)
2025-06-01 17:40:41,494 - train - INFO - Train: 71 [ 150/224 ( 67%)]  Loss:  3.196749 (3.1885)  Time: 0.559s, 10181.26/s  (0.854s, 6669.52/s)  LR: 8.682e-03  Data: 0.000 (0.049)
2025-06-01 17:41:22,497 - train - INFO - Train: 71 [ 200/224 ( 90%)]  Loss:  3.205151 (3.1918)  Time: 1.316s, 4328.00/s  (0.846s, 6736.25/s)  LR: 8.682e-03  Data: 0.000 (0.037)
2025-06-01 17:41:40,519 - train - INFO - Train: 71 [ 223/224 (100%)]  Loss:  3.177714 (3.1895)  Time: 0.608s, 9361.31/s  (0.839s, 6787.44/s)  LR: 8.682e-03  Data: 0.000 (0.033)
2025-06-01 17:41:45,393 - train - INFO - Test: [   0/70]  Time: 4.635 (4.635)  Loss:  1.3613 (1.3613)  Acc@1: 73.7184 (73.7184)  Acc@5: 89.4839 (89.4839)
2025-06-01 17:42:27,303 - train - INFO - Test: [  50/70]  Time: 0.120 (0.913)  Loss:  2.0547 (1.8165)  Acc@1: 55.4775 (60.6253)  Acc@5: 77.5456 (83.3192)
2025-06-01 17:42:44,118 - train - INFO - Test: [  70/70]  Time: 0.034 (0.892)  Loss:  2.1367 (1.8806)  Acc@1: 48.2812 (59.2710)  Acc@5: 80.5469 (82.0710)
2025-06-01 17:42:49,219 - train - INFO - Train: 72 [   0/224 (  0%)]  Loss:  3.213468 (3.2135)  Time: 4.785s, 1190.51/s  (4.785s, 1190.51/s)  LR: 8.646e-03  Data: 3.811 (3.811)
2025-06-01 17:43:30,013 - train - INFO - Train: 72 [  50/224 ( 22%)]  Loss:  3.198216 (3.2058)  Time: 0.549s, 10370.97/s  (0.894s, 6373.71/s)  LR: 8.646e-03  Data: 0.000 (0.233)
2025-06-01 17:44:11,486 - train - INFO - Train: 72 [ 100/224 ( 45%)]  Loss:  3.218742 (3.2101)  Time: 1.537s, 3704.94/s  (0.862s, 6608.84/s)  LR: 8.646e-03  Data: 0.033 (0.131)
2025-06-01 17:44:51,323 - train - INFO - Train: 72 [ 150/224 ( 67%)]  Loss:  3.199999 (3.2076)  Time: 0.548s, 10398.83/s  (0.840s, 6778.55/s)  LR: 8.646e-03  Data: 0.000 (0.148)
2025-06-01 17:45:32,303 - train - INFO - Train: 72 [ 200/224 ( 90%)]  Loss:  3.180202 (3.2021)  Time: 1.639s, 3475.00/s  (0.835s, 6820.40/s)  LR: 8.646e-03  Data: 0.996 (0.171)
2025-06-01 17:45:50,190 - train - INFO - Train: 72 [ 223/224 (100%)]  Loss:  3.161245 (3.1953)  Time: 0.545s, 10448.00/s  (0.829s, 6868.94/s)  LR: 8.646e-03  Data: 0.000 (0.176)
2025-06-01 17:45:55,070 - train - INFO - Test: [   0/70]  Time: 4.621 (4.621)  Loss:  1.4268 (1.4268)  Acc@1: 70.4881 (70.4881)  Acc@5: 89.4839 (89.4839)
2025-06-01 17:46:37,430 - train - INFO - Test: [  50/70]  Time: 0.120 (0.921)  Loss:  1.9775 (1.8620)  Acc@1: 55.7760 (58.9461)  Acc@5: 79.8455 (82.6352)
2025-06-01 17:46:54,132 - train - INFO - Test: [  70/70]  Time: 0.035 (0.897)  Loss:  2.2695 (1.9330)  Acc@1: 42.8906 (57.6183)  Acc@5: 79.3750 (81.3493)
2025-06-01 17:46:59,018 - train - INFO - Train: 73 [   0/224 (  0%)]  Loss:  3.202617 (3.2026)  Time: 4.581s, 1243.44/s  (4.581s, 1243.44/s)  LR: 8.610e-03  Data: 4.021 (4.021)
2025-06-01 17:47:39,828 - train - INFO - Train: 73 [  50/224 ( 22%)]  Loss:  3.200399 (3.2015)  Time: 0.560s, 10165.69/s  (0.890s, 6400.10/s)  LR: 8.610e-03  Data: 0.000 (0.158)
2025-06-01 17:48:21,199 - train - INFO - Train: 73 [ 100/224 ( 45%)]  Loss:  3.246671 (3.2166)  Time: 1.613s, 3532.02/s  (0.859s, 6630.95/s)  LR: 8.610e-03  Data: 0.000 (0.084)
2025-06-01 17:49:02,307 - train - INFO - Train: 73 [ 150/224 ( 67%)]  Loss:  3.207589 (3.2143)  Time: 1.043s, 5463.57/s  (0.847s, 6726.55/s)  LR: 8.610e-03  Data: 0.000 (0.056)
2025-06-01 17:49:43,347 - train - INFO - Train: 73 [ 200/224 ( 90%)]  Loss:  3.236302 (3.2187)  Time: 1.072s, 5314.13/s  (0.840s, 6778.38/s)  LR: 8.610e-03  Data: 0.000 (0.042)
2025-06-01 17:50:01,493 - train - INFO - Train: 73 [ 223/224 (100%)]  Loss:  3.161267 (3.2091)  Time: 0.547s, 10417.73/s  (0.835s, 6821.19/s)  LR: 8.610e-03  Data: 0.000 (0.038)
2025-06-01 17:50:06,249 - train - INFO - Test: [   0/70]  Time: 4.508 (4.508)  Loss:  1.4004 (1.4004)  Acc@1: 72.1032 (72.1032)  Acc@5: 89.8701 (89.8701)
2025-06-01 17:50:48,556 - train - INFO - Test: [  50/70]  Time: 0.120 (0.918)  Loss:  2.0234 (1.8623)  Acc@1: 56.3553 (59.7492)  Acc@5: 78.5112 (82.9908)
2025-06-01 17:51:04,790 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.6172 (1.9137)  Acc@1: 36.5625 (58.3235)  Acc@5: 72.8906 (81.8115)
2025-06-01 17:51:09,768 - train - INFO - Train: 74 [   0/224 (  0%)]  Loss:  3.180696 (3.1807)  Time: 4.675s, 1218.37/s  (4.675s, 1218.37/s)  LR: 8.574e-03  Data: 3.673 (3.673)
2025-06-01 17:51:52,069 - train - INFO - Train: 74 [  50/224 ( 22%)]  Loss:  3.204182 (3.1924)  Time: 0.549s, 10380.65/s  (0.921s, 6184.00/s)  LR: 8.574e-03  Data: 0.000 (0.077)
2025-06-01 17:52:33,317 - train - INFO - Train: 74 [ 100/224 ( 45%)]  Loss:  3.220398 (3.2018)  Time: 1.007s, 5654.24/s  (0.873s, 6520.99/s)  LR: 8.574e-03  Data: 0.000 (0.039)
2025-06-01 17:53:14,556 - train - INFO - Train: 74 [ 150/224 ( 67%)]  Loss:  3.230961 (3.2091)  Time: 0.555s, 10260.92/s  (0.857s, 6643.75/s)  LR: 8.574e-03  Data: 0.000 (0.026)
2025-06-01 17:53:55,157 - train - INFO - Train: 74 [ 200/224 ( 90%)]  Loss:  3.172245 (3.2017)  Time: 0.585s, 9741.22/s  (0.846s, 6732.31/s)  LR: 8.574e-03  Data: 0.000 (0.020)
2025-06-01 17:54:14,240 - train - INFO - Train: 74 [ 223/224 (100%)]  Loss:  3.161398 (3.1950)  Time: 0.545s, 10460.56/s  (0.844s, 6745.78/s)  LR: 8.574e-03  Data: 0.000 (0.018)
2025-06-01 17:54:19,115 - train - INFO - Test: [   0/70]  Time: 4.612 (4.612)  Loss:  1.4512 (1.4512)  Acc@1: 71.1552 (71.1552)  Acc@5: 89.3259 (89.3259)
2025-06-01 17:55:01,578 - train - INFO - Test: [  50/70]  Time: 0.120 (0.923)  Loss:  2.1074 (1.8347)  Acc@1: 57.3034 (60.8311)  Acc@5: 78.7746 (83.3578)
2025-06-01 17:55:18,181 - train - INFO - Test: [  70/70]  Time: 0.034 (0.897)  Loss:  2.5527 (1.9152)  Acc@1: 37.8125 (59.2050)  Acc@5: 75.7031 (81.8173)
2025-06-01 17:55:23,158 - train - INFO - Train: 75 [   0/224 (  0%)]  Loss:  3.219114 (3.2191)  Time: 4.667s, 1220.45/s  (4.667s, 1220.45/s)  LR: 8.537e-03  Data: 3.785 (3.785)
2025-06-01 17:56:04,471 - train - INFO - Train: 75 [  50/224 ( 22%)]  Loss:  3.209964 (3.2145)  Time: 0.551s, 10345.50/s  (0.902s, 6317.99/s)  LR: 8.537e-03  Data: 0.000 (0.247)
2025-06-01 17:56:45,933 - train - INFO - Train: 75 [ 100/224 ( 45%)]  Loss:  3.207821 (3.2123)  Time: 1.410s, 4039.46/s  (0.866s, 6579.30/s)  LR: 8.537e-03  Data: 0.000 (0.138)
2025-06-01 17:57:26,653 - train - INFO - Train: 75 [ 150/224 ( 67%)]  Loss:  3.206471 (3.2108)  Time: 0.550s, 10351.69/s  (0.849s, 6711.18/s)  LR: 8.537e-03  Data: 0.000 (0.092)
2025-06-01 17:58:07,949 - train - INFO - Train: 75 [ 200/224 ( 90%)]  Loss:  3.193311 (3.2073)  Time: 0.549s, 10374.37/s  (0.843s, 6756.42/s)  LR: 8.537e-03  Data: 0.000 (0.069)
2025-06-01 17:58:26,719 - train - INFO - Train: 75 [ 223/224 (100%)]  Loss:  3.172478 (3.2015)  Time: 0.545s, 10445.05/s  (0.840s, 6778.75/s)  LR: 8.537e-03  Data: 0.000 (0.062)
2025-06-01 17:58:31,758 - train - INFO - Test: [   0/70]  Time: 4.791 (4.791)  Loss:  1.4307 (1.4307)  Acc@1: 70.4003 (70.4003)  Acc@5: 88.9572 (88.9572)
2025-06-01 17:59:14,928 - train - INFO - Test: [  50/70]  Time: 0.120 (0.940)  Loss:  1.9316 (1.8230)  Acc@1: 59.3399 (60.7003)  Acc@5: 81.0569 (83.3185)
2025-06-01 17:59:31,575 - train - INFO - Test: [  70/70]  Time: 0.034 (0.910)  Loss:  2.8027 (1.9072)  Acc@1: 34.6094 (58.9565)  Acc@5: 70.0000 (81.8623)
2025-06-01 17:59:36,664 - train - INFO - Train: 76 [   0/224 (  0%)]  Loss:  3.192998 (3.1930)  Time: 4.784s, 1190.52/s  (4.784s, 1190.52/s)  LR: 8.500e-03  Data: 3.448 (3.448)
2025-06-01 18:00:18,319 - train - INFO - Train: 76 [  50/224 ( 22%)]  Loss:  3.197448 (3.1952)  Time: 0.549s, 10372.14/s  (0.911s, 6255.82/s)  LR: 8.500e-03  Data: 0.000 (0.068)
2025-06-01 18:00:58,472 - train - INFO - Train: 76 [ 100/224 ( 45%)]  Loss:  3.164785 (3.1851)  Time: 0.551s, 10344.58/s  (0.857s, 6644.38/s)  LR: 8.500e-03  Data: 0.000 (0.034)
2025-06-01 18:01:39,851 - train - INFO - Train: 76 [ 150/224 ( 67%)]  Loss:  3.204531 (3.1899)  Time: 0.549s, 10374.72/s  (0.847s, 6721.70/s)  LR: 8.500e-03  Data: 0.000 (0.023)
2025-06-01 18:02:20,827 - train - INFO - Train: 76 [ 200/224 ( 90%)]  Loss:  3.192676 (3.1905)  Time: 0.556s, 10250.45/s  (0.840s, 6777.32/s)  LR: 8.500e-03  Data: 0.000 (0.017)
2025-06-01 18:02:39,579 - train - INFO - Train: 76 [ 223/224 (100%)]  Loss:  3.170420 (3.1871)  Time: 0.546s, 10430.76/s  (0.838s, 6798.34/s)  LR: 8.500e-03  Data: 0.000 (0.016)
2025-06-01 18:02:44,447 - train - INFO - Test: [   0/70]  Time: 4.630 (4.630)  Loss:  1.4629 (1.4629)  Acc@1: 69.2416 (69.2416)  Acc@5: 87.8160 (87.8160)
2025-06-01 18:03:26,102 - train - INFO - Test: [  50/70]  Time: 0.120 (0.908)  Loss:  1.8613 (1.8907)  Acc@1: 59.7086 (58.4335)  Acc@5: 80.5302 (81.6187)
2025-06-01 18:03:42,742 - train - INFO - Test: [  70/70]  Time: 0.034 (0.886)  Loss:  2.1523 (1.9464)  Acc@1: 35.9375 (57.0150)  Acc@5: 80.5469 (80.4933)
2025-06-01 18:03:47,940 - train - INFO - Train: 77 [   0/224 (  0%)]  Loss:  3.151699 (3.1517)  Time: 4.905s, 1161.17/s  (4.905s, 1161.17/s)  LR: 8.462e-03  Data: 4.354 (4.354)
2025-06-01 18:04:28,771 - train - INFO - Train: 77 [  50/224 ( 22%)]  Loss:  3.192220 (3.1720)  Time: 0.548s, 10385.12/s  (0.897s, 6352.02/s)  LR: 8.462e-03  Data: 0.000 (0.308)
2025-06-01 18:05:10,273 - train - INFO - Train: 77 [ 100/224 ( 45%)]  Loss:  3.180068 (3.1747)  Time: 1.485s, 3836.29/s  (0.864s, 6594.87/s)  LR: 8.462e-03  Data: 0.003 (0.184)
2025-06-01 18:05:51,255 - train - INFO - Train: 77 [ 150/224 ( 67%)]  Loss:  3.196125 (3.1800)  Time: 0.550s, 10363.20/s  (0.849s, 6708.32/s)  LR: 8.462e-03  Data: 0.000 (0.123)
2025-06-01 18:06:32,076 - train - INFO - Train: 77 [ 200/224 ( 90%)]  Loss:  3.192098 (3.1824)  Time: 0.550s, 10364.54/s  (0.841s, 6773.18/s)  LR: 8.462e-03  Data: 0.000 (0.093)
2025-06-01 18:06:50,733 - train - INFO - Train: 77 [ 223/224 (100%)]  Loss:  3.201371 (3.1856)  Time: 0.546s, 10435.51/s  (0.838s, 6797.97/s)  LR: 8.462e-03  Data: 0.000 (0.083)
2025-06-01 18:06:55,633 - train - INFO - Test: [   0/70]  Time: 4.654 (4.654)  Loss:  1.5410 (1.5410)  Acc@1: 68.5569 (68.5569)  Acc@5: 87.8511 (87.8511)
2025-06-01 18:07:37,222 - train - INFO - Test: [  50/70]  Time: 0.120 (0.907)  Loss:  2.0508 (1.8648)  Acc@1: 55.7760 (59.6876)  Acc@5: 78.3532 (82.7860)
2025-06-01 18:07:53,773 - train - INFO - Test: [  70/70]  Time: 0.034 (0.884)  Loss:  2.0430 (1.9338)  Acc@1: 50.0000 (58.1333)  Acc@5: 82.7344 (81.3815)
2025-06-01 18:07:58,727 - train - INFO - Train: 78 [   0/224 (  0%)]  Loss:  3.226257 (3.2263)  Time: 4.653s, 1224.23/s  (4.653s, 1224.23/s)  LR: 8.424e-03  Data: 3.791 (3.791)
2025-06-01 18:08:39,913 - train - INFO - Train: 78 [  50/224 ( 22%)]  Loss:  3.188222 (3.2072)  Time: 0.548s, 10392.85/s  (0.899s, 6337.53/s)  LR: 8.424e-03  Data: 0.000 (0.224)
2025-06-01 18:09:20,662 - train - INFO - Train: 78 [ 100/224 ( 45%)]  Loss:  3.202899 (3.2058)  Time: 0.800s, 7120.38/s  (0.857s, 6644.26/s)  LR: 8.424e-03  Data: 0.235 (0.164)
2025-06-01 18:10:02,483 - train - INFO - Train: 78 [ 150/224 ( 67%)]  Loss:  3.163297 (3.1952)  Time: 1.774s, 3211.34/s  (0.850s, 6698.29/s)  LR: 8.424e-03  Data: 0.000 (0.111)
2025-06-01 18:10:42,825 - train - INFO - Train: 78 [ 200/224 ( 90%)]  Loss:  3.244592 (3.2051)  Time: 0.567s, 10044.89/s  (0.840s, 6784.73/s)  LR: 8.424e-03  Data: 0.000 (0.083)
2025-06-01 18:11:01,396 - train - INFO - Train: 78 [ 223/224 (100%)]  Loss:  3.206720 (3.2053)  Time: 0.547s, 10419.62/s  (0.836s, 6811.49/s)  LR: 8.424e-03  Data: 0.000 (0.075)
2025-06-01 18:11:06,254 - train - INFO - Test: [   0/70]  Time: 4.610 (4.610)  Loss:  1.2158 (1.2158)  Acc@1: 74.5260 (74.5260)  Acc@5: 91.9417 (91.9417)
2025-06-01 18:11:48,658 - train - INFO - Test: [  50/70]  Time: 0.120 (0.922)  Loss:  1.8535 (1.8561)  Acc@1: 61.0955 (59.6986)  Acc@5: 80.9867 (82.7746)
2025-06-01 18:12:05,244 - train - INFO - Test: [  70/70]  Time: 0.036 (0.896)  Loss:  2.6445 (1.9359)  Acc@1: 40.7031 (58.1305)  Acc@5: 71.3281 (81.3235)
2025-06-01 18:12:10,096 - train - INFO - Train: 79 [   0/224 (  0%)]  Loss:  3.195646 (3.1956)  Time: 4.544s, 1253.56/s  (4.544s, 1253.56/s)  LR: 8.386e-03  Data: 3.819 (3.819)
2025-06-01 18:12:51,688 - train - INFO - Train: 79 [  50/224 ( 22%)]  Loss:  3.183916 (3.1898)  Time: 0.549s, 10369.06/s  (0.905s, 6296.76/s)  LR: 8.386e-03  Data: 0.000 (0.104)
2025-06-01 18:13:33,987 - train - INFO - Train: 79 [ 100/224 ( 45%)]  Loss:  3.186235 (3.1886)  Time: 1.594s, 3572.72/s  (0.876s, 6505.54/s)  LR: 8.386e-03  Data: 0.000 (0.053)
2025-06-01 18:14:14,260 - train - INFO - Train: 79 [ 150/224 ( 67%)]  Loss:  3.164579 (3.1826)  Time: 0.550s, 10363.97/s  (0.852s, 6682.78/s)  LR: 8.386e-03  Data: 0.000 (0.035)
2025-06-01 18:14:56,234 - train - INFO - Train: 79 [ 200/224 ( 90%)]  Loss:  3.218914 (3.1899)  Time: 1.527s, 3729.07/s  (0.849s, 6708.03/s)  LR: 8.386e-03  Data: 0.000 (0.027)
2025-06-01 18:15:14,228 - train - INFO - Train: 79 [ 223/224 (100%)]  Loss:  3.198544 (3.1913)  Time: 0.546s, 10433.71/s  (0.842s, 6762.71/s)  LR: 8.386e-03  Data: 0.000 (0.024)
2025-06-01 18:15:19,025 - train - INFO - Test: [   0/70]  Time: 4.525 (4.525)  Loss:  1.8838 (1.8838)  Acc@1: 66.9066 (66.9066)  Acc@5: 86.0779 (86.0779)
2025-06-01 18:16:01,471 - train - INFO - Test: [  50/70]  Time: 0.120 (0.921)  Loss:  2.2188 (2.0533)  Acc@1: 55.3898 (58.8700)  Acc@5: 79.3890 (82.1753)
2025-06-01 18:16:18,140 - train - INFO - Test: [  70/70]  Time: 0.034 (0.896)  Loss:  2.6172 (2.1436)  Acc@1: 45.0781 (57.0307)  Acc@5: 72.5000 (80.3658)
2025-06-01 18:16:23,304 - train - INFO - Train: 80 [   0/224 (  0%)]  Loss:  3.206571 (3.2066)  Time: 4.856s, 1172.91/s  (4.856s, 1172.91/s)  LR: 8.347e-03  Data: 4.012 (4.012)
2025-06-01 18:17:04,809 - train - INFO - Train: 80 [  50/224 ( 22%)]  Loss:  3.199746 (3.2032)  Time: 0.551s, 10334.58/s  (0.909s, 6266.08/s)  LR: 8.347e-03  Data: 0.000 (0.100)
2025-06-01 18:17:47,467 - train - INFO - Train: 80 [ 100/224 ( 45%)]  Loss:  3.207176 (3.2045)  Time: 1.737s, 3278.89/s  (0.881s, 6462.83/s)  LR: 8.347e-03  Data: 0.000 (0.051)
2025-06-01 18:18:29,195 - train - INFO - Train: 80 [ 150/224 ( 67%)]  Loss:  3.165340 (3.1947)  Time: 0.549s, 10373.89/s  (0.866s, 6578.46/s)  LR: 8.347e-03  Data: 0.000 (0.034)
2025-06-01 18:19:11,304 - train - INFO - Train: 80 [ 200/224 ( 90%)]  Loss:  3.205906 (3.1969)  Time: 1.738s, 3277.24/s  (0.860s, 6623.60/s)  LR: 8.347e-03  Data: 0.000 (0.026)
2025-06-01 18:19:29,385 - train - INFO - Train: 80 [ 223/224 (100%)]  Loss:  3.188067 (3.1955)  Time: 0.552s, 10327.70/s  (0.852s, 6682.53/s)  LR: 8.347e-03  Data: 0.000 (0.023)
2025-06-01 18:19:34,076 - train - INFO - Test: [   0/70]  Time: 4.459 (4.459)  Loss:  1.1328 (1.1328)  Acc@1: 74.9473 (74.9473)  Acc@5: 92.3455 (92.3455)
2025-06-01 18:20:16,424 - train - INFO - Test: [  50/70]  Time: 0.121 (0.918)  Loss:  1.8486 (1.8681)  Acc@1: 61.8504 (59.3895)  Acc@5: 82.9530 (82.6287)
2025-06-01 18:20:33,012 - train - INFO - Test: [  70/70]  Time: 0.034 (0.893)  Loss:  2.3926 (1.9478)  Acc@1: 41.8750 (57.9590)  Acc@5: 74.7656 (81.2843)
2025-06-01 18:20:37,936 - train - INFO - Train: 81 [   0/224 (  0%)]  Loss:  3.196069 (3.1961)  Time: 4.617s, 1233.57/s  (4.617s, 1233.57/s)  LR: 8.308e-03  Data: 4.026 (4.026)
2025-06-01 18:21:19,213 - train - INFO - Train: 81 [  50/224 ( 22%)]  Loss:  3.185688 (3.1909)  Time: 0.551s, 10342.88/s  (0.900s, 6330.11/s)  LR: 8.308e-03  Data: 0.000 (0.222)
2025-06-01 18:22:00,874 - train - INFO - Train: 81 [ 100/224 ( 45%)]  Loss:  3.243063 (3.2083)  Time: 1.577s, 3612.00/s  (0.867s, 6571.05/s)  LR: 8.308e-03  Data: 0.000 (0.121)
2025-06-01 18:22:41,268 - train - INFO - Train: 81 [ 150/224 ( 67%)]  Loss:  3.207160 (3.2080)  Time: 0.556s, 10247.10/s  (0.847s, 6722.53/s)  LR: 8.308e-03  Data: 0.000 (0.081)
2025-06-01 18:23:22,921 - train - INFO - Train: 81 [ 200/224 ( 90%)]  Loss:  3.204162 (3.2072)  Time: 1.717s, 3317.30/s  (0.844s, 6750.83/s)  LR: 8.308e-03  Data: 0.000 (0.061)
2025-06-01 18:23:41,367 - train - INFO - Train: 81 [ 223/224 (100%)]  Loss:  3.241257 (3.2129)  Time: 1.124s, 5068.40/s  (0.839s, 6785.35/s)  LR: 8.308e-03  Data: 0.000 (0.055)
2025-06-01 18:23:46,291 - train - INFO - Test: [   0/70]  Time: 4.688 (4.688)  Loss:  1.2070 (1.2070)  Acc@1: 75.1404 (75.1404)  Acc@5: 91.3624 (91.3624)
2025-06-01 18:24:28,891 - train - INFO - Test: [  50/70]  Time: 0.120 (0.927)  Loss:  1.6104 (1.6881)  Acc@1: 62.5527 (62.0219)  Acc@5: 84.4803 (84.5155)
2025-06-01 18:24:45,706 - train - INFO - Test: [  70/70]  Time: 0.035 (0.903)  Loss:  2.5352 (1.7760)  Acc@1: 43.5938 (60.1525)  Acc@5: 72.5781 (83.0088)
2025-06-01 18:24:50,685 - train - INFO - Train: 82 [   0/224 (  0%)]  Loss:  3.194344 (3.1943)  Time: 4.669s, 1219.98/s  (4.669s, 1219.98/s)  LR: 8.269e-03  Data: 4.108 (4.108)
2025-06-01 18:25:31,165 - train - INFO - Train: 82 [  50/224 ( 22%)]  Loss:  3.170737 (3.1825)  Time: 0.554s, 10280.86/s  (0.885s, 6434.42/s)  LR: 8.269e-03  Data: 0.000 (0.168)
2025-06-01 18:26:12,221 - train - INFO - Train: 82 [ 100/224 ( 45%)]  Loss:  3.229411 (3.1982)  Time: 1.070s, 5322.75/s  (0.853s, 6673.85/s)  LR: 8.269e-03  Data: 0.000 (0.086)
2025-06-01 18:26:52,891 - train - INFO - Train: 82 [ 150/224 ( 67%)]  Loss:  3.200184 (3.1987)  Time: 0.549s, 10383.91/s  (0.840s, 6779.32/s)  LR: 8.269e-03  Data: 0.000 (0.058)
2025-06-01 18:27:33,395 - train - INFO - Train: 82 [ 200/224 ( 90%)]  Loss:  3.236195 (3.2062)  Time: 0.883s, 6451.67/s  (0.833s, 6840.39/s)  LR: 8.269e-03  Data: 0.000 (0.044)
2025-06-01 18:27:51,671 - train - INFO - Train: 82 [ 223/224 (100%)]  Loss:  3.209238 (3.2067)  Time: 0.546s, 10439.51/s  (0.829s, 6872.70/s)  LR: 8.269e-03  Data: 0.000 (0.039)
2025-06-01 18:27:56,543 - train - INFO - Test: [   0/70]  Time: 4.628 (4.628)  Loss:  1.4922 (1.4922)  Acc@1: 72.6475 (72.6475)  Acc@5: 90.3792 (90.3792)
2025-06-01 18:28:38,612 - train - INFO - Test: [  50/70]  Time: 0.120 (0.916)  Loss:  1.9561 (1.8769)  Acc@1: 60.6215 (61.5237)  Acc@5: 80.9867 (84.1526)
2025-06-01 18:28:55,095 - train - INFO - Test: [  70/70]  Time: 0.034 (0.890)  Loss:  2.1602 (1.9320)  Acc@1: 47.9688 (60.2482)  Acc@5: 81.3281 (82.9775)
2025-06-01 18:29:00,166 - train - INFO - Train: 83 [   0/224 (  0%)]  Loss:  3.192559 (3.1926)  Time: 4.755s, 1198.00/s  (4.755s, 1198.00/s)  LR: 8.229e-03  Data: 3.814 (3.814)
2025-06-01 18:29:41,081 - train - INFO - Train: 83 [  50/224 ( 22%)]  Loss:  3.213099 (3.2028)  Time: 0.549s, 10380.34/s  (0.895s, 6360.93/s)  LR: 8.229e-03  Data: 0.000 (0.187)
2025-06-01 18:30:22,449 - train - INFO - Train: 83 [ 100/224 ( 45%)]  Loss:  3.165583 (3.1904)  Time: 1.198s, 4755.85/s  (0.862s, 6609.88/s)  LR: 8.229e-03  Data: 0.000 (0.138)
2025-06-01 18:31:03,376 - train - INFO - Train: 83 [ 150/224 ( 67%)]  Loss:  3.197460 (3.1922)  Time: 0.550s, 10353.56/s  (0.847s, 6721.53/s)  LR: 8.229e-03  Data: 0.000 (0.123)
2025-06-01 18:31:44,798 - train - INFO - Train: 83 [ 200/224 ( 90%)]  Loss:  3.232680 (3.2003)  Time: 1.305s, 4363.27/s  (0.843s, 6759.24/s)  LR: 8.229e-03  Data: 0.000 (0.095)
2025-06-01 18:32:02,898 - train - INFO - Train: 83 [ 223/224 (100%)]  Loss:  3.209944 (3.2019)  Time: 0.545s, 10456.54/s  (0.837s, 6805.49/s)  LR: 8.229e-03  Data: 0.000 (0.085)
2025-06-01 18:32:07,862 - train - INFO - Test: [   0/70]  Time: 4.714 (4.714)  Loss:  1.4316 (1.4316)  Acc@1: 72.8933 (72.8933)  Acc@5: 91.5028 (91.5028)
2025-06-01 18:32:50,305 - train - INFO - Test: [  50/70]  Time: 0.120 (0.925)  Loss:  2.1445 (1.8927)  Acc@1: 58.3216 (61.5788)  Acc@5: 78.7044 (84.2036)
2025-06-01 18:33:06,807 - train - INFO - Test: [  70/70]  Time: 0.034 (0.897)  Loss:  2.5000 (1.9615)  Acc@1: 47.6562 (60.1510)  Acc@5: 74.5312 (82.9555)
2025-06-01 18:33:11,835 - train - INFO - Train: 84 [   0/224 (  0%)]  Loss:  3.186136 (3.1861)  Time: 4.717s, 1207.49/s  (4.717s, 1207.49/s)  LR: 8.189e-03  Data: 3.670 (3.670)
2025-06-01 18:33:52,943 - train - INFO - Train: 84 [  50/224 ( 22%)]  Loss:  3.234599 (3.2104)  Time: 0.548s, 10402.90/s  (0.899s, 6339.44/s)  LR: 8.189e-03  Data: 0.000 (0.156)
2025-06-01 18:34:34,949 - train - INFO - Train: 84 [ 100/224 ( 45%)]  Loss:  3.148693 (3.1898)  Time: 1.565s, 3639.20/s  (0.870s, 6550.21/s)  LR: 8.189e-03  Data: 0.000 (0.079)
2025-06-01 18:35:15,089 - train - INFO - Train: 84 [ 150/224 ( 67%)]  Loss:  3.204317 (3.1934)  Time: 0.548s, 10386.40/s  (0.847s, 6721.26/s)  LR: 8.189e-03  Data: 0.000 (0.053)
2025-06-01 18:35:56,178 - train - INFO - Train: 84 [ 200/224 ( 90%)]  Loss:  3.170761 (3.1889)  Time: 1.562s, 3647.47/s  (0.841s, 6772.40/s)  LR: 8.189e-03  Data: 0.000 (0.040)
2025-06-01 18:36:14,351 - train - INFO - Train: 84 [ 223/224 (100%)]  Loss:  3.238772 (3.1972)  Time: 0.547s, 10412.47/s  (0.836s, 6814.81/s)  LR: 8.189e-03  Data: 0.000 (0.036)
2025-06-01 18:36:19,195 - train - INFO - Test: [   0/70]  Time: 4.588 (4.588)  Loss:  1.4131 (1.4131)  Acc@1: 71.9452 (71.9452)  Acc@5: 90.1510 (90.1510)
2025-06-01 18:37:02,171 - train - INFO - Test: [  50/70]  Time: 0.120 (0.933)  Loss:  1.9590 (1.8109)  Acc@1: 59.5154 (61.8239)  Acc@5: 81.3378 (84.6710)
2025-06-01 18:37:18,790 - train - INFO - Test: [  70/70]  Time: 0.034 (0.904)  Loss:  2.8711 (1.8966)  Acc@1: 31.9531 (60.2183)  Acc@5: 72.6562 (83.1928)
2025-06-01 18:37:23,770 - train - INFO - Train: 85 [   0/224 (  0%)]  Loss:  3.193844 (3.1938)  Time: 4.665s, 1220.95/s  (4.665s, 1220.95/s)  LR: 8.148e-03  Data: 3.881 (3.881)
2025-06-01 18:38:06,321 - train - INFO - Train: 85 [  50/224 ( 22%)]  Loss:  3.216424 (3.2051)  Time: 0.714s, 7979.54/s  (0.926s, 6152.70/s)  LR: 8.148e-03  Data: 0.000 (0.093)
2025-06-01 18:38:48,609 - train - INFO - Train: 85 [ 100/224 ( 45%)]  Loss:  3.167935 (3.1927)  Time: 1.643s, 3466.74/s  (0.886s, 6427.88/s)  LR: 8.148e-03  Data: 0.000 (0.047)
2025-06-01 18:39:29,994 - train - INFO - Train: 85 [ 150/224 ( 67%)]  Loss:  3.165849 (3.1860)  Time: 0.547s, 10405.51/s  (0.867s, 6571.40/s)  LR: 8.148e-03  Data: 0.000 (0.031)
2025-06-01 18:40:11,851 - train - INFO - Train: 85 [ 200/224 ( 90%)]  Loss:  3.251907 (3.1992)  Time: 1.705s, 3341.53/s  (0.859s, 6627.85/s)  LR: 8.148e-03  Data: 0.000 (0.024)
2025-06-01 18:40:29,773 - train - INFO - Train: 85 [ 223/224 (100%)]  Loss:  3.215044 (3.2018)  Time: 0.545s, 10455.58/s  (0.851s, 6692.03/s)  LR: 8.148e-03  Data: 0.000 (0.021)
2025-06-01 18:40:34,755 - train - INFO - Test: [   0/70]  Time: 4.731 (4.731)  Loss:  1.2500 (1.2500)  Acc@1: 71.9628 (71.9628)  Acc@5: 89.7296 (89.7296)
2025-06-01 18:41:16,611 - train - INFO - Test: [  50/70]  Time: 0.120 (0.913)  Loss:  1.9600 (1.7221)  Acc@1: 56.3378 (59.9299)  Acc@5: 77.9846 (83.0504)
2025-06-01 18:41:33,130 - train - INFO - Test: [  70/70]  Time: 0.034 (0.889)  Loss:  2.2012 (1.8113)  Acc@1: 46.0938 (58.2485)  Acc@5: 78.3594 (81.6163)
2025-06-01 18:41:38,136 - train - INFO - Train: 86 [   0/224 (  0%)]  Loss:  3.153902 (3.1539)  Time: 4.693s, 1213.84/s  (4.693s, 1213.84/s)  LR: 8.108e-03  Data: 3.768 (3.768)
2025-06-01 18:42:19,436 - train - INFO - Train: 86 [  50/224 ( 22%)]  Loss:  3.226919 (3.1904)  Time: 0.549s, 10378.85/s  (0.902s, 6316.28/s)  LR: 8.108e-03  Data: 0.000 (0.170)
2025-06-01 18:43:01,642 - train - INFO - Train: 86 [ 100/224 ( 45%)]  Loss:  3.190205 (3.1903)  Time: 1.659s, 3433.74/s  (0.873s, 6522.92/s)  LR: 8.108e-03  Data: 0.000 (0.087)
2025-06-01 18:43:42,876 - train - INFO - Train: 86 [ 150/224 ( 67%)]  Loss:  3.152177 (3.1808)  Time: 0.556s, 10241.12/s  (0.857s, 6645.30/s)  LR: 8.108e-03  Data: 0.000 (0.058)
2025-06-01 18:44:24,599 - train - INFO - Train: 86 [ 200/224 ( 90%)]  Loss:  3.180724 (3.1808)  Time: 1.391s, 4095.67/s  (0.851s, 6689.47/s)  LR: 8.108e-03  Data: 0.000 (0.044)
2025-06-01 18:44:43,289 - train - INFO - Train: 86 [ 223/224 (100%)]  Loss:  3.184239 (3.1814)  Time: 0.770s, 7396.15/s  (0.847s, 6721.06/s)  LR: 8.108e-03  Data: 0.000 (0.039)
2025-06-01 18:44:48,262 - train - INFO - Test: [   0/70]  Time: 4.725 (4.725)  Loss:  1.2188 (1.2188)  Acc@1: 74.7191 (74.7191)  Acc@5: 91.9066 (91.9066)
2025-06-01 18:45:30,441 - train - INFO - Test: [  50/70]  Time: 0.120 (0.920)  Loss:  1.8945 (1.8544)  Acc@1: 59.7086 (60.4810)  Acc@5: 82.5140 (83.6332)
2025-06-01 18:45:46,914 - train - INFO - Test: [  70/70]  Time: 0.035 (0.893)  Loss:  2.2891 (1.9119)  Acc@1: 46.5625 (59.2333)  Acc@5: 79.0625 (82.4183)
2025-06-01 18:45:52,008 - train - INFO - Train: 87 [   0/224 (  0%)]  Loss:  3.179057 (3.1791)  Time: 4.793s, 1188.48/s  (4.793s, 1188.48/s)  LR: 8.066e-03  Data: 3.579 (3.579)
2025-06-01 18:46:33,017 - train - INFO - Train: 87 [  50/224 ( 22%)]  Loss:  3.165126 (3.1721)  Time: 0.549s, 10376.47/s  (0.898s, 6342.62/s)  LR: 8.066e-03  Data: 0.000 (0.099)
2025-06-01 18:47:14,998 - train - INFO - Train: 87 [ 100/224 ( 45%)]  Loss:  3.135039 (3.1597)  Time: 1.661s, 3429.43/s  (0.869s, 6553.91/s)  LR: 8.066e-03  Data: 0.000 (0.050)
2025-06-01 18:47:56,119 - train - INFO - Train: 87 [ 150/224 ( 67%)]  Loss:  3.155715 (3.1587)  Time: 0.548s, 10386.75/s  (0.854s, 6672.68/s)  LR: 8.066e-03  Data: 0.000 (0.034)
2025-06-01 18:48:38,084 - train - INFO - Train: 87 [ 200/224 ( 90%)]  Loss:  3.178755 (3.1627)  Time: 1.828s, 3115.99/s  (0.850s, 6700.75/s)  LR: 8.066e-03  Data: 0.000 (0.025)
2025-06-01 18:48:56,345 - train - INFO - Train: 87 [ 223/224 (100%)]  Loss:  3.210367 (3.1707)  Time: 0.545s, 10454.66/s  (0.844s, 6746.50/s)  LR: 8.066e-03  Data: 0.000 (0.023)
2025-06-01 18:49:01,311 - train - INFO - Test: [   0/70]  Time: 4.710 (4.710)  Loss:  1.3477 (1.3477)  Acc@1: 70.9972 (70.9972)  Acc@5: 89.5892 (89.5892)
2025-06-01 18:49:43,683 - train - INFO - Test: [  50/70]  Time: 0.120 (0.923)  Loss:  2.0527 (1.8539)  Acc@1: 56.7416 (59.2091)  Acc@5: 78.5463 (82.8307)
2025-06-01 18:50:00,231 - train - INFO - Test: [  70/70]  Time: 0.034 (0.896)  Loss:  2.6445 (1.9379)  Acc@1: 33.2031 (57.4788)  Acc@5: 71.7188 (81.3058)
2025-06-01 18:50:05,494 - train - INFO - Train: 88 [   0/224 (  0%)]  Loss:  3.196904 (3.1969)  Time: 4.954s, 1149.67/s  (4.954s, 1149.67/s)  LR: 8.025e-03  Data: 4.016 (4.016)
2025-06-01 18:50:46,614 - train - INFO - Train: 88 [  50/224 ( 22%)]  Loss:  3.219662 (3.2083)  Time: 0.556s, 10236.51/s  (0.903s, 6304.99/s)  LR: 8.025e-03  Data: 0.000 (0.170)
2025-06-01 18:51:29,199 - train - INFO - Train: 88 [ 100/224 ( 45%)]  Loss:  3.212324 (3.2096)  Time: 1.727s, 3297.59/s  (0.878s, 6489.05/s)  LR: 8.025e-03  Data: 0.000 (0.086)
2025-06-01 18:52:10,145 - train - INFO - Train: 88 [ 150/224 ( 67%)]  Loss:  3.159875 (3.1972)  Time: 0.555s, 10261.14/s  (0.858s, 6636.47/s)  LR: 8.025e-03  Data: 0.000 (0.058)
2025-06-01 18:52:52,849 - train - INFO - Train: 88 [ 200/224 ( 90%)]  Loss:  3.165864 (3.1909)  Time: 1.674s, 3402.47/s  (0.857s, 6644.63/s)  LR: 8.025e-03  Data: 0.000 (0.043)
2025-06-01 18:53:10,920 - train - INFO - Train: 88 [ 223/224 (100%)]  Loss:  3.245370 (3.2000)  Time: 0.553s, 10301.35/s  (0.850s, 6702.14/s)  LR: 8.025e-03  Data: 0.000 (0.039)
2025-06-01 18:53:15,664 - train - INFO - Test: [   0/70]  Time: 4.499 (4.499)  Loss:  1.4717 (1.4717)  Acc@1: 73.6657 (73.6657)  Acc@5: 92.8546 (92.8546)
2025-06-01 18:53:58,466 - train - INFO - Test: [  50/70]  Time: 0.120 (0.927)  Loss:  2.1211 (1.9723)  Acc@1: 60.7093 (60.5523)  Acc@5: 81.1973 (83.6728)
2025-06-01 18:54:14,933 - train - INFO - Test: [  70/70]  Time: 0.034 (0.898)  Loss:  2.5195 (2.0587)  Acc@1: 44.5312 (59.0645)  Acc@5: 77.5000 (82.2530)
2025-06-01 18:54:20,103 - train - INFO - Train: 89 [   0/224 (  0%)]  Loss:  3.225285 (3.2253)  Time: 4.866s, 1170.55/s  (4.866s, 1170.55/s)  LR: 7.983e-03  Data: 4.158 (4.158)
2025-06-01 18:55:02,223 - train - INFO - Train: 89 [  50/224 ( 22%)]  Loss:  3.177167 (3.2012)  Time: 0.555s, 10262.29/s  (0.921s, 6182.73/s)  LR: 7.983e-03  Data: 0.000 (0.175)
2025-06-01 18:55:44,604 - train - INFO - Train: 89 [ 100/224 ( 45%)]  Loss:  3.197610 (3.2000)  Time: 1.712s, 3326.93/s  (0.885s, 6437.71/s)  LR: 7.983e-03  Data: 0.000 (0.094)
2025-06-01 18:56:25,669 - train - INFO - Train: 89 [ 150/224 ( 67%)]  Loss:  3.168440 (3.1921)  Time: 0.549s, 10370.57/s  (0.864s, 6594.43/s)  LR: 7.983e-03  Data: 0.000 (0.063)
2025-06-01 18:57:08,028 - train - INFO - Train: 89 [ 200/224 ( 90%)]  Loss:  3.166360 (3.1870)  Time: 1.681s, 3388.28/s  (0.860s, 6626.11/s)  LR: 7.983e-03  Data: 0.000 (0.047)
2025-06-01 18:57:25,824 - train - INFO - Train: 89 [ 223/224 (100%)]  Loss:  3.135772 (3.1784)  Time: 0.548s, 10398.14/s  (0.851s, 6694.84/s)  LR: 7.983e-03  Data: 0.000 (0.043)
2025-06-01 18:57:30,611 - train - INFO - Test: [   0/70]  Time: 4.540 (4.540)  Loss:  1.1357 (1.1357)  Acc@1: 76.0709 (76.0709)  Acc@5: 92.2577 (92.2577)
2025-06-01 18:58:12,597 - train - INFO - Test: [  50/70]  Time: 0.120 (0.912)  Loss:  1.8008 (1.7982)  Acc@1: 60.7268 (61.2384)  Acc@5: 83.5674 (83.8204)
2025-06-01 18:58:29,011 - train - INFO - Test: [  70/70]  Time: 0.034 (0.886)  Loss:  2.1758 (1.8592)  Acc@1: 44.6875 (59.9698)  Acc@5: 79.9219 (82.7123)
2025-06-01 18:58:33,909 - train - INFO - Train: 90 [   0/224 (  0%)]  Loss:  3.207461 (3.2075)  Time: 4.572s, 1245.71/s  (4.572s, 1245.71/s)  LR: 7.941e-03  Data: 3.783 (3.783)
2025-06-01 18:59:14,904 - train - INFO - Train: 90 [  50/224 ( 22%)]  Loss:  3.190845 (3.1992)  Time: 0.550s, 10351.41/s  (0.893s, 6375.21/s)  LR: 7.941e-03  Data: 0.000 (0.131)
2025-06-01 18:59:56,583 - train - INFO - Train: 90 [ 100/224 ( 45%)]  Loss:  3.216397 (3.2049)  Time: 1.578s, 3610.39/s  (0.864s, 6594.09/s)  LR: 7.941e-03  Data: 0.000 (0.066)
2025-06-01 19:00:37,877 - train - INFO - Train: 90 [ 150/224 ( 67%)]  Loss:  3.188619 (3.2008)  Time: 0.549s, 10372.52/s  (0.851s, 6691.50/s)  LR: 7.941e-03  Data: 0.000 (0.044)
2025-06-01 19:01:19,785 - train - INFO - Train: 90 [ 200/224 ( 90%)]  Loss:  3.194666 (3.1996)  Time: 1.754s, 3248.31/s  (0.848s, 6717.25/s)  LR: 7.941e-03  Data: 0.000 (0.033)
2025-06-01 19:01:37,234 - train - INFO - Train: 90 [ 223/224 (100%)]  Loss:  3.211818 (3.2016)  Time: 0.704s, 8090.08/s  (0.839s, 6790.79/s)  LR: 7.941e-03  Data: 0.000 (0.030)
2025-06-01 19:01:42,038 - train - INFO - Test: [   0/70]  Time: 4.552 (4.552)  Loss:  1.2725 (1.2725)  Acc@1: 71.5239 (71.5239)  Acc@5: 89.5716 (89.5716)
2025-06-01 19:02:24,111 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  2.3320 (1.8698)  Acc@1: 51.5625 (58.9502)  Acc@5: 74.8596 (82.2328)
2025-06-01 19:02:40,555 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.1172 (1.9523)  Acc@1: 47.9688 (57.4543)  Acc@5: 80.3125 (80.7608)
2025-06-01 19:02:45,485 - train - INFO - Train: 91 [   0/224 (  0%)]  Loss:  3.187701 (3.1877)  Time: 4.627s, 1231.11/s  (4.627s, 1231.11/s)  LR: 7.899e-03  Data: 4.072 (4.072)
2025-06-01 19:03:26,689 - train - INFO - Train: 91 [  50/224 ( 22%)]  Loss:  3.168014 (3.1779)  Time: 0.557s, 10234.21/s  (0.899s, 6338.96/s)  LR: 7.899e-03  Data: 0.000 (0.201)
2025-06-01 19:04:09,324 - train - INFO - Train: 91 [ 100/224 ( 45%)]  Loss:  3.199944 (3.1852)  Time: 1.662s, 3428.21/s  (0.876s, 6503.45/s)  LR: 7.899e-03  Data: 0.000 (0.102)
2025-06-01 19:04:50,173 - train - INFO - Train: 91 [ 150/224 ( 67%)]  Loss:  3.189659 (3.1863)  Time: 0.556s, 10246.05/s  (0.856s, 6651.57/s)  LR: 7.899e-03  Data: 0.000 (0.068)
2025-06-01 19:05:32,254 - train - INFO - Train: 91 [ 200/224 ( 90%)]  Loss:  3.199481 (3.1890)  Time: 1.520s, 3746.75/s  (0.853s, 6680.18/s)  LR: 7.899e-03  Data: 0.000 (0.051)
2025-06-01 19:05:50,257 - train - INFO - Train: 91 [ 223/224 (100%)]  Loss:  3.174086 (3.1865)  Time: 0.552s, 10322.73/s  (0.845s, 6736.97/s)  LR: 7.899e-03  Data: 0.000 (0.046)
2025-06-01 19:05:55,246 - train - INFO - Test: [   0/70]  Time: 4.754 (4.754)  Loss:  2.0273 (2.0273)  Acc@1: 68.2935 (68.2935)  Acc@5: 85.8497 (85.8497)
2025-06-01 19:06:37,536 - train - INFO - Test: [  50/70]  Time: 0.120 (0.922)  Loss:  2.2695 (2.1628)  Acc@1: 55.0211 (58.5147)  Acc@5: 78.5990 (81.9932)
2025-06-01 19:06:54,423 - train - INFO - Test: [  70/70]  Time: 0.035 (0.900)  Loss:  2.6523 (2.2325)  Acc@1: 33.6719 (56.6483)  Acc@5: 75.7031 (80.3638)
2025-06-01 19:06:59,314 - train - INFO - Train: 92 [   0/224 (  0%)]  Loss:  3.156856 (3.1569)  Time: 4.575s, 1245.15/s  (4.575s, 1245.15/s)  LR: 7.856e-03  Data: 3.899 (3.899)
2025-06-01 19:07:40,913 - train - INFO - Train: 92 [  50/224 ( 22%)]  Loss:  3.258680 (3.2078)  Time: 0.552s, 10323.07/s  (0.905s, 6291.56/s)  LR: 7.856e-03  Data: 0.000 (0.127)
2025-06-01 19:08:22,409 - train - INFO - Train: 92 [ 100/224 ( 45%)]  Loss:  3.121645 (3.1791)  Time: 0.853s, 6673.97/s  (0.868s, 6562.32/s)  LR: 7.856e-03  Data: 0.000 (0.064)
2025-06-01 19:09:04,272 - train - INFO - Train: 92 [ 150/224 ( 67%)]  Loss:  3.238977 (3.1940)  Time: 0.550s, 10365.25/s  (0.858s, 6640.25/s)  LR: 7.856e-03  Data: 0.000 (0.043)
2025-06-01 19:09:45,446 - train - INFO - Train: 92 [ 200/224 ( 90%)]  Loss:  3.166143 (3.1885)  Time: 0.687s, 8297.06/s  (0.849s, 6707.03/s)  LR: 7.856e-03  Data: 0.000 (0.032)
2025-06-01 19:10:04,093 - train - INFO - Train: 92 [ 223/224 (100%)]  Loss:  3.162500 (3.1841)  Time: 0.546s, 10436.22/s  (0.845s, 6738.52/s)  LR: 7.856e-03  Data: 0.000 (0.029)
2025-06-01 19:10:08,869 - train - INFO - Test: [   0/70]  Time: 4.535 (4.535)  Loss:  1.5977 (1.5977)  Acc@1: 64.3610 (64.3610)  Acc@5: 87.5702 (87.5702)
2025-06-01 19:10:50,960 - train - INFO - Test: [  50/70]  Time: 0.121 (0.914)  Loss:  2.0781 (2.0081)  Acc@1: 54.4768 (55.9870)  Acc@5: 79.4944 (80.7003)
2025-06-01 19:11:07,590 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.7578 (2.1036)  Acc@1: 34.6875 (54.2078)  Acc@5: 66.0938 (78.8863)
2025-06-01 19:11:12,541 - train - INFO - Train: 93 [   0/224 (  0%)]  Loss:  3.165442 (3.1654)  Time: 4.631s, 1229.93/s  (4.631s, 1229.93/s)  LR: 7.813e-03  Data: 3.621 (3.621)
2025-06-01 19:11:53,545 - train - INFO - Train: 93 [  50/224 ( 22%)]  Loss:  3.181593 (3.1735)  Time: 0.547s, 10403.99/s  (0.895s, 6365.74/s)  LR: 7.813e-03  Data: 0.000 (0.128)
2025-06-01 19:12:35,483 - train - INFO - Train: 93 [ 100/224 ( 45%)]  Loss:  3.207573 (3.1849)  Time: 1.534s, 3713.29/s  (0.867s, 6569.49/s)  LR: 7.813e-03  Data: 0.000 (0.065)
2025-06-01 19:13:16,055 - train - INFO - Train: 93 [ 150/224 ( 67%)]  Loss:  3.203036 (3.1894)  Time: 0.554s, 10273.17/s  (0.849s, 6712.10/s)  LR: 7.813e-03  Data: 0.000 (0.043)
2025-06-01 19:13:57,247 - train - INFO - Train: 93 [ 200/224 ( 90%)]  Loss:  3.153323 (3.1822)  Time: 1.644s, 3463.73/s  (0.842s, 6761.26/s)  LR: 7.813e-03  Data: 0.000 (0.033)
2025-06-01 19:14:15,180 - train - INFO - Train: 93 [ 223/224 (100%)]  Loss:  3.203953 (3.1858)  Time: 0.547s, 10420.03/s  (0.836s, 6813.39/s)  LR: 7.813e-03  Data: 0.000 (0.029)
2025-06-01 19:14:20,157 - train - INFO - Test: [   0/70]  Time: 4.729 (4.729)  Loss:  1.3555 (1.3555)  Acc@1: 71.9452 (71.9452)  Acc@5: 88.0267 (88.0267)
2025-06-01 19:15:01,837 - train - INFO - Test: [  50/70]  Time: 0.120 (0.910)  Loss:  1.9316 (1.8527)  Acc@1: 58.4796 (58.5561)  Acc@5: 79.8806 (82.1516)
2025-06-01 19:15:18,128 - train - INFO - Test: [  70/70]  Time: 0.034 (0.883)  Loss:  2.4355 (1.9177)  Acc@1: 41.0938 (57.3390)  Acc@5: 71.7188 (80.7473)
2025-06-01 19:15:23,187 - train - INFO - Train: 94 [   0/224 (  0%)]  Loss:  3.194851 (3.1949)  Time: 4.734s, 1203.11/s  (4.734s, 1203.11/s)  LR: 7.769e-03  Data: 3.700 (3.700)
2025-06-01 19:16:04,918 - train - INFO - Train: 94 [  50/224 ( 22%)]  Loss:  3.188086 (3.1915)  Time: 0.554s, 10289.45/s  (0.911s, 6252.05/s)  LR: 7.769e-03  Data: 0.000 (0.150)
2025-06-01 19:16:46,809 - train - INFO - Train: 94 [ 100/224 ( 45%)]  Loss:  3.211120 (3.1980)  Time: 1.604s, 3550.36/s  (0.875s, 6511.29/s)  LR: 7.769e-03  Data: 0.000 (0.076)
2025-06-01 19:17:27,549 - train - INFO - Train: 94 [ 150/224 ( 67%)]  Loss:  3.203375 (3.1994)  Time: 0.555s, 10259.28/s  (0.855s, 6662.70/s)  LR: 7.769e-03  Data: 0.000 (0.051)
2025-06-01 19:18:09,149 - train - INFO - Train: 94 [ 200/224 ( 90%)]  Loss:  3.181038 (3.1957)  Time: 1.520s, 3746.77/s  (0.849s, 6707.48/s)  LR: 7.769e-03  Data: 0.000 (0.038)
2025-06-01 19:18:27,217 - train - INFO - Train: 94 [ 223/224 (100%)]  Loss:  3.186572 (3.1942)  Time: 0.550s, 10347.30/s  (0.843s, 6759.59/s)  LR: 7.769e-03  Data: 0.000 (0.034)
2025-06-01 19:18:32,041 - train - INFO - Test: [   0/70]  Time: 4.580 (4.580)  Loss:  1.4531 (1.4531)  Acc@1: 70.6987 (70.6987)  Acc@5: 88.8167 (88.8167)
2025-06-01 19:19:13,529 - train - INFO - Test: [  50/70]  Time: 0.326 (0.903)  Loss:  2.3359 (1.9355)  Acc@1: 50.8603 (57.7757)  Acc@5: 76.5098 (81.6538)
2025-06-01 19:19:29,656 - train - INFO - Test: [  70/70]  Time: 0.034 (0.876)  Loss:  2.4570 (2.0017)  Acc@1: 39.3750 (56.6030)  Acc@5: 76.4844 (80.4300)
2025-06-01 19:19:34,473 - train - INFO - Train: 95 [   0/224 (  0%)]  Loss:  3.181720 (3.1817)  Time: 4.508s, 1263.57/s  (4.508s, 1263.57/s)  LR: 7.725e-03  Data: 3.800 (3.800)
2025-06-01 19:20:15,360 - train - INFO - Train: 95 [  50/224 ( 22%)]  Loss:  3.158761 (3.1702)  Time: 0.555s, 10261.41/s  (0.890s, 6400.00/s)  LR: 7.725e-03  Data: 0.000 (0.276)
2025-06-01 19:20:57,319 - train - INFO - Train: 95 [ 100/224 ( 45%)]  Loss:  3.176135 (3.1722)  Time: 1.452s, 3923.57/s  (0.865s, 6586.28/s)  LR: 7.725e-03  Data: 0.000 (0.159)
2025-06-01 19:21:37,717 - train - INFO - Train: 95 [ 150/224 ( 67%)]  Loss:  3.151530 (3.1670)  Time: 0.556s, 10252.35/s  (0.846s, 6732.98/s)  LR: 7.725e-03  Data: 0.000 (0.106)
2025-06-01 19:22:18,904 - train - INFO - Train: 95 [ 200/224 ( 90%)]  Loss:  3.123896 (3.1584)  Time: 1.532s, 3717.31/s  (0.840s, 6777.37/s)  LR: 7.725e-03  Data: 0.000 (0.082)
2025-06-01 19:22:37,024 - train - INFO - Train: 95 [ 223/224 (100%)]  Loss:  3.197866 (3.1650)  Time: 0.546s, 10432.22/s  (0.835s, 6821.25/s)  LR: 7.725e-03  Data: 0.000 (0.074)
2025-06-01 19:22:41,690 - train - INFO - Test: [   0/70]  Time: 4.401 (4.401)  Loss:  1.3359 (1.3359)  Acc@1: 71.0850 (71.0850)  Acc@5: 90.4670 (90.4670)
2025-06-01 19:23:23,965 - train - INFO - Test: [  50/70]  Time: 0.120 (0.915)  Loss:  1.9092 (1.9585)  Acc@1: 58.5499 (57.4566)  Acc@5: 80.2669 (81.2793)
2025-06-01 19:23:40,328 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.6172 (2.0039)  Acc@1: 42.7344 (56.4000)  Acc@5: 70.2344 (80.2805)
2025-06-01 19:23:45,345 - train - INFO - Train: 96 [   0/224 (  0%)]  Loss:  3.170682 (3.1707)  Time: 4.706s, 1210.24/s  (4.706s, 1210.24/s)  LR: 7.681e-03  Data: 3.705 (3.705)
2025-06-01 19:24:26,429 - train - INFO - Train: 96 [  50/224 ( 22%)]  Loss:  3.179281 (3.1750)  Time: 0.554s, 10288.93/s  (0.898s, 6344.36/s)  LR: 7.681e-03  Data: 0.000 (0.077)
2025-06-01 19:25:08,317 - train - INFO - Train: 96 [ 100/224 ( 45%)]  Loss:  3.168375 (3.1728)  Time: 1.933s, 2946.07/s  (0.868s, 6561.76/s)  LR: 7.681e-03  Data: 0.000 (0.039)
2025-06-01 19:25:49,238 - train - INFO - Train: 96 [ 150/224 ( 67%)]  Loss:  3.157124 (3.1689)  Time: 0.548s, 10395.00/s  (0.852s, 6688.53/s)  LR: 7.681e-03  Data: 0.000 (0.026)
2025-06-01 19:26:29,778 - train - INFO - Train: 96 [ 200/224 ( 90%)]  Loss:  3.201903 (3.1755)  Time: 0.549s, 10373.15/s  (0.841s, 6769.27/s)  LR: 7.681e-03  Data: 0.000 (0.020)
2025-06-01 19:26:48,880 - train - INFO - Train: 96 [ 223/224 (100%)]  Loss:  3.166478 (3.1740)  Time: 0.546s, 10425.06/s  (0.840s, 6778.34/s)  LR: 7.681e-03  Data: 0.000 (0.018)
2025-06-01 19:26:53,800 - train - INFO - Test: [   0/70]  Time: 4.676 (4.676)  Loss:  1.5332 (1.5332)  Acc@1: 68.3111 (68.3111)  Acc@5: 86.5168 (86.5168)
2025-06-01 19:27:35,662 - train - INFO - Test: [  50/70]  Time: 0.121 (0.913)  Loss:  2.1875 (2.1181)  Acc@1: 53.0021 (54.6252)  Acc@5: 76.6503 (78.3945)
2025-06-01 19:27:52,173 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.6504 (2.1809)  Acc@1: 38.5156 (53.3765)  Acc@5: 71.4062 (77.2727)
2025-06-01 19:27:57,194 - train - INFO - Train: 97 [   0/224 (  0%)]  Loss:  3.168264 (3.1683)  Time: 4.716s, 1207.70/s  (4.716s, 1207.70/s)  LR: 7.637e-03  Data: 4.173 (4.173)
2025-06-01 19:28:38,383 - train - INFO - Train: 97 [  50/224 ( 22%)]  Loss:  3.170267 (3.1693)  Time: 0.549s, 10379.34/s  (0.900s, 6328.23/s)  LR: 7.637e-03  Data: 0.000 (0.279)
2025-06-01 19:29:19,922 - train - INFO - Train: 97 [ 100/224 ( 45%)]  Loss:  3.192734 (3.1771)  Time: 1.518s, 3751.61/s  (0.866s, 6579.18/s)  LR: 7.637e-03  Data: 0.000 (0.161)
2025-06-01 19:30:00,588 - train - INFO - Train: 97 [ 150/224 ( 67%)]  Loss:  3.216586 (3.1870)  Time: 0.549s, 10366.63/s  (0.848s, 6713.86/s)  LR: 7.637e-03  Data: 0.000 (0.108)
2025-06-01 19:30:41,954 - train - INFO - Train: 97 [ 200/224 ( 90%)]  Loss:  3.138537 (3.1773)  Time: 1.614s, 3528.42/s  (0.843s, 6755.64/s)  LR: 7.637e-03  Data: 0.000 (0.081)
2025-06-01 19:30:59,552 - train - INFO - Train: 97 [ 223/224 (100%)]  Loss:  3.183720 (3.1784)  Time: 0.544s, 10463.76/s  (0.835s, 6820.51/s)  LR: 7.637e-03  Data: 0.000 (0.073)
2025-06-01 19:31:04,115 - train - INFO - Test: [   0/70]  Time: 4.319 (4.319)  Loss:  1.1309 (1.1309)  Acc@1: 75.7725 (75.7725)  Acc@5: 91.8188 (91.8188)
2025-06-01 19:31:46,435 - train - INFO - Test: [  50/70]  Time: 0.741 (0.914)  Loss:  1.8389 (1.7319)  Acc@1: 61.0604 (61.4762)  Acc@5: 81.7591 (84.1895)
2025-06-01 19:32:02,017 - train - INFO - Test: [  70/70]  Time: 0.034 (0.876)  Loss:  2.3535 (1.8071)  Acc@1: 34.0625 (60.0160)  Acc@5: 78.2812 (82.9190)
2025-06-01 19:32:06,667 - train - INFO - Train: 98 [   0/224 (  0%)]  Loss:  3.163010 (3.1630)  Time: 4.336s, 1313.67/s  (4.336s, 1313.67/s)  LR: 7.593e-03  Data: 3.607 (3.607)
2025-06-01 19:32:47,937 - train - INFO - Train: 98 [  50/224 ( 22%)]  Loss:  3.103889 (3.1334)  Time: 0.549s, 10369.18/s  (0.894s, 6369.83/s)  LR: 7.593e-03  Data: 0.000 (0.215)
2025-06-01 19:33:30,087 - train - INFO - Train: 98 [ 100/224 ( 45%)]  Loss:  3.173808 (3.1469)  Time: 1.384s, 4114.34/s  (0.869s, 6555.82/s)  LR: 7.593e-03  Data: 0.000 (0.109)
2025-06-01 19:34:10,958 - train - INFO - Train: 98 [ 150/224 ( 67%)]  Loss:  3.176475 (3.1543)  Time: 0.549s, 10373.87/s  (0.852s, 6686.92/s)  LR: 7.593e-03  Data: 0.000 (0.073)
2025-06-01 19:34:52,053 - train - INFO - Train: 98 [ 200/224 ( 90%)]  Loss:  3.207577 (3.1650)  Time: 1.753s, 3249.78/s  (0.844s, 6745.89/s)  LR: 7.593e-03  Data: 0.000 (0.055)
2025-06-01 19:35:10,459 - train - INFO - Train: 98 [ 223/224 (100%)]  Loss:  3.172399 (3.1662)  Time: 0.546s, 10439.75/s  (0.840s, 6782.31/s)  LR: 7.593e-03  Data: 0.000 (0.049)
2025-06-01 19:35:15,185 - train - INFO - Test: [   0/70]  Time: 4.454 (4.454)  Loss:  1.3535 (1.3535)  Acc@1: 74.7191 (74.7191)  Acc@5: 91.0639 (91.0639)
2025-06-01 19:35:57,840 - train - INFO - Test: [  50/70]  Time: 0.120 (0.924)  Loss:  1.8320 (1.8338)  Acc@1: 60.5864 (60.6198)  Acc@5: 81.4080 (83.5777)
2025-06-01 19:36:14,528 - train - INFO - Test: [  70/70]  Time: 0.034 (0.899)  Loss:  2.2363 (1.8924)  Acc@1: 47.9688 (59.2243)  Acc@5: 79.7656 (82.2168)
2025-06-01 19:36:19,613 - train - INFO - Train: 99 [   0/224 (  0%)]  Loss:  3.167937 (3.1679)  Time: 4.775s, 1192.77/s  (4.775s, 1192.77/s)  LR: 7.548e-03  Data: 4.038 (4.038)
2025-06-01 19:37:00,729 - train - INFO - Train: 99 [  50/224 ( 22%)]  Loss:  3.166002 (3.1670)  Time: 0.549s, 10371.40/s  (0.900s, 6330.14/s)  LR: 7.548e-03  Data: 0.000 (0.174)
2025-06-01 19:37:42,695 - train - INFO - Train: 99 [ 100/224 ( 45%)]  Loss:  3.192099 (3.1753)  Time: 1.710s, 3331.12/s  (0.870s, 6548.25/s)  LR: 7.548e-03  Data: 0.000 (0.088)
2025-06-01 19:38:23,205 - train - INFO - Train: 99 [ 150/224 ( 67%)]  Loss:  3.127718 (3.1634)  Time: 0.550s, 10361.51/s  (0.850s, 6700.49/s)  LR: 7.548e-03  Data: 0.000 (0.059)
2025-06-01 19:39:05,262 - train - INFO - Train: 99 [ 200/224 ( 90%)]  Loss:  3.181426 (3.1670)  Time: 1.575s, 3617.35/s  (0.848s, 6718.10/s)  LR: 7.548e-03  Data: 0.000 (0.044)
2025-06-01 19:39:23,068 - train - INFO - Train: 99 [ 223/224 (100%)]  Loss:  3.138232 (3.1622)  Time: 0.545s, 10452.37/s  (0.840s, 6778.62/s)  LR: 7.548e-03  Data: 0.000 (0.040)
2025-06-01 19:39:27,745 - train - INFO - Test: [   0/70]  Time: 4.441 (4.441)  Loss:  1.3408 (1.3408)  Acc@1: 73.4726 (73.4726)  Acc@5: 90.0632 (90.0632)
2025-06-01 19:40:09,762 - train - INFO - Test: [  50/70]  Time: 0.124 (0.911)  Loss:  1.6729 (1.7946)  Acc@1: 63.3603 (61.3847)  Acc@5: 84.4979 (83.6163)
2025-06-01 19:40:26,317 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.6465 (1.8734)  Acc@1: 40.4688 (59.5848)  Acc@5: 74.7656 (82.2415)
2025-06-01 19:40:31,364 - train - INFO - Train: 100 [   0/224 (  0%)]  Loss:  3.205608 (3.2056)  Time: 4.730s, 1204.13/s  (4.730s, 1204.13/s)  LR: 7.503e-03  Data: 3.570 (3.570)
2025-06-01 19:41:11,983 - train - INFO - Train: 100 [  50/224 ( 22%)]  Loss:  3.149384 (3.1775)  Time: 0.549s, 10373.50/s  (0.889s, 6405.86/s)  LR: 7.503e-03  Data: 0.000 (0.321)
2025-06-01 19:41:53,652 - train - INFO - Train: 100 [ 100/224 ( 45%)]  Loss:  3.127360 (3.1608)  Time: 1.606s, 3546.10/s  (0.862s, 6611.41/s)  LR: 7.503e-03  Data: 1.015 (0.299)
2025-06-01 19:42:34,239 - train - INFO - Train: 100 [ 150/224 ( 67%)]  Loss:  3.178097 (3.1651)  Time: 0.550s, 10365.28/s  (0.845s, 6740.46/s)  LR: 7.503e-03  Data: 0.000 (0.285)
2025-06-01 19:43:16,244 - train - INFO - Train: 100 [ 200/224 ( 90%)]  Loss:  3.188367 (3.1698)  Time: 1.588s, 3587.84/s  (0.844s, 6750.35/s)  LR: 7.503e-03  Data: 1.047 (0.287)
2025-06-01 19:43:33,925 - train - INFO - Train: 100 [ 223/224 (100%)]  Loss:  3.168348 (3.1695)  Time: 0.545s, 10448.83/s  (0.836s, 6812.62/s)  LR: 7.503e-03  Data: 0.000 (0.280)
2025-06-01 19:43:38,868 - train - INFO - Test: [   0/70]  Time: 4.682 (4.682)  Loss:  1.3164 (1.3164)  Acc@1: 73.7886 (73.7886)  Acc@5: 90.5899 (90.5899)
2025-06-01 19:44:21,451 - train - INFO - Test: [  50/70]  Time: 0.120 (0.927)  Loss:  2.1074 (1.8303)  Acc@1: 57.3912 (60.8731)  Acc@5: 81.2851 (83.8762)
2025-06-01 19:44:38,449 - train - INFO - Test: [  70/70]  Time: 0.035 (0.905)  Loss:  2.8105 (1.9150)  Acc@1: 36.7188 (59.2700)  Acc@5: 69.3750 (82.3663)
2025-06-01 19:44:43,434 - train - INFO - Train: 101 [   0/224 (  0%)]  Loss:  3.144314 (3.1443)  Time: 4.680s, 1217.03/s  (4.680s, 1217.03/s)  LR: 7.457e-03  Data: 4.136 (4.136)
2025-06-01 19:45:24,626 - train - INFO - Train: 101 [  50/224 ( 22%)]  Loss:  3.197193 (3.1708)  Time: 0.549s, 10380.89/s  (0.899s, 6332.95/s)  LR: 7.457e-03  Data: 0.000 (0.181)
2025-06-01 19:46:06,623 - train - INFO - Train: 101 [ 100/224 ( 45%)]  Loss:  3.183610 (3.1750)  Time: 1.661s, 3429.78/s  (0.870s, 6547.37/s)  LR: 7.457e-03  Data: 0.000 (0.092)
2025-06-01 19:46:47,269 - train - INFO - Train: 101 [ 150/224 ( 67%)]  Loss:  3.207106 (3.1831)  Time: 0.548s, 10399.45/s  (0.851s, 6692.79/s)  LR: 7.457e-03  Data: 0.000 (0.061)
2025-06-01 19:47:29,250 - train - INFO - Train: 101 [ 200/224 ( 90%)]  Loss:  3.178944 (3.1822)  Time: 1.592s, 3576.86/s  (0.848s, 6715.36/s)  LR: 7.457e-03  Data: 0.000 (0.046)
2025-06-01 19:47:47,302 - train - INFO - Train: 101 [ 223/224 (100%)]  Loss:  3.132017 (3.1739)  Time: 0.552s, 10317.29/s  (0.842s, 6767.34/s)  LR: 7.457e-03  Data: 0.000 (0.041)
2025-06-01 19:47:51,982 - train - INFO - Test: [   0/70]  Time: 4.434 (4.434)  Loss:  1.3154 (1.3154)  Acc@1: 73.9291 (73.9291)  Acc@5: 91.2395 (91.2395)
2025-06-01 19:48:34,006 - train - INFO - Test: [  50/70]  Time: 0.188 (0.911)  Loss:  2.0977 (1.7990)  Acc@1: 54.6875 (61.4900)  Acc@5: 77.6159 (83.8421)
2025-06-01 19:48:50,333 - train - INFO - Test: [  70/70]  Time: 0.034 (0.884)  Loss:  2.1074 (1.8577)  Acc@1: 45.6250 (60.1410)  Acc@5: 81.8750 (82.6528)
2025-06-01 19:48:55,348 - train - INFO - Train: 102 [   0/224 (  0%)]  Loss:  3.153193 (3.1532)  Time: 4.695s, 1213.10/s  (4.695s, 1213.10/s)  LR: 7.411e-03  Data: 3.965 (3.965)
2025-06-01 19:49:36,065 - train - INFO - Train: 102 [  50/224 ( 22%)]  Loss:  3.141649 (3.1474)  Time: 0.550s, 10350.35/s  (0.890s, 6397.01/s)  LR: 7.411e-03  Data: 0.000 (0.201)
2025-06-01 19:50:18,497 - train - INFO - Train: 102 [ 100/224 ( 45%)]  Loss:  3.128039 (3.1410)  Time: 1.820s, 3130.41/s  (0.870s, 6549.27/s)  LR: 7.411e-03  Data: 0.000 (0.107)
2025-06-01 19:50:59,359 - train - INFO - Train: 102 [ 150/224 ( 67%)]  Loss:  3.180502 (3.1508)  Time: 0.549s, 10380.70/s  (0.852s, 6682.83/s)  LR: 7.411e-03  Data: 0.000 (0.071)
2025-06-01 19:51:41,223 - train - INFO - Train: 102 [ 200/224 ( 90%)]  Loss:  3.134506 (3.1476)  Time: 1.640s, 3472.28/s  (0.849s, 6712.39/s)  LR: 7.411e-03  Data: 0.000 (0.054)
2025-06-01 19:51:59,448 - train - INFO - Train: 102 [ 223/224 (100%)]  Loss:  3.175206 (3.1522)  Time: 0.544s, 10469.48/s  (0.843s, 6758.40/s)  LR: 7.411e-03  Data: 0.000 (0.048)
2025-06-01 19:52:04,244 - train - INFO - Test: [   0/70]  Time: 4.545 (4.545)  Loss:  1.2607 (1.2607)  Acc@1: 78.9150 (78.9150)  Acc@5: 92.5035 (92.5035)
2025-06-01 19:52:46,468 - train - INFO - Test: [  50/70]  Time: 0.120 (0.917)  Loss:  1.7236 (1.8730)  Acc@1: 67.0471 (62.3293)  Acc@5: 84.4452 (84.5182)
2025-06-01 19:53:03,200 - train - INFO - Test: [  70/70]  Time: 0.035 (0.894)  Loss:  2.7852 (1.9520)  Acc@1: 42.1094 (60.3090)  Acc@5: 72.2656 (83.0180)
2025-06-01 19:53:08,066 - train - INFO - Train: 103 [   0/224 (  0%)]  Loss:  3.169532 (3.1695)  Time: 4.516s, 1261.36/s  (4.516s, 1261.36/s)  LR: 7.365e-03  Data: 3.666 (3.666)
2025-06-01 19:53:50,943 - train - INFO - Train: 103 [  50/224 ( 22%)]  Loss:  3.150629 (3.1601)  Time: 0.550s, 10355.82/s  (0.929s, 6129.77/s)  LR: 7.365e-03  Data: 0.000 (0.113)
2025-06-01 19:54:32,684 - train - INFO - Train: 103 [ 100/224 ( 45%)]  Loss:  3.187157 (3.1691)  Time: 1.548s, 3679.07/s  (0.882s, 6454.58/s)  LR: 7.365e-03  Data: 0.000 (0.057)
2025-06-01 19:55:12,749 - train - INFO - Train: 103 [ 150/224 ( 67%)]  Loss:  3.161788 (3.1673)  Time: 0.551s, 10339.51/s  (0.856s, 6657.44/s)  LR: 7.365e-03  Data: 0.001 (0.038)
2025-06-01 19:55:54,914 - train - INFO - Train: 103 [ 200/224 ( 90%)]  Loss:  3.143556 (3.1625)  Time: 1.799s, 3165.67/s  (0.853s, 6681.36/s)  LR: 7.365e-03  Data: 0.000 (0.029)
2025-06-01 19:56:13,681 - train - INFO - Train: 103 [ 223/224 (100%)]  Loss:  3.175060 (3.1646)  Time: 0.551s, 10333.02/s  (0.849s, 6710.94/s)  LR: 7.365e-03  Data: 0.000 (0.026)
2025-06-01 19:56:18,775 - train - INFO - Test: [   0/70]  Time: 4.802 (4.802)  Loss:  1.3701 (1.3701)  Acc@1: 74.8596 (74.8596)  Acc@5: 92.3806 (92.3806)
2025-06-01 19:57:01,981 - train - INFO - Test: [  50/70]  Time: 0.121 (0.941)  Loss:  1.7744 (1.8719)  Acc@1: 66.0815 (62.0515)  Acc@5: 85.2879 (84.6239)
2025-06-01 19:57:18,827 - train - INFO - Test: [  70/70]  Time: 0.035 (0.913)  Loss:  2.4414 (1.9205)  Acc@1: 43.5938 (60.7250)  Acc@5: 76.7969 (83.4788)
2025-06-01 19:57:24,140 - train - INFO - Train: 104 [   0/224 (  0%)]  Loss:  3.125934 (3.1259)  Time: 5.001s, 1138.98/s  (5.001s, 1138.98/s)  LR: 7.319e-03  Data: 4.169 (4.169)
2025-06-01 19:58:06,510 - train - INFO - Train: 104 [  50/224 ( 22%)]  Loss:  3.192654 (3.1593)  Time: 0.554s, 10286.55/s  (0.929s, 6132.54/s)  LR: 7.319e-03  Data: 0.000 (0.302)
2025-06-01 19:58:48,216 - train - INFO - Train: 104 [ 100/224 ( 45%)]  Loss:  3.143625 (3.1541)  Time: 0.860s, 6625.49/s  (0.882s, 6458.70/s)  LR: 7.319e-03  Data: 0.311 (0.232)
2025-06-01 19:59:30,038 - train - INFO - Train: 104 [ 150/224 ( 67%)]  Loss:  3.212921 (3.1688)  Time: 0.551s, 10332.84/s  (0.867s, 6570.94/s)  LR: 7.319e-03  Data: 0.000 (0.172)
2025-06-01 20:00:10,640 - train - INFO - Train: 104 [ 200/224 ( 90%)]  Loss:  3.178822 (3.1708)  Time: 0.556s, 10240.78/s  (0.853s, 6676.03/s)  LR: 7.319e-03  Data: 0.000 (0.132)
2025-06-01 20:00:29,911 - train - INFO - Train: 104 [ 223/224 (100%)]  Loss:  3.187776 (3.1736)  Time: 0.552s, 10325.09/s  (0.852s, 6688.39/s)  LR: 7.319e-03  Data: 0.000 (0.118)
2025-06-01 20:00:35,179 - train - INFO - Test: [   0/70]  Time: 4.962 (4.962)  Loss:  1.1523 (1.1523)  Acc@1: 72.4192 (72.4192)  Acc@5: 90.6426 (90.6426)
2025-06-01 20:01:18,579 - train - INFO - Test: [  50/70]  Time: 0.122 (0.948)  Loss:  1.7637 (1.7543)  Acc@1: 60.5864 (59.1089)  Acc@5: 81.0042 (82.7602)
2025-06-01 20:01:35,411 - train - INFO - Test: [  70/70]  Time: 0.040 (0.918)  Loss:  1.6963 (1.8033)  Acc@1: 56.5625 (58.2070)  Acc@5: 85.0781 (81.8258)
2025-06-01 20:01:40,413 - train - INFO - Train: 105 [   0/224 (  0%)]  Loss:  3.135509 (3.1355)  Time: 4.636s, 1228.66/s  (4.636s, 1228.66/s)  LR: 7.273e-03  Data: 3.654 (3.654)
2025-06-01 20:02:22,027 - train - INFO - Train: 105 [  50/224 ( 22%)]  Loss:  3.158377 (3.1469)  Time: 0.549s, 10369.77/s  (0.907s, 6281.23/s)  LR: 7.273e-03  Data: 0.000 (0.326)
2025-06-01 20:03:03,638 - train - INFO - Train: 105 [ 100/224 ( 45%)]  Loss:  3.189665 (3.1612)  Time: 1.616s, 3524.84/s  (0.870s, 6548.08/s)  LR: 7.273e-03  Data: 0.960 (0.301)
2025-06-01 20:03:44,141 - train - INFO - Train: 105 [ 150/224 ( 67%)]  Loss:  3.165155 (3.1622)  Time: 0.555s, 10265.55/s  (0.850s, 6700.71/s)  LR: 7.273e-03  Data: 0.000 (0.268)
2025-06-01 20:04:26,247 - train - INFO - Train: 105 [ 200/224 ( 90%)]  Loss:  3.138396 (3.1574)  Time: 1.842s, 3092.88/s  (0.848s, 6716.37/s)  LR: 7.273e-03  Data: 0.703 (0.249)
2025-06-01 20:04:44,196 - train - INFO - Train: 105 [ 223/224 (100%)]  Loss:  3.206507 (3.1656)  Time: 0.545s, 10457.75/s  (0.841s, 6771.90/s)  LR: 7.273e-03  Data: 0.000 (0.232)
2025-06-01 20:04:49,280 - train - INFO - Test: [   0/70]  Time: 4.802 (4.802)  Loss:  0.8853 (0.8853)  Acc@1: 78.3357 (78.3357)  Acc@5: 93.8553 (93.8553)
2025-06-01 20:05:31,338 - train - INFO - Test: [  50/70]  Time: 0.124 (0.919)  Loss:  1.7920 (1.7554)  Acc@1: 59.6559 (60.5344)  Acc@5: 81.6714 (83.4449)
2025-06-01 20:05:47,731 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.2461 (1.8131)  Acc@1: 41.4062 (59.4835)  Acc@5: 75.7812 (82.4800)
2025-06-01 20:05:52,795 - train - INFO - Train: 106 [   0/224 (  0%)]  Loss:  3.169066 (3.1691)  Time: 4.755s, 1197.82/s  (4.755s, 1197.82/s)  LR: 7.226e-03  Data: 4.046 (4.046)
2025-06-01 20:06:33,995 - train - INFO - Train: 106 [  50/224 ( 22%)]  Loss:  3.159801 (3.1644)  Time: 0.549s, 10375.22/s  (0.901s, 6321.34/s)  LR: 7.226e-03  Data: 0.000 (0.209)
2025-06-01 20:07:15,772 - train - INFO - Train: 106 [ 100/224 ( 45%)]  Loss:  3.149127 (3.1593)  Time: 1.636s, 3481.02/s  (0.869s, 6557.59/s)  LR: 7.226e-03  Data: 0.000 (0.115)
2025-06-01 20:07:56,122 - train - INFO - Train: 106 [ 150/224 ( 67%)]  Loss:  3.162700 (3.1602)  Time: 0.551s, 10335.67/s  (0.848s, 6715.36/s)  LR: 7.226e-03  Data: 0.000 (0.077)
2025-06-01 20:08:37,609 - train - INFO - Train: 106 [ 200/224 ( 90%)]  Loss:  3.121203 (3.1524)  Time: 1.679s, 3392.97/s  (0.844s, 6752.00/s)  LR: 7.226e-03  Data: 0.000 (0.058)
2025-06-01 20:08:55,667 - train - INFO - Train: 106 [ 223/224 (100%)]  Loss:  3.154491 (3.1527)  Time: 0.544s, 10465.79/s  (0.838s, 6800.49/s)  LR: 7.226e-03  Data: 0.000 (0.052)
2025-06-01 20:09:00,411 - train - INFO - Test: [   0/70]  Time: 4.491 (4.491)  Loss:  1.2998 (1.2998)  Acc@1: 74.5787 (74.5787)  Acc@5: 91.2570 (91.2570)
2025-06-01 20:09:43,578 - train - INFO - Test: [  50/70]  Time: 0.121 (0.934)  Loss:  1.6904 (1.7323)  Acc@1: 62.6756 (61.6883)  Acc@5: 85.0421 (84.6263)
2025-06-01 20:10:00,311 - train - INFO - Test: [  70/70]  Time: 0.034 (0.907)  Loss:  3.0137 (1.8135)  Acc@1: 32.5000 (60.1285)  Acc@5: 64.2188 (83.1110)
2025-06-01 20:10:05,227 - train - INFO - Train: 107 [   0/224 (  0%)]  Loss:  3.177977 (3.1780)  Time: 4.603s, 1237.34/s  (4.603s, 1237.34/s)  LR: 7.179e-03  Data: 3.632 (3.632)
2025-06-01 20:10:46,881 - train - INFO - Train: 107 [  50/224 ( 22%)]  Loss:  3.144647 (3.1613)  Time: 0.550s, 10348.39/s  (0.907s, 6279.98/s)  LR: 7.179e-03  Data: 0.000 (0.160)
2025-06-01 20:11:28,577 - train - INFO - Train: 107 [ 100/224 ( 45%)]  Loss:  3.132831 (3.1518)  Time: 1.634s, 3486.29/s  (0.871s, 6541.11/s)  LR: 7.179e-03  Data: 0.000 (0.081)
2025-06-01 20:12:09,488 - train - INFO - Train: 107 [ 150/224 ( 67%)]  Loss:  3.153476 (3.1522)  Time: 0.547s, 10404.85/s  (0.853s, 6674.60/s)  LR: 7.179e-03  Data: 0.000 (0.054)
2025-06-01 20:12:51,110 - train - INFO - Train: 107 [ 200/224 ( 90%)]  Loss:  3.182265 (3.1582)  Time: 1.655s, 3441.83/s  (0.848s, 6715.66/s)  LR: 7.179e-03  Data: 0.000 (0.041)
2025-06-01 20:13:09,149 - train - INFO - Train: 107 [ 223/224 (100%)]  Loss:  3.133056 (3.1540)  Time: 0.544s, 10462.40/s  (0.842s, 6768.06/s)  LR: 7.179e-03  Data: 0.000 (0.037)
2025-06-01 20:13:13,975 - train - INFO - Test: [   0/70]  Time: 4.595 (4.595)  Loss:  1.3828 (1.3828)  Acc@1: 74.7542 (74.7542)  Acc@5: 90.5899 (90.5899)
2025-06-01 20:13:56,942 - train - INFO - Test: [  50/70]  Time: 0.120 (0.933)  Loss:  1.8252 (1.8711)  Acc@1: 60.9902 (60.0070)  Acc@5: 83.0056 (83.2190)
2025-06-01 20:14:13,788 - train - INFO - Test: [  70/70]  Time: 0.034 (0.907)  Loss:  2.3379 (1.9448)  Acc@1: 45.7812 (58.4030)  Acc@5: 77.9688 (81.7960)
2025-06-01 20:14:18,828 - train - INFO - Train: 108 [   0/224 (  0%)]  Loss:  3.201867 (3.2019)  Time: 4.745s, 1200.38/s  (4.745s, 1200.38/s)  LR: 7.132e-03  Data: 3.683 (3.683)
2025-06-01 20:14:59,679 - train - INFO - Train: 108 [  50/224 ( 22%)]  Loss:  3.149077 (3.1755)  Time: 0.548s, 10396.65/s  (0.894s, 6371.33/s)  LR: 7.132e-03  Data: 0.000 (0.150)
2025-06-01 20:15:41,166 - train - INFO - Train: 108 [ 100/224 ( 45%)]  Loss:  3.145062 (3.1653)  Time: 1.680s, 3390.73/s  (0.862s, 6606.50/s)  LR: 7.132e-03  Data: 0.000 (0.076)
2025-06-01 20:16:21,677 - train - INFO - Train: 108 [ 150/224 ( 67%)]  Loss:  3.160627 (3.1642)  Time: 0.549s, 10383.93/s  (0.845s, 6741.09/s)  LR: 7.132e-03  Data: 0.000 (0.051)
2025-06-01 20:17:03,404 - train - INFO - Train: 108 [ 200/224 ( 90%)]  Loss:  3.131187 (3.1576)  Time: 1.618s, 3520.29/s  (0.842s, 6761.89/s)  LR: 7.132e-03  Data: 0.000 (0.038)
2025-06-01 20:17:21,213 - train - INFO - Train: 108 [ 223/224 (100%)]  Loss:  3.149099 (3.1562)  Time: 0.545s, 10457.60/s  (0.835s, 6818.49/s)  LR: 7.132e-03  Data: 0.000 (0.034)
2025-06-01 20:17:26,048 - train - INFO - Test: [   0/70]  Time: 4.581 (4.581)  Loss:  1.3857 (1.3857)  Acc@1: 72.0154 (72.0154)  Acc@5: 89.3259 (89.3259)
2025-06-01 20:18:08,847 - train - INFO - Test: [  50/70]  Time: 0.120 (0.929)  Loss:  2.0273 (1.8791)  Acc@1: 56.3553 (59.5932)  Acc@5: 79.4944 (82.1905)
2025-06-01 20:18:25,619 - train - INFO - Test: [  70/70]  Time: 0.034 (0.904)  Loss:  2.4551 (1.9431)  Acc@1: 45.4688 (58.1000)  Acc@5: 73.7500 (80.9865)
2025-06-01 20:18:30,939 - train - INFO - Train: 109 [   0/224 (  0%)]  Loss:  3.149658 (3.1497)  Time: 5.005s, 1138.04/s  (5.005s, 1138.04/s)  LR: 7.084e-03  Data: 4.026 (4.026)
2025-06-01 20:19:11,452 - train - INFO - Train: 109 [  50/224 ( 22%)]  Loss:  3.164505 (3.1571)  Time: 0.549s, 10380.35/s  (0.892s, 6382.09/s)  LR: 7.084e-03  Data: 0.000 (0.275)
2025-06-01 20:19:53,304 - train - INFO - Train: 109 [ 100/224 ( 45%)]  Loss:  3.194261 (3.1695)  Time: 1.689s, 3372.50/s  (0.865s, 6584.67/s)  LR: 7.084e-03  Data: 0.150 (0.241)
2025-06-01 20:20:33,848 - train - INFO - Train: 109 [ 150/224 ( 67%)]  Loss:  3.180349 (3.1722)  Time: 0.556s, 10249.45/s  (0.847s, 6724.15/s)  LR: 7.084e-03  Data: 0.000 (0.166)
2025-06-01 20:21:14,785 - train - INFO - Train: 109 [ 200/224 ( 90%)]  Loss:  3.202492 (3.1783)  Time: 0.774s, 7360.33/s  (0.840s, 6780.63/s)  LR: 7.084e-03  Data: 0.000 (0.125)
2025-06-01 20:21:33,391 - train - INFO - Train: 109 [ 223/224 (100%)]  Loss:  3.130048 (3.1702)  Time: 0.545s, 10443.72/s  (0.837s, 6806.55/s)  LR: 7.084e-03  Data: 0.000 (0.112)
2025-06-01 20:21:38,120 - train - INFO - Test: [   0/70]  Time: 4.488 (4.488)  Loss:  1.1865 (1.1865)  Acc@1: 75.1756 (75.1756)  Acc@5: 93.2233 (93.2233)
2025-06-01 20:22:20,019 - train - INFO - Test: [  50/70]  Time: 0.124 (0.910)  Loss:  2.0762 (1.8274)  Acc@1: 54.6348 (61.0163)  Acc@5: 77.7037 (83.6996)
2025-06-01 20:22:36,495 - train - INFO - Test: [  70/70]  Time: 0.034 (0.885)  Loss:  2.7422 (1.9043)  Acc@1: 39.2188 (59.3685)  Acc@5: 69.5312 (82.2160)
2025-06-01 20:22:41,498 - train - INFO - Train: 110 [   0/224 (  0%)]  Loss:  3.164084 (3.1641)  Time: 4.688s, 1214.91/s  (4.688s, 1214.91/s)  LR: 7.037e-03  Data: 4.090 (4.090)
2025-06-01 20:23:22,199 - train - INFO - Train: 110 [  50/224 ( 22%)]  Loss:  3.141715 (3.1529)  Time: 0.548s, 10385.48/s  (0.890s, 6400.41/s)  LR: 7.037e-03  Data: 0.000 (0.191)
2025-06-01 20:24:03,344 - train - INFO - Train: 110 [ 100/224 ( 45%)]  Loss:  3.198646 (3.1681)  Time: 1.601s, 3556.95/s  (0.857s, 6648.45/s)  LR: 7.037e-03  Data: 0.000 (0.096)
2025-06-01 20:24:43,652 - train - INFO - Train: 110 [ 150/224 ( 67%)]  Loss:  3.151124 (3.1639)  Time: 0.568s, 10034.61/s  (0.840s, 6781.24/s)  LR: 7.037e-03  Data: 0.000 (0.065)
2025-06-01 20:25:25,382 - train - INFO - Train: 110 [ 200/224 ( 90%)]  Loss:  3.148035 (3.1607)  Time: 1.557s, 3657.63/s  (0.839s, 6792.13/s)  LR: 7.037e-03  Data: 0.000 (0.049)
2025-06-01 20:25:43,076 - train - INFO - Train: 110 [ 223/224 (100%)]  Loss:  3.164882 (3.1614)  Time: 0.553s, 10301.45/s  (0.831s, 6850.32/s)  LR: 7.037e-03  Data: 0.000 (0.044)
2025-06-01 20:25:47,864 - train - INFO - Test: [   0/70]  Time: 4.554 (4.554)  Loss:  1.5820 (1.5820)  Acc@1: 72.4017 (72.4017)  Acc@5: 89.5716 (89.5716)
2025-06-01 20:26:30,683 - train - INFO - Test: [  50/70]  Time: 0.120 (0.929)  Loss:  1.9854 (2.0149)  Acc@1: 61.0604 (61.0872)  Acc@5: 83.3567 (83.6018)
2025-06-01 20:26:47,267 - train - INFO - Test: [  70/70]  Time: 0.034 (0.901)  Loss:  2.1777 (2.1024)  Acc@1: 49.5312 (59.3915)  Acc@5: 83.5938 (82.0335)
2025-06-01 20:26:52,126 - train - INFO - Train: 111 [   0/224 (  0%)]  Loss:  3.153305 (3.1533)  Time: 4.547s, 1252.70/s  (4.547s, 1252.70/s)  LR: 6.989e-03  Data: 3.995 (3.995)
2025-06-01 20:27:33,150 - train - INFO - Train: 111 [  50/224 ( 22%)]  Loss:  3.111389 (3.1323)  Time: 0.556s, 10246.84/s  (0.893s, 6374.97/s)  LR: 6.989e-03  Data: 0.000 (0.155)
2025-06-01 20:28:14,809 - train - INFO - Train: 111 [ 100/224 ( 45%)]  Loss:  3.157960 (3.1409)  Time: 1.253s, 4546.60/s  (0.864s, 6595.47/s)  LR: 6.989e-03  Data: 0.000 (0.078)
2025-06-01 20:28:56,004 - train - INFO - Train: 111 [ 150/224 ( 67%)]  Loss:  3.193418 (3.1540)  Time: 0.548s, 10390.80/s  (0.850s, 6697.59/s)  LR: 6.989e-03  Data: 0.000 (0.052)
2025-06-01 20:29:37,181 - train - INFO - Train: 111 [ 200/224 ( 90%)]  Loss:  3.148674 (3.1529)  Time: 0.550s, 10358.50/s  (0.844s, 6750.80/s)  LR: 6.989e-03  Data: 0.000 (0.039)
2025-06-01 20:29:55,792 - train - INFO - Train: 111 [ 223/224 (100%)]  Loss:  3.196968 (3.1603)  Time: 0.545s, 10458.48/s  (0.840s, 6779.41/s)  LR: 6.989e-03  Data: 0.000 (0.036)
2025-06-01 20:30:00,580 - train - INFO - Test: [   0/70]  Time: 4.533 (4.533)  Loss:  1.3467 (1.3467)  Acc@1: 72.7879 (72.7879)  Acc@5: 89.9930 (89.9930)
2025-06-01 20:30:42,488 - train - INFO - Test: [  50/70]  Time: 0.120 (0.911)  Loss:  1.7773 (1.7435)  Acc@1: 64.0801 (63.5589)  Acc@5: 84.0590 (85.3127)
2025-06-01 20:30:59,095 - train - INFO - Test: [  70/70]  Time: 0.035 (0.888)  Loss:  2.2910 (1.8337)  Acc@1: 52.1875 (61.7450)  Acc@5: 76.4062 (83.5535)
2025-06-01 20:31:04,082 - train - INFO - Train: 112 [   0/224 (  0%)]  Loss:  3.185893 (3.1859)  Time: 4.679s, 1217.47/s  (4.679s, 1217.47/s)  LR: 6.941e-03  Data: 3.842 (3.842)
2025-06-01 20:31:45,235 - train - INFO - Train: 112 [  50/224 ( 22%)]  Loss:  3.116294 (3.1511)  Time: 0.773s, 7370.55/s  (0.899s, 6338.52/s)  LR: 6.941e-03  Data: 0.000 (0.214)
2025-06-01 20:32:27,331 - train - INFO - Train: 112 [ 100/224 ( 45%)]  Loss:  3.126017 (3.1427)  Time: 1.560s, 3651.27/s  (0.871s, 6543.03/s)  LR: 6.941e-03  Data: 0.000 (0.109)
2025-06-01 20:33:08,220 - train - INFO - Train: 112 [ 150/224 ( 67%)]  Loss:  3.181595 (3.1524)  Time: 0.550s, 10362.04/s  (0.853s, 6677.08/s)  LR: 6.941e-03  Data: 0.000 (0.073)
2025-06-01 20:33:50,211 - train - INFO - Train: 112 [ 200/224 ( 90%)]  Loss:  3.142654 (3.1505)  Time: 1.680s, 3391.40/s  (0.850s, 6703.01/s)  LR: 6.941e-03  Data: 0.000 (0.055)
2025-06-01 20:34:07,902 - train - INFO - Train: 112 [ 223/224 (100%)]  Loss:  3.149240 (3.1503)  Time: 0.544s, 10468.36/s  (0.841s, 6768.96/s)  LR: 6.941e-03  Data: 0.000 (0.049)
2025-06-01 20:34:12,630 - train - INFO - Test: [   0/70]  Time: 4.477 (4.477)  Loss:  1.0752 (1.0752)  Acc@1: 75.3862 (75.3862)  Acc@5: 92.1348 (92.1348)
2025-06-01 20:34:54,753 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  1.8154 (1.6517)  Acc@1: 59.3048 (62.1606)  Acc@5: 82.7949 (84.5230)
2025-06-01 20:35:11,290 - train - INFO - Test: [  70/70]  Time: 0.034 (0.889)  Loss:  2.2617 (1.7259)  Acc@1: 38.5938 (60.8035)  Acc@5: 79.8438 (83.3455)
2025-06-01 20:35:16,387 - train - INFO - Train: 113 [   0/224 (  0%)]  Loss:  3.137540 (3.1375)  Time: 4.797s, 1187.39/s  (4.797s, 1187.39/s)  LR: 6.892e-03  Data: 4.253 (4.253)
2025-06-01 20:35:57,697 - train - INFO - Train: 113 [  50/224 ( 22%)]  Loss:  3.106397 (3.1220)  Time: 0.553s, 10306.81/s  (0.904s, 6300.63/s)  LR: 6.892e-03  Data: 0.000 (0.245)
2025-06-01 20:36:40,146 - train - INFO - Train: 113 [ 100/224 ( 45%)]  Loss:  3.171876 (3.1386)  Time: 1.831s, 3110.50/s  (0.877s, 6496.68/s)  LR: 6.892e-03  Data: 0.000 (0.124)
2025-06-01 20:37:21,250 - train - INFO - Train: 113 [ 150/224 ( 67%)]  Loss:  3.119936 (3.1339)  Time: 0.555s, 10262.93/s  (0.859s, 6633.74/s)  LR: 6.892e-03  Data: 0.000 (0.083)
2025-06-01 20:38:02,699 - train - INFO - Train: 113 [ 200/224 ( 90%)]  Loss:  3.187708 (3.1447)  Time: 1.543s, 3691.92/s  (0.851s, 6691.36/s)  LR: 6.892e-03  Data: 0.000 (0.062)
2025-06-01 20:38:20,786 - train - INFO - Train: 113 [ 223/224 (100%)]  Loss:  3.150460 (3.1457)  Time: 0.553s, 10306.95/s  (0.845s, 6744.14/s)  LR: 6.892e-03  Data: 0.000 (0.056)
2025-06-01 20:38:25,749 - train - INFO - Test: [   0/70]  Time: 4.717 (4.717)  Loss:  1.3193 (1.3193)  Acc@1: 72.7528 (72.7528)  Acc@5: 90.5899 (90.5899)
2025-06-01 20:39:07,823 - train - INFO - Test: [  50/70]  Time: 0.121 (0.917)  Loss:  1.8291 (1.7550)  Acc@1: 61.7626 (62.7664)  Acc@5: 83.3919 (84.8934)
2025-06-01 20:39:24,611 - train - INFO - Test: [  70/70]  Time: 0.034 (0.895)  Loss:  2.3164 (1.8168)  Acc@1: 47.6562 (61.3965)  Acc@5: 77.9688 (83.7195)
2025-06-01 20:39:30,144 - train - INFO - Train: 114 [   0/224 (  0%)]  Loss:  3.200317 (3.2003)  Time: 5.230s, 1089.13/s  (5.230s, 1089.13/s)  LR: 6.844e-03  Data: 4.119 (4.119)
2025-06-01 20:40:11,120 - train - INFO - Train: 114 [  50/224 ( 22%)]  Loss:  3.177612 (3.1890)  Time: 0.548s, 10384.92/s  (0.906s, 6287.17/s)  LR: 6.844e-03  Data: 0.000 (0.124)
2025-06-01 20:40:53,399 - train - INFO - Train: 114 [ 100/224 ( 45%)]  Loss:  3.139805 (3.1726)  Time: 1.643s, 3466.67/s  (0.876s, 6501.81/s)  LR: 6.844e-03  Data: 0.000 (0.063)
2025-06-01 20:41:33,249 - train - INFO - Train: 114 [ 150/224 ( 67%)]  Loss:  3.185812 (3.1759)  Time: 0.550s, 10349.69/s  (0.850s, 6702.15/s)  LR: 6.844e-03  Data: 0.000 (0.042)
2025-06-01 20:42:14,766 - train - INFO - Train: 114 [ 200/224 ( 90%)]  Loss:  3.129612 (3.1666)  Time: 1.284s, 4434.62/s  (0.845s, 6740.80/s)  LR: 6.844e-03  Data: 0.000 (0.032)
2025-06-01 20:42:32,799 - train - INFO - Train: 114 [ 223/224 (100%)]  Loss:  3.117932 (3.1585)  Time: 0.545s, 10442.55/s  (0.839s, 6791.12/s)  LR: 6.844e-03  Data: 0.000 (0.029)
2025-06-01 20:42:37,638 - train - INFO - Test: [   0/70]  Time: 4.604 (4.604)  Loss:  1.3125 (1.3125)  Acc@1: 71.5239 (71.5239)  Acc@5: 90.3441 (90.3441)
2025-06-01 20:43:19,811 - train - INFO - Test: [  50/70]  Time: 0.120 (0.917)  Loss:  1.9980 (1.8669)  Acc@1: 57.9705 (59.5368)  Acc@5: 80.0913 (82.4452)
2025-06-01 20:43:36,380 - train - INFO - Test: [  70/70]  Time: 0.034 (0.892)  Loss:  2.7500 (1.9530)  Acc@1: 35.4688 (57.9280)  Acc@5: 69.8438 (81.0290)
2025-06-01 20:43:41,311 - train - INFO - Train: 115 [   0/224 (  0%)]  Loss:  3.185962 (3.1860)  Time: 4.640s, 1227.50/s  (4.640s, 1227.50/s)  LR: 6.795e-03  Data: 3.840 (3.840)
2025-06-01 20:44:22,561 - train - INFO - Train: 115 [  50/224 ( 22%)]  Loss:  3.137201 (3.1616)  Time: 0.557s, 10222.18/s  (0.900s, 6330.39/s)  LR: 6.795e-03  Data: 0.000 (0.183)
2025-06-01 20:45:04,254 - train - INFO - Train: 115 [ 100/224 ( 45%)]  Loss:  3.157343 (3.1602)  Time: 1.587s, 3590.28/s  (0.867s, 6568.76/s)  LR: 6.795e-03  Data: 0.000 (0.118)
2025-06-01 20:45:45,054 - train - INFO - Train: 115 [ 150/224 ( 67%)]  Loss:  3.154226 (3.1587)  Time: 0.556s, 10240.82/s  (0.850s, 6699.67/s)  LR: 6.795e-03  Data: 0.000 (0.085)
2025-06-01 20:46:27,507 - train - INFO - Train: 115 [ 200/224 ( 90%)]  Loss:  3.161480 (3.1592)  Time: 1.713s, 3324.73/s  (0.850s, 6701.91/s)  LR: 6.795e-03  Data: 0.000 (0.064)
2025-06-01 20:46:45,595 - train - INFO - Train: 115 [ 223/224 (100%)]  Loss:  3.119948 (3.1527)  Time: 0.553s, 10294.27/s  (0.843s, 6753.79/s)  LR: 6.795e-03  Data: 0.000 (0.057)
2025-06-01 20:46:50,758 - train - INFO - Test: [   0/70]  Time: 4.914 (4.914)  Loss:  1.4619 (1.4619)  Acc@1: 71.4888 (71.4888)  Acc@5: 90.0632 (90.0632)
2025-06-01 20:47:33,288 - train - INFO - Test: [  50/70]  Time: 0.120 (0.930)  Loss:  2.1094 (1.9705)  Acc@1: 57.2683 (59.2593)  Acc@5: 79.4944 (82.0121)
2025-06-01 20:47:49,918 - train - INFO - Test: [  70/70]  Time: 0.034 (0.902)  Loss:  2.2051 (2.0133)  Acc@1: 47.0312 (58.2615)  Acc@5: 81.7188 (81.0940)
2025-06-01 20:47:54,826 - train - INFO - Train: 116 [   0/224 (  0%)]  Loss:  3.203591 (3.2036)  Time: 4.606s, 1236.73/s  (4.606s, 1236.73/s)  LR: 6.746e-03  Data: 3.497 (3.497)
2025-06-01 20:48:36,451 - train - INFO - Train: 116 [  50/224 ( 22%)]  Loss:  3.102942 (3.1533)  Time: 0.555s, 10258.24/s  (0.906s, 6284.00/s)  LR: 6.746e-03  Data: 0.000 (0.163)
2025-06-01 20:49:17,318 - train - INFO - Train: 116 [ 100/224 ( 45%)]  Loss:  3.148141 (3.1516)  Time: 1.354s, 4206.23/s  (0.862s, 6605.41/s)  LR: 6.746e-03  Data: 0.000 (0.082)
2025-06-01 20:49:57,718 - train - INFO - Train: 116 [ 150/224 ( 67%)]  Loss:  3.176681 (3.1578)  Time: 0.550s, 10358.74/s  (0.844s, 6746.19/s)  LR: 6.746e-03  Data: 0.000 (0.055)
2025-06-01 20:50:39,101 - train - INFO - Train: 116 [ 200/224 ( 90%)]  Loss:  3.162801 (3.1588)  Time: 1.703s, 3345.39/s  (0.840s, 6779.58/s)  LR: 6.746e-03  Data: 0.000 (0.041)
2025-06-01 20:50:56,751 - train - INFO - Train: 116 [ 223/224 (100%)]  Loss:  3.198402 (3.1654)  Time: 0.545s, 10444.81/s  (0.833s, 6840.45/s)  LR: 6.746e-03  Data: 0.000 (0.037)
2025-06-01 20:51:01,522 - train - INFO - Test: [   0/70]  Time: 4.516 (4.516)  Loss:  1.7549 (1.7549)  Acc@1: 71.2430 (71.2430)  Acc@5: 89.6770 (89.6770)
2025-06-01 20:51:44,052 - train - INFO - Test: [  50/70]  Time: 0.120 (0.922)  Loss:  2.0078 (2.0479)  Acc@1: 61.6924 (59.9058)  Acc@5: 81.4958 (83.0517)
2025-06-01 20:52:00,405 - train - INFO - Test: [  70/70]  Time: 0.034 (0.893)  Loss:  2.6953 (2.1005)  Acc@1: 43.1250 (58.6290)  Acc@5: 76.0938 (81.7670)
2025-06-01 20:52:05,397 - train - INFO - Train: 117 [   0/224 (  0%)]  Loss:  3.150238 (3.1502)  Time: 4.684s, 1216.01/s  (4.684s, 1216.01/s)  LR: 6.697e-03  Data: 3.581 (3.581)
2025-06-01 20:52:45,955 - train - INFO - Train: 117 [  50/224 ( 22%)]  Loss:  3.110923 (3.1306)  Time: 0.555s, 10260.21/s  (0.887s, 6421.24/s)  LR: 6.697e-03  Data: 0.000 (0.090)
2025-06-01 20:53:27,616 - train - INFO - Train: 117 [ 100/224 ( 45%)]  Loss:  3.169255 (3.1435)  Time: 1.403s, 4060.49/s  (0.860s, 6620.32/s)  LR: 6.697e-03  Data: 0.000 (0.046)
2025-06-01 20:54:08,779 - train - INFO - Train: 117 [ 150/224 ( 67%)]  Loss:  3.141274 (3.1429)  Time: 0.556s, 10243.38/s  (0.848s, 6716.36/s)  LR: 6.697e-03  Data: 0.000 (0.031)
2025-06-01 20:54:50,346 - train - INFO - Train: 117 [ 200/224 ( 90%)]  Loss:  3.162491 (3.1468)  Time: 1.471s, 3870.98/s  (0.844s, 6749.58/s)  LR: 6.697e-03  Data: 0.000 (0.023)
2025-06-01 20:55:08,459 - train - INFO - Train: 117 [ 223/224 (100%)]  Loss:  3.140547 (3.1458)  Time: 0.554s, 10273.30/s  (0.838s, 6796.25/s)  LR: 6.697e-03  Data: 0.000 (0.021)
2025-06-01 20:55:13,106 - train - INFO - Test: [   0/70]  Time: 4.399 (4.399)  Loss:  1.1045 (1.1045)  Acc@1: 75.3862 (75.3862)  Acc@5: 91.2921 (91.2921)
2025-06-01 20:55:55,148 - train - INFO - Test: [  50/70]  Time: 0.120 (0.911)  Loss:  1.7148 (1.7289)  Acc@1: 61.2711 (60.2748)  Acc@5: 83.9537 (83.1605)
2025-06-01 20:56:11,976 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.1406 (1.8220)  Acc@1: 51.2500 (58.4805)  Acc@5: 77.1875 (81.7155)
2025-06-01 20:56:17,043 - train - INFO - Train: 118 [   0/224 (  0%)]  Loss:  3.125739 (3.1257)  Time: 4.762s, 1196.17/s  (4.762s, 1196.17/s)  LR: 6.648e-03  Data: 4.000 (4.000)
2025-06-01 20:56:57,863 - train - INFO - Train: 118 [  50/224 ( 22%)]  Loss:  3.129549 (3.1276)  Time: 0.556s, 10249.64/s  (0.894s, 6373.19/s)  LR: 6.648e-03  Data: 0.000 (0.187)
2025-06-01 20:57:39,658 - train - INFO - Train: 118 [ 100/224 ( 45%)]  Loss:  3.135783 (3.1304)  Time: 1.677s, 3396.78/s  (0.865s, 6584.21/s)  LR: 6.648e-03  Data: 0.021 (0.098)
2025-06-01 20:58:19,934 - train - INFO - Train: 118 [ 150/224 ( 67%)]  Loss:  3.195575 (3.1467)  Time: 0.553s, 10294.00/s  (0.845s, 6737.96/s)  LR: 6.648e-03  Data: 0.000 (0.066)
2025-06-01 20:59:01,245 - train - INFO - Train: 118 [ 200/224 ( 90%)]  Loss:  3.195776 (3.1565)  Time: 1.592s, 3577.74/s  (0.841s, 6776.17/s)  LR: 6.648e-03  Data: 0.000 (0.052)
2025-06-01 20:59:18,864 - train - INFO - Train: 118 [ 223/224 (100%)]  Loss:  3.143604 (3.1543)  Time: 0.545s, 10446.07/s  (0.833s, 6838.48/s)  LR: 6.648e-03  Data: 0.000 (0.047)
2025-06-01 20:59:23,614 - train - INFO - Test: [   0/70]  Time: 4.503 (4.503)  Loss:  1.4854 (1.4854)  Acc@1: 73.3497 (73.3497)  Acc@5: 90.5548 (90.5548)
2025-06-01 21:00:05,346 - train - INFO - Test: [  50/70]  Time: 0.125 (0.907)  Loss:  1.9590 (1.9163)  Acc@1: 60.3582 (61.8129)  Acc@5: 83.1110 (84.1402)
2025-06-01 21:00:21,701 - train - INFO - Test: [  70/70]  Time: 0.034 (0.882)  Loss:  2.4160 (1.9915)  Acc@1: 43.9062 (60.1780)  Acc@5: 75.1562 (82.7605)
2025-06-01 21:00:26,611 - train - INFO - Train: 119 [   0/224 (  0%)]  Loss:  3.146633 (3.1466)  Time: 4.613s, 1234.73/s  (4.613s, 1234.73/s)  LR: 6.598e-03  Data: 4.029 (4.029)
2025-06-01 21:01:07,811 - train - INFO - Train: 119 [  50/224 ( 22%)]  Loss:  3.193761 (3.1702)  Time: 0.549s, 10368.99/s  (0.898s, 6341.28/s)  LR: 6.598e-03  Data: 0.000 (0.333)
2025-06-01 21:01:49,407 - train - INFO - Train: 119 [ 100/224 ( 45%)]  Loss:  3.159355 (3.1666)  Time: 1.592s, 3578.53/s  (0.865s, 6581.95/s)  LR: 6.598e-03  Data: 0.490 (0.257)
2025-06-01 21:02:29,328 - train - INFO - Train: 119 [ 150/224 ( 67%)]  Loss:  3.129093 (3.1572)  Time: 0.551s, 10331.67/s  (0.843s, 6755.18/s)  LR: 6.598e-03  Data: 0.000 (0.210)
2025-06-01 21:03:11,493 - train - INFO - Train: 119 [ 200/224 ( 90%)]  Loss:  3.136733 (3.1531)  Time: 1.552s, 3670.02/s  (0.843s, 6755.04/s)  LR: 6.598e-03  Data: 0.000 (0.163)
2025-06-01 21:03:29,720 - train - INFO - Train: 119 [ 223/224 (100%)]  Loss:  3.121680 (3.1479)  Time: 0.544s, 10465.82/s  (0.838s, 6797.08/s)  LR: 6.598e-03  Data: 0.000 (0.146)
2025-06-01 21:03:34,878 - train - INFO - Test: [   0/70]  Time: 4.918 (4.918)  Loss:  1.7432 (1.7432)  Acc@1: 68.6973 (68.6973)  Acc@5: 88.0267 (88.0267)
2025-06-01 21:04:17,356 - train - INFO - Test: [  50/70]  Time: 0.120 (0.929)  Loss:  2.1895 (2.2853)  Acc@1: 55.8287 (54.4393)  Acc@5: 78.8448 (78.7412)
2025-06-01 21:04:33,923 - train - INFO - Test: [  70/70]  Time: 0.034 (0.901)  Loss:  3.0312 (2.3773)  Acc@1: 30.2344 (52.8173)  Acc@5: 69.9219 (77.0828)
2025-06-01 21:04:38,751 - train - INFO - Train: 120 [   0/224 (  0%)]  Loss:  3.160934 (3.1609)  Time: 4.523s, 1259.37/s  (4.523s, 1259.37/s)  LR: 6.549e-03  Data: 3.735 (3.735)
2025-06-01 21:05:19,636 - train - INFO - Train: 120 [  50/224 ( 22%)]  Loss:  3.128923 (3.1449)  Time: 0.549s, 10379.88/s  (0.890s, 6397.71/s)  LR: 6.549e-03  Data: 0.000 (0.263)
2025-06-01 21:06:01,841 - train - INFO - Train: 120 [ 100/224 ( 45%)]  Loss:  3.172828 (3.1542)  Time: 1.702s, 3346.61/s  (0.867s, 6566.66/s)  LR: 6.549e-03  Data: 0.000 (0.136)
2025-06-01 21:06:42,724 - train - INFO - Train: 120 [ 150/224 ( 67%)]  Loss:  3.125787 (3.1471)  Time: 0.552s, 10327.44/s  (0.851s, 6693.81/s)  LR: 6.549e-03  Data: 0.000 (0.091)
2025-06-01 21:07:24,010 - train - INFO - Train: 120 [ 200/224 ( 90%)]  Loss:  3.140749 (3.1458)  Time: 1.596s, 3569.68/s  (0.845s, 6743.59/s)  LR: 6.549e-03  Data: 0.000 (0.069)
2025-06-01 21:07:41,782 - train - INFO - Train: 120 [ 223/224 (100%)]  Loss:  3.131155 (3.1434)  Time: 0.546s, 10433.10/s  (0.837s, 6803.14/s)  LR: 6.549e-03  Data: 0.000 (0.062)
2025-06-01 21:07:46,516 - train - INFO - Test: [   0/70]  Time: 4.485 (4.485)  Loss:  1.2783 (1.2783)  Acc@1: 76.7732 (76.7732)  Acc@5: 90.3441 (90.3441)
2025-06-01 21:08:28,931 - train - INFO - Test: [  50/70]  Time: 0.120 (0.920)  Loss:  1.7979 (1.8351)  Acc@1: 63.4832 (61.0387)  Acc@5: 80.4775 (83.4070)
2025-06-01 21:08:45,521 - train - INFO - Test: [  70/70]  Time: 0.034 (0.894)  Loss:  2.3672 (1.9079)  Acc@1: 36.4844 (59.3693)  Acc@5: 79.3750 (82.0450)
2025-06-01 21:08:50,181 - train - INFO - Train: 121 [   0/224 (  0%)]  Loss:  3.105128 (3.1051)  Time: 4.342s, 1311.75/s  (4.342s, 1311.75/s)  LR: 6.499e-03  Data: 3.785 (3.785)
2025-06-01 21:09:30,892 - train - INFO - Train: 121 [  50/224 ( 22%)]  Loss:  3.147567 (3.1263)  Time: 0.550s, 10353.54/s  (0.883s, 6448.15/s)  LR: 6.499e-03  Data: 0.000 (0.227)
2025-06-01 21:10:12,230 - train - INFO - Train: 121 [ 100/224 ( 45%)]  Loss:  3.165385 (3.1394)  Time: 1.558s, 3654.82/s  (0.855s, 6659.46/s)  LR: 6.499e-03  Data: 0.000 (0.115)
2025-06-01 21:10:52,331 - train - INFO - Train: 121 [ 150/224 ( 67%)]  Loss:  3.149388 (3.1419)  Time: 0.550s, 10362.70/s  (0.838s, 6799.81/s)  LR: 6.499e-03  Data: 0.000 (0.077)
2025-06-01 21:11:33,528 - train - INFO - Train: 121 [ 200/224 ( 90%)]  Loss:  3.165603 (3.1466)  Time: 0.554s, 10288.57/s  (0.834s, 6827.66/s)  LR: 6.499e-03  Data: 0.000 (0.058)
2025-06-01 21:11:52,783 - train - INFO - Train: 121 [ 223/224 (100%)]  Loss:  3.154442 (3.1479)  Time: 0.545s, 10452.79/s  (0.835s, 6825.26/s)  LR: 6.499e-03  Data: 0.000 (0.052)
2025-06-01 21:11:57,481 - train - INFO - Test: [   0/70]  Time: 4.458 (4.458)  Loss:  1.5137 (1.5137)  Acc@1: 66.5555 (66.5555)  Acc@5: 86.3237 (86.3237)
2025-06-01 21:12:39,685 - train - INFO - Test: [  50/70]  Time: 0.120 (0.915)  Loss:  1.8848 (1.7555)  Acc@1: 57.0049 (59.5932)  Acc@5: 81.8118 (82.7144)
2025-06-01 21:12:56,202 - train - INFO - Test: [  70/70]  Time: 0.034 (0.890)  Loss:  2.2324 (1.8390)  Acc@1: 43.1250 (58.1670)  Acc@5: 78.8281 (81.5375)
2025-06-01 21:13:00,855 - train - INFO - Train: 122 [   0/224 (  0%)]  Loss:  3.167800 (3.1678)  Time: 4.340s, 1312.48/s  (4.340s, 1312.48/s)  LR: 6.449e-03  Data: 3.584 (3.584)
2025-06-01 21:13:42,554 - train - INFO - Train: 122 [  50/224 ( 22%)]  Loss:  3.126217 (3.1470)  Time: 0.551s, 10334.99/s  (0.903s, 6309.97/s)  LR: 6.449e-03  Data: 0.000 (0.180)
2025-06-01 21:14:23,820 - train - INFO - Train: 122 [ 100/224 ( 45%)]  Loss:  3.179107 (3.1577)  Time: 1.561s, 3649.30/s  (0.864s, 6589.65/s)  LR: 6.449e-03  Data: 0.000 (0.091)
2025-06-01 21:15:04,012 - train - INFO - Train: 122 [ 150/224 ( 67%)]  Loss:  3.149227 (3.1556)  Time: 0.548s, 10397.10/s  (0.844s, 6746.21/s)  LR: 6.449e-03  Data: 0.000 (0.061)
2025-06-01 21:15:45,920 - train - INFO - Train: 122 [ 200/224 ( 90%)]  Loss:  3.172798 (3.1590)  Time: 1.622s, 3510.76/s  (0.843s, 6758.52/s)  LR: 6.449e-03  Data: 0.000 (0.046)
2025-06-01 21:16:03,556 - train - INFO - Train: 122 [ 223/224 (100%)]  Loss:  3.170866 (3.1610)  Time: 0.547s, 10415.12/s  (0.835s, 6821.76/s)  LR: 6.449e-03  Data: 0.000 (0.041)
2025-06-01 21:16:08,519 - train - INFO - Test: [   0/70]  Time: 4.715 (4.715)  Loss:  1.3643 (1.3643)  Acc@1: 73.0513 (73.0513)  Acc@5: 89.9579 (89.9579)
2025-06-01 21:16:51,251 - train - INFO - Test: [  50/70]  Time: 0.120 (0.930)  Loss:  2.0566 (1.8402)  Acc@1: 58.3567 (60.8091)  Acc@5: 78.8624 (83.5616)
2025-06-01 21:17:08,133 - train - INFO - Test: [  70/70]  Time: 0.034 (0.906)  Loss:  2.6660 (1.9226)  Acc@1: 40.9375 (59.1913)  Acc@5: 72.8906 (82.0865)
2025-06-01 21:17:13,432 - train - INFO - Train: 123 [   0/224 (  0%)]  Loss:  3.134331 (3.1343)  Time: 4.997s, 1139.85/s  (4.997s, 1139.85/s)  LR: 6.399e-03  Data: 3.427 (3.427)
2025-06-01 21:17:54,384 - train - INFO - Train: 123 [  50/224 ( 22%)]  Loss:  3.152963 (3.1436)  Time: 0.550s, 10347.53/s  (0.901s, 6322.23/s)  LR: 6.399e-03  Data: 0.000 (0.068)
2025-06-01 21:18:36,823 - train - INFO - Train: 123 [ 100/224 ( 45%)]  Loss:  3.083711 (3.1237)  Time: 1.615s, 3526.26/s  (0.875s, 6508.89/s)  LR: 6.399e-03  Data: 0.000 (0.034)
2025-06-01 21:19:17,884 - train - INFO - Train: 123 [ 150/224 ( 67%)]  Loss:  3.161797 (3.1332)  Time: 0.555s, 10268.07/s  (0.857s, 6644.46/s)  LR: 6.399e-03  Data: 0.000 (0.023)
2025-06-01 21:19:59,586 - train - INFO - Train: 123 [ 200/224 ( 90%)]  Loss:  3.156486 (3.1379)  Time: 1.681s, 3388.22/s  (0.851s, 6689.61/s)  LR: 6.399e-03  Data: 0.000 (0.017)
2025-06-01 21:20:17,626 - train - INFO - Train: 123 [ 223/224 (100%)]  Loss:  3.156481 (3.1410)  Time: 0.552s, 10321.24/s  (0.845s, 6744.25/s)  LR: 6.399e-03  Data: 0.000 (0.016)
2025-06-01 21:20:22,599 - train - INFO - Test: [   0/70]  Time: 4.720 (4.720)  Loss:  1.2871 (1.2871)  Acc@1: 68.4340 (68.4340)  Acc@5: 89.7296 (89.7296)
2025-06-01 21:21:04,372 - train - INFO - Test: [  50/70]  Time: 0.120 (0.912)  Loss:  1.9531 (1.7214)  Acc@1: 58.3743 (60.9499)  Acc@5: 79.2310 (84.0273)
2025-06-01 21:21:20,831 - train - INFO - Test: [  70/70]  Time: 0.034 (0.887)  Loss:  2.6348 (1.8101)  Acc@1: 42.3438 (59.3778)  Acc@5: 68.6719 (82.5013)
2025-06-01 21:21:25,972 - train - INFO - Train: 124 [   0/224 (  0%)]  Loss:  3.119907 (3.1199)  Time: 4.833s, 1178.62/s  (4.833s, 1178.62/s)  LR: 6.348e-03  Data: 3.677 (3.677)
2025-06-01 21:22:07,574 - train - INFO - Train: 124 [  50/224 ( 22%)]  Loss:  3.119426 (3.1197)  Time: 0.550s, 10362.60/s  (0.910s, 6256.21/s)  LR: 6.348e-03  Data: 0.000 (0.079)
2025-06-01 21:22:49,586 - train - INFO - Train: 124 [ 100/224 ( 45%)]  Loss:  3.196486 (3.1453)  Time: 1.687s, 3377.38/s  (0.876s, 6504.61/s)  LR: 6.348e-03  Data: 0.000 (0.040)
2025-06-01 21:23:30,714 - train - INFO - Train: 124 [ 150/224 ( 67%)]  Loss:  3.167063 (3.1507)  Time: 0.550s, 10356.62/s  (0.858s, 6637.98/s)  LR: 6.348e-03  Data: 0.000 (0.027)
2025-06-01 21:24:12,109 - train - INFO - Train: 124 [ 200/224 ( 90%)]  Loss:  3.149099 (3.1504)  Time: 1.082s, 5263.58/s  (0.851s, 6696.67/s)  LR: 6.348e-03  Data: 0.000 (0.020)
2025-06-01 21:24:30,261 - train - INFO - Train: 124 [ 223/224 (100%)]  Loss:  3.106385 (3.1431)  Time: 0.545s, 10457.61/s  (0.844s, 6746.71/s)  LR: 6.348e-03  Data: 0.000 (0.018)
2025-06-01 21:24:34,958 - train - INFO - Test: [   0/70]  Time: 4.452 (4.452)  Loss:  1.3682 (1.3682)  Acc@1: 70.8041 (70.8041)  Acc@5: 89.8174 (89.8174)
2025-06-01 21:25:17,063 - train - INFO - Test: [  50/70]  Time: 0.120 (0.913)  Loss:  1.6113 (1.8493)  Acc@1: 65.7830 (60.7372)  Acc@5: 84.3048 (83.5450)
2025-06-01 21:25:33,469 - train - INFO - Test: [  70/70]  Time: 0.034 (0.887)  Loss:  2.0156 (1.9182)  Acc@1: 53.8281 (59.2888)  Acc@5: 80.7812 (82.2045)
2025-06-01 21:25:38,462 - train - INFO - Train: 125 [   0/224 (  0%)]  Loss:  3.136024 (3.1360)  Time: 4.677s, 1217.79/s  (4.677s, 1217.79/s)  LR: 6.298e-03  Data: 4.132 (4.132)
2025-06-01 21:26:19,665 - train - INFO - Train: 125 [  50/224 ( 22%)]  Loss:  3.141209 (3.1386)  Time: 0.551s, 10334.31/s  (0.900s, 6331.78/s)  LR: 6.298e-03  Data: 0.001 (0.170)
2025-06-01 21:27:00,755 - train - INFO - Train: 125 [ 100/224 ( 45%)]  Loss:  3.122658 (3.1333)  Time: 0.549s, 10370.11/s  (0.861s, 6615.12/s)  LR: 6.298e-03  Data: 0.000 (0.086)
2025-06-01 21:27:42,139 - train - INFO - Train: 125 [ 150/224 ( 67%)]  Loss:  3.137691 (3.1344)  Time: 0.555s, 10266.52/s  (0.850s, 6701.20/s)  LR: 6.298e-03  Data: 0.000 (0.058)
2025-06-01 21:28:23,007 - train - INFO - Train: 125 [ 200/224 ( 90%)]  Loss:  3.149946 (3.1375)  Time: 0.555s, 10262.63/s  (0.842s, 6765.90/s)  LR: 6.298e-03  Data: 0.000 (0.043)
2025-06-01 21:28:42,036 - train - INFO - Train: 125 [ 223/224 (100%)]  Loss:  3.154065 (3.1403)  Time: 0.551s, 10339.36/s  (0.840s, 6777.99/s)  LR: 6.298e-03  Data: 0.000 (0.039)
2025-06-01 21:28:46,894 - train - INFO - Test: [   0/70]  Time: 4.616 (4.616)  Loss:  1.0850 (1.0850)  Acc@1: 75.2633 (75.2633)  Acc@5: 91.7662 (91.7662)
2025-06-01 21:29:28,842 - train - INFO - Test: [  50/70]  Time: 0.121 (0.913)  Loss:  1.7920 (1.6760)  Acc@1: 60.0421 (61.2415)  Acc@5: 81.1798 (84.2084)
2025-06-01 21:29:45,514 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.4648 (1.7602)  Acc@1: 42.1875 (59.7772)  Acc@5: 73.9844 (82.7678)
2025-06-01 21:29:50,449 - train - INFO - Train: 126 [   0/224 (  0%)]  Loss:  3.094501 (3.0945)  Time: 4.618s, 1233.33/s  (4.618s, 1233.33/s)  LR: 6.247e-03  Data: 3.881 (3.881)
2025-06-01 21:30:31,483 - train - INFO - Train: 126 [  50/224 ( 22%)]  Loss:  3.117495 (3.1060)  Time: 0.557s, 10234.25/s  (0.895s, 6363.31/s)  LR: 6.247e-03  Data: 0.000 (0.227)
2025-06-01 21:31:13,720 - train - INFO - Train: 126 [ 100/224 ( 45%)]  Loss:  3.111472 (3.1078)  Time: 1.658s, 3435.43/s  (0.870s, 6545.83/s)  LR: 6.247e-03  Data: 0.000 (0.135)
2025-06-01 21:31:54,337 - train - INFO - Train: 126 [ 150/224 ( 67%)]  Loss:  3.156739 (3.1201)  Time: 0.548s, 10389.86/s  (0.851s, 6693.22/s)  LR: 6.247e-03  Data: 0.000 (0.090)
2025-06-01 21:32:36,259 - train - INFO - Train: 126 [ 200/224 ( 90%)]  Loss:  3.172310 (3.1305)  Time: 1.706s, 3338.88/s  (0.848s, 6717.97/s)  LR: 6.247e-03  Data: 0.000 (0.068)
2025-06-01 21:32:54,176 - train - INFO - Train: 126 [ 223/224 (100%)]  Loss:  3.164581 (3.1362)  Time: 0.546s, 10440.00/s  (0.841s, 6774.50/s)  LR: 6.247e-03  Data: 0.000 (0.061)
2025-06-01 21:32:58,924 - train - INFO - Test: [   0/70]  Time: 4.506 (4.506)  Loss:  1.5859 (1.5859)  Acc@1: 70.5407 (70.5407)  Acc@5: 88.9045 (88.9045)
2025-06-01 21:33:41,171 - train - INFO - Test: [  50/70]  Time: 0.120 (0.917)  Loss:  2.1406 (1.9331)  Acc@1: 57.4438 (60.6008)  Acc@5: 77.4052 (83.4204)
2025-06-01 21:33:57,742 - train - INFO - Test: [  70/70]  Time: 0.035 (0.892)  Loss:  2.5410 (1.9987)  Acc@1: 39.4531 (59.0700)  Acc@5: 74.0625 (82.1150)
2025-06-01 21:34:02,675 - train - INFO - Train: 127 [   0/224 (  0%)]  Loss:  3.176920 (3.1769)  Time: 4.618s, 1233.49/s  (4.618s, 1233.49/s)  LR: 6.196e-03  Data: 3.977 (3.977)
2025-06-01 21:34:43,957 - train - INFO - Train: 127 [  50/224 ( 22%)]  Loss:  3.148420 (3.1627)  Time: 0.550s, 10348.80/s  (0.900s, 6329.13/s)  LR: 6.196e-03  Data: 0.000 (0.199)
2025-06-01 21:35:26,427 - train - INFO - Train: 127 [ 100/224 ( 45%)]  Loss:  3.140870 (3.1554)  Time: 2.059s, 2766.39/s  (0.875s, 6510.39/s)  LR: 6.196e-03  Data: 0.000 (0.101)
2025-06-01 21:36:07,149 - train - INFO - Train: 127 [ 150/224 ( 67%)]  Loss:  3.164511 (3.1577)  Time: 0.556s, 10244.54/s  (0.855s, 6662.98/s)  LR: 6.196e-03  Data: 0.000 (0.067)
2025-06-01 21:36:49,044 - train - INFO - Train: 127 [ 200/224 ( 90%)]  Loss:  3.136100 (3.1534)  Time: 1.672s, 3407.52/s  (0.851s, 6696.12/s)  LR: 6.196e-03  Data: 0.000 (0.051)
2025-06-01 21:37:07,189 - train - INFO - Train: 127 [ 223/224 (100%)]  Loss:  3.161992 (3.1548)  Time: 0.550s, 10358.66/s  (0.844s, 6746.48/s)  LR: 6.196e-03  Data: 0.000 (0.046)
2025-06-01 21:37:11,936 - train - INFO - Test: [   0/70]  Time: 4.496 (4.496)  Loss:  1.5781 (1.5781)  Acc@1: 71.8048 (71.8048)  Acc@5: 89.2556 (89.2556)
2025-06-01 21:37:53,319 - train - INFO - Test: [  50/70]  Time: 0.169 (0.900)  Loss:  1.6943 (1.9277)  Acc@1: 65.5021 (60.4645)  Acc@5: 86.4291 (83.2029)
2025-06-01 21:38:09,693 - train - INFO - Test: [  70/70]  Time: 0.034 (0.877)  Loss:  2.7207 (2.0037)  Acc@1: 48.2031 (58.6893)  Acc@5: 72.0312 (81.7463)
2025-06-01 21:38:14,539 - train - INFO - Train: 128 [   0/224 (  0%)]  Loss:  3.183221 (3.1832)  Time: 4.536s, 1255.64/s  (4.536s, 1255.64/s)  LR: 6.146e-03  Data: 3.986 (3.986)
2025-06-01 21:38:55,524 - train - INFO - Train: 128 [  50/224 ( 22%)]  Loss:  3.134194 (3.1587)  Time: 0.557s, 10224.19/s  (0.893s, 6381.74/s)  LR: 6.146e-03  Data: 0.000 (0.098)
2025-06-01 21:39:37,931 - train - INFO - Train: 128 [ 100/224 ( 45%)]  Loss:  3.156218 (3.1579)  Time: 1.650s, 3451.40/s  (0.871s, 6543.02/s)  LR: 6.146e-03  Data: 0.000 (0.049)
2025-06-01 21:40:18,484 - train - INFO - Train: 128 [ 150/224 ( 67%)]  Loss:  3.142470 (3.1540)  Time: 0.554s, 10283.48/s  (0.851s, 6694.59/s)  LR: 6.146e-03  Data: 0.000 (0.033)
2025-06-01 21:40:59,758 - train - INFO - Train: 128 [ 200/224 ( 90%)]  Loss:  3.136467 (3.1505)  Time: 1.486s, 3832.79/s  (0.845s, 6744.67/s)  LR: 6.146e-03  Data: 0.000 (0.025)
2025-06-01 21:41:17,820 - train - INFO - Train: 128 [ 223/224 (100%)]  Loss:  3.151076 (3.1506)  Time: 0.546s, 10438.62/s  (0.838s, 6793.63/s)  LR: 6.146e-03  Data: 0.000 (0.022)
2025-06-01 21:41:22,603 - train - INFO - Test: [   0/70]  Time: 4.537 (4.537)  Loss:  1.4043 (1.4043)  Acc@1: 71.0323 (71.0323)  Acc@5: 89.0098 (89.0098)
2025-06-01 21:42:05,154 - train - INFO - Test: [  50/70]  Time: 0.120 (0.923)  Loss:  2.1699 (1.9223)  Acc@1: 56.2851 (59.5292)  Acc@5: 78.4586 (82.7251)
2025-06-01 21:42:21,943 - train - INFO - Test: [  70/70]  Time: 0.034 (0.900)  Loss:  2.4297 (1.9996)  Acc@1: 44.8438 (58.1453)  Acc@5: 77.7344 (81.3418)
2025-06-01 21:42:26,939 - train - INFO - Train: 129 [   0/224 (  0%)]  Loss:  3.119913 (3.1199)  Time: 4.677s, 1217.76/s  (4.677s, 1217.76/s)  LR: 6.095e-03  Data: 4.133 (4.133)
2025-06-01 21:43:08,248 - train - INFO - Train: 129 [  50/224 ( 22%)]  Loss:  3.154641 (3.1373)  Time: 0.552s, 10317.46/s  (0.902s, 6317.32/s)  LR: 6.095e-03  Data: 0.000 (0.112)
2025-06-01 21:43:49,654 - train - INFO - Train: 129 [ 100/224 ( 45%)]  Loss:  3.113143 (3.1292)  Time: 0.674s, 8449.39/s  (0.865s, 6583.20/s)  LR: 6.095e-03  Data: 0.000 (0.057)
2025-06-01 21:44:30,389 - train - INFO - Train: 129 [ 150/224 ( 67%)]  Loss:  3.129323 (3.1293)  Time: 0.553s, 10295.41/s  (0.848s, 6713.09/s)  LR: 6.095e-03  Data: 0.000 (0.038)
2025-06-01 21:45:11,404 - train - INFO - Train: 129 [ 200/224 ( 90%)]  Loss:  3.154389 (3.1343)  Time: 0.820s, 6944.49/s  (0.841s, 6769.09/s)  LR: 6.095e-03  Data: 0.000 (0.029)
2025-06-01 21:45:29,998 - train - INFO - Train: 129 [ 223/224 (100%)]  Loss:  3.113195 (3.1308)  Time: 0.967s, 5889.48/s  (0.838s, 6796.56/s)  LR: 6.095e-03  Data: 0.000 (0.026)
2025-06-01 21:45:34,712 - train - INFO - Test: [   0/70]  Time: 4.467 (4.467)  Loss:  1.3184 (1.3184)  Acc@1: 75.0176 (75.0176)  Acc@5: 90.9059 (90.9059)
2025-06-01 21:46:16,922 - train - INFO - Test: [  50/70]  Time: 0.125 (0.915)  Loss:  2.0469 (1.9117)  Acc@1: 56.8820 (59.8222)  Acc@5: 80.3020 (82.8786)
2025-06-01 21:46:33,529 - train - INFO - Test: [  70/70]  Time: 0.035 (0.891)  Loss:  2.3125 (1.9866)  Acc@1: 44.9219 (58.2495)  Acc@5: 78.5156 (81.5078)
2025-06-01 21:46:38,593 - train - INFO - Train: 130 [   0/224 (  0%)]  Loss:  3.115554 (3.1156)  Time: 4.738s, 1202.14/s  (4.738s, 1202.14/s)  LR: 6.044e-03  Data: 3.993 (3.993)
2025-06-01 21:47:19,232 - train - INFO - Train: 130 [  50/224 ( 22%)]  Loss:  3.169648 (3.1426)  Time: 0.550s, 10362.31/s  (0.890s, 6402.19/s)  LR: 6.044e-03  Data: 0.000 (0.171)
2025-06-01 21:48:01,388 - train - INFO - Train: 130 [ 100/224 ( 45%)]  Loss:  3.108810 (3.1313)  Time: 1.821s, 3127.60/s  (0.867s, 6572.87/s)  LR: 6.044e-03  Data: 0.000 (0.086)
2025-06-01 21:48:42,440 - train - INFO - Train: 130 [ 150/224 ( 67%)]  Loss:  3.162632 (3.1392)  Time: 0.558s, 10207.94/s  (0.851s, 6689.46/s)  LR: 6.044e-03  Data: 0.000 (0.058)
2025-06-01 21:49:24,220 - train - INFO - Train: 130 [ 200/224 ( 90%)]  Loss:  3.110198 (3.1334)  Time: 1.557s, 3657.80/s  (0.848s, 6720.71/s)  LR: 6.044e-03  Data: 0.000 (0.043)
2025-06-01 21:49:42,421 - train - INFO - Train: 130 [ 223/224 (100%)]  Loss:  3.162111 (3.1382)  Time: 0.555s, 10262.51/s  (0.842s, 6766.77/s)  LR: 6.044e-03  Data: 0.000 (0.039)
2025-06-01 21:49:47,401 - train - INFO - Test: [   0/70]  Time: 4.737 (4.737)  Loss:  1.3818 (1.3818)  Acc@1: 68.5393 (68.5393)  Acc@5: 90.0808 (90.0808)
2025-06-01 21:50:30,048 - train - INFO - Test: [  50/70]  Time: 0.121 (0.929)  Loss:  2.0957 (1.9469)  Acc@1: 54.5295 (57.5526)  Acc@5: 77.7388 (81.1694)
2025-06-01 21:50:46,548 - train - INFO - Test: [  70/70]  Time: 0.034 (0.900)  Loss:  2.4473 (2.0161)  Acc@1: 37.8125 (56.2203)  Acc@5: 76.7969 (79.8205)
2025-06-01 21:50:51,940 - train - INFO - Train: 131 [   0/224 (  0%)]  Loss:  3.111889 (3.1119)  Time: 5.087s, 1119.81/s  (5.087s, 1119.81/s)  LR: 5.992e-03  Data: 4.027 (4.027)
2025-06-01 21:51:32,735 - train - INFO - Train: 131 [  50/224 ( 22%)]  Loss:  3.145551 (3.1287)  Time: 0.549s, 10367.99/s  (0.900s, 6331.68/s)  LR: 5.992e-03  Data: 0.000 (0.160)
2025-06-01 21:52:15,038 - train - INFO - Train: 131 [ 100/224 ( 45%)]  Loss:  3.163318 (3.1403)  Time: 1.739s, 3274.81/s  (0.873s, 6524.02/s)  LR: 5.992e-03  Data: 0.000 (0.081)
2025-06-01 21:52:56,121 - train - INFO - Train: 131 [ 150/224 ( 67%)]  Loss:  3.137053 (3.1395)  Time: 0.556s, 10237.22/s  (0.856s, 6653.87/s)  LR: 5.992e-03  Data: 0.000 (0.054)
2025-06-01 21:53:37,819 - train - INFO - Train: 131 [ 200/224 ( 90%)]  Loss:  3.185386 (3.1486)  Time: 1.642s, 3469.68/s  (0.851s, 6696.92/s)  LR: 5.992e-03  Data: 0.000 (0.041)
2025-06-01 21:53:55,854 - train - INFO - Train: 131 [ 223/224 (100%)]  Loss:  3.113223 (3.1427)  Time: 0.545s, 10448.21/s  (0.844s, 6751.11/s)  LR: 5.992e-03  Data: 0.000 (0.037)
2025-06-01 21:54:00,806 - train - INFO - Test: [   0/70]  Time: 4.705 (4.705)  Loss:  1.0918 (1.0918)  Acc@1: 78.4235 (78.4235)  Acc@5: 93.4867 (93.4867)
2025-06-01 21:54:42,342 - train - INFO - Test: [  50/70]  Time: 0.120 (0.907)  Loss:  1.9180 (1.7568)  Acc@1: 59.2521 (63.1775)  Acc@5: 82.0927 (85.2511)
2025-06-01 21:54:58,777 - train - INFO - Test: [  70/70]  Time: 0.034 (0.883)  Loss:  2.3594 (1.8369)  Acc@1: 47.5000 (61.5643)  Acc@5: 75.7031 (83.9640)
2025-06-01 21:55:03,666 - train - INFO - Train: 132 [   0/224 (  0%)]  Loss:  3.106028 (3.1060)  Time: 4.549s, 1252.22/s  (4.549s, 1252.22/s)  LR: 5.941e-03  Data: 4.005 (4.005)
2025-06-01 21:55:44,246 - train - INFO - Train: 132 [  50/224 ( 22%)]  Loss:  3.124962 (3.1155)  Time: 0.548s, 10388.75/s  (0.885s, 6437.39/s)  LR: 5.941e-03  Data: 0.000 (0.152)
2025-06-01 21:56:25,413 - train - INFO - Train: 132 [ 100/224 ( 45%)]  Loss:  3.126765 (3.1193)  Time: 1.562s, 3646.23/s  (0.854s, 6666.87/s)  LR: 5.941e-03  Data: 0.000 (0.077)
2025-06-01 21:57:05,841 - train - INFO - Train: 132 [ 150/224 ( 67%)]  Loss:  3.158511 (3.1291)  Time: 0.552s, 10324.98/s  (0.839s, 6787.47/s)  LR: 5.941e-03  Data: 0.000 (0.051)
2025-06-01 21:57:47,230 - train - INFO - Train: 132 [ 200/224 ( 90%)]  Loss:  3.149107 (3.1331)  Time: 1.397s, 4077.44/s  (0.836s, 6810.56/s)  LR: 5.941e-03  Data: 0.000 (0.039)
2025-06-01 21:58:04,776 - train - INFO - Train: 132 [ 223/224 (100%)]  Loss:  3.114496 (3.1300)  Time: 0.547s, 10417.23/s  (0.829s, 6872.59/s)  LR: 5.941e-03  Data: 0.000 (0.035)
2025-06-01 21:58:09,810 - train - INFO - Test: [   0/70]  Time: 4.791 (4.791)  Loss:  1.3320 (1.3320)  Acc@1: 69.2240 (69.2240)  Acc@5: 88.2725 (88.2725)
2025-06-01 21:58:51,933 - train - INFO - Test: [  50/70]  Time: 0.120 (0.920)  Loss:  1.9531 (1.7527)  Acc@1: 55.5478 (60.2050)  Acc@5: 79.7051 (83.3619)
2025-06-01 21:59:08,646 - train - INFO - Test: [  70/70]  Time: 0.034 (0.896)  Loss:  2.6660 (1.8460)  Acc@1: 43.9844 (58.4070)  Acc@5: 68.0469 (81.7418)
2025-06-01 21:59:13,777 - train - INFO - Train: 133 [   0/224 (  0%)]  Loss:  3.130932 (3.1309)  Time: 4.827s, 1180.01/s  (4.827s, 1180.01/s)  LR: 5.890e-03  Data: 4.276 (4.276)
2025-06-01 21:59:54,309 - train - INFO - Train: 133 [  50/224 ( 22%)]  Loss:  3.127702 (3.1293)  Time: 0.548s, 10401.01/s  (0.889s, 6404.61/s)  LR: 5.890e-03  Data: 0.000 (0.196)
2025-06-01 22:00:36,029 - train - INFO - Train: 133 [ 100/224 ( 45%)]  Loss:  3.168246 (3.1423)  Time: 0.550s, 10359.29/s  (0.862s, 6606.78/s)  LR: 5.890e-03  Data: 0.000 (0.099)
2025-06-01 22:01:17,441 - train - INFO - Train: 133 [ 150/224 ( 67%)]  Loss:  3.149410 (3.1441)  Time: 0.549s, 10383.29/s  (0.851s, 6693.99/s)  LR: 5.890e-03  Data: 0.000 (0.066)
2025-06-01 22:01:58,659 - train - INFO - Train: 133 [ 200/224 ( 90%)]  Loss:  3.136523 (3.1426)  Time: 0.972s, 5860.50/s  (0.844s, 6746.44/s)  LR: 5.890e-03  Data: 0.000 (0.050)
2025-06-01 22:02:16,948 - train - INFO - Train: 133 [ 223/224 (100%)]  Loss:  3.146264 (3.1432)  Time: 0.545s, 10442.72/s  (0.839s, 6787.01/s)  LR: 5.890e-03  Data: 0.000 (0.045)
2025-06-01 22:02:21,842 - train - INFO - Test: [   0/70]  Time: 4.644 (4.644)  Loss:  1.1895 (1.1895)  Acc@1: 73.3322 (73.3322)  Acc@5: 91.1517 (91.1517)
2025-06-01 22:03:04,397 - train - INFO - Test: [  50/70]  Time: 0.131 (0.925)  Loss:  1.9629 (1.6826)  Acc@1: 58.5323 (61.7737)  Acc@5: 79.7051 (84.3247)
2025-06-01 22:03:20,983 - train - INFO - Test: [  70/70]  Time: 0.034 (0.898)  Loss:  2.5820 (1.7565)  Acc@1: 31.4062 (60.3663)  Acc@5: 73.0469 (83.0973)
2025-06-01 22:03:26,221 - train - INFO - Train: 134 [   0/224 (  0%)]  Loss:  3.136342 (3.1363)  Time: 4.889s, 1165.07/s  (4.889s, 1165.07/s)  LR: 5.838e-03  Data: 4.075 (4.075)
2025-06-01 22:04:06,767 - train - INFO - Train: 134 [  50/224 ( 22%)]  Loss:  3.151726 (3.1440)  Time: 0.550s, 10349.47/s  (0.891s, 6393.75/s)  LR: 5.838e-03  Data: 0.000 (0.161)
2025-06-01 22:04:48,161 - train - INFO - Train: 134 [ 100/224 ( 45%)]  Loss:  3.107063 (3.1317)  Time: 1.573s, 3621.82/s  (0.860s, 6625.83/s)  LR: 5.838e-03  Data: 0.000 (0.081)
2025-06-01 22:05:28,587 - train - INFO - Train: 134 [ 150/224 ( 67%)]  Loss:  3.131482 (3.1317)  Time: 0.552s, 10316.90/s  (0.843s, 6758.99/s)  LR: 5.838e-03  Data: 0.000 (0.054)
2025-06-01 22:06:10,482 - train - INFO - Train: 134 [ 200/224 ( 90%)]  Loss:  3.083655 (3.1221)  Time: 1.734s, 3284.61/s  (0.842s, 6768.68/s)  LR: 5.838e-03  Data: 0.000 (0.041)
2025-06-01 22:06:28,416 - train - INFO - Train: 134 [ 223/224 (100%)]  Loss:  3.138535 (3.1248)  Time: 0.547s, 10418.35/s  (0.835s, 6820.13/s)  LR: 5.838e-03  Data: 0.000 (0.037)
2025-06-01 22:06:33,149 - train - INFO - Test: [   0/70]  Time: 4.491 (4.491)  Loss:  1.3506 (1.3506)  Acc@1: 72.3139 (72.3139)  Acc@5: 90.8181 (90.8181)
2025-06-01 22:07:15,215 - train - INFO - Test: [  50/70]  Time: 0.120 (0.913)  Loss:  1.6592 (1.7616)  Acc@1: 63.9572 (61.6318)  Acc@5: 84.7963 (84.3640)
2025-06-01 22:07:31,816 - train - INFO - Test: [  70/70]  Time: 0.034 (0.890)  Loss:  2.0391 (1.8177)  Acc@1: 50.0781 (60.3270)  Acc@5: 83.1250 (83.1283)
2025-06-01 22:07:36,803 - train - INFO - Train: 135 [   0/224 (  0%)]  Loss:  3.125822 (3.1258)  Time: 4.666s, 1220.63/s  (4.666s, 1220.63/s)  LR: 5.786e-03  Data: 4.117 (4.117)
2025-06-01 22:08:18,299 - train - INFO - Train: 135 [  50/224 ( 22%)]  Loss:  3.170296 (3.1481)  Time: 0.549s, 10366.27/s  (0.905s, 6292.95/s)  LR: 5.786e-03  Data: 0.000 (0.173)
2025-06-01 22:08:59,867 - train - INFO - Train: 135 [ 100/224 ( 45%)]  Loss:  3.122355 (3.1395)  Time: 1.253s, 4546.96/s  (0.869s, 6557.76/s)  LR: 5.786e-03  Data: 0.000 (0.107)
2025-06-01 22:09:41,178 - train - INFO - Train: 135 [ 150/224 ( 67%)]  Loss:  3.148209 (3.1417)  Time: 0.551s, 10330.84/s  (0.855s, 6665.45/s)  LR: 5.786e-03  Data: 0.000 (0.124)
2025-06-01 22:10:21,895 - train - INFO - Train: 135 [ 200/224 ( 90%)]  Loss:  3.120488 (3.1374)  Time: 0.753s, 7568.49/s  (0.845s, 6744.48/s)  LR: 5.786e-03  Data: 0.000 (0.138)
2025-06-01 22:10:40,788 - train - INFO - Train: 135 [ 223/224 (100%)]  Loss:  3.124567 (3.1353)  Time: 0.545s, 10454.96/s  (0.842s, 6763.51/s)  LR: 5.786e-03  Data: 0.000 (0.150)
2025-06-01 22:10:45,675 - train - INFO - Test: [   0/70]  Time: 4.656 (4.656)  Loss:  1.6250 (1.6250)  Acc@1: 72.4895 (72.4895)  Acc@5: 89.4136 (89.4136)
2025-06-01 22:11:27,285 - train - INFO - Test: [  50/70]  Time: 0.120 (0.907)  Loss:  2.0840 (2.0946)  Acc@1: 58.4270 (58.2060)  Acc@5: 81.8645 (81.9922)
2025-06-01 22:11:43,805 - train - INFO - Test: [  70/70]  Time: 0.034 (0.884)  Loss:  2.3809 (2.1381)  Acc@1: 50.7812 (56.9305)  Acc@5: 78.1250 (80.8468)
2025-06-01 22:11:48,505 - train - INFO - Train: 136 [   0/224 (  0%)]  Loss:  3.163990 (3.1640)  Time: 4.398s, 1295.07/s  (4.398s, 1295.07/s)  LR: 5.735e-03  Data: 3.690 (3.690)
2025-06-01 22:12:29,847 - train - INFO - Train: 136 [  50/224 ( 22%)]  Loss:  3.129799 (3.1469)  Time: 0.550s, 10352.47/s  (0.897s, 6351.31/s)  LR: 5.735e-03  Data: 0.000 (0.125)
2025-06-01 22:13:12,776 - train - INFO - Train: 136 [ 100/224 ( 45%)]  Loss:  3.154459 (3.1494)  Time: 1.708s, 3334.50/s  (0.878s, 6488.37/s)  LR: 5.735e-03  Data: 0.000 (0.063)
2025-06-01 22:13:53,864 - train - INFO - Train: 136 [ 150/224 ( 67%)]  Loss:  3.122847 (3.1428)  Time: 0.549s, 10367.20/s  (0.859s, 6628.75/s)  LR: 5.735e-03  Data: 0.000 (0.042)
2025-06-01 22:14:36,066 - train - INFO - Train: 136 [ 200/224 ( 90%)]  Loss:  3.099058 (3.1340)  Time: 1.694s, 3361.62/s  (0.855s, 6658.15/s)  LR: 5.735e-03  Data: 0.000 (0.032)
2025-06-01 22:14:53,616 - train - INFO - Train: 136 [ 223/224 (100%)]  Loss:  3.111385 (3.1303)  Time: 0.545s, 10446.89/s  (0.846s, 6732.90/s)  LR: 5.735e-03  Data: 0.000 (0.029)
2025-06-01 22:14:58,227 - train - INFO - Test: [   0/70]  Time: 4.371 (4.371)  Loss:  1.1895 (1.1895)  Acc@1: 74.4031 (74.4031)  Acc@5: 90.8006 (90.8006)
2025-06-01 22:15:40,828 - train - INFO - Test: [  50/70]  Time: 0.125 (0.921)  Loss:  1.5195 (1.7129)  Acc@1: 65.2388 (60.9816)  Acc@5: 85.7619 (83.9636)
2025-06-01 22:15:57,806 - train - INFO - Test: [  70/70]  Time: 0.034 (0.901)  Loss:  2.2715 (1.7923)  Acc@1: 42.8125 (59.3150)  Acc@5: 78.7500 (82.6305)
2025-06-01 22:16:02,781 - train - INFO - Train: 137 [   0/224 (  0%)]  Loss:  3.170877 (3.1709)  Time: 4.670s, 1219.78/s  (4.670s, 1219.78/s)  LR: 5.683e-03  Data: 3.518 (3.518)
2025-06-01 22:16:43,812 - train - INFO - Train: 137 [  50/224 ( 22%)]  Loss:  3.124830 (3.1479)  Time: 0.548s, 10384.97/s  (0.896s, 6356.58/s)  LR: 5.683e-03  Data: 0.000 (0.079)
2025-06-01 22:17:26,270 - train - INFO - Train: 137 [ 100/224 ( 45%)]  Loss:  3.155599 (3.1504)  Time: 1.655s, 3442.43/s  (0.873s, 6525.84/s)  LR: 5.683e-03  Data: 0.000 (0.040)
2025-06-01 22:18:07,188 - train - INFO - Train: 137 [ 150/224 ( 67%)]  Loss:  3.105625 (3.1392)  Time: 0.550s, 10350.73/s  (0.855s, 6663.58/s)  LR: 5.683e-03  Data: 0.000 (0.027)
2025-06-01 22:18:48,990 - train - INFO - Train: 137 [ 200/224 ( 90%)]  Loss:  3.149452 (3.1413)  Time: 1.634s, 3484.86/s  (0.850s, 6700.24/s)  LR: 5.683e-03  Data: 0.000 (0.020)
2025-06-01 22:19:07,092 - train - INFO - Train: 137 [ 223/224 (100%)]  Loss:  3.129671 (3.1393)  Time: 0.552s, 10317.49/s  (0.844s, 6751.78/s)  LR: 5.683e-03  Data: 0.000 (0.018)
2025-06-01 22:19:12,026 - train - INFO - Test: [   0/70]  Time: 4.686 (4.686)  Loss:  1.4141 (1.4141)  Acc@1: 71.9452 (71.9452)  Acc@5: 89.5365 (89.5365)
2025-06-01 22:19:54,423 - train - INFO - Test: [  50/70]  Time: 0.120 (0.923)  Loss:  1.7998 (1.8361)  Acc@1: 63.2900 (61.1244)  Acc@5: 84.3750 (83.7485)
2025-06-01 22:20:10,860 - train - INFO - Test: [  70/70]  Time: 0.034 (0.895)  Loss:  2.3145 (1.9148)  Acc@1: 44.0625 (59.4745)  Acc@5: 79.4531 (82.3042)
2025-06-01 22:20:15,842 - train - INFO - Train: 138 [   0/224 (  0%)]  Loss:  3.099061 (3.0991)  Time: 4.668s, 1220.10/s  (4.668s, 1220.10/s)  LR: 5.631e-03  Data: 3.668 (3.668)
2025-06-01 22:20:56,981 - train - INFO - Train: 138 [  50/224 ( 22%)]  Loss:  3.134606 (3.1168)  Time: 0.550s, 10359.73/s  (0.898s, 6341.81/s)  LR: 5.631e-03  Data: 0.000 (0.172)
2025-06-01 22:21:38,778 - train - INFO - Train: 138 [ 100/224 ( 45%)]  Loss:  3.123957 (3.1192)  Time: 1.601s, 3556.89/s  (0.867s, 6567.12/s)  LR: 5.631e-03  Data: 0.000 (0.087)
2025-06-01 22:22:19,816 - train - INFO - Train: 138 [ 150/224 ( 67%)]  Loss:  3.112585 (3.1176)  Time: 0.549s, 10378.22/s  (0.852s, 6686.14/s)  LR: 5.631e-03  Data: 0.000 (0.058)
2025-06-01 22:23:00,597 - train - INFO - Train: 138 [ 200/224 ( 90%)]  Loss:  3.161824 (3.1264)  Time: 1.030s, 5531.83/s  (0.843s, 6757.83/s)  LR: 5.631e-03  Data: 0.000 (0.044)
2025-06-01 22:23:19,820 - train - INFO - Train: 138 [ 223/224 (100%)]  Loss:  3.125696 (3.1263)  Time: 0.544s, 10465.38/s  (0.842s, 6763.76/s)  LR: 5.631e-03  Data: 0.000 (0.039)
2025-06-01 22:23:24,603 - train - INFO - Test: [   0/70]  Time: 4.520 (4.520)  Loss:  1.1787 (1.1787)  Acc@1: 75.3511 (75.3511)  Acc@5: 92.9249 (92.9249)
2025-06-01 22:24:07,159 - train - INFO - Test: [  50/70]  Time: 0.120 (0.923)  Loss:  1.9561 (1.6885)  Acc@1: 59.2521 (64.0291)  Acc@5: 82.0400 (85.8625)
2025-06-01 22:24:23,776 - train - INFO - Test: [  70/70]  Time: 0.034 (0.897)  Loss:  2.0586 (1.7860)  Acc@1: 51.7969 (62.1110)  Acc@5: 82.1094 (84.2088)
2025-06-01 22:24:29,024 - train - INFO - Train: 139 [   0/224 (  0%)]  Loss:  3.130298 (3.1303)  Time: 4.933s, 1154.72/s  (4.933s, 1154.72/s)  LR: 5.579e-03  Data: 3.693 (3.693)
2025-06-01 22:25:10,076 - train - INFO - Train: 139 [  50/224 ( 22%)]  Loss:  3.151254 (3.1408)  Time: 0.549s, 10379.05/s  (0.902s, 6317.37/s)  LR: 5.579e-03  Data: 0.000 (0.190)
2025-06-01 22:25:52,297 - train - INFO - Train: 139 [ 100/224 ( 45%)]  Loss:  3.201571 (3.1610)  Time: 1.471s, 3872.77/s  (0.873s, 6522.37/s)  LR: 5.579e-03  Data: 0.000 (0.097)
2025-06-01 22:26:32,781 - train - INFO - Train: 139 [ 150/224 ( 67%)]  Loss:  3.136058 (3.1548)  Time: 0.550s, 10357.59/s  (0.852s, 6683.68/s)  LR: 5.579e-03  Data: 0.000 (0.065)
2025-06-01 22:27:14,630 - train - INFO - Train: 139 [ 200/224 ( 90%)]  Loss:  3.148180 (3.1535)  Time: 1.583s, 3598.26/s  (0.848s, 6713.59/s)  LR: 5.579e-03  Data: 0.000 (0.049)
2025-06-01 22:27:32,462 - train - INFO - Train: 139 [ 223/224 (100%)]  Loss:  3.127211 (3.1491)  Time: 0.546s, 10423.62/s  (0.841s, 6773.61/s)  LR: 5.579e-03  Data: 0.000 (0.044)
2025-06-01 22:27:37,201 - train - INFO - Test: [   0/70]  Time: 4.490 (4.490)  Loss:  1.2988 (1.2988)  Acc@1: 75.2458 (75.2458)  Acc@5: 90.6075 (90.6075)
2025-06-01 22:28:20,125 - train - INFO - Test: [  50/70]  Time: 0.120 (0.930)  Loss:  1.6406 (1.7802)  Acc@1: 63.9396 (61.0349)  Acc@5: 83.2338 (83.8311)
2025-06-01 22:28:36,560 - train - INFO - Test: [  70/70]  Time: 0.034 (0.899)  Loss:  2.5879 (1.8667)  Acc@1: 41.6406 (59.1603)  Acc@5: 73.0469 (82.2623)
2025-06-01 22:28:41,616 - train - INFO - Train: 140 [   0/224 (  0%)]  Loss:  3.204628 (3.2046)  Time: 4.750s, 1199.22/s  (4.750s, 1199.22/s)  LR: 5.527e-03  Data: 3.714 (3.714)
2025-06-01 22:29:23,491 - train - INFO - Train: 140 [  50/224 ( 22%)]  Loss:  3.108990 (3.1568)  Time: 0.557s, 10232.18/s  (0.914s, 6230.86/s)  LR: 5.527e-03  Data: 0.000 (0.177)
2025-06-01 22:30:05,474 - train - INFO - Train: 140 [ 100/224 ( 45%)]  Loss:  3.178807 (3.1641)  Time: 1.596s, 3569.70/s  (0.877s, 6492.93/s)  LR: 5.527e-03  Data: 0.000 (0.090)
2025-06-01 22:30:46,310 - train - INFO - Train: 140 [ 150/224 ( 67%)]  Loss:  3.179373 (3.1679)  Time: 0.550s, 10361.36/s  (0.857s, 6644.79/s)  LR: 5.527e-03  Data: 0.000 (0.060)
2025-06-01 22:31:28,579 - train - INFO - Train: 140 [ 200/224 ( 90%)]  Loss:  3.129518 (3.1603)  Time: 1.692s, 3367.22/s  (0.854s, 6667.71/s)  LR: 5.527e-03  Data: 0.000 (0.045)
2025-06-01 22:31:46,589 - train - INFO - Train: 140 [ 223/224 (100%)]  Loss:  3.152905 (3.1590)  Time: 0.545s, 10447.49/s  (0.847s, 6725.31/s)  LR: 5.527e-03  Data: 0.000 (0.041)
2025-06-01 22:31:51,472 - train - INFO - Test: [   0/70]  Time: 4.638 (4.638)  Loss:  1.3320 (1.3320)  Acc@1: 73.5955 (73.5955)  Acc@5: 91.8188 (91.8188)
2025-06-01 22:32:33,208 - train - INFO - Test: [  50/70]  Time: 0.122 (0.909)  Loss:  2.1250 (2.1396)  Acc@1: 58.7079 (57.1058)  Acc@5: 79.5997 (80.6844)
2025-06-01 22:32:49,562 - train - INFO - Test: [  70/70]  Time: 0.034 (0.883)  Loss:  1.9766 (2.2108)  Acc@1: 46.0938 (55.7290)  Acc@5: 86.8750 (79.3665)
2025-06-01 22:32:54,371 - train - INFO - Train: 141 [   0/224 (  0%)]  Loss:  3.083355 (3.0834)  Time: 4.506s, 1264.00/s  (4.506s, 1264.00/s)  LR: 5.475e-03  Data: 3.592 (3.592)
2025-06-01 22:33:36,150 - train - INFO - Train: 141 [  50/224 ( 22%)]  Loss:  3.163498 (3.1234)  Time: 0.550s, 10351.91/s  (0.908s, 6276.55/s)  LR: 5.475e-03  Data: 0.000 (0.097)
2025-06-01 22:34:18,372 - train - INFO - Train: 141 [ 100/224 ( 45%)]  Loss:  3.136783 (3.1279)  Time: 1.700s, 3350.58/s  (0.876s, 6500.29/s)  LR: 5.475e-03  Data: 0.000 (0.049)
2025-06-01 22:34:58,526 - train - INFO - Train: 141 [ 150/224 ( 67%)]  Loss:  3.121727 (3.1263)  Time: 0.561s, 10157.38/s  (0.852s, 6685.26/s)  LR: 5.475e-03  Data: 0.000 (0.033)
2025-06-01 22:35:40,144 - train - INFO - Train: 141 [ 200/224 ( 90%)]  Loss:  3.143963 (3.1299)  Time: 1.516s, 3757.93/s  (0.847s, 6723.93/s)  LR: 5.475e-03  Data: 0.000 (0.025)
2025-06-01 22:35:58,195 - train - INFO - Train: 141 [ 223/224 (100%)]  Loss:  3.178753 (3.1380)  Time: 0.545s, 10446.88/s  (0.841s, 6775.11/s)  LR: 5.475e-03  Data: 0.000 (0.022)
2025-06-01 22:36:02,930 - train - INFO - Test: [   0/70]  Time: 4.493 (4.493)  Loss:  1.3672 (1.3672)  Acc@1: 76.6327 (76.6327)  Acc@5: 92.3631 (92.3631)
2025-06-01 22:36:44,867 - train - INFO - Test: [  50/70]  Time: 0.120 (0.910)  Loss:  2.0879 (1.9546)  Acc@1: 60.3757 (61.1492)  Acc@5: 81.4256 (84.0614)
2025-06-01 22:37:01,130 - train - INFO - Test: [  70/70]  Time: 0.034 (0.883)  Loss:  2.4453 (2.0301)  Acc@1: 41.0938 (59.4103)  Acc@5: 76.7188 (82.6963)
2025-06-01 22:37:06,192 - train - INFO - Train: 142 [   0/224 (  0%)]  Loss:  3.217929 (3.2179)  Time: 4.756s, 1197.58/s  (4.756s, 1197.58/s)  LR: 5.423e-03  Data: 3.601 (3.601)
2025-06-01 22:37:47,980 - train - INFO - Train: 142 [  50/224 ( 22%)]  Loss:  3.145875 (3.1819)  Time: 0.557s, 10231.14/s  (0.913s, 6241.62/s)  LR: 5.423e-03  Data: 0.000 (0.094)
2025-06-01 22:38:29,660 - train - INFO - Train: 142 [ 100/224 ( 45%)]  Loss:  3.096319 (3.1534)  Time: 1.526s, 3733.72/s  (0.873s, 6521.17/s)  LR: 5.423e-03  Data: 0.000 (0.048)
2025-06-01 22:39:11,285 - train - INFO - Train: 142 [ 150/224 ( 67%)]  Loss:  3.151533 (3.1529)  Time: 0.549s, 10367.07/s  (0.860s, 6624.06/s)  LR: 5.423e-03  Data: 0.000 (0.032)
2025-06-01 22:39:52,792 - train - INFO - Train: 142 [ 200/224 ( 90%)]  Loss:  3.115741 (3.1455)  Time: 1.459s, 3905.36/s  (0.852s, 6681.62/s)  LR: 5.423e-03  Data: 0.000 (0.024)
2025-06-01 22:40:11,077 - train - INFO - Train: 142 [ 223/224 (100%)]  Loss:  3.143867 (3.1452)  Time: 0.545s, 10454.26/s  (0.847s, 6728.26/s)  LR: 5.423e-03  Data: 0.000 (0.022)
2025-06-01 22:40:15,895 - train - INFO - Test: [   0/70]  Time: 4.568 (4.568)  Loss:  1.1572 (1.1572)  Acc@1: 73.4024 (73.4024)  Acc@5: 89.5014 (89.5014)
2025-06-01 22:40:58,050 - train - INFO - Test: [  50/70]  Time: 0.120 (0.916)  Loss:  1.9424 (1.6489)  Acc@1: 57.5667 (62.6697)  Acc@5: 81.2851 (84.6208)
2025-06-01 22:41:14,783 - train - INFO - Test: [  70/70]  Time: 0.034 (0.894)  Loss:  2.0293 (1.7392)  Acc@1: 53.1250 (61.0050)  Acc@5: 79.4531 (83.2715)
2025-06-01 22:41:19,683 - train - INFO - Train: 143 [   0/224 (  0%)]  Loss:  3.163240 (3.1632)  Time: 4.581s, 1243.31/s  (4.581s, 1243.31/s)  LR: 5.371e-03  Data: 3.872 (3.872)
2025-06-01 22:42:00,914 - train - INFO - Train: 143 [  50/224 ( 22%)]  Loss:  3.218744 (3.1910)  Time: 0.554s, 10282.64/s  (0.898s, 6341.31/s)  LR: 5.371e-03  Data: 0.000 (0.144)
2025-06-01 22:42:43,080 - train - INFO - Train: 143 [ 100/224 ( 45%)]  Loss:  3.100962 (3.1610)  Time: 1.472s, 3870.20/s  (0.871s, 6539.37/s)  LR: 5.371e-03  Data: 0.000 (0.073)
2025-06-01 22:43:24,786 - train - INFO - Train: 143 [ 150/224 ( 67%)]  Loss:  3.167626 (3.1626)  Time: 0.557s, 10223.54/s  (0.859s, 6632.45/s)  LR: 5.371e-03  Data: 0.000 (0.049)
2025-06-01 22:44:05,732 - train - INFO - Train: 143 [ 200/224 ( 90%)]  Loss:  3.171493 (3.1644)  Time: 0.550s, 10349.98/s  (0.849s, 6710.11/s)  LR: 5.371e-03  Data: 0.000 (0.037)
2025-06-01 22:44:24,630 - train - INFO - Train: 143 [ 223/224 (100%)]  Loss:  3.148392 (3.1617)  Time: 0.545s, 10448.58/s  (0.846s, 6732.29/s)  LR: 5.371e-03  Data: 0.000 (0.033)
2025-06-01 22:44:29,454 - train - INFO - Test: [   0/70]  Time: 4.584 (4.584)  Loss:  1.0303 (1.0303)  Acc@1: 76.6327 (76.6327)  Acc@5: 92.6440 (92.6440)
2025-06-01 22:45:11,663 - train - INFO - Test: [  50/70]  Time: 0.120 (0.918)  Loss:  1.6719 (1.6394)  Acc@1: 64.4136 (62.8064)  Acc@5: 82.8827 (85.2480)
2025-06-01 22:45:27,889 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.1250 (1.7253)  Acc@1: 47.5781 (61.2118)  Acc@5: 79.4531 (83.7968)
2025-06-01 22:45:32,845 - train - INFO - Train: 144 [   0/224 (  0%)]  Loss:  3.121004 (3.1210)  Time: 4.652s, 1224.48/s  (4.652s, 1224.48/s)  LR: 5.319e-03  Data: 4.099 (4.099)
2025-06-01 22:46:13,919 - train - INFO - Train: 144 [  50/224 ( 22%)]  Loss:  3.105492 (3.1132)  Time: 0.556s, 10246.99/s  (0.897s, 6353.32/s)  LR: 5.319e-03  Data: 0.000 (0.142)
2025-06-01 22:46:55,691 - train - INFO - Train: 144 [ 100/224 ( 45%)]  Loss:  3.136917 (3.1211)  Time: 1.657s, 3438.03/s  (0.866s, 6575.21/s)  LR: 5.319e-03  Data: 0.000 (0.072)
2025-06-01 22:47:36,348 - train - INFO - Train: 144 [ 150/224 ( 67%)]  Loss:  3.153599 (3.1293)  Time: 0.557s, 10235.05/s  (0.849s, 6711.59/s)  LR: 5.319e-03  Data: 0.000 (0.048)
2025-06-01 22:48:18,178 - train - INFO - Train: 144 [ 200/224 ( 90%)]  Loss:  3.124449 (3.1283)  Time: 0.765s, 7450.48/s  (0.846s, 6735.52/s)  LR: 5.319e-03  Data: 0.000 (0.036)
2025-06-01 22:48:37,091 - train - INFO - Train: 144 [ 223/224 (100%)]  Loss:  3.146295 (3.1313)  Time: 0.544s, 10472.41/s  (0.843s, 6754.72/s)  LR: 5.319e-03  Data: 0.000 (0.033)
2025-06-01 22:48:41,834 - train - INFO - Test: [   0/70]  Time: 4.497 (4.497)  Loss:  1.2383 (1.2383)  Acc@1: 75.0351 (75.0351)  Acc@5: 92.0295 (92.0295)
2025-06-01 22:49:23,623 - train - INFO - Test: [  50/70]  Time: 0.161 (0.908)  Loss:  1.7539 (1.7795)  Acc@1: 62.5176 (62.1950)  Acc@5: 84.1292 (84.8036)
2025-06-01 22:49:40,308 - train - INFO - Test: [  70/70]  Time: 0.035 (0.887)  Loss:  2.5449 (1.8593)  Acc@1: 42.5000 (60.4588)  Acc@5: 71.2500 (83.2908)
2025-06-01 22:49:45,317 - train - INFO - Train: 145 [   0/224 (  0%)]  Loss:  3.157015 (3.1570)  Time: 4.693s, 1213.62/s  (4.693s, 1213.62/s)  LR: 5.266e-03  Data: 3.543 (3.543)
2025-06-01 22:50:26,282 - train - INFO - Train: 145 [  50/224 ( 22%)]  Loss:  3.120808 (3.1389)  Time: 0.556s, 10251.00/s  (0.895s, 6362.74/s)  LR: 5.266e-03  Data: 0.000 (0.116)
2025-06-01 22:51:08,557 - train - INFO - Train: 145 [ 100/224 ( 45%)]  Loss:  3.106243 (3.1280)  Time: 1.758s, 3240.16/s  (0.871s, 6542.69/s)  LR: 5.266e-03  Data: 0.000 (0.059)
2025-06-01 22:51:49,300 - train - INFO - Train: 145 [ 150/224 ( 67%)]  Loss:  3.144116 (3.1320)  Time: 0.555s, 10270.21/s  (0.852s, 6684.55/s)  LR: 5.266e-03  Data: 0.000 (0.039)
2025-06-01 22:52:31,420 - train - INFO - Train: 145 [ 200/224 ( 90%)]  Loss:  3.158775 (3.1374)  Time: 1.537s, 3704.99/s  (0.850s, 6703.67/s)  LR: 5.266e-03  Data: 0.000 (0.030)
2025-06-01 22:52:49,740 - train - INFO - Train: 145 [ 223/224 (100%)]  Loss:  3.152239 (3.1399)  Time: 0.550s, 10349.76/s  (0.844s, 6747.03/s)  LR: 5.266e-03  Data: 0.000 (0.027)
2025-06-01 22:52:54,649 - train - INFO - Test: [   0/70]  Time: 4.672 (4.672)  Loss:  1.3691 (1.3691)  Acc@1: 67.8722 (67.8722)  Acc@5: 87.3947 (87.3947)
2025-06-01 22:53:37,205 - train - INFO - Test: [  50/70]  Time: 0.120 (0.926)  Loss:  1.9600 (1.8194)  Acc@1: 58.9537 (59.0821)  Acc@5: 78.2128 (82.1065)
2025-06-01 22:53:54,190 - train - INFO - Test: [  70/70]  Time: 0.034 (0.904)  Loss:  2.6133 (1.9096)  Acc@1: 30.7812 (57.4945)  Acc@5: 75.0781 (80.7015)
2025-06-01 22:53:59,327 - train - INFO - Train: 146 [   0/224 (  0%)]  Loss:  3.134847 (3.1348)  Time: 4.796s, 1187.74/s  (4.796s, 1187.74/s)  LR: 5.214e-03  Data: 4.253 (4.253)
2025-06-01 22:54:39,923 - train - INFO - Train: 146 [  50/224 ( 22%)]  Loss:  3.174577 (3.1547)  Time: 0.557s, 10227.49/s  (0.890s, 6399.92/s)  LR: 5.214e-03  Data: 0.000 (0.113)
2025-06-01 22:55:21,877 - train - INFO - Train: 146 [ 100/224 ( 45%)]  Loss:  3.154923 (3.1548)  Time: 1.479s, 3850.88/s  (0.865s, 6586.61/s)  LR: 5.214e-03  Data: 0.000 (0.057)
2025-06-01 22:56:03,068 - train - INFO - Train: 146 [ 150/224 ( 67%)]  Loss:  3.118687 (3.1458)  Time: 0.556s, 10251.76/s  (0.851s, 6691.67/s)  LR: 5.214e-03  Data: 0.000 (0.038)
2025-06-01 22:56:43,828 - train - INFO - Train: 146 [ 200/224 ( 90%)]  Loss:  3.110551 (3.1387)  Time: 0.550s, 10359.35/s  (0.842s, 6762.89/s)  LR: 5.214e-03  Data: 0.000 (0.029)
2025-06-01 22:57:02,992 - train - INFO - Train: 146 [ 223/224 (100%)]  Loss:  3.187123 (3.1468)  Time: 0.548s, 10391.69/s  (0.841s, 6770.35/s)  LR: 5.214e-03  Data: 0.000 (0.026)
2025-06-01 22:57:07,973 - train - INFO - Test: [   0/70]  Time: 4.728 (4.728)  Loss:  1.3350 (1.3350)  Acc@1: 74.5962 (74.5962)  Acc@5: 91.1868 (91.1868)
2025-06-01 22:57:50,626 - train - INFO - Test: [  50/70]  Time: 0.120 (0.929)  Loss:  1.7812 (1.9410)  Acc@1: 62.4122 (60.4057)  Acc@5: 84.0765 (83.1798)
2025-06-01 22:58:07,456 - train - INFO - Test: [  70/70]  Time: 0.034 (0.904)  Loss:  2.9531 (2.0360)  Acc@1: 36.7188 (58.2683)  Acc@5: 68.7500 (81.5435)
2025-06-01 22:58:12,574 - train - INFO - Train: 147 [   0/224 (  0%)]  Loss:  3.123580 (3.1236)  Time: 4.791s, 1188.85/s  (4.791s, 1188.85/s)  LR: 5.162e-03  Data: 3.957 (3.957)
2025-06-01 22:58:53,852 - train - INFO - Train: 147 [  50/224 ( 22%)]  Loss:  3.122758 (3.1232)  Time: 0.547s, 10409.48/s  (0.903s, 6306.02/s)  LR: 5.162e-03  Data: 0.000 (0.220)
2025-06-01 22:59:36,037 - train - INFO - Train: 147 [ 100/224 ( 45%)]  Loss:  3.153323 (3.1332)  Time: 1.565s, 3640.36/s  (0.874s, 6519.05/s)  LR: 5.162e-03  Data: 0.000 (0.117)
2025-06-01 23:00:16,519 - train - INFO - Train: 147 [ 150/224 ( 67%)]  Loss:  3.124102 (3.1309)  Time: 0.551s, 10337.15/s  (0.853s, 6681.42/s)  LR: 5.162e-03  Data: 0.000 (0.078)
2025-06-01 23:00:57,935 - train - INFO - Train: 147 [ 200/224 ( 90%)]  Loss:  3.144626 (3.1337)  Time: 1.552s, 3669.12/s  (0.846s, 6728.97/s)  LR: 5.162e-03  Data: 0.000 (0.059)
2025-06-01 23:01:16,059 - train - INFO - Train: 147 [ 223/224 (100%)]  Loss:  3.123297 (3.1319)  Time: 0.547s, 10405.78/s  (0.840s, 6777.07/s)  LR: 5.162e-03  Data: 0.000 (0.053)
2025-06-01 23:01:20,957 - train - INFO - Test: [   0/70]  Time: 4.657 (4.657)  Loss:  1.1143 (1.1143)  Acc@1: 74.9649 (74.9649)  Acc@5: 91.4677 (91.4677)
2025-06-01 23:02:04,166 - train - INFO - Test: [  50/70]  Time: 0.123 (0.939)  Loss:  1.8008 (1.6801)  Acc@1: 59.3926 (61.8890)  Acc@5: 81.5836 (84.3963)
2025-06-01 23:02:20,881 - train - INFO - Test: [  70/70]  Time: 0.034 (0.910)  Loss:  2.0977 (1.7590)  Acc@1: 48.2812 (60.5235)  Acc@5: 82.3438 (83.1323)
2025-06-01 23:02:25,991 - train - INFO - Train: 148 [   0/224 (  0%)]  Loss:  3.161629 (3.1616)  Time: 4.796s, 1187.74/s  (4.796s, 1187.74/s)  LR: 5.110e-03  Data: 4.092 (4.092)
2025-06-01 23:03:06,779 - train - INFO - Train: 148 [  50/224 ( 22%)]  Loss:  3.131419 (3.1465)  Time: 0.551s, 10343.94/s  (0.894s, 6373.14/s)  LR: 5.110e-03  Data: 0.000 (0.296)
2025-06-01 23:03:48,424 - train - INFO - Train: 148 [ 100/224 ( 45%)]  Loss:  3.121820 (3.1383)  Time: 1.739s, 3275.72/s  (0.864s, 6595.73/s)  LR: 5.110e-03  Data: 0.000 (0.209)
2025-06-01 23:04:29,154 - train - INFO - Train: 148 [ 150/224 ( 67%)]  Loss:  3.166022 (3.1452)  Time: 0.550s, 10363.34/s  (0.847s, 6722.13/s)  LR: 5.110e-03  Data: 0.000 (0.140)
2025-06-01 23:05:10,914 - train - INFO - Train: 148 [ 200/224 ( 90%)]  Loss:  3.201696 (3.1565)  Time: 1.668s, 3414.09/s  (0.844s, 6746.20/s)  LR: 5.110e-03  Data: 0.000 (0.105)
2025-06-01 23:05:28,675 - train - INFO - Train: 148 [ 223/224 (100%)]  Loss:  3.106428 (3.1482)  Time: 0.546s, 10424.49/s  (0.837s, 6805.95/s)  LR: 5.110e-03  Data: 0.000 (0.095)
2025-06-01 23:05:33,518 - train - INFO - Test: [   0/70]  Time: 4.595 (4.595)  Loss:  1.1543 (1.1543)  Acc@1: 75.5793 (75.5793)  Acc@5: 92.4333 (92.4333)
2025-06-01 23:06:16,110 - train - INFO - Test: [  50/70]  Time: 0.120 (0.925)  Loss:  1.7324 (1.8846)  Acc@1: 62.9038 (59.4766)  Acc@5: 83.8483 (82.5461)
2025-06-01 23:06:32,769 - train - INFO - Test: [  70/70]  Time: 0.034 (0.899)  Loss:  2.6855 (1.9672)  Acc@1: 43.1250 (57.8308)  Acc@5: 71.1719 (81.2255)
2025-06-01 23:06:37,772 - train - INFO - Train: 149 [   0/224 (  0%)]  Loss:  3.183580 (3.1836)  Time: 4.710s, 1209.32/s  (4.710s, 1209.32/s)  LR: 5.057e-03  Data: 4.130 (4.130)
2025-06-01 23:07:18,792 - train - INFO - Train: 149 [  50/224 ( 22%)]  Loss:  3.113087 (3.1483)  Time: 0.549s, 10377.63/s  (0.897s, 6352.86/s)  LR: 5.057e-03  Data: 0.000 (0.288)
2025-06-01 23:08:00,262 - train - INFO - Train: 149 [ 100/224 ( 45%)]  Loss:  3.151525 (3.1494)  Time: 1.719s, 3313.01/s  (0.863s, 6597.88/s)  LR: 5.057e-03  Data: 0.615 (0.229)
2025-06-01 23:08:40,380 - train - INFO - Train: 149 [ 150/224 ( 67%)]  Loss:  3.155220 (3.1509)  Time: 0.549s, 10370.12/s  (0.843s, 6755.86/s)  LR: 5.057e-03  Data: 0.000 (0.200)
2025-06-01 23:09:22,590 - train - INFO - Train: 149 [ 200/224 ( 90%)]  Loss:  3.147697 (3.1502)  Time: 1.749s, 3256.84/s  (0.843s, 6753.75/s)  LR: 5.057e-03  Data: 0.000 (0.164)
2025-06-01 23:09:40,594 - train - INFO - Train: 149 [ 223/224 (100%)]  Loss:  3.126173 (3.1462)  Time: 0.547s, 10417.88/s  (0.837s, 6803.96/s)  LR: 5.057e-03  Data: 0.000 (0.147)
2025-06-01 23:09:45,504 - train - INFO - Test: [   0/70]  Time: 4.660 (4.660)  Loss:  1.4912 (1.4912)  Acc@1: 72.1910 (72.1910)  Acc@5: 90.9235 (90.9235)
2025-06-01 23:10:27,846 - train - INFO - Test: [  50/70]  Time: 0.120 (0.922)  Loss:  2.2070 (1.9337)  Acc@1: 56.8996 (61.0508)  Acc@5: 80.8111 (84.0008)
2025-06-01 23:10:44,520 - train - INFO - Test: [  70/70]  Time: 0.034 (0.897)  Loss:  2.7969 (2.0107)  Acc@1: 32.5781 (59.5545)  Acc@5: 71.9531 (82.7025)
2025-06-01 23:10:49,542 - train - INFO - Train: 150 [   0/224 (  0%)]  Loss:  3.113878 (3.1139)  Time: 4.720s, 1206.86/s  (4.720s, 1206.86/s)  LR: 5.005e-03  Data: 3.903 (3.903)
2025-06-01 23:11:31,359 - train - INFO - Train: 150 [  50/224 ( 22%)]  Loss:  3.129503 (3.1217)  Time: 0.557s, 10232.17/s  (0.912s, 6242.49/s)  LR: 5.005e-03  Data: 0.000 (0.098)
2025-06-01 23:12:12,955 - train - INFO - Train: 150 [ 100/224 ( 45%)]  Loss:  3.134348 (3.1259)  Time: 1.593s, 3575.24/s  (0.873s, 6527.79/s)  LR: 5.005e-03  Data: 0.000 (0.049)
2025-06-01 23:12:53,815 - train - INFO - Train: 150 [ 150/224 ( 67%)]  Loss:  3.118589 (3.1241)  Time: 0.554s, 10285.28/s  (0.854s, 6668.04/s)  LR: 5.005e-03  Data: 0.000 (0.033)
2025-06-01 23:13:34,879 - train - INFO - Train: 150 [ 200/224 ( 90%)]  Loss:  3.103423 (3.1199)  Time: 1.594s, 3573.41/s  (0.846s, 6732.63/s)  LR: 5.005e-03  Data: 0.000 (0.025)
2025-06-01 23:13:52,693 - train - INFO - Train: 150 [ 223/224 (100%)]  Loss:  3.150889 (3.1251)  Time: 0.552s, 10314.64/s  (0.839s, 6791.61/s)  LR: 5.005e-03  Data: 0.000 (0.022)
2025-06-01 23:13:57,768 - train - INFO - Test: [   0/70]  Time: 4.833 (4.833)  Loss:  1.4268 (1.4268)  Acc@1: 73.7886 (73.7886)  Acc@5: 90.8883 (90.8883)
2025-06-01 23:14:40,149 - train - INFO - Test: [  50/70]  Time: 0.120 (0.926)  Loss:  1.8047 (1.8327)  Acc@1: 64.1854 (62.0935)  Acc@5: 82.5316 (84.5595)
2025-06-01 23:14:56,684 - train - INFO - Test: [  70/70]  Time: 0.034 (0.898)  Loss:  2.4980 (1.9095)  Acc@1: 40.8594 (60.4860)  Acc@5: 76.5625 (83.1463)
2025-06-01 23:15:01,566 - train - INFO - Train: 151 [   0/224 (  0%)]  Loss:  3.120105 (3.1201)  Time: 4.577s, 1244.40/s  (4.577s, 1244.40/s)  LR: 4.953e-03  Data: 3.799 (3.799)
2025-06-01 23:15:42,785 - train - INFO - Train: 151 [  50/224 ( 22%)]  Loss:  3.143871 (3.1320)  Time: 0.552s, 10319.83/s  (0.898s, 6343.49/s)  LR: 4.953e-03  Data: 0.000 (0.148)
2025-06-01 23:16:24,442 - train - INFO - Train: 151 [ 100/224 ( 45%)]  Loss:  3.142462 (3.1355)  Time: 1.675s, 3399.89/s  (0.866s, 6578.60/s)  LR: 4.953e-03  Data: 0.000 (0.075)
2025-06-01 23:17:04,968 - train - INFO - Train: 151 [ 150/224 ( 67%)]  Loss:  3.140440 (3.1367)  Time: 0.550s, 10354.02/s  (0.848s, 6720.86/s)  LR: 4.953e-03  Data: 0.000 (0.050)
2025-06-01 23:17:46,882 - train - INFO - Train: 151 [ 200/224 ( 90%)]  Loss:  3.177199 (3.1448)  Time: 1.634s, 3485.00/s  (0.845s, 6739.18/s)  LR: 4.953e-03  Data: 0.000 (0.038)
2025-06-01 23:18:05,183 - train - INFO - Train: 151 [ 223/224 (100%)]  Loss:  3.156907 (3.1468)  Time: 0.545s, 10448.77/s  (0.840s, 6780.00/s)  LR: 4.953e-03  Data: 0.000 (0.034)
2025-06-01 23:18:10,052 - train - INFO - Test: [   0/70]  Time: 4.620 (4.620)  Loss:  1.1504 (1.1504)  Acc@1: 75.2809 (75.2809)  Acc@5: 92.3455 (92.3455)
2025-06-01 23:18:53,080 - train - INFO - Test: [  50/70]  Time: 0.121 (0.934)  Loss:  1.9082 (1.7265)  Acc@1: 60.6039 (61.3396)  Acc@5: 81.0569 (84.1127)
2025-06-01 23:19:10,127 - train - INFO - Test: [  70/70]  Time: 0.036 (0.911)  Loss:  2.6719 (1.8169)  Acc@1: 40.3125 (59.9423)  Acc@5: 71.4062 (82.6933)
2025-06-01 23:19:15,028 - train - INFO - Train: 152 [   0/224 (  0%)]  Loss:  3.136733 (3.1367)  Time: 4.585s, 1242.28/s  (4.585s, 1242.28/s)  LR: 4.900e-03  Data: 3.628 (3.628)
2025-06-01 23:19:56,150 - train - INFO - Train: 152 [  50/224 ( 22%)]  Loss:  3.113806 (3.1253)  Time: 0.734s, 7756.88/s  (0.896s, 6356.19/s)  LR: 4.900e-03  Data: 0.000 (0.259)
2025-06-01 23:20:38,206 - train - INFO - Train: 152 [ 100/224 ( 45%)]  Loss:  3.145853 (3.1321)  Time: 1.629s, 3497.28/s  (0.869s, 6555.43/s)  LR: 4.900e-03  Data: 0.037 (0.189)
2025-06-01 23:21:19,025 - train - INFO - Train: 152 [ 150/224 ( 67%)]  Loss:  3.148938 (3.1363)  Time: 0.551s, 10341.55/s  (0.851s, 6689.44/s)  LR: 4.900e-03  Data: 0.000 (0.127)
2025-06-01 23:22:01,455 - train - INFO - Train: 152 [ 200/224 ( 90%)]  Loss:  3.111687 (3.1314)  Time: 1.751s, 3252.79/s  (0.851s, 6695.12/s)  LR: 4.900e-03  Data: 0.000 (0.096)
2025-06-01 23:22:19,269 - train - INFO - Train: 152 [ 223/224 (100%)]  Loss:  3.125049 (3.1303)  Time: 0.546s, 10438.58/s  (0.843s, 6757.31/s)  LR: 4.900e-03  Data: 0.000 (0.086)
2025-06-01 23:22:23,934 - train - INFO - Test: [   0/70]  Time: 4.416 (4.416)  Loss:  1.3652 (1.3652)  Acc@1: 73.7535 (73.7535)  Acc@5: 90.6601 (90.6601)
2025-06-01 23:23:05,845 - train - INFO - Test: [  50/70]  Time: 0.120 (0.908)  Loss:  2.0059 (1.7983)  Acc@1: 58.6728 (62.4301)  Acc@5: 79.4944 (84.5461)
2025-06-01 23:23:22,350 - train - INFO - Test: [  70/70]  Time: 0.034 (0.885)  Loss:  2.3887 (1.8601)  Acc@1: 46.4062 (61.0478)  Acc@5: 80.4688 (83.3418)
2025-06-01 23:23:27,579 - train - INFO - Train: 153 [   0/224 (  0%)]  Loss:  3.176551 (3.1766)  Time: 4.919s, 1157.93/s  (4.919s, 1157.93/s)  LR: 4.848e-03  Data: 3.683 (3.683)
2025-06-01 23:24:09,418 - train - INFO - Train: 153 [  50/224 ( 22%)]  Loss:  3.147514 (3.1620)  Time: 0.555s, 10256.25/s  (0.917s, 6212.78/s)  LR: 4.848e-03  Data: 0.000 (0.091)
2025-06-01 23:24:51,678 - train - INFO - Train: 153 [ 100/224 ( 45%)]  Loss:  3.128466 (3.1508)  Time: 1.793s, 3176.88/s  (0.881s, 6462.79/s)  LR: 4.848e-03  Data: 0.000 (0.046)
2025-06-01 23:25:32,229 - train - INFO - Train: 153 [ 150/224 ( 67%)]  Loss:  3.133127 (3.1464)  Time: 0.555s, 10257.00/s  (0.858s, 6638.33/s)  LR: 4.848e-03  Data: 0.000 (0.031)
2025-06-01 23:26:13,947 - train - INFO - Train: 153 [ 200/224 ( 90%)]  Loss:  3.145069 (3.1461)  Time: 1.479s, 3851.37/s  (0.852s, 6684.31/s)  LR: 4.848e-03  Data: 0.000 (0.023)
2025-06-01 23:26:32,009 - train - INFO - Train: 153 [ 223/224 (100%)]  Loss:  3.200184 (3.1552)  Time: 0.551s, 10332.38/s  (0.845s, 6738.59/s)  LR: 4.848e-03  Data: 0.000 (0.021)
2025-06-01 23:26:36,933 - train - INFO - Test: [   0/70]  Time: 4.674 (4.674)  Loss:  1.5596 (1.5596)  Acc@1: 71.1728 (71.1728)  Acc@5: 89.1503 (89.1503)
2025-06-01 23:27:19,056 - train - INFO - Test: [  50/70]  Time: 0.124 (0.918)  Loss:  1.8496 (1.9085)  Acc@1: 61.8680 (59.8900)  Acc@5: 84.2872 (83.3203)
2025-06-01 23:27:35,513 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  3.1270 (1.9802)  Acc@1: 23.6719 (58.4235)  Acc@5: 65.1562 (81.9773)
2025-06-01 23:27:40,544 - train - INFO - Train: 154 [   0/224 (  0%)]  Loss:  3.111802 (3.1118)  Time: 4.707s, 1210.22/s  (4.707s, 1210.22/s)  LR: 4.796e-03  Data: 4.146 (4.146)
2025-06-01 23:28:22,233 - train - INFO - Train: 154 [  50/224 ( 22%)]  Loss:  3.147079 (3.1294)  Time: 0.551s, 10340.02/s  (0.910s, 6262.03/s)  LR: 4.796e-03  Data: 0.000 (0.147)
2025-06-01 23:29:03,979 - train - INFO - Train: 154 [ 100/224 ( 45%)]  Loss:  3.144173 (3.1344)  Time: 1.623s, 3509.28/s  (0.873s, 6527.43/s)  LR: 4.796e-03  Data: 0.000 (0.074)
2025-06-01 23:29:44,500 - train - INFO - Train: 154 [ 150/224 ( 67%)]  Loss:  3.123022 (3.1315)  Time: 0.550s, 10363.51/s  (0.852s, 6685.36/s)  LR: 4.796e-03  Data: 0.000 (0.050)
2025-06-01 23:30:26,214 - train - INFO - Train: 154 [ 200/224 ( 90%)]  Loss:  3.138975 (3.1330)  Time: 1.661s, 3428.69/s  (0.848s, 6720.24/s)  LR: 4.796e-03  Data: 0.000 (0.037)
2025-06-01 23:30:43,830 - train - INFO - Train: 154 [ 223/224 (100%)]  Loss:  3.170614 (3.1393)  Time: 0.551s, 10329.85/s  (0.839s, 6787.43/s)  LR: 4.796e-03  Data: 0.000 (0.034)
2025-06-01 23:30:48,585 - train - INFO - Test: [   0/70]  Time: 4.497 (4.497)  Loss:  1.2715 (1.2715)  Acc@1: 72.7353 (72.7353)  Acc@5: 90.0105 (90.0105)
2025-06-01 23:31:31,176 - train - INFO - Test: [  50/70]  Time: 0.701 (0.923)  Loss:  1.8418 (1.7330)  Acc@1: 59.5506 (60.9220)  Acc@5: 82.4614 (83.4889)
2025-06-01 23:31:47,352 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.8594 (1.8447)  Acc@1: 32.7344 (58.8120)  Acc@5: 69.2969 (81.6488)
2025-06-01 23:31:52,310 - train - INFO - Train: 155 [   0/224 (  0%)]  Loss:  3.172488 (3.1725)  Time: 4.643s, 1226.85/s  (4.643s, 1226.85/s)  LR: 4.744e-03  Data: 3.923 (3.923)
2025-06-01 23:32:33,619 - train - INFO - Train: 155 [  50/224 ( 22%)]  Loss:  3.133734 (3.1531)  Time: 0.551s, 10340.81/s  (0.901s, 6321.83/s)  LR: 4.744e-03  Data: 0.000 (0.171)
2025-06-01 23:33:15,703 - train - INFO - Train: 155 [ 100/224 ( 45%)]  Loss:  3.152457 (3.1529)  Time: 1.878s, 3032.71/s  (0.872s, 6534.96/s)  LR: 4.744e-03  Data: 0.000 (0.087)
2025-06-01 23:33:56,113 - train - INFO - Train: 155 [ 150/224 ( 67%)]  Loss:  3.125185 (3.1460)  Time: 0.550s, 10355.04/s  (0.851s, 6696.33/s)  LR: 4.744e-03  Data: 0.000 (0.058)
2025-06-01 23:34:37,510 - train - INFO - Train: 155 [ 200/224 ( 90%)]  Loss:  3.182168 (3.1532)  Time: 1.598s, 3564.86/s  (0.845s, 6741.09/s)  LR: 4.744e-03  Data: 0.000 (0.044)
2025-06-01 23:34:55,503 - train - INFO - Train: 155 [ 223/224 (100%)]  Loss:  3.100790 (3.1445)  Time: 0.547s, 10417.39/s  (0.839s, 6792.87/s)  LR: 4.744e-03  Data: 0.000 (0.039)
2025-06-01 23:35:00,366 - train - INFO - Test: [   0/70]  Time: 4.650 (4.650)  Loss:  1.5615 (1.5615)  Acc@1: 71.6292 (71.6292)  Acc@5: 91.1341 (91.1341)
2025-06-01 23:35:42,600 - train - INFO - Test: [  50/70]  Time: 0.120 (0.919)  Loss:  2.2539 (1.9789)  Acc@1: 52.2472 (60.5592)  Acc@5: 78.3532 (83.2311)
2025-06-01 23:35:59,108 - train - INFO - Test: [  70/70]  Time: 0.034 (0.893)  Loss:  2.4277 (2.0273)  Acc@1: 48.5938 (59.2330)  Acc@5: 77.8125 (82.2108)
2025-06-01 23:36:04,046 - train - INFO - Train: 156 [   0/224 (  0%)]  Loss:  3.094831 (3.0948)  Time: 4.632s, 1229.83/s  (4.632s, 1229.83/s)  LR: 4.691e-03  Data: 3.418 (3.418)
2025-06-01 23:36:45,002 - train - INFO - Train: 156 [  50/224 ( 22%)]  Loss:  3.135507 (3.1152)  Time: 0.550s, 10365.27/s  (0.894s, 6372.61/s)  LR: 4.691e-03  Data: 0.000 (0.077)
2025-06-01 23:37:27,056 - train - INFO - Train: 156 [ 100/224 ( 45%)]  Loss:  3.142318 (3.1242)  Time: 1.688s, 3373.64/s  (0.868s, 6564.50/s)  LR: 4.691e-03  Data: 0.000 (0.039)
2025-06-01 23:38:07,819 - train - INFO - Train: 156 [ 150/224 ( 67%)]  Loss:  3.166844 (3.1349)  Time: 0.549s, 10383.41/s  (0.850s, 6698.67/s)  LR: 4.691e-03  Data: 0.000 (0.026)
2025-06-01 23:38:49,253 - train - INFO - Train: 156 [ 200/224 ( 90%)]  Loss:  3.129339 (3.1338)  Time: 1.572s, 3622.75/s  (0.845s, 6741.40/s)  LR: 4.691e-03  Data: 0.000 (0.020)
2025-06-01 23:39:07,104 - train - INFO - Train: 156 [ 223/224 (100%)]  Loss:  3.127275 (3.1327)  Time: 0.546s, 10423.14/s  (0.838s, 6798.25/s)  LR: 4.691e-03  Data: 0.000 (0.018)
2025-06-01 23:39:11,807 - train - INFO - Test: [   0/70]  Time: 4.442 (4.442)  Loss:  1.1396 (1.1396)  Acc@1: 74.8947 (74.8947)  Acc@5: 92.1524 (92.1524)
2025-06-01 23:39:53,948 - train - INFO - Test: [  50/70]  Time: 0.120 (0.913)  Loss:  1.6738 (1.6986)  Acc@1: 65.3617 (62.7048)  Acc@5: 84.0414 (84.9912)
2025-06-01 23:40:10,413 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.0645 (1.7673)  Acc@1: 48.2031 (61.3365)  Acc@5: 81.2500 (83.7755)
2025-06-01 23:40:15,335 - train - INFO - Train: 157 [   0/224 (  0%)]  Loss:  3.132455 (3.1325)  Time: 4.618s, 1233.36/s  (4.618s, 1233.36/s)  LR: 4.639e-03  Data: 3.933 (3.933)
2025-06-01 23:40:56,444 - train - INFO - Train: 157 [  50/224 ( 22%)]  Loss:  3.119823 (3.1261)  Time: 0.550s, 10350.70/s  (0.897s, 6353.45/s)  LR: 4.639e-03  Data: 0.000 (0.346)
2025-06-01 23:41:38,201 - train - INFO - Train: 157 [ 100/224 ( 45%)]  Loss:  3.114501 (3.1223)  Time: 1.501s, 3794.55/s  (0.866s, 6576.56/s)  LR: 4.639e-03  Data: 0.962 (0.316)
2025-06-01 23:42:19,147 - train - INFO - Train: 157 [ 150/224 ( 67%)]  Loss:  3.126749 (3.1234)  Time: 0.556s, 10252.44/s  (0.850s, 6697.48/s)  LR: 4.639e-03  Data: 0.000 (0.300)
2025-06-01 23:43:00,152 - train - INFO - Train: 157 [ 200/224 ( 90%)]  Loss:  3.092245 (3.1172)  Time: 1.443s, 3946.80/s  (0.843s, 6757.54/s)  LR: 4.639e-03  Data: 0.903 (0.292)
2025-06-01 23:43:18,300 - train - INFO - Train: 157 [ 223/224 (100%)]  Loss:  3.146441 (3.1220)  Time: 0.546s, 10430.73/s  (0.837s, 6802.19/s)  LR: 4.639e-03  Data: 0.000 (0.287)
2025-06-01 23:43:23,071 - train - INFO - Test: [   0/70]  Time: 4.521 (4.521)  Loss:  1.3564 (1.3564)  Acc@1: 72.7528 (72.7528)  Acc@5: 90.8181 (90.8181)
2025-06-01 23:44:04,895 - train - INFO - Test: [  50/70]  Time: 0.120 (0.909)  Loss:  1.9287 (1.8426)  Acc@1: 56.3553 (61.0566)  Acc@5: 82.5667 (83.7148)
2025-06-01 23:44:21,453 - train - INFO - Test: [  70/70]  Time: 0.035 (0.886)  Loss:  2.9395 (1.9203)  Acc@1: 41.9531 (59.4135)  Acc@5: 70.3906 (82.3898)
2025-06-01 23:44:26,503 - train - INFO - Train: 158 [   0/224 (  0%)]  Loss:  3.124565 (3.1246)  Time: 4.745s, 1200.48/s  (4.745s, 1200.48/s)  LR: 4.587e-03  Data: 4.194 (4.194)
2025-06-01 23:45:07,186 - train - INFO - Train: 158 [  50/224 ( 22%)]  Loss:  3.147262 (3.1359)  Time: 0.550s, 10357.87/s  (0.891s, 6395.27/s)  LR: 4.587e-03  Data: 0.000 (0.268)
2025-06-01 23:45:48,380 - train - INFO - Train: 158 [ 100/224 ( 45%)]  Loss:  3.132606 (3.1348)  Time: 1.178s, 4835.04/s  (0.858s, 6642.11/s)  LR: 4.587e-03  Data: 0.001 (0.138)
2025-06-01 23:46:29,470 - train - INFO - Train: 158 [ 150/224 ( 67%)]  Loss:  3.148567 (3.1382)  Time: 0.620s, 9187.22/s  (0.846s, 6735.25/s)  LR: 4.587e-03  Data: 0.000 (0.093)
2025-06-01 23:47:10,365 - train - INFO - Train: 158 [ 200/224 ( 90%)]  Loss:  3.156841 (3.1420)  Time: 0.824s, 6916.24/s  (0.839s, 6790.96/s)  LR: 4.587e-03  Data: 0.000 (0.070)
2025-06-01 23:47:29,054 - train - INFO - Train: 158 [ 223/224 (100%)]  Loss:  3.136430 (3.1410)  Time: 0.546s, 10429.72/s  (0.836s, 6812.98/s)  LR: 4.587e-03  Data: 0.000 (0.062)
2025-06-01 23:47:33,950 - train - INFO - Test: [   0/70]  Time: 4.671 (4.671)  Loss:  1.9668 (1.9668)  Acc@1: 64.4312 (64.4312)  Acc@5: 84.7788 (84.7788)
2025-06-01 23:48:15,935 - train - INFO - Test: [  50/70]  Time: 0.120 (0.915)  Loss:  1.6445 (1.8838)  Acc@1: 63.4480 (59.4170)  Acc@5: 85.8146 (82.8583)
2025-06-01 23:48:32,538 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.4609 (1.9610)  Acc@1: 43.9844 (57.8108)  Acc@5: 76.5625 (81.4605)
2025-06-01 23:48:37,609 - train - INFO - Train: 159 [   0/224 (  0%)]  Loss:  3.148559 (3.1486)  Time: 4.758s, 1197.13/s  (4.758s, 1197.13/s)  LR: 4.535e-03  Data: 3.828 (3.828)
2025-06-01 23:49:17,994 - train - INFO - Train: 159 [  50/224 ( 22%)]  Loss:  3.155530 (3.1520)  Time: 0.554s, 10281.47/s  (0.885s, 6435.56/s)  LR: 4.535e-03  Data: 0.000 (0.166)
2025-06-01 23:50:00,229 - train - INFO - Train: 159 [ 100/224 ( 45%)]  Loss:  3.149932 (3.1513)  Time: 1.493s, 3814.82/s  (0.865s, 6584.68/s)  LR: 4.535e-03  Data: 0.000 (0.086)
2025-06-01 23:50:41,060 - train - INFO - Train: 159 [ 150/224 ( 67%)]  Loss:  3.119887 (3.1435)  Time: 0.590s, 9646.60/s  (0.849s, 6709.22/s)  LR: 4.535e-03  Data: 0.000 (0.058)
2025-06-01 23:51:22,472 - train - INFO - Train: 159 [ 200/224 ( 90%)]  Loss:  3.138370 (3.1425)  Time: 1.522s, 3742.56/s  (0.844s, 6750.41/s)  LR: 4.535e-03  Data: 0.000 (0.043)
2025-06-01 23:51:40,455 - train - INFO - Train: 159 [ 223/224 (100%)]  Loss:  3.088732 (3.1335)  Time: 0.544s, 10461.52/s  (0.837s, 6801.77/s)  LR: 4.535e-03  Data: 0.000 (0.039)
2025-06-01 23:51:45,210 - train - INFO - Test: [   0/70]  Time: 4.501 (4.501)  Loss:  1.1279 (1.1279)  Acc@1: 75.5442 (75.5442)  Acc@5: 93.1882 (93.1882)
2025-06-01 23:52:26,688 - train - INFO - Test: [  50/70]  Time: 0.120 (0.902)  Loss:  2.1133 (1.8411)  Acc@1: 56.0218 (61.8232)  Acc@5: 79.5646 (84.3929)
2025-06-01 23:52:43,115 - train - INFO - Test: [  70/70]  Time: 0.034 (0.879)  Loss:  2.6133 (1.9262)  Acc@1: 34.7656 (60.2705)  Acc@5: 75.9375 (82.8008)
2025-06-01 23:52:48,057 - train - INFO - Train: 160 [   0/224 (  0%)]  Loss:  3.137217 (3.1372)  Time: 4.635s, 1229.01/s  (4.635s, 1229.01/s)  LR: 4.483e-03  Data: 4.089 (4.089)
2025-06-01 23:53:29,165 - train - INFO - Train: 160 [  50/224 ( 22%)]  Loss:  3.141059 (3.1391)  Time: 0.549s, 10367.04/s  (0.897s, 6351.01/s)  LR: 4.483e-03  Data: 0.000 (0.145)
2025-06-01 23:54:10,325 - train - INFO - Train: 160 [ 100/224 ( 45%)]  Loss:  3.148429 (3.1422)  Time: 1.558s, 3655.70/s  (0.860s, 6620.38/s)  LR: 4.483e-03  Data: 0.000 (0.073)
2025-06-01 23:54:50,484 - train - INFO - Train: 160 [ 150/224 ( 67%)]  Loss:  3.113201 (3.1350)  Time: 0.551s, 10337.27/s  (0.841s, 6769.45/s)  LR: 4.483e-03  Data: 0.000 (0.049)
2025-06-01 23:55:31,734 - train - INFO - Train: 160 [ 200/224 ( 90%)]  Loss:  3.137136 (3.1354)  Time: 1.360s, 4186.76/s  (0.837s, 6802.56/s)  LR: 4.483e-03  Data: 0.000 (0.037)
2025-06-01 23:55:49,557 - train - INFO - Train: 160 [ 223/224 (100%)]  Loss:  3.160553 (3.1396)  Time: 0.555s, 10262.53/s  (0.831s, 6855.10/s)  LR: 4.483e-03  Data: 0.000 (0.033)
2025-06-01 23:55:54,528 - train - INFO - Test: [   0/70]  Time: 4.732 (4.732)  Loss:  1.1543 (1.1543)  Acc@1: 75.6145 (75.6145)  Acc@5: 90.9937 (90.9937)
2025-06-01 23:56:36,612 - train - INFO - Test: [  50/70]  Time: 0.121 (0.918)  Loss:  1.7842 (1.6646)  Acc@1: 62.1313 (62.4305)  Acc@5: 83.0232 (85.0170)
2025-06-01 23:56:53,022 - train - INFO - Test: [  70/70]  Time: 0.039 (0.891)  Loss:  1.7246 (1.7476)  Acc@1: 51.9531 (60.7968)  Acc@5: 84.9219 (83.5683)
2025-06-01 23:56:57,963 - train - INFO - Train: 161 [   0/224 (  0%)]  Loss:  3.122395 (3.1224)  Time: 4.628s, 1230.90/s  (4.628s, 1230.90/s)  LR: 4.431e-03  Data: 3.811 (3.811)
2025-06-01 23:57:39,469 - train - INFO - Train: 161 [  50/224 ( 22%)]  Loss:  3.168850 (3.1456)  Time: 0.555s, 10262.84/s  (0.905s, 6297.13/s)  LR: 4.431e-03  Data: 0.000 (0.119)
2025-06-01 23:58:20,491 - train - INFO - Train: 161 [ 100/224 ( 45%)]  Loss:  3.168685 (3.1533)  Time: 1.533s, 3716.34/s  (0.863s, 6601.10/s)  LR: 4.431e-03  Data: 0.000 (0.060)
2025-06-01 23:59:01,865 - train - INFO - Train: 161 [ 150/224 ( 67%)]  Loss:  3.116839 (3.1442)  Time: 0.550s, 10349.60/s  (0.851s, 6692.09/s)  LR: 4.431e-03  Data: 0.000 (0.040)
2025-06-01 23:59:43,414 - train - INFO - Train: 161 [ 200/224 ( 90%)]  Loss:  3.165786 (3.1485)  Time: 1.595s, 3570.50/s  (0.846s, 6731.82/s)  LR: 4.431e-03  Data: 0.000 (0.030)
2025-06-02 00:00:01,348 - train - INFO - Train: 161 [ 223/224 (100%)]  Loss:  3.061023 (3.1339)  Time: 0.547s, 10419.36/s  (0.839s, 6786.50/s)  LR: 4.431e-03  Data: 0.000 (0.027)
2025-06-02 00:00:06,165 - train - INFO - Test: [   0/70]  Time: 4.555 (4.555)  Loss:  1.5059 (1.5059)  Acc@1: 77.2999 (77.2999)  Acc@5: 91.0990 (91.0990)
2025-06-02 00:00:48,852 - train - INFO - Test: [  50/70]  Time: 0.120 (0.926)  Loss:  2.0000 (2.0416)  Acc@1: 60.3406 (61.1778)  Acc@5: 82.0751 (83.7488)
2025-06-02 00:01:05,636 - train - INFO - Test: [  70/70]  Time: 0.034 (0.902)  Loss:  2.3516 (2.0886)  Acc@1: 49.0625 (59.6078)  Acc@5: 81.5625 (82.4068)
2025-06-02 00:01:10,573 - train - INFO - Train: 162 [   0/224 (  0%)]  Loss:  3.128094 (3.1281)  Time: 4.639s, 1227.98/s  (4.639s, 1227.98/s)  LR: 4.379e-03  Data: 4.093 (4.093)
2025-06-02 00:01:51,359 - train - INFO - Train: 162 [  50/224 ( 22%)]  Loss:  3.141184 (3.1346)  Time: 0.557s, 10232.78/s  (0.891s, 6395.59/s)  LR: 4.379e-03  Data: 0.000 (0.176)
2025-06-02 00:02:33,153 - train - INFO - Train: 162 [ 100/224 ( 45%)]  Loss:  3.109011 (3.1261)  Time: 1.592s, 3577.13/s  (0.864s, 6596.37/s)  LR: 4.379e-03  Data: 0.000 (0.089)
2025-06-02 00:03:13,615 - train - INFO - Train: 162 [ 150/224 ( 67%)]  Loss:  3.161284 (3.1349)  Time: 0.550s, 10346.98/s  (0.846s, 6736.64/s)  LR: 4.379e-03  Data: 0.000 (0.060)
2025-06-02 00:03:54,727 - train - INFO - Train: 162 [ 200/224 ( 90%)]  Loss:  3.159988 (3.1399)  Time: 1.007s, 5656.62/s  (0.840s, 6783.17/s)  LR: 4.379e-03  Data: 0.000 (0.045)
2025-06-02 00:04:13,054 - train - INFO - Train: 162 [ 223/224 (100%)]  Loss:  3.166601 (3.1444)  Time: 0.546s, 10424.47/s  (0.835s, 6818.95/s)  LR: 4.379e-03  Data: 0.000 (0.040)
2025-06-02 00:04:17,962 - train - INFO - Test: [   0/70]  Time: 4.664 (4.664)  Loss:  1.7109 (1.7109)  Acc@1: 71.3659 (71.3659)  Acc@5: 88.9747 (88.9747)
2025-06-02 00:05:00,199 - train - INFO - Test: [  50/70]  Time: 0.120 (0.920)  Loss:  1.8984 (2.1849)  Acc@1: 62.9565 (59.5106)  Acc@5: 84.9895 (82.7695)
2025-06-02 00:05:16,587 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.9277 (2.2525)  Acc@1: 38.2031 (57.7805)  Acc@5: 70.0000 (81.2190)
2025-06-02 00:05:21,764 - train - INFO - Train: 163 [   0/224 (  0%)]  Loss:  3.143288 (3.1433)  Time: 4.886s, 1165.70/s  (4.886s, 1165.70/s)  LR: 4.327e-03  Data: 4.189 (4.189)
2025-06-02 00:06:01,988 - train - INFO - Train: 163 [  50/224 ( 22%)]  Loss:  3.119879 (3.1316)  Time: 0.554s, 10281.99/s  (0.884s, 6440.06/s)  LR: 4.327e-03  Data: 0.000 (0.283)
2025-06-02 00:06:42,979 - train - INFO - Train: 163 [ 100/224 ( 45%)]  Loss:  3.119205 (3.1275)  Time: 1.465s, 3887.07/s  (0.852s, 6682.01/s)  LR: 4.327e-03  Data: 0.034 (0.174)
2025-06-02 00:07:23,186 - train - INFO - Train: 163 [ 150/224 ( 67%)]  Loss:  3.113256 (3.1239)  Time: 0.551s, 10334.61/s  (0.836s, 6809.83/s)  LR: 4.327e-03  Data: 0.000 (0.119)
2025-06-02 00:08:04,108 - train - INFO - Train: 163 [ 200/224 ( 90%)]  Loss:  3.115909 (3.1223)  Time: 1.533s, 3716.57/s  (0.832s, 6846.51/s)  LR: 4.327e-03  Data: 0.000 (0.090)
2025-06-02 00:08:22,144 - train - INFO - Train: 163 [ 223/224 (100%)]  Loss:  3.170959 (3.1304)  Time: 0.551s, 10335.87/s  (0.827s, 6887.19/s)  LR: 4.327e-03  Data: 0.000 (0.080)
2025-06-02 00:08:26,869 - train - INFO - Test: [   0/70]  Time: 4.490 (4.490)  Loss:  1.3604 (1.3604)  Acc@1: 72.0330 (72.0330)  Acc@5: 91.3097 (91.3097)
2025-06-02 00:09:08,910 - train - INFO - Test: [  50/70]  Time: 0.120 (0.912)  Loss:  1.8457 (1.7615)  Acc@1: 61.6749 (62.9685)  Acc@5: 83.3216 (85.1179)
2025-06-02 00:09:25,442 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.3281 (1.8199)  Acc@1: 46.0938 (61.6090)  Acc@5: 77.5781 (83.8983)
2025-06-02 00:09:30,461 - train - INFO - Train: 164 [   0/224 (  0%)]  Loss:  3.123316 (3.1233)  Time: 4.709s, 1209.63/s  (4.709s, 1209.63/s)  LR: 4.275e-03  Data: 3.410 (3.410)
2025-06-02 00:10:11,784 - train - INFO - Train: 164 [  50/224 ( 22%)]  Loss:  3.113854 (3.1186)  Time: 0.554s, 10273.95/s  (0.903s, 6311.11/s)  LR: 4.275e-03  Data: 0.000 (0.076)
2025-06-02 00:10:54,408 - train - INFO - Train: 164 [ 100/224 ( 45%)]  Loss:  3.134724 (3.1240)  Time: 1.481s, 3846.80/s  (0.878s, 6489.34/s)  LR: 4.275e-03  Data: 0.000 (0.038)
2025-06-02 00:11:34,142 - train - INFO - Train: 164 [ 150/224 ( 67%)]  Loss:  3.134503 (3.1266)  Time: 0.556s, 10251.75/s  (0.850s, 6699.35/s)  LR: 4.275e-03  Data: 0.000 (0.026)
2025-06-02 00:12:15,995 - train - INFO - Train: 164 [ 200/224 ( 90%)]  Loss:  3.148016 (3.1309)  Time: 1.701s, 3348.19/s  (0.847s, 6725.31/s)  LR: 4.275e-03  Data: 0.000 (0.019)
2025-06-02 00:12:34,067 - train - INFO - Train: 164 [ 223/224 (100%)]  Loss:  3.116319 (3.1285)  Time: 0.546s, 10426.19/s  (0.841s, 6775.66/s)  LR: 4.275e-03  Data: 0.000 (0.017)
2025-06-02 00:12:38,904 - train - INFO - Test: [   0/70]  Time: 4.589 (4.589)  Loss:  1.1211 (1.1211)  Acc@1: 75.9831 (75.9831)  Acc@5: 91.9242 (91.9242)
2025-06-02 00:13:21,329 - train - INFO - Test: [  50/70]  Time: 0.120 (0.922)  Loss:  1.8691 (1.6387)  Acc@1: 58.1461 (62.8855)  Acc@5: 81.9874 (85.1764)
2025-06-02 00:13:37,984 - train - INFO - Test: [  70/70]  Time: 0.034 (0.897)  Loss:  1.8574 (1.7223)  Acc@1: 53.7500 (61.4308)  Acc@5: 85.1562 (83.8553)
2025-06-02 00:13:42,974 - train - INFO - Train: 165 [   0/224 (  0%)]  Loss:  3.090389 (3.0904)  Time: 4.672s, 1219.20/s  (4.672s, 1219.20/s)  LR: 4.224e-03  Data: 3.948 (3.948)
2025-06-02 00:14:23,796 - train - INFO - Train: 165 [  50/224 ( 22%)]  Loss:  3.119087 (3.1047)  Time: 0.556s, 10245.14/s  (0.892s, 6385.55/s)  LR: 4.224e-03  Data: 0.000 (0.266)
2025-06-02 00:15:04,995 - train - INFO - Train: 165 [ 100/224 ( 45%)]  Loss:  3.114394 (3.1080)  Time: 1.510s, 3772.98/s  (0.858s, 6636.23/s)  LR: 4.224e-03  Data: 0.000 (0.155)
2025-06-02 00:15:45,417 - train - INFO - Train: 165 [ 150/224 ( 67%)]  Loss:  3.136590 (3.1151)  Time: 0.550s, 10353.32/s  (0.842s, 6766.51/s)  LR: 4.224e-03  Data: 0.000 (0.104)
2025-06-02 00:16:26,142 - train - INFO - Train: 165 [ 200/224 ( 90%)]  Loss:  3.130189 (3.1181)  Time: 0.736s, 7741.74/s  (0.835s, 6821.56/s)  LR: 4.224e-03  Data: 0.000 (0.078)
2025-06-02 00:16:44,867 - train - INFO - Train: 165 [ 223/224 (100%)]  Loss:  3.119067 (3.1183)  Time: 0.547s, 10421.94/s  (0.833s, 6839.17/s)  LR: 4.224e-03  Data: 0.000 (0.070)
2025-06-02 00:16:49,672 - train - INFO - Test: [   0/70]  Time: 4.555 (4.555)  Loss:  1.1992 (1.1992)  Acc@1: 74.5611 (74.5611)  Acc@5: 92.7318 (92.7318)
2025-06-02 00:17:31,521 - train - INFO - Test: [  50/70]  Time: 0.120 (0.910)  Loss:  1.8135 (1.8624)  Acc@1: 63.3251 (60.9674)  Acc@5: 83.4972 (83.7261)
2025-06-02 00:17:47,845 - train - INFO - Test: [  70/70]  Time: 0.034 (0.883)  Loss:  2.5977 (1.9447)  Acc@1: 38.2031 (59.4878)  Acc@5: 70.8594 (82.5328)
2025-06-02 00:17:52,721 - train - INFO - Train: 166 [   0/224 (  0%)]  Loss:  3.151196 (3.1512)  Time: 4.565s, 1247.74/s  (4.565s, 1247.74/s)  LR: 4.172e-03  Data: 4.016 (4.016)
2025-06-02 00:18:33,536 - train - INFO - Train: 166 [  50/224 ( 22%)]  Loss:  3.116739 (3.1340)  Time: 0.552s, 10320.43/s  (0.890s, 6401.65/s)  LR: 4.172e-03  Data: 0.000 (0.114)
2025-06-02 00:19:15,061 - train - INFO - Train: 166 [ 100/224 ( 45%)]  Loss:  3.108282 (3.1254)  Time: 1.570s, 3627.11/s  (0.860s, 6620.03/s)  LR: 4.172e-03  Data: 0.000 (0.058)
2025-06-02 00:19:55,854 - train - INFO - Train: 166 [ 150/224 ( 67%)]  Loss:  3.140032 (3.1291)  Time: 0.547s, 10404.23/s  (0.846s, 6735.64/s)  LR: 4.172e-03  Data: 0.000 (0.039)
2025-06-02 00:20:37,066 - train - INFO - Train: 166 [ 200/224 ( 90%)]  Loss:  3.136129 (3.1305)  Time: 1.408s, 4046.76/s  (0.840s, 6778.42/s)  LR: 4.172e-03  Data: 0.000 (0.029)
2025-06-02 00:20:55,351 - train - INFO - Train: 166 [ 223/224 (100%)]  Loss:  3.152481 (3.1341)  Time: 0.547s, 10411.22/s  (0.836s, 6816.16/s)  LR: 4.172e-03  Data: 0.000 (0.026)
2025-06-02 00:21:00,173 - train - INFO - Test: [   0/70]  Time: 4.580 (4.580)  Loss:  1.1094 (1.1094)  Acc@1: 74.3855 (74.3855)  Acc@5: 92.3982 (92.3982)
2025-06-02 00:21:42,188 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  1.9854 (1.7617)  Acc@1: 55.9340 (60.5158)  Acc@5: 80.9340 (83.4876)
2025-06-02 00:21:58,366 - train - INFO - Test: [  70/70]  Time: 0.034 (0.884)  Loss:  2.0293 (1.8410)  Acc@1: 52.3438 (59.1040)  Acc@5: 81.2500 (82.2555)
2025-06-02 00:22:03,454 - train - INFO - Train: 167 [   0/224 (  0%)]  Loss:  3.174109 (3.1741)  Time: 4.777s, 1192.42/s  (4.777s, 1192.42/s)  LR: 4.120e-03  Data: 4.229 (4.229)
2025-06-02 00:22:45,318 - train - INFO - Train: 167 [  50/224 ( 22%)]  Loss:  3.107071 (3.1406)  Time: 0.735s, 7746.67/s  (0.915s, 6228.50/s)  LR: 4.120e-03  Data: 0.000 (0.305)
2025-06-02 00:23:27,571 - train - INFO - Train: 167 [ 100/224 ( 45%)]  Loss:  3.128099 (3.1364)  Time: 1.585s, 3592.79/s  (0.880s, 6471.88/s)  LR: 4.120e-03  Data: 0.000 (0.154)
2025-06-02 00:24:08,133 - train - INFO - Train: 167 [ 150/224 ( 67%)]  Loss:  3.127829 (3.1343)  Time: 0.555s, 10268.47/s  (0.857s, 6644.12/s)  LR: 4.120e-03  Data: 0.000 (0.103)
2025-06-02 00:24:50,152 - train - INFO - Train: 167 [ 200/224 ( 90%)]  Loss:  3.132565 (3.1339)  Time: 1.589s, 3585.09/s  (0.853s, 6676.95/s)  LR: 4.120e-03  Data: 0.000 (0.078)
2025-06-02 00:25:08,372 - train - INFO - Train: 167 [ 223/224 (100%)]  Loss:  3.079155 (3.1248)  Time: 0.546s, 10441.67/s  (0.847s, 6726.28/s)  LR: 4.120e-03  Data: 0.000 (0.070)
2025-06-02 00:25:13,548 - train - INFO - Test: [   0/70]  Time: 4.932 (4.932)  Loss:  1.2422 (1.2422)  Acc@1: 75.7900 (75.7900)  Acc@5: 91.0288 (91.0288)
2025-06-02 00:25:56,145 - train - INFO - Test: [  50/70]  Time: 0.120 (0.932)  Loss:  1.7148 (1.6309)  Acc@1: 62.5000 (64.2560)  Acc@5: 83.4621 (85.9396)
2025-06-02 00:26:12,673 - train - INFO - Test: [  70/70]  Time: 0.034 (0.902)  Loss:  2.7227 (1.7303)  Acc@1: 36.4062 (62.3325)  Acc@5: 68.3594 (84.3145)
2025-06-02 00:26:17,741 - train - INFO - Train: 168 [   0/224 (  0%)]  Loss:  3.150198 (3.1502)  Time: 4.764s, 1195.70/s  (4.764s, 1195.70/s)  LR: 4.069e-03  Data: 4.212 (4.212)
2025-06-02 00:26:59,030 - train - INFO - Train: 168 [  50/224 ( 22%)]  Loss:  3.131680 (3.1409)  Time: 0.548s, 10391.06/s  (0.903s, 6308.07/s)  LR: 4.069e-03  Data: 0.000 (0.184)
2025-06-02 00:27:40,613 - train - INFO - Train: 168 [ 100/224 ( 45%)]  Loss:  3.126737 (3.1362)  Time: 1.224s, 4653.38/s  (0.868s, 6564.83/s)  LR: 4.069e-03  Data: 0.000 (0.093)
2025-06-02 00:28:21,553 - train - INFO - Train: 168 [ 150/224 ( 67%)]  Loss:  3.110162 (3.1297)  Time: 0.699s, 8143.58/s  (0.851s, 6689.61/s)  LR: 4.069e-03  Data: 0.000 (0.062)
2025-06-02 00:29:02,942 - train - INFO - Train: 168 [ 200/224 ( 90%)]  Loss:  3.145840 (3.1329)  Time: 1.450s, 3929.06/s  (0.846s, 6736.25/s)  LR: 4.069e-03  Data: 0.000 (0.047)
2025-06-02 00:29:20,869 - train - INFO - Train: 168 [ 223/224 (100%)]  Loss:  3.133821 (3.1331)  Time: 0.545s, 10456.46/s  (0.839s, 6790.87/s)  LR: 4.069e-03  Data: 0.000 (0.042)
2025-06-02 00:29:25,563 - train - INFO - Test: [   0/70]  Time: 4.446 (4.446)  Loss:  1.5830 (1.5830)  Acc@1: 73.2795 (73.2795)  Acc@5: 90.1861 (90.1861)
2025-06-02 00:30:07,815 - train - INFO - Test: [  50/70]  Time: 0.120 (0.916)  Loss:  2.0508 (1.9566)  Acc@1: 60.9024 (62.4298)  Acc@5: 82.9705 (85.0232)
2025-06-02 00:30:24,503 - train - INFO - Test: [  70/70]  Time: 0.034 (0.893)  Loss:  2.8652 (2.0262)  Acc@1: 33.0469 (60.8470)  Acc@5: 70.5469 (83.6025)
2025-06-02 00:30:29,396 - train - INFO - Train: 169 [   0/224 (  0%)]  Loss:  3.141767 (3.1418)  Time: 4.532s, 1256.72/s  (4.532s, 1256.72/s)  LR: 4.018e-03  Data: 3.989 (3.989)
2025-06-02 00:31:10,213 - train - INFO - Train: 169 [  50/224 ( 22%)]  Loss:  3.107794 (3.1248)  Time: 0.548s, 10398.42/s  (0.889s, 6406.10/s)  LR: 4.018e-03  Data: 0.000 (0.301)
2025-06-02 00:31:51,546 - train - INFO - Train: 169 [ 100/224 ( 45%)]  Loss:  3.148464 (3.1327)  Time: 1.500s, 3796.88/s  (0.858s, 6637.17/s)  LR: 4.018e-03  Data: 0.482 (0.245)
2025-06-02 00:32:32,043 - train - INFO - Train: 169 [ 150/224 ( 67%)]  Loss:  3.166015 (3.1410)  Time: 0.549s, 10369.51/s  (0.842s, 6763.20/s)  LR: 4.018e-03  Data: 0.000 (0.192)
2025-06-02 00:33:13,433 - train - INFO - Train: 169 [ 200/224 ( 90%)]  Loss:  3.127095 (3.1382)  Time: 0.830s, 6865.36/s  (0.839s, 6792.14/s)  LR: 4.018e-03  Data: 0.000 (0.148)
2025-06-02 00:33:33,829 - train - INFO - Train: 169 [ 223/224 (100%)]  Loss:  3.128300 (3.1366)  Time: 3.044s, 1871.06/s  (0.844s, 6752.36/s)  LR: 4.018e-03  Data: 0.000 (0.133)
2025-06-02 00:33:38,584 - train - INFO - Test: [   0/70]  Time: 4.501 (4.501)  Loss:  1.3428 (1.3428)  Acc@1: 73.4024 (73.4024)  Acc@5: 92.1348 (92.1348)
2025-06-02 00:34:20,502 - train - INFO - Test: [  50/70]  Time: 0.120 (0.910)  Loss:  1.8789 (1.7808)  Acc@1: 61.5344 (62.7540)  Acc@5: 82.8125 (85.1877)
2025-06-02 00:34:36,931 - train - INFO - Test: [  70/70]  Time: 0.034 (0.885)  Loss:  1.7598 (1.8483)  Acc@1: 54.5312 (61.1328)  Acc@5: 84.4531 (83.7478)
2025-06-02 00:34:41,802 - train - INFO - Train: 170 [   0/224 (  0%)]  Loss:  3.161086 (3.1611)  Time: 4.564s, 1247.94/s  (4.564s, 1247.94/s)  LR: 3.966e-03  Data: 4.009 (4.009)
2025-06-02 00:35:22,635 - train - INFO - Train: 170 [  50/224 ( 22%)]  Loss:  3.143015 (3.1521)  Time: 0.550s, 10363.87/s  (0.890s, 6399.15/s)  LR: 3.966e-03  Data: 0.000 (0.265)
2025-06-02 00:36:04,564 - train - INFO - Train: 170 [ 100/224 ( 45%)]  Loss:  3.110138 (3.1381)  Time: 1.346s, 4232.45/s  (0.865s, 6588.13/s)  LR: 3.966e-03  Data: 0.000 (0.134)
2025-06-02 00:36:45,408 - train - INFO - Train: 170 [ 150/224 ( 67%)]  Loss:  3.128699 (3.1357)  Time: 0.551s, 10340.11/s  (0.849s, 6710.82/s)  LR: 3.966e-03  Data: 0.000 (0.090)
2025-06-02 00:37:26,482 - train - INFO - Train: 170 [ 200/224 ( 90%)]  Loss:  3.174751 (3.1435)  Time: 1.796s, 3171.62/s  (0.842s, 6765.03/s)  LR: 3.966e-03  Data: 0.000 (0.067)
2025-06-02 00:37:44,674 - train - INFO - Train: 170 [ 223/224 (100%)]  Loss:  3.163321 (3.1468)  Time: 0.550s, 10351.26/s  (0.837s, 6807.45/s)  LR: 3.966e-03  Data: 0.000 (0.061)
2025-06-02 00:37:49,421 - train - INFO - Test: [   0/70]  Time: 4.504 (4.504)  Loss:  1.1934 (1.1934)  Acc@1: 73.7535 (73.7535)  Acc@5: 90.9059 (90.9059)
2025-06-02 00:38:31,130 - train - INFO - Test: [  50/70]  Time: 0.120 (0.906)  Loss:  1.8115 (1.6883)  Acc@1: 63.0969 (62.1905)  Acc@5: 82.0927 (84.7815)
2025-06-02 00:38:47,652 - train - INFO - Test: [  70/70]  Time: 0.034 (0.884)  Loss:  2.8340 (1.8024)  Acc@1: 35.5469 (60.0818)  Acc@5: 66.5625 (82.9420)
2025-06-02 00:38:52,697 - train - INFO - Train: 171 [   0/224 (  0%)]  Loss:  3.137286 (3.1373)  Time: 4.731s, 1203.91/s  (4.731s, 1203.91/s)  LR: 3.915e-03  Data: 3.834 (3.834)
2025-06-02 00:39:34,632 - train - INFO - Train: 171 [  50/224 ( 22%)]  Loss:  3.105395 (3.1213)  Time: 0.550s, 10349.71/s  (0.915s, 6225.43/s)  LR: 3.915e-03  Data: 0.000 (0.111)
2025-06-02 00:40:17,297 - train - INFO - Train: 171 [ 100/224 ( 45%)]  Loss:  3.133472 (3.1254)  Time: 1.609s, 3539.26/s  (0.884s, 6440.43/s)  LR: 3.915e-03  Data: 0.000 (0.056)
2025-06-02 00:40:58,326 - train - INFO - Train: 171 [ 150/224 ( 67%)]  Loss:  3.148921 (3.1313)  Time: 0.549s, 10369.76/s  (0.863s, 6598.26/s)  LR: 3.915e-03  Data: 0.000 (0.038)
2025-06-02 00:41:40,504 - train - INFO - Train: 171 [ 200/224 ( 90%)]  Loss:  3.167259 (3.1385)  Time: 1.671s, 3408.49/s  (0.858s, 6636.05/s)  LR: 3.915e-03  Data: 0.000 (0.028)
2025-06-02 00:41:58,932 - train - INFO - Train: 171 [ 223/224 (100%)]  Loss:  3.133679 (3.1377)  Time: 0.545s, 10444.67/s  (0.852s, 6681.76/s)  LR: 3.915e-03  Data: 0.000 (0.025)
2025-06-02 00:42:03,789 - train - INFO - Test: [   0/70]  Time: 4.624 (4.624)  Loss:  1.2852 (1.2852)  Acc@1: 70.0667 (70.0667)  Acc@5: 89.0976 (89.0976)
2025-06-02 00:42:45,787 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  1.6924 (1.5858)  Acc@1: 60.0773 (62.8146)  Acc@5: 83.6025 (85.0225)
2025-06-02 00:43:01,975 - train - INFO - Test: [  70/70]  Time: 0.034 (0.885)  Loss:  2.3652 (1.6654)  Acc@1: 39.1406 (61.3515)  Acc@5: 75.1562 (83.7538)
2025-06-02 00:43:07,001 - train - INFO - Train: 172 [   0/224 (  0%)]  Loss:  3.103292 (3.1033)  Time: 4.716s, 1207.70/s  (4.716s, 1207.70/s)  LR: 3.864e-03  Data: 3.660 (3.660)
2025-06-02 00:43:48,168 - train - INFO - Train: 172 [  50/224 ( 22%)]  Loss:  3.080583 (3.0919)  Time: 0.549s, 10381.64/s  (0.900s, 6331.32/s)  LR: 3.864e-03  Data: 0.000 (0.085)
2025-06-02 00:44:30,013 - train - INFO - Train: 172 [ 100/224 ( 45%)]  Loss:  3.148336 (3.1107)  Time: 1.650s, 3451.76/s  (0.869s, 6557.87/s)  LR: 3.864e-03  Data: 0.000 (0.043)
2025-06-02 00:45:10,477 - train - INFO - Train: 172 [ 150/224 ( 67%)]  Loss:  3.161629 (3.1235)  Time: 0.752s, 7572.08/s  (0.849s, 6709.58/s)  LR: 3.864e-03  Data: 0.000 (0.029)
2025-06-02 00:45:51,563 - train - INFO - Train: 172 [ 200/224 ( 90%)]  Loss:  3.137943 (3.1264)  Time: 1.462s, 3894.98/s  (0.842s, 6763.60/s)  LR: 3.864e-03  Data: 0.000 (0.022)
2025-06-02 00:46:09,705 - train - INFO - Train: 172 [ 223/224 (100%)]  Loss:  3.130542 (3.1271)  Time: 0.547s, 10408.59/s  (0.837s, 6807.94/s)  LR: 3.864e-03  Data: 0.000 (0.020)
2025-06-02 00:46:14,571 - train - INFO - Test: [   0/70]  Time: 4.622 (4.622)  Loss:  1.7969 (1.7969)  Acc@1: 71.9277 (71.9277)  Acc@5: 89.4663 (89.4663)
2025-06-02 00:46:56,398 - train - INFO - Test: [  50/70]  Time: 0.120 (0.911)  Loss:  2.2578 (2.2539)  Acc@1: 60.7619 (60.4476)  Acc@5: 80.6882 (83.3684)
2025-06-02 00:47:13,000 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.7520 (2.3041)  Acc@1: 44.9219 (58.8898)  Acc@5: 75.0781 (81.9915)
2025-06-02 00:47:17,977 - train - INFO - Train: 173 [   0/224 (  0%)]  Loss:  3.147085 (3.1471)  Time: 4.669s, 1220.08/s  (4.669s, 1220.08/s)  LR: 3.814e-03  Data: 4.117 (4.117)
2025-06-02 00:47:59,223 - train - INFO - Train: 173 [  50/224 ( 22%)]  Loss:  3.151858 (3.1495)  Time: 0.571s, 9973.88/s  (0.900s, 6327.07/s)  LR: 3.814e-03  Data: 0.000 (0.229)
2025-06-02 00:48:40,964 - train - INFO - Train: 173 [ 100/224 ( 45%)]  Loss:  3.158619 (3.1525)  Time: 1.654s, 3444.01/s  (0.868s, 6563.36/s)  LR: 3.814e-03  Data: 0.000 (0.116)
2025-06-02 00:49:21,444 - train - INFO - Train: 173 [ 150/224 ( 67%)]  Loss:  3.143161 (3.1502)  Time: 0.551s, 10340.22/s  (0.849s, 6712.57/s)  LR: 3.814e-03  Data: 0.000 (0.078)
2025-06-02 00:50:02,725 - train - INFO - Train: 173 [ 200/224 ( 90%)]  Loss:  3.095505 (3.1392)  Time: 0.952s, 5982.46/s  (0.843s, 6758.11/s)  LR: 3.814e-03  Data: 0.000 (0.058)
2025-06-02 00:50:21,119 - train - INFO - Train: 173 [ 223/224 (100%)]  Loss:  3.147209 (3.1406)  Time: 0.545s, 10455.58/s  (0.838s, 6793.81/s)  LR: 3.814e-03  Data: 0.000 (0.052)
2025-06-02 00:50:26,054 - train - INFO - Test: [   0/70]  Time: 4.698 (4.698)  Loss:  1.3320 (1.3320)  Acc@1: 73.3146 (73.3146)  Acc@5: 91.3097 (91.3097)
2025-06-02 00:51:08,336 - train - INFO - Test: [  50/70]  Time: 0.120 (0.921)  Loss:  1.8994 (1.9508)  Acc@1: 59.2346 (59.4259)  Acc@5: 82.3034 (82.6225)
2025-06-02 00:51:24,955 - train - INFO - Test: [  70/70]  Time: 0.034 (0.896)  Loss:  2.3340 (1.9886)  Acc@1: 37.5781 (58.4098)  Acc@5: 79.8438 (81.6960)
2025-06-02 00:51:30,118 - train - INFO - Train: 174 [   0/224 (  0%)]  Loss:  3.130288 (3.1303)  Time: 4.853s, 1173.65/s  (4.853s, 1173.65/s)  LR: 3.763e-03  Data: 3.927 (3.927)
2025-06-02 00:52:11,260 - train - INFO - Train: 174 [  50/224 ( 22%)]  Loss:  3.127822 (3.1291)  Time: 0.550s, 10350.81/s  (0.902s, 6316.01/s)  LR: 3.763e-03  Data: 0.000 (0.111)
2025-06-02 00:52:53,191 - train - INFO - Train: 174 [ 100/224 ( 45%)]  Loss:  3.178056 (3.1454)  Time: 1.526s, 3733.82/s  (0.871s, 6543.15/s)  LR: 3.763e-03  Data: 0.000 (0.056)
2025-06-02 00:53:33,691 - train - INFO - Train: 174 [ 150/224 ( 67%)]  Loss:  3.136292 (3.1431)  Time: 0.551s, 10328.86/s  (0.850s, 6697.41/s)  LR: 3.763e-03  Data: 0.000 (0.038)
2025-06-02 00:54:15,474 - train - INFO - Train: 174 [ 200/224 ( 90%)]  Loss:  3.167025 (3.1479)  Time: 1.621s, 3514.22/s  (0.847s, 6726.59/s)  LR: 3.763e-03  Data: 0.000 (0.028)
2025-06-02 00:54:33,614 - train - INFO - Train: 174 [ 223/224 (100%)]  Loss:  3.092478 (3.1387)  Time: 0.546s, 10425.56/s  (0.841s, 6774.35/s)  LR: 3.763e-03  Data: 0.000 (0.025)
2025-06-02 00:54:38,485 - train - INFO - Test: [   0/70]  Time: 4.616 (4.616)  Loss:  1.0986 (1.0986)  Acc@1: 76.4747 (76.4747)  Acc@5: 93.0478 (93.0478)
2025-06-02 00:55:20,640 - train - INFO - Test: [  50/70]  Time: 0.120 (0.917)  Loss:  1.9307 (1.7297)  Acc@1: 60.9551 (61.6215)  Acc@5: 80.1264 (84.2397)
2025-06-02 00:55:37,306 - train - INFO - Test: [  70/70]  Time: 0.034 (0.893)  Loss:  2.2676 (1.8179)  Acc@1: 43.8281 (60.1940)  Acc@5: 75.5469 (82.7485)
2025-06-02 00:55:42,456 - train - INFO - Train: 175 [   0/224 (  0%)]  Loss:  3.110954 (3.1110)  Time: 4.837s, 1177.50/s  (4.837s, 1177.50/s)  LR: 3.712e-03  Data: 3.993 (3.993)
2025-06-02 00:56:22,974 - train - INFO - Train: 175 [  50/224 ( 22%)]  Loss:  3.112979 (3.1120)  Time: 0.549s, 10378.06/s  (0.889s, 6405.19/s)  LR: 3.712e-03  Data: 0.000 (0.167)
2025-06-02 00:57:05,557 - train - INFO - Train: 175 [ 100/224 ( 45%)]  Loss:  3.141650 (3.1219)  Time: 1.634s, 3486.18/s  (0.871s, 6542.39/s)  LR: 3.712e-03  Data: 0.000 (0.084)
2025-06-02 00:57:46,255 - train - INFO - Train: 175 [ 150/224 ( 67%)]  Loss:  3.145762 (3.1278)  Time: 0.551s, 10343.76/s  (0.852s, 6686.61/s)  LR: 3.712e-03  Data: 0.000 (0.056)
2025-06-02 00:58:27,987 - train - INFO - Train: 175 [ 200/224 ( 90%)]  Loss:  3.125334 (3.1273)  Time: 1.420s, 4010.93/s  (0.848s, 6720.45/s)  LR: 3.712e-03  Data: 0.000 (0.042)
2025-06-02 00:58:46,295 - train - INFO - Train: 175 [ 223/224 (100%)]  Loss:  3.131054 (3.1280)  Time: 0.813s, 7003.45/s  (0.842s, 6762.76/s)  LR: 3.712e-03  Data: 0.000 (0.038)
2025-06-02 00:58:51,045 - train - INFO - Test: [   0/70]  Time: 4.498 (4.498)  Loss:  1.4209 (1.4209)  Acc@1: 73.0337 (73.0337)  Acc@5: 90.0632 (90.0632)
2025-06-02 00:59:33,022 - train - INFO - Test: [  50/70]  Time: 0.154 (0.911)  Loss:  2.1074 (1.9024)  Acc@1: 58.0583 (59.5320)  Acc@5: 80.5478 (82.7684)
2025-06-02 00:59:49,645 - train - INFO - Test: [  70/70]  Time: 0.039 (0.889)  Loss:  3.0801 (2.0014)  Acc@1: 29.3750 (58.0388)  Acc@5: 65.9375 (81.2758)
2025-06-02 00:59:54,589 - train - INFO - Train: 176 [   0/224 (  0%)]  Loss:  3.138824 (3.1388)  Time: 4.647s, 1225.63/s  (4.647s, 1225.63/s)  LR: 3.662e-03  Data: 4.102 (4.102)
2025-06-02 01:00:35,860 - train - INFO - Train: 176 [  50/224 ( 22%)]  Loss:  3.104165 (3.1215)  Time: 0.549s, 10367.97/s  (0.900s, 6326.69/s)  LR: 3.662e-03  Data: 0.000 (0.306)
2025-06-02 01:01:18,098 - train - INFO - Train: 176 [ 100/224 ( 45%)]  Loss:  3.160978 (3.1347)  Time: 1.699s, 3352.14/s  (0.873s, 6526.21/s)  LR: 3.662e-03  Data: 0.000 (0.168)
2025-06-02 01:01:58,898 - train - INFO - Train: 176 [ 150/224 ( 67%)]  Loss:  3.064173 (3.1170)  Time: 0.551s, 10336.60/s  (0.854s, 6670.04/s)  LR: 3.662e-03  Data: 0.000 (0.112)
2025-06-02 01:02:41,196 - train - INFO - Train: 176 [ 200/224 ( 90%)]  Loss:  3.110106 (3.1156)  Time: 1.556s, 3661.11/s  (0.852s, 6685.68/s)  LR: 3.662e-03  Data: 0.000 (0.084)
2025-06-02 01:02:59,097 - train - INFO - Train: 176 [ 223/224 (100%)]  Loss:  3.191156 (3.1282)  Time: 0.542s, 10500.43/s  (0.844s, 6745.66/s)  LR: 3.662e-03  Data: 0.000 (0.076)
2025-06-02 01:03:04,054 - train - INFO - Test: [   0/70]  Time: 4.717 (4.717)  Loss:  1.1836 (1.1836)  Acc@1: 75.5969 (75.5969)  Acc@5: 91.0815 (91.0815)
2025-06-02 01:03:46,216 - train - INFO - Test: [  50/70]  Time: 0.120 (0.919)  Loss:  1.6260 (1.6705)  Acc@1: 62.1489 (62.8105)  Acc@5: 84.6032 (84.9974)
2025-06-02 01:04:02,782 - train - INFO - Test: [  70/70]  Time: 0.034 (0.894)  Loss:  2.0977 (1.7464)  Acc@1: 51.1719 (61.2018)  Acc@5: 80.4688 (83.6525)
2025-06-02 01:04:07,876 - train - INFO - Train: 177 [   0/224 (  0%)]  Loss:  3.166566 (3.1666)  Time: 4.778s, 1192.06/s  (4.778s, 1192.06/s)  LR: 3.611e-03  Data: 3.789 (3.789)
2025-06-02 01:04:48,968 - train - INFO - Train: 177 [  50/224 ( 22%)]  Loss:  3.149094 (3.1578)  Time: 0.553s, 10300.95/s  (0.899s, 6333.46/s)  LR: 3.611e-03  Data: 0.000 (0.169)
2025-06-02 01:05:30,719 - train - INFO - Train: 177 [ 100/224 ( 45%)]  Loss:  3.104742 (3.1401)  Time: 1.677s, 3397.07/s  (0.867s, 6566.07/s)  LR: 3.611e-03  Data: 0.000 (0.086)
2025-06-02 01:06:11,331 - train - INFO - Train: 177 [ 150/224 ( 67%)]  Loss:  3.109055 (3.1324)  Time: 0.550s, 10350.30/s  (0.849s, 6707.53/s)  LR: 3.611e-03  Data: 0.000 (0.057)
2025-06-02 01:06:53,003 - train - INFO - Train: 177 [ 200/224 ( 90%)]  Loss:  3.151509 (3.1362)  Time: 1.608s, 3541.20/s  (0.845s, 6738.74/s)  LR: 3.611e-03  Data: 0.000 (0.043)
2025-06-02 01:07:10,634 - train - INFO - Train: 177 [ 223/224 (100%)]  Loss:  3.131020 (3.1353)  Time: 0.545s, 10450.38/s  (0.837s, 6803.80/s)  LR: 3.611e-03  Data: 0.000 (0.039)
2025-06-02 01:07:15,505 - train - INFO - Test: [   0/70]  Time: 4.617 (4.617)  Loss:  1.1357 (1.1357)  Acc@1: 72.7353 (72.7353)  Acc@5: 91.7310 (91.7310)
2025-06-02 01:07:57,016 - train - INFO - Test: [  50/70]  Time: 0.120 (0.904)  Loss:  1.9121 (1.7501)  Acc@1: 56.5836 (60.4614)  Acc@5: 80.0913 (83.4569)
2025-06-02 01:08:13,616 - train - INFO - Test: [  70/70]  Time: 0.034 (0.883)  Loss:  2.0898 (1.8018)  Acc@1: 49.4531 (59.3295)  Acc@5: 78.6719 (82.4840)
2025-06-02 01:08:18,711 - train - INFO - Train: 178 [   0/224 (  0%)]  Loss:  3.146649 (3.1466)  Time: 4.784s, 1190.55/s  (4.784s, 1190.55/s)  LR: 3.561e-03  Data: 3.968 (3.968)
2025-06-02 01:09:01,067 - train - INFO - Train: 178 [  50/224 ( 22%)]  Loss:  3.138149 (3.1424)  Time: 0.549s, 10381.93/s  (0.924s, 6162.71/s)  LR: 3.561e-03  Data: 0.000 (0.098)
2025-06-02 01:09:43,501 - train - INFO - Train: 178 [ 100/224 ( 45%)]  Loss:  3.158864 (3.1479)  Time: 1.590s, 3581.86/s  (0.887s, 6422.86/s)  LR: 3.561e-03  Data: 0.000 (0.049)
2025-06-02 01:10:24,316 - train - INFO - Train: 178 [ 150/224 ( 67%)]  Loss:  3.138709 (3.1456)  Time: 0.549s, 10370.52/s  (0.863s, 6596.73/s)  LR: 3.561e-03  Data: 0.000 (0.033)
2025-06-02 01:11:06,103 - train - INFO - Train: 178 [ 200/224 ( 90%)]  Loss:  3.110110 (3.1385)  Time: 1.550s, 3674.58/s  (0.857s, 6649.89/s)  LR: 3.561e-03  Data: 0.000 (0.025)
2025-06-02 01:11:24,185 - train - INFO - Train: 178 [ 223/224 (100%)]  Loss:  3.132611 (3.1375)  Time: 0.545s, 10451.17/s  (0.849s, 6706.55/s)  LR: 3.561e-03  Data: 0.000 (0.022)
2025-06-02 01:11:29,147 - train - INFO - Test: [   0/70]  Time: 4.723 (4.723)  Loss:  1.4004 (1.4004)  Acc@1: 72.5070 (72.5070)  Acc@5: 90.8883 (90.8883)
2025-06-02 01:12:11,141 - train - INFO - Test: [  50/70]  Time: 0.120 (0.916)  Loss:  1.7988 (1.6999)  Acc@1: 63.0267 (63.2993)  Acc@5: 82.5141 (85.3113)
2025-06-02 01:12:27,528 - train - INFO - Test: [  70/70]  Time: 0.034 (0.889)  Loss:  2.4062 (1.7636)  Acc@1: 41.4844 (61.8250)  Acc@5: 75.2344 (84.0575)
2025-06-02 01:12:32,496 - train - INFO - Train: 179 [   0/224 (  0%)]  Loss:  3.114687 (3.1147)  Time: 4.677s, 1218.00/s  (4.677s, 1218.00/s)  LR: 3.511e-03  Data: 3.808 (3.808)
2025-06-02 01:13:14,182 - train - INFO - Train: 179 [  50/224 ( 22%)]  Loss:  3.166444 (3.1406)  Time: 0.551s, 10341.06/s  (0.909s, 6265.96/s)  LR: 3.511e-03  Data: 0.000 (0.096)
2025-06-02 01:13:55,012 - train - INFO - Train: 179 [ 100/224 ( 45%)]  Loss:  3.161439 (3.1475)  Time: 1.502s, 3792.16/s  (0.863s, 6598.15/s)  LR: 3.511e-03  Data: 0.000 (0.049)
2025-06-02 01:14:35,078 - train - INFO - Train: 179 [ 150/224 ( 67%)]  Loss:  3.150316 (3.1482)  Time: 0.553s, 10293.99/s  (0.843s, 6758.95/s)  LR: 3.511e-03  Data: 0.000 (0.033)
2025-06-02 01:15:16,410 - train - INFO - Train: 179 [ 200/224 ( 90%)]  Loss:  3.097343 (3.1380)  Time: 1.489s, 3824.29/s  (0.839s, 6791.25/s)  LR: 3.511e-03  Data: 0.000 (0.025)
2025-06-02 01:15:34,524 - train - INFO - Train: 179 [ 223/224 (100%)]  Loss:  3.125422 (3.1359)  Time: 0.546s, 10441.35/s  (0.833s, 6834.07/s)  LR: 3.511e-03  Data: 0.000 (0.022)
2025-06-02 01:15:39,359 - train - INFO - Test: [   0/70]  Time: 4.593 (4.593)  Loss:  1.3096 (1.3096)  Acc@1: 76.7732 (76.7732)  Acc@5: 92.3982 (92.3982)
2025-06-02 01:16:21,586 - train - INFO - Test: [  50/70]  Time: 0.120 (0.918)  Loss:  1.9785 (1.8552)  Acc@1: 59.9368 (62.1189)  Acc@5: 80.4775 (84.7382)
2025-06-02 01:16:38,405 - train - INFO - Test: [  70/70]  Time: 0.034 (0.896)  Loss:  2.2930 (1.9398)  Acc@1: 45.3906 (60.4240)  Acc@5: 79.0625 (83.1285)
2025-06-02 01:16:43,592 - train - INFO - Train: 180 [   0/224 (  0%)]  Loss:  3.153182 (3.1532)  Time: 4.877s, 1167.96/s  (4.877s, 1167.96/s)  LR: 3.461e-03  Data: 4.133 (4.133)
2025-06-02 01:17:24,747 - train - INFO - Train: 180 [  50/224 ( 22%)]  Loss:  3.165365 (3.1593)  Time: 0.551s, 10345.36/s  (0.903s, 6310.84/s)  LR: 3.461e-03  Data: 0.000 (0.138)
2025-06-02 01:18:07,482 - train - INFO - Train: 180 [ 100/224 ( 45%)]  Loss:  3.175784 (3.1648)  Time: 1.930s, 2951.85/s  (0.879s, 6481.11/s)  LR: 3.461e-03  Data: 0.000 (0.070)
2025-06-02 01:18:48,121 - train - INFO - Train: 180 [ 150/224 ( 67%)]  Loss:  3.098449 (3.1482)  Time: 0.551s, 10329.57/s  (0.857s, 6646.70/s)  LR: 3.461e-03  Data: 0.000 (0.047)
2025-06-02 01:19:29,873 - train - INFO - Train: 180 [ 200/224 ( 90%)]  Loss:  3.147667 (3.1481)  Time: 1.249s, 4561.29/s  (0.851s, 6689.37/s)  LR: 3.461e-03  Data: 0.000 (0.035)
2025-06-02 01:19:48,148 - train - INFO - Train: 180 [ 223/224 (100%)]  Loss:  3.191988 (3.1554)  Time: 0.546s, 10437.03/s  (0.846s, 6735.79/s)  LR: 3.461e-03  Data: 0.000 (0.032)
2025-06-02 01:19:52,807 - train - INFO - Test: [   0/70]  Time: 4.405 (4.405)  Loss:  1.3809 (1.3809)  Acc@1: 74.4382 (74.4382)  Acc@5: 93.1180 (93.1180)
2025-06-02 01:20:35,316 - train - INFO - Test: [  50/70]  Time: 0.121 (0.920)  Loss:  2.1465 (1.9562)  Acc@1: 57.5843 (60.9826)  Acc@5: 79.2135 (84.1678)
2025-06-02 01:20:52,226 - train - INFO - Test: [  70/70]  Time: 0.035 (0.899)  Loss:  2.4355 (2.0039)  Acc@1: 45.0000 (59.8300)  Acc@5: 75.0000 (83.0960)
2025-06-02 01:20:57,565 - train - INFO - Train: 181 [   0/224 (  0%)]  Loss:  3.123794 (3.1238)  Time: 5.035s, 1131.19/s  (5.035s, 1131.19/s)  LR: 3.412e-03  Data: 3.949 (3.949)
2025-06-02 01:21:38,637 - train - INFO - Train: 181 [  50/224 ( 22%)]  Loss:  3.187648 (3.1557)  Time: 0.555s, 10270.90/s  (0.904s, 6300.72/s)  LR: 3.412e-03  Data: 0.000 (0.266)
2025-06-02 01:22:19,891 - train - INFO - Train: 181 [ 100/224 ( 45%)]  Loss:  3.115257 (3.1422)  Time: 0.969s, 5876.80/s  (0.865s, 6585.52/s)  LR: 3.412e-03  Data: 0.422 (0.193)
2025-06-02 01:23:01,777 - train - INFO - Train: 181 [ 150/224 ( 67%)]  Loss:  3.139962 (3.1417)  Time: 0.557s, 10222.91/s  (0.856s, 6654.91/s)  LR: 3.412e-03  Data: 0.000 (0.150)
2025-06-02 01:23:42,505 - train - INFO - Train: 181 [ 200/224 ( 90%)]  Loss:  3.119658 (3.1373)  Time: 0.549s, 10376.21/s  (0.846s, 6736.00/s)  LR: 3.412e-03  Data: 0.000 (0.117)
2025-06-02 01:24:01,436 - train - INFO - Train: 181 [ 223/224 (100%)]  Loss:  3.104637 (3.1318)  Time: 0.550s, 10354.94/s  (0.843s, 6754.65/s)  LR: 3.412e-03  Data: 0.000 (0.105)
2025-06-02 01:24:06,261 - train - INFO - Test: [   0/70]  Time: 4.569 (4.569)  Loss:  1.3037 (1.3037)  Acc@1: 72.8933 (72.8933)  Acc@5: 92.0119 (92.0119)
2025-06-02 01:24:48,058 - train - INFO - Test: [  50/70]  Time: 0.120 (0.909)  Loss:  2.0938 (1.8759)  Acc@1: 58.6552 (60.7495)  Acc@5: 78.5639 (83.5894)
2025-06-02 01:25:04,549 - train - INFO - Test: [  70/70]  Time: 0.034 (0.885)  Loss:  2.1055 (1.9581)  Acc@1: 46.0938 (58.9375)  Acc@5: 81.4062 (82.1585)
2025-06-02 01:25:09,430 - train - INFO - Train: 182 [   0/224 (  0%)]  Loss:  3.128783 (3.1288)  Time: 4.569s, 1246.75/s  (4.569s, 1246.75/s)  LR: 3.362e-03  Data: 3.808 (3.808)
2025-06-02 01:25:50,414 - train - INFO - Train: 182 [  50/224 ( 22%)]  Loss:  3.145261 (3.1370)  Time: 0.555s, 10271.80/s  (0.893s, 6377.65/s)  LR: 3.362e-03  Data: 0.000 (0.115)
2025-06-02 01:26:31,561 - train - INFO - Train: 182 [ 100/224 ( 45%)]  Loss:  3.181631 (3.1519)  Time: 1.563s, 3644.20/s  (0.858s, 6636.10/s)  LR: 3.362e-03  Data: 0.000 (0.058)
2025-06-02 01:27:11,774 - train - INFO - Train: 182 [ 150/224 ( 67%)]  Loss:  3.153082 (3.1522)  Time: 0.556s, 10246.97/s  (0.840s, 6777.70/s)  LR: 3.362e-03  Data: 0.000 (0.039)
2025-06-02 01:27:53,104 - train - INFO - Train: 182 [ 200/224 ( 90%)]  Loss:  3.164535 (3.1547)  Time: 1.540s, 3699.31/s  (0.837s, 6805.66/s)  LR: 3.362e-03  Data: 0.000 (0.029)
2025-06-02 01:28:10,955 - train - INFO - Train: 182 [ 223/224 (100%)]  Loss:  3.146693 (3.1533)  Time: 0.546s, 10431.07/s  (0.831s, 6856.96/s)  LR: 3.362e-03  Data: 0.000 (0.026)
2025-06-02 01:28:15,701 - train - INFO - Test: [   0/70]  Time: 4.489 (4.489)  Loss:  1.4678 (1.4678)  Acc@1: 72.6826 (72.6826)  Acc@5: 89.4312 (89.4312)
2025-06-02 01:28:57,959 - train - INFO - Test: [  50/70]  Time: 0.364 (0.917)  Loss:  2.1230 (1.9651)  Acc@1: 59.0239 (60.1433)  Acc@5: 80.0913 (83.3189)
2025-06-02 01:29:14,389 - train - INFO - Test: [  70/70]  Time: 0.034 (0.890)  Loss:  2.4922 (2.0157)  Acc@1: 38.1250 (59.0505)  Acc@5: 76.4062 (82.2105)
2025-06-02 01:29:19,497 - train - INFO - Train: 183 [   0/224 (  0%)]  Loss:  3.170134 (3.1701)  Time: 4.797s, 1187.29/s  (4.797s, 1187.29/s)  LR: 3.313e-03  Data: 3.676 (3.676)
2025-06-02 01:30:01,078 - train - INFO - Train: 183 [  50/224 ( 22%)]  Loss:  3.150567 (3.1604)  Time: 0.549s, 10370.77/s  (0.909s, 6264.01/s)  LR: 3.313e-03  Data: 0.000 (0.162)
2025-06-02 01:30:42,444 - train - INFO - Train: 183 [ 100/224 ( 45%)]  Loss:  3.132540 (3.1511)  Time: 1.597s, 3567.72/s  (0.869s, 6556.99/s)  LR: 3.313e-03  Data: 0.000 (0.082)
2025-06-02 01:31:23,083 - train - INFO - Train: 183 [ 150/224 ( 67%)]  Loss:  3.125690 (3.1447)  Time: 0.549s, 10376.00/s  (0.850s, 6699.96/s)  LR: 3.313e-03  Data: 0.000 (0.055)
2025-06-02 01:32:05,021 - train - INFO - Train: 183 [ 200/224 ( 90%)]  Loss:  3.131253 (3.1420)  Time: 1.695s, 3361.23/s  (0.847s, 6722.41/s)  LR: 3.313e-03  Data: 0.000 (0.041)
2025-06-02 01:32:22,818 - train - INFO - Train: 183 [ 223/224 (100%)]  Loss:  3.135604 (3.1410)  Time: 0.545s, 10450.42/s  (0.840s, 6782.89/s)  LR: 3.313e-03  Data: 0.000 (0.037)
2025-06-02 01:32:27,621 - train - INFO - Test: [   0/70]  Time: 4.559 (4.559)  Loss:  1.0010 (1.0010)  Acc@1: 79.5295 (79.5295)  Acc@5: 92.3455 (92.3455)
2025-06-02 01:33:09,655 - train - INFO - Test: [  50/70]  Time: 0.121 (0.914)  Loss:  1.7480 (1.7676)  Acc@1: 62.5351 (61.6656)  Acc@5: 83.6552 (84.1013)
2025-06-02 01:33:26,166 - train - INFO - Test: [  70/70]  Time: 0.034 (0.889)  Loss:  2.2168 (1.8337)  Acc@1: 44.0625 (60.2053)  Acc@5: 79.3750 (82.9583)
2025-06-02 01:33:30,949 - train - INFO - Train: 184 [   0/224 (  0%)]  Loss:  3.135522 (3.1355)  Time: 4.486s, 1269.65/s  (4.486s, 1269.65/s)  LR: 3.264e-03  Data: 3.918 (3.918)
2025-06-02 01:34:12,512 - train - INFO - Train: 184 [  50/224 ( 22%)]  Loss:  3.134229 (3.1349)  Time: 0.553s, 10294.49/s  (0.903s, 6308.75/s)  LR: 3.264e-03  Data: 0.000 (0.113)
2025-06-02 01:34:54,830 - train - INFO - Train: 184 [ 100/224 ( 45%)]  Loss:  3.162065 (3.1439)  Time: 1.573s, 3621.84/s  (0.875s, 6510.66/s)  LR: 3.264e-03  Data: 0.000 (0.057)
2025-06-02 01:35:35,824 - train - INFO - Train: 184 [ 150/224 ( 67%)]  Loss:  3.149505 (3.1453)  Time: 0.551s, 10328.51/s  (0.857s, 6649.10/s)  LR: 3.264e-03  Data: 0.000 (0.038)
2025-06-02 01:36:17,648 - train - INFO - Train: 184 [ 200/224 ( 90%)]  Loss:  3.180172 (3.1523)  Time: 1.664s, 3423.27/s  (0.852s, 6688.39/s)  LR: 3.264e-03  Data: 0.000 (0.029)
2025-06-02 01:36:35,175 - train - INFO - Train: 184 [ 223/224 (100%)]  Loss:  3.143366 (3.1508)  Time: 0.544s, 10474.48/s  (0.842s, 6761.51/s)  LR: 3.264e-03  Data: 0.000 (0.026)
2025-06-02 01:36:39,885 - train - INFO - Test: [   0/70]  Time: 4.460 (4.460)  Loss:  1.1396 (1.1396)  Acc@1: 76.7732 (76.7732)  Acc@5: 92.3982 (92.3982)
2025-06-02 01:37:21,981 - train - INFO - Test: [  50/70]  Time: 0.121 (0.913)  Loss:  2.0215 (1.8073)  Acc@1: 57.8827 (61.8315)  Acc@5: 78.2654 (83.9268)
2025-06-02 01:37:38,539 - train - INFO - Test: [  70/70]  Time: 0.034 (0.889)  Loss:  2.6250 (1.8867)  Acc@1: 33.9062 (60.0388)  Acc@5: 71.3281 (82.5118)
2025-06-02 01:37:43,528 - train - INFO - Train: 185 [   0/224 (  0%)]  Loss:  3.189625 (3.1896)  Time: 4.678s, 1217.67/s  (4.678s, 1217.67/s)  LR: 3.215e-03  Data: 4.124 (4.124)
2025-06-02 01:38:24,466 - train - INFO - Train: 185 [  50/224 ( 22%)]  Loss:  3.141113 (3.1654)  Time: 0.551s, 10332.88/s  (0.894s, 6368.72/s)  LR: 3.215e-03  Data: 0.000 (0.176)
2025-06-02 01:39:06,257 - train - INFO - Train: 185 [ 100/224 ( 45%)]  Loss:  3.107559 (3.1461)  Time: 1.660s, 3432.09/s  (0.865s, 6582.18/s)  LR: 3.215e-03  Data: 0.000 (0.089)
2025-06-02 01:39:46,231 - train - INFO - Train: 185 [ 150/224 ( 67%)]  Loss:  3.142706 (3.1453)  Time: 0.553s, 10308.51/s  (0.844s, 6752.48/s)  LR: 3.215e-03  Data: 0.000 (0.060)
2025-06-02 01:40:27,315 - train - INFO - Train: 185 [ 200/224 ( 90%)]  Loss:  3.156535 (3.1475)  Time: 1.613s, 3532.22/s  (0.838s, 6796.37/s)  LR: 3.215e-03  Data: 0.000 (0.045)
2025-06-02 01:40:45,137 - train - INFO - Train: 185 [ 223/224 (100%)]  Loss:  3.108437 (3.1410)  Time: 0.551s, 10328.35/s  (0.832s, 6849.44/s)  LR: 3.215e-03  Data: 0.000 (0.040)
2025-06-02 01:40:49,938 - train - INFO - Test: [   0/70]  Time: 4.554 (4.554)  Loss:  1.3975 (1.3975)  Acc@1: 73.8588 (73.8588)  Acc@5: 93.0478 (93.0478)
2025-06-02 01:41:31,645 - train - INFO - Test: [  50/70]  Time: 0.120 (0.907)  Loss:  2.2188 (1.9562)  Acc@1: 56.4431 (62.0301)  Acc@5: 79.2837 (84.1086)
2025-06-02 01:41:47,974 - train - INFO - Test: [  70/70]  Time: 0.034 (0.882)  Loss:  2.0449 (2.0451)  Acc@1: 61.5625 (60.3583)  Acc@5: 86.9531 (82.6065)
2025-06-02 01:41:52,885 - train - INFO - Train: 186 [   0/224 (  0%)]  Loss:  3.199458 (3.1995)  Time: 4.592s, 1240.41/s  (4.592s, 1240.41/s)  LR: 3.166e-03  Data: 3.684 (3.684)
2025-06-02 01:42:33,388 - train - INFO - Train: 186 [  50/224 ( 22%)]  Loss:  3.134628 (3.1670)  Time: 0.553s, 10294.44/s  (0.884s, 6442.28/s)  LR: 3.166e-03  Data: 0.000 (0.090)
2025-06-02 01:43:14,800 - train - INFO - Train: 186 [ 100/224 ( 45%)]  Loss:  3.093777 (3.1426)  Time: 1.317s, 4323.54/s  (0.856s, 6650.57/s)  LR: 3.166e-03  Data: 0.000 (0.046)
2025-06-02 01:43:55,852 - train - INFO - Train: 186 [ 150/224 ( 67%)]  Loss:  3.129430 (3.1393)  Time: 0.549s, 10377.43/s  (0.845s, 6743.02/s)  LR: 3.166e-03  Data: 0.000 (0.031)
2025-06-02 01:44:36,985 - train - INFO - Train: 186 [ 200/224 ( 90%)]  Loss:  3.126682 (3.1368)  Time: 0.549s, 10376.13/s  (0.839s, 6787.20/s)  LR: 3.166e-03  Data: 0.000 (0.023)
2025-06-02 01:44:56,238 - train - INFO - Train: 186 [ 223/224 (100%)]  Loss:  3.157430 (3.1402)  Time: 0.545s, 10449.35/s  (0.839s, 6789.04/s)  LR: 3.166e-03  Data: 0.000 (0.021)
2025-06-02 01:45:00,948 - train - INFO - Test: [   0/70]  Time: 4.457 (4.457)  Loss:  1.7832 (1.7832)  Acc@1: 72.2437 (72.2437)  Acc@5: 92.2928 (92.2928)
2025-06-02 01:45:43,703 - train - INFO - Test: [  50/70]  Time: 0.120 (0.926)  Loss:  2.1250 (2.2542)  Acc@1: 63.1496 (61.0607)  Acc@5: 83.1987 (83.7554)
2025-06-02 01:46:00,193 - train - INFO - Test: [  70/70]  Time: 0.034 (0.897)  Loss:  2.8711 (2.3210)  Acc@1: 39.9219 (59.4188)  Acc@5: 72.4219 (82.2985)
2025-06-02 01:46:05,081 - train - INFO - Train: 187 [   0/224 (  0%)]  Loss:  3.133192 (3.1332)  Time: 4.575s, 1244.97/s  (4.575s, 1244.97/s)  LR: 3.118e-03  Data: 3.894 (3.894)
2025-06-02 01:46:46,681 - train - INFO - Train: 187 [  50/224 ( 22%)]  Loss:  3.128258 (3.1307)  Time: 0.550s, 10356.37/s  (0.905s, 6291.42/s)  LR: 3.118e-03  Data: 0.000 (0.247)
2025-06-02 01:47:28,716 - train - INFO - Train: 187 [ 100/224 ( 45%)]  Loss:  3.095021 (3.1188)  Time: 1.817s, 3134.89/s  (0.873s, 6522.03/s)  LR: 3.118e-03  Data: 0.043 (0.152)
2025-06-02 01:48:09,459 - train - INFO - Train: 187 [ 150/224 ( 67%)]  Loss:  3.115960 (3.1181)  Time: 0.554s, 10287.95/s  (0.854s, 6670.07/s)  LR: 3.118e-03  Data: 0.000 (0.107)
2025-06-02 01:48:51,353 - train - INFO - Train: 187 [ 200/224 ( 90%)]  Loss:  3.173677 (3.1292)  Time: 1.702s, 3346.29/s  (0.850s, 6701.50/s)  LR: 3.118e-03  Data: 0.000 (0.095)
2025-06-02 01:49:09,387 - train - INFO - Train: 187 [ 223/224 (100%)]  Loss:  3.169948 (3.1360)  Time: 0.544s, 10476.33/s  (0.843s, 6755.34/s)  LR: 3.118e-03  Data: 0.000 (0.085)
2025-06-02 01:49:14,042 - train - INFO - Test: [   0/70]  Time: 4.410 (4.410)  Loss:  1.3750 (1.3750)  Acc@1: 72.7528 (72.7528)  Acc@5: 90.7303 (90.7303)
2025-06-02 01:49:57,028 - train - INFO - Test: [  50/70]  Time: 0.120 (0.929)  Loss:  1.9844 (1.8393)  Acc@1: 60.2528 (61.1561)  Acc@5: 80.4775 (83.8263)
2025-06-02 01:50:13,377 - train - INFO - Test: [  70/70]  Time: 0.034 (0.898)  Loss:  2.5469 (1.9016)  Acc@1: 44.3750 (59.7320)  Acc@5: 74.3750 (82.6180)
2025-06-02 01:50:18,551 - train - INFO - Train: 188 [   0/224 (  0%)]  Loss:  3.128062 (3.1281)  Time: 4.868s, 1170.08/s  (4.868s, 1170.08/s)  LR: 3.069e-03  Data: 3.641 (3.641)
2025-06-02 01:50:59,377 - train - INFO - Train: 188 [  50/224 ( 22%)]  Loss:  3.139014 (3.1335)  Time: 0.554s, 10288.58/s  (0.896s, 6357.65/s)  LR: 3.069e-03  Data: 0.000 (0.093)
2025-06-02 01:51:41,146 - train - INFO - Train: 188 [ 100/224 ( 45%)]  Loss:  3.145750 (3.1376)  Time: 1.666s, 3419.87/s  (0.866s, 6577.97/s)  LR: 3.069e-03  Data: 0.000 (0.047)
2025-06-02 01:52:21,563 - train - INFO - Train: 188 [ 150/224 ( 67%)]  Loss:  3.107541 (3.1301)  Time: 0.551s, 10344.72/s  (0.847s, 6726.11/s)  LR: 3.069e-03  Data: 0.000 (0.032)
2025-06-02 01:53:03,131 - train - INFO - Train: 188 [ 200/224 ( 90%)]  Loss:  3.158741 (3.1358)  Time: 1.577s, 3612.64/s  (0.843s, 6756.91/s)  LR: 3.069e-03  Data: 0.000 (0.024)
2025-06-02 01:53:20,890 - train - INFO - Train: 188 [ 223/224 (100%)]  Loss:  3.115530 (3.1324)  Time: 0.551s, 10338.89/s  (0.836s, 6815.78/s)  LR: 3.069e-03  Data: 0.000 (0.021)
2025-06-02 01:53:25,765 - train - INFO - Test: [   0/70]  Time: 4.626 (4.626)  Loss:  1.3438 (1.3438)  Acc@1: 72.2437 (72.2437)  Acc@5: 90.0456 (90.0456)
2025-06-02 01:54:08,175 - train - INFO - Test: [  50/70]  Time: 0.120 (0.922)  Loss:  1.9883 (1.8212)  Acc@1: 58.1636 (60.5464)  Acc@5: 79.2310 (82.9560)
2025-06-02 01:54:24,550 - train - INFO - Test: [  70/70]  Time: 0.034 (0.893)  Loss:  2.8418 (1.9110)  Acc@1: 36.7969 (58.9310)  Acc@5: 71.7188 (81.5148)
2025-06-02 01:54:29,321 - train - INFO - Train: 189 [   0/224 (  0%)]  Loss:  3.123399 (3.1234)  Time: 4.476s, 1272.69/s  (4.476s, 1272.69/s)  LR: 3.021e-03  Data: 3.819 (3.819)
2025-06-02 01:55:10,176 - train - INFO - Train: 189 [  50/224 ( 22%)]  Loss:  3.149417 (3.1364)  Time: 0.549s, 10367.71/s  (0.889s, 6408.67/s)  LR: 3.021e-03  Data: 0.000 (0.155)
2025-06-02 01:55:51,886 - train - INFO - Train: 189 [ 100/224 ( 45%)]  Loss:  3.153952 (3.1423)  Time: 1.577s, 3611.44/s  (0.862s, 6609.81/s)  LR: 3.021e-03  Data: 0.000 (0.078)
2025-06-02 01:56:32,344 - train - INFO - Train: 189 [ 150/224 ( 67%)]  Loss:  3.145229 (3.1430)  Time: 0.557s, 10218.45/s  (0.844s, 6746.27/s)  LR: 3.021e-03  Data: 0.000 (0.052)
2025-06-02 01:57:13,330 - train - INFO - Train: 189 [ 200/224 ( 90%)]  Loss:  3.157514 (3.1459)  Time: 1.250s, 4558.13/s  (0.838s, 6795.54/s)  LR: 3.021e-03  Data: 0.000 (0.039)
2025-06-02 01:57:30,925 - train - INFO - Train: 189 [ 223/224 (100%)]  Loss:  3.130449 (3.1433)  Time: 0.544s, 10471.82/s  (0.831s, 6857.07/s)  LR: 3.021e-03  Data: 0.000 (0.035)
2025-06-02 01:57:35,779 - train - INFO - Test: [   0/70]  Time: 4.608 (4.608)  Loss:  1.3828 (1.3828)  Acc@1: 70.0843 (70.0843)  Acc@5: 87.9213 (87.9213)
2025-06-02 01:58:18,217 - train - INFO - Test: [  50/70]  Time: 0.121 (0.922)  Loss:  2.0254 (1.7747)  Acc@1: 56.1798 (60.0270)  Acc@5: 78.6517 (82.5485)
2025-06-02 01:58:35,185 - train - INFO - Test: [  70/70]  Time: 0.034 (0.902)  Loss:  1.7676 (1.8366)  Acc@1: 59.3750 (58.7880)  Acc@5: 83.7500 (81.6980)
2025-06-02 01:58:40,175 - train - INFO - Train: 190 [   0/224 (  0%)]  Loss:  3.103138 (3.1031)  Time: 4.696s, 1212.89/s  (4.696s, 1212.89/s)  LR: 2.973e-03  Data: 3.695 (3.695)
2025-06-02 01:59:20,768 - train - INFO - Train: 190 [  50/224 ( 22%)]  Loss:  3.189285 (3.1462)  Time: 0.556s, 10245.38/s  (0.888s, 6414.51/s)  LR: 2.973e-03  Data: 0.000 (0.091)
2025-06-02 02:00:02,043 - train - INFO - Train: 190 [ 100/224 ( 45%)]  Loss:  3.090865 (3.1278)  Time: 1.529s, 3725.78/s  (0.857s, 6646.10/s)  LR: 2.973e-03  Data: 0.000 (0.046)
2025-06-02 02:00:42,130 - train - INFO - Train: 190 [ 150/224 ( 67%)]  Loss:  3.114384 (3.1244)  Time: 0.558s, 10212.71/s  (0.839s, 6791.35/s)  LR: 2.973e-03  Data: 0.000 (0.031)
2025-06-02 02:01:23,428 - train - INFO - Train: 190 [ 200/224 ( 90%)]  Loss:  3.122849 (3.1241)  Time: 1.131s, 5035.40/s  (0.836s, 6817.17/s)  LR: 2.973e-03  Data: 0.000 (0.023)
2025-06-02 02:01:41,588 - train - INFO - Train: 190 [ 223/224 (100%)]  Loss:  3.106912 (3.1212)  Time: 0.969s, 5875.93/s  (0.831s, 6855.96/s)  LR: 2.973e-03  Data: 0.000 (0.021)
2025-06-02 02:01:46,303 - train - INFO - Test: [   0/70]  Time: 4.468 (4.468)  Loss:  1.1289 (1.1289)  Acc@1: 75.6320 (75.6320)  Acc@5: 93.9256 (93.9256)
2025-06-02 02:02:27,858 - train - INFO - Test: [  50/70]  Time: 0.120 (0.902)  Loss:  1.8154 (1.7900)  Acc@1: 65.6777 (62.4732)  Acc@5: 83.2163 (84.5912)
2025-06-02 02:02:44,423 - train - INFO - Test: [  70/70]  Time: 0.034 (0.882)  Loss:  2.4492 (1.8590)  Acc@1: 41.5625 (60.8528)  Acc@5: 76.9531 (83.3930)
2025-06-02 02:02:49,398 - train - INFO - Train: 191 [   0/224 (  0%)]  Loss:  3.149849 (3.1498)  Time: 4.667s, 1220.40/s  (4.667s, 1220.40/s)  LR: 2.926e-03  Data: 4.121 (4.121)
2025-06-02 02:03:30,372 - train - INFO - Train: 191 [  50/224 ( 22%)]  Loss:  3.124034 (3.1369)  Time: 0.554s, 10276.66/s  (0.895s, 6365.07/s)  LR: 2.926e-03  Data: 0.000 (0.240)
2025-06-02 02:04:11,725 - train - INFO - Train: 191 [ 100/224 ( 45%)]  Loss:  3.095421 (3.1231)  Time: 1.594s, 3573.19/s  (0.861s, 6613.29/s)  LR: 2.926e-03  Data: 0.239 (0.181)
2025-06-02 02:04:51,805 - train - INFO - Train: 191 [ 150/224 ( 67%)]  Loss:  3.170736 (3.1350)  Time: 0.563s, 10112.34/s  (0.842s, 6768.66/s)  LR: 2.926e-03  Data: 0.000 (0.149)
2025-06-02 02:05:33,234 - train - INFO - Train: 191 [ 200/224 ( 90%)]  Loss:  3.158385 (3.1397)  Time: 1.506s, 3783.15/s  (0.838s, 6794.74/s)  LR: 2.926e-03  Data: 0.964 (0.166)
2025-06-02 02:05:51,400 - train - INFO - Train: 191 [ 223/224 (100%)]  Loss:  3.116450 (3.1358)  Time: 0.545s, 10455.88/s  (0.833s, 6835.41/s)  LR: 2.926e-03  Data: 0.000 (0.174)
2025-06-02 02:05:56,372 - train - INFO - Test: [   0/70]  Time: 4.712 (4.712)  Loss:  1.0547 (1.0547)  Acc@1: 75.6496 (75.6496)  Acc@5: 92.1875 (92.1875)
2025-06-02 02:06:38,786 - train - INFO - Test: [  50/70]  Time: 0.120 (0.924)  Loss:  1.7676 (1.6505)  Acc@1: 61.0780 (61.8480)  Acc@5: 82.3385 (84.5881)
2025-06-02 02:06:55,294 - train - INFO - Test: [  70/70]  Time: 0.034 (0.896)  Loss:  2.4805 (1.7253)  Acc@1: 34.8438 (60.4655)  Acc@5: 76.4062 (83.4828)
2025-06-02 02:07:00,457 - train - INFO - Train: 192 [   0/224 (  0%)]  Loss:  3.160867 (3.1609)  Time: 4.845s, 1175.62/s  (4.845s, 1175.62/s)  LR: 2.878e-03  Data: 4.018 (4.018)
2025-06-02 02:07:41,544 - train - INFO - Train: 192 [  50/224 ( 22%)]  Loss:  3.154569 (3.1577)  Time: 0.550s, 10364.57/s  (0.901s, 6324.64/s)  LR: 2.878e-03  Data: 0.000 (0.145)
2025-06-02 02:08:23,396 - train - INFO - Train: 192 [ 100/224 ( 45%)]  Loss:  3.186275 (3.1672)  Time: 1.505s, 3783.71/s  (0.869s, 6553.71/s)  LR: 2.878e-03  Data: 0.000 (0.073)
2025-06-02 02:09:04,085 - train - INFO - Train: 192 [ 150/224 ( 67%)]  Loss:  3.124687 (3.1566)  Time: 0.554s, 10283.22/s  (0.851s, 6695.03/s)  LR: 2.878e-03  Data: 0.000 (0.049)
2025-06-02 02:09:44,997 - train - INFO - Train: 192 [ 200/224 ( 90%)]  Loss:  3.128534 (3.1510)  Time: 1.587s, 3590.11/s  (0.843s, 6759.38/s)  LR: 2.878e-03  Data: 0.000 (0.037)
2025-06-02 02:10:03,208 - train - INFO - Train: 192 [ 223/224 (100%)]  Loss:  3.200861 (3.1593)  Time: 0.545s, 10453.65/s  (0.837s, 6801.60/s)  LR: 2.878e-03  Data: 0.000 (0.033)
2025-06-02 02:10:08,153 - train - INFO - Test: [   0/70]  Time: 4.689 (4.689)  Loss:  1.4521 (1.4521)  Acc@1: 71.7697 (71.7697)  Acc@5: 88.9045 (88.9045)
2025-06-02 02:10:49,418 - train - INFO - Test: [  50/70]  Time: 0.120 (0.901)  Loss:  1.7188 (2.0470)  Acc@1: 62.7809 (56.8269)  Acc@5: 83.8483 (80.4114)
2025-06-02 02:11:05,903 - train - INFO - Test: [  70/70]  Time: 0.034 (0.879)  Loss:  2.5137 (2.1134)  Acc@1: 36.8750 (55.5640)  Acc@5: 77.5000 (79.2400)
2025-06-02 02:11:10,852 - train - INFO - Train: 193 [   0/224 (  0%)]  Loss:  3.174846 (3.1748)  Time: 4.638s, 1228.12/s  (4.638s, 1228.12/s)  LR: 2.831e-03  Data: 3.702 (3.702)
2025-06-02 02:11:52,135 - train - INFO - Train: 193 [  50/224 ( 22%)]  Loss:  3.137375 (3.1561)  Time: 0.550s, 10351.40/s  (0.900s, 6326.05/s)  LR: 2.831e-03  Data: 0.000 (0.088)
2025-06-02 02:12:33,794 - train - INFO - Train: 193 [ 100/224 ( 45%)]  Loss:  3.164895 (3.1590)  Time: 1.693s, 3365.13/s  (0.867s, 6568.93/s)  LR: 2.831e-03  Data: 0.000 (0.045)
2025-06-02 02:13:14,697 - train - INFO - Train: 193 [ 150/224 ( 67%)]  Loss:  3.118442 (3.1489)  Time: 0.549s, 10369.44/s  (0.851s, 6694.37/s)  LR: 2.831e-03  Data: 0.000 (0.030)
2025-06-02 02:13:55,308 - train - INFO - Train: 193 [ 200/224 ( 90%)]  Loss:  3.083879 (3.1359)  Time: 1.166s, 4884.58/s  (0.841s, 6770.88/s)  LR: 2.831e-03  Data: 0.000 (0.023)
2025-06-02 02:14:13,804 - train - INFO - Train: 193 [ 223/224 (100%)]  Loss:  3.123475 (3.1338)  Time: 0.544s, 10474.04/s  (0.837s, 6801.77/s)  LR: 2.831e-03  Data: 0.000 (0.020)
2025-06-02 02:14:18,606 - train - INFO - Test: [   0/70]  Time: 4.553 (4.553)  Loss:  1.1338 (1.1338)  Acc@1: 74.5787 (74.5787)  Acc@5: 93.3989 (93.3989)
2025-06-02 02:15:00,333 - train - INFO - Test: [  50/70]  Time: 0.120 (0.907)  Loss:  1.9365 (1.8002)  Acc@1: 59.4101 (60.3547)  Acc@5: 80.6180 (83.5592)
2025-06-02 02:15:16,430 - train - INFO - Test: [  70/70]  Time: 0.034 (0.879)  Loss:  2.6172 (1.8728)  Acc@1: 40.6250 (58.9240)  Acc@5: 70.6250 (82.1720)
2025-06-02 02:15:21,457 - train - INFO - Train: 194 [   0/224 (  0%)]  Loss:  3.157399 (3.1574)  Time: 4.723s, 1205.99/s  (4.723s, 1205.99/s)  LR: 2.784e-03  Data: 4.170 (4.170)
2025-06-02 02:16:02,803 - train - INFO - Train: 194 [  50/224 ( 22%)]  Loss:  3.166958 (3.1622)  Time: 0.549s, 10366.14/s  (0.903s, 6305.84/s)  LR: 2.784e-03  Data: 0.000 (0.264)
2025-06-02 02:16:44,864 - train - INFO - Train: 194 [ 100/224 ( 45%)]  Loss:  3.125701 (3.1500)  Time: 1.620s, 3515.46/s  (0.873s, 6528.00/s)  LR: 2.784e-03  Data: 0.000 (0.136)
2025-06-02 02:17:25,908 - train - INFO - Train: 194 [ 150/224 ( 67%)]  Loss:  3.092086 (3.1355)  Time: 0.554s, 10281.78/s  (0.855s, 6658.65/s)  LR: 2.784e-03  Data: 0.000 (0.091)
2025-06-02 02:18:07,319 - train - INFO - Train: 194 [ 200/224 ( 90%)]  Loss:  3.137320 (3.1359)  Time: 1.251s, 4552.99/s  (0.849s, 6711.79/s)  LR: 2.784e-03  Data: 0.000 (0.069)
2025-06-02 02:18:25,444 - train - INFO - Train: 194 [ 223/224 (100%)]  Loss:  3.095479 (3.1292)  Time: 0.546s, 10431.14/s  (0.842s, 6761.40/s)  LR: 2.784e-03  Data: 0.000 (0.062)
2025-06-02 02:18:30,239 - train - INFO - Test: [   0/70]  Time: 4.559 (4.559)  Loss:  1.2627 (1.2627)  Acc@1: 73.5955 (73.5955)  Acc@5: 90.8357 (90.8357)
2025-06-02 02:19:12,152 - train - INFO - Test: [  50/70]  Time: 0.138 (0.911)  Loss:  1.8848 (1.7531)  Acc@1: 61.3764 (62.5640)  Acc@5: 83.1987 (84.9093)
2025-06-02 02:19:28,753 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.3164 (1.8480)  Acc@1: 46.0156 (60.8780)  Acc@5: 76.7188 (83.3485)
2025-06-02 02:19:33,752 - train - INFO - Train: 195 [   0/224 (  0%)]  Loss:  3.121631 (3.1216)  Time: 4.690s, 1214.44/s  (4.690s, 1214.44/s)  LR: 2.737e-03  Data: 3.715 (3.715)
2025-06-02 02:20:14,791 - train - INFO - Train: 195 [  50/224 ( 22%)]  Loss:  3.134658 (3.1281)  Time: 0.555s, 10256.24/s  (0.897s, 6352.79/s)  LR: 2.737e-03  Data: 0.000 (0.140)
2025-06-02 02:20:56,049 - train - INFO - Train: 195 [ 100/224 ( 45%)]  Loss:  3.114452 (3.1236)  Time: 1.598s, 3563.82/s  (0.861s, 6613.79/s)  LR: 2.737e-03  Data: 0.000 (0.071)
2025-06-02 02:21:36,713 - train - INFO - Train: 195 [ 150/224 ( 67%)]  Loss:  3.145718 (3.1291)  Time: 0.550s, 10350.36/s  (0.845s, 6738.04/s)  LR: 2.737e-03  Data: 0.000 (0.047)
2025-06-02 02:22:18,029 - train - INFO - Train: 195 [ 200/224 ( 90%)]  Loss:  3.157434 (3.1348)  Time: 1.563s, 3644.89/s  (0.841s, 6776.18/s)  LR: 2.737e-03  Data: 0.000 (0.036)
2025-06-02 02:22:35,800 - train - INFO - Train: 195 [ 223/224 (100%)]  Loss:  3.122270 (3.1327)  Time: 0.555s, 10264.61/s  (0.834s, 6832.91/s)  LR: 2.737e-03  Data: 0.000 (0.032)
2025-06-02 02:22:40,403 - train - INFO - Test: [   0/70]  Time: 4.357 (4.357)  Loss:  1.6279 (1.6279)  Acc@1: 71.9101 (71.9101)  Acc@5: 90.2739 (90.2739)
2025-06-02 02:23:22,333 - train - INFO - Test: [  50/70]  Time: 0.121 (0.908)  Loss:  1.9639 (1.9940)  Acc@1: 59.4101 (60.4545)  Acc@5: 82.1103 (83.6328)
2025-06-02 02:23:39,057 - train - INFO - Test: [  70/70]  Time: 0.034 (0.887)  Loss:  2.4570 (2.0372)  Acc@1: 48.9062 (59.2595)  Acc@5: 77.4219 (82.4375)
2025-06-02 02:23:43,977 - train - INFO - Train: 196 [   0/224 (  0%)]  Loss:  3.124586 (3.1246)  Time: 4.615s, 1234.33/s  (4.615s, 1234.33/s)  LR: 2.691e-03  Data: 4.067 (4.067)
2025-06-02 02:24:24,586 - train - INFO - Train: 196 [  50/224 ( 22%)]  Loss:  3.116732 (3.1207)  Time: 0.549s, 10377.00/s  (0.887s, 6423.82/s)  LR: 2.691e-03  Data: 0.000 (0.338)
2025-06-02 02:25:05,992 - train - INFO - Train: 196 [ 100/224 ( 45%)]  Loss:  3.157107 (3.1328)  Time: 1.532s, 3718.11/s  (0.858s, 6641.26/s)  LR: 2.691e-03  Data: 0.986 (0.308)
2025-06-02 02:25:46,229 - train - INFO - Train: 196 [ 150/224 ( 67%)]  Loss:  3.115462 (3.1285)  Time: 0.555s, 10267.82/s  (0.840s, 6779.86/s)  LR: 2.691e-03  Data: 0.000 (0.289)
2025-06-02 02:26:27,915 - train - INFO - Train: 196 [ 200/224 ( 90%)]  Loss:  3.108669 (3.1245)  Time: 1.587s, 3588.92/s  (0.839s, 6792.78/s)  LR: 2.691e-03  Data: 0.639 (0.264)
2025-06-02 02:26:45,731 - train - INFO - Train: 196 [ 223/224 (100%)]  Loss:  3.151074 (3.1289)  Time: 0.551s, 10328.32/s  (0.832s, 6846.43/s)  LR: 2.691e-03  Data: 0.000 (0.252)
2025-06-02 02:26:50,587 - train - INFO - Test: [   0/70]  Time: 4.612 (4.612)  Loss:  1.2217 (1.2217)  Acc@1: 72.4719 (72.4719)  Acc@5: 89.7472 (89.7472)
2025-06-02 02:27:32,585 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  1.5557 (1.6751)  Acc@1: 64.3258 (62.0098)  Acc@5: 85.2528 (84.3385)
2025-06-02 02:27:49,249 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.1230 (1.7332)  Acc@1: 45.6250 (60.7300)  Acc@5: 81.8750 (83.3760)
2025-06-02 02:27:54,110 - train - INFO - Train: 197 [   0/224 (  0%)]  Loss:  3.174801 (3.1748)  Time: 4.545s, 1253.21/s  (4.545s, 1253.21/s)  LR: 2.645e-03  Data: 3.989 (3.989)
2025-06-02 02:28:35,268 - train - INFO - Train: 197 [  50/224 ( 22%)]  Loss:  3.135259 (3.1550)  Time: 0.550s, 10364.80/s  (0.896s, 6356.20/s)  LR: 2.645e-03  Data: 0.000 (0.156)
2025-06-02 02:29:16,424 - train - INFO - Train: 197 [ 100/224 ( 45%)]  Loss:  3.114248 (3.1414)  Time: 1.522s, 3742.73/s  (0.860s, 6623.54/s)  LR: 2.645e-03  Data: 0.000 (0.079)
2025-06-02 02:29:57,075 - train - INFO - Train: 197 [ 150/224 ( 67%)]  Loss:  3.134414 (3.1397)  Time: 0.552s, 10316.62/s  (0.844s, 6745.57/s)  LR: 2.645e-03  Data: 0.000 (0.053)
2025-06-02 02:30:37,629 - train - INFO - Train: 197 [ 200/224 ( 90%)]  Loss:  3.145558 (3.1409)  Time: 1.483s, 3840.53/s  (0.836s, 6812.51/s)  LR: 2.645e-03  Data: 0.000 (0.040)
2025-06-02 02:30:55,606 - train - INFO - Train: 197 [ 223/224 (100%)]  Loss:  3.108080 (3.1354)  Time: 0.545s, 10456.34/s  (0.831s, 6858.45/s)  LR: 2.645e-03  Data: 0.000 (0.036)
2025-06-02 02:31:00,448 - train - INFO - Test: [   0/70]  Time: 4.601 (4.601)  Loss:  1.4355 (1.4355)  Acc@1: 74.4733 (74.4733)  Acc@5: 90.5197 (90.5197)
2025-06-02 02:31:42,373 - train - INFO - Test: [  50/70]  Time: 0.120 (0.912)  Loss:  1.9844 (1.9552)  Acc@1: 58.7079 (59.4755)  Acc@5: 80.2142 (82.6789)
2025-06-02 02:31:58,697 - train - INFO - Test: [  70/70]  Time: 0.035 (0.885)  Loss:  2.2188 (2.0170)  Acc@1: 46.4062 (58.0128)  Acc@5: 80.4688 (81.3553)
2025-06-02 02:32:03,767 - train - INFO - Train: 198 [   0/224 (  0%)]  Loss:  3.129522 (3.1295)  Time: 4.766s, 1195.20/s  (4.766s, 1195.20/s)  LR: 2.599e-03  Data: 4.169 (4.169)
2025-06-02 02:32:44,777 - train - INFO - Train: 198 [  50/224 ( 22%)]  Loss:  3.144880 (3.1372)  Time: 0.554s, 10289.25/s  (0.897s, 6346.69/s)  LR: 2.599e-03  Data: 0.000 (0.197)
2025-06-02 02:33:26,574 - train - INFO - Train: 198 [ 100/224 ( 45%)]  Loss:  3.109617 (3.1280)  Time: 1.539s, 3701.98/s  (0.867s, 6569.83/s)  LR: 2.599e-03  Data: 0.000 (0.100)
2025-06-02 02:34:07,330 - train - INFO - Train: 198 [ 150/224 ( 67%)]  Loss:  3.110661 (3.1237)  Time: 0.556s, 10235.68/s  (0.850s, 6702.70/s)  LR: 2.599e-03  Data: 0.000 (0.067)
2025-06-02 02:34:48,786 - train - INFO - Train: 198 [ 200/224 ( 90%)]  Loss:  3.132617 (3.1255)  Time: 1.544s, 3689.26/s  (0.845s, 6743.61/s)  LR: 2.599e-03  Data: 0.000 (0.050)
2025-06-02 02:35:06,723 - train - INFO - Train: 198 [ 223/224 (100%)]  Loss:  3.125824 (3.1255)  Time: 0.553s, 10307.91/s  (0.838s, 6797.20/s)  LR: 2.599e-03  Data: 0.000 (0.045)
2025-06-02 02:35:11,491 - train - INFO - Test: [   0/70]  Time: 4.516 (4.516)  Loss:  1.5039 (1.5039)  Acc@1: 71.7170 (71.7170)  Acc@5: 89.1503 (89.1503)
2025-06-02 02:35:54,139 - train - INFO - Test: [  50/70]  Time: 0.124 (0.925)  Loss:  2.1094 (1.9039)  Acc@1: 56.8820 (61.3692)  Acc@5: 78.4410 (84.0824)
2025-06-02 02:36:10,689 - train - INFO - Test: [  70/70]  Time: 0.035 (0.897)  Loss:  2.7891 (1.9741)  Acc@1: 38.8281 (59.9193)  Acc@5: 74.4531 (82.8975)
2025-06-02 02:36:15,534 - train - INFO - Train: 199 [   0/224 (  0%)]  Loss:  3.141508 (3.1415)  Time: 4.538s, 1255.11/s  (4.538s, 1255.11/s)  LR: 2.553e-03  Data: 3.577 (3.577)
2025-06-02 02:36:56,324 - train - INFO - Train: 199 [  50/224 ( 22%)]  Loss:  3.178304 (3.1599)  Time: 0.556s, 10251.32/s  (0.889s, 6408.99/s)  LR: 2.553e-03  Data: 0.000 (0.129)
2025-06-02 02:37:38,186 - train - INFO - Train: 199 [ 100/224 ( 45%)]  Loss:  3.127737 (3.1492)  Time: 1.261s, 4516.29/s  (0.863s, 6598.39/s)  LR: 2.553e-03  Data: 0.000 (0.065)
2025-06-02 02:38:19,218 - train - INFO - Train: 199 [ 150/224 ( 67%)]  Loss:  3.128089 (3.1439)  Time: 0.550s, 10356.32/s  (0.849s, 6708.11/s)  LR: 2.553e-03  Data: 0.000 (0.044)
2025-06-02 02:39:00,208 - train - INFO - Train: 199 [ 200/224 ( 90%)]  Loss:  3.124511 (3.1400)  Time: 1.381s, 4124.63/s  (0.842s, 6766.25/s)  LR: 2.553e-03  Data: 0.000 (0.033)
2025-06-02 02:39:18,687 - train - INFO - Train: 199 [ 223/224 (100%)]  Loss:  3.177943 (3.1463)  Time: 0.545s, 10449.71/s  (0.838s, 6798.11/s)  LR: 2.553e-03  Data: 0.000 (0.030)
2025-06-02 02:39:23,569 - train - INFO - Test: [   0/70]  Time: 4.645 (4.645)  Loss:  1.3555 (1.3555)  Acc@1: 71.9979 (71.9979)  Acc@5: 88.1671 (88.1671)
2025-06-02 02:40:05,626 - train - INFO - Test: [  50/70]  Time: 0.120 (0.916)  Loss:  1.6201 (1.6619)  Acc@1: 64.2556 (61.6965)  Acc@5: 85.0597 (84.4098)
2025-06-02 02:40:21,899 - train - INFO - Test: [  70/70]  Time: 0.034 (0.887)  Loss:  2.5781 (1.7378)  Acc@1: 48.0469 (60.3678)  Acc@5: 69.8438 (83.1888)
2025-06-02 02:40:26,774 - train - INFO - Train: 200 [   0/224 (  0%)]  Loss:  3.152254 (3.1523)  Time: 4.577s, 1244.60/s  (4.577s, 1244.60/s)  LR: 2.507e-03  Data: 3.762 (3.762)
2025-06-02 02:41:07,525 - train - INFO - Train: 200 [  50/224 ( 22%)]  Loss:  3.089800 (3.1210)  Time: 0.549s, 10374.35/s  (0.889s, 6409.23/s)  LR: 2.507e-03  Data: 0.000 (0.184)
2025-06-02 02:41:48,418 - train - INFO - Train: 200 [ 100/224 ( 45%)]  Loss:  3.147470 (3.1298)  Time: 1.490s, 3824.09/s  (0.854s, 6672.83/s)  LR: 2.507e-03  Data: 0.000 (0.097)
2025-06-02 02:42:28,564 - train - INFO - Train: 200 [ 150/224 ( 67%)]  Loss:  3.144908 (3.1336)  Time: 0.549s, 10372.46/s  (0.837s, 6806.84/s)  LR: 2.507e-03  Data: 0.000 (0.065)
2025-06-02 02:43:09,799 - train - INFO - Train: 200 [ 200/224 ( 90%)]  Loss:  3.152377 (3.1374)  Time: 0.986s, 5776.63/s  (0.834s, 6831.58/s)  LR: 2.507e-03  Data: 0.000 (0.049)
2025-06-02 02:43:28,466 - train - INFO - Train: 200 [ 223/224 (100%)]  Loss:  3.131634 (3.1364)  Time: 1.465s, 3889.23/s  (0.831s, 6850.44/s)  LR: 2.507e-03  Data: 0.000 (0.044)
2025-06-02 02:43:33,237 - train - INFO - Test: [   0/70]  Time: 4.529 (4.529)  Loss:  0.9932 (0.9932)  Acc@1: 77.2472 (77.2472)  Acc@5: 92.6966 (92.6966)
2025-06-02 02:44:14,885 - train - INFO - Test: [  50/70]  Time: 0.120 (0.905)  Loss:  1.4932 (1.5300)  Acc@1: 66.2921 (64.3479)  Acc@5: 86.9382 (86.2800)
2025-06-02 02:44:31,321 - train - INFO - Test: [  70/70]  Time: 0.034 (0.882)  Loss:  2.3262 (1.6305)  Acc@1: 43.7500 (62.7180)  Acc@5: 75.6250 (84.7760)
2025-06-02 02:44:36,394 - train - INFO - Train: 201 [   0/224 (  0%)]  Loss:  3.144920 (3.1449)  Time: 4.623s, 1232.16/s  (4.623s, 1232.16/s)  LR: 2.462e-03  Data: 3.709 (3.709)
2025-06-02 02:45:18,054 - train - INFO - Train: 201 [  50/224 ( 22%)]  Loss:  3.120075 (3.1325)  Time: 0.557s, 10221.01/s  (0.907s, 6276.76/s)  LR: 2.462e-03  Data: 0.000 (0.107)
2025-06-02 02:45:58,769 - train - INFO - Train: 201 [ 100/224 ( 45%)]  Loss:  3.104503 (3.1232)  Time: 0.610s, 9336.31/s  (0.861s, 6613.00/s)  LR: 2.462e-03  Data: 0.000 (0.054)
2025-06-02 02:46:40,281 - train - INFO - Train: 201 [ 150/224 ( 67%)]  Loss:  3.136944 (3.1266)  Time: 0.551s, 10344.36/s  (0.851s, 6693.04/s)  LR: 2.462e-03  Data: 0.000 (0.036)
2025-06-02 02:47:20,307 - train - INFO - Train: 201 [ 200/224 ( 90%)]  Loss:  3.145754 (3.1304)  Time: 0.549s, 10373.34/s  (0.838s, 6793.40/s)  LR: 2.462e-03  Data: 0.000 (0.027)
2025-06-02 02:47:39,105 - train - INFO - Train: 201 [ 223/224 (100%)]  Loss:  3.097191 (3.1249)  Time: 0.547s, 10405.31/s  (0.836s, 6811.09/s)  LR: 2.462e-03  Data: 0.000 (0.024)
2025-06-02 02:47:43,967 - train - INFO - Test: [   0/70]  Time: 4.614 (4.614)  Loss:  1.6660 (1.6660)  Acc@1: 73.2444 (73.2444)  Acc@5: 91.6784 (91.6784)
2025-06-02 02:48:26,220 - train - INFO - Test: [  50/70]  Time: 0.120 (0.919)  Loss:  2.1875 (2.1306)  Acc@1: 58.6376 (60.7165)  Acc@5: 80.8287 (83.6352)
2025-06-02 02:48:42,855 - train - INFO - Test: [  70/70]  Time: 0.034 (0.894)  Loss:  2.6328 (2.1939)  Acc@1: 47.7344 (59.2900)  Acc@5: 76.0156 (82.1878)
2025-06-02 02:48:48,017 - train - INFO - Train: 202 [   0/224 (  0%)]  Loss:  3.095641 (3.0956)  Time: 4.863s, 1171.18/s  (4.863s, 1171.18/s)  LR: 2.417e-03  Data: 4.319 (4.319)
2025-06-02 02:49:28,807 - train - INFO - Train: 202 [  50/224 ( 22%)]  Loss:  3.137608 (3.1166)  Time: 0.550s, 10351.40/s  (0.895s, 6363.23/s)  LR: 2.417e-03  Data: 0.000 (0.171)
2025-06-02 02:50:10,545 - train - INFO - Train: 202 [ 100/224 ( 45%)]  Loss:  3.141572 (3.1249)  Time: 1.654s, 3443.36/s  (0.865s, 6583.19/s)  LR: 2.417e-03  Data: 0.000 (0.086)
2025-06-02 02:50:51,018 - train - INFO - Train: 202 [ 150/224 ( 67%)]  Loss:  3.148534 (3.1308)  Time: 0.552s, 10315.71/s  (0.847s, 6726.90/s)  LR: 2.417e-03  Data: 0.000 (0.058)
2025-06-02 02:51:31,866 - train - INFO - Train: 202 [ 200/224 ( 90%)]  Loss:  3.165956 (3.1379)  Time: 1.126s, 5059.00/s  (0.839s, 6786.35/s)  LR: 2.417e-03  Data: 0.000 (0.043)
2025-06-02 02:51:50,118 - train - INFO - Train: 202 [ 223/224 (100%)]  Loss:  3.129932 (3.1365)  Time: 0.545s, 10444.39/s  (0.835s, 6824.60/s)  LR: 2.417e-03  Data: 0.000 (0.039)
2025-06-02 02:51:55,100 - train - INFO - Test: [   0/70]  Time: 4.726 (4.726)  Loss:  1.0430 (1.0430)  Acc@1: 75.8603 (75.8603)  Acc@5: 92.2928 (92.2928)
2025-06-02 02:52:37,184 - train - INFO - Test: [  50/70]  Time: 0.120 (0.918)  Loss:  1.7725 (1.7828)  Acc@1: 61.8680 (60.1161)  Acc@5: 81.6011 (82.7110)
2025-06-02 02:52:53,869 - train - INFO - Test: [  70/70]  Time: 0.034 (0.894)  Loss:  2.3555 (1.8620)  Acc@1: 42.5000 (58.4355)  Acc@5: 76.7188 (81.2928)
2025-06-02 02:52:58,917 - train - INFO - Train: 203 [   0/224 (  0%)]  Loss:  3.129345 (3.1293)  Time: 4.744s, 1200.76/s  (4.744s, 1200.76/s)  LR: 2.373e-03  Data: 3.473 (3.473)
2025-06-02 02:53:40,022 - train - INFO - Train: 203 [  50/224 ( 22%)]  Loss:  3.143804 (3.1366)  Time: 0.548s, 10391.60/s  (0.899s, 6336.09/s)  LR: 2.373e-03  Data: 0.000 (0.072)
2025-06-02 02:54:21,966 - train - INFO - Train: 203 [ 100/224 ( 45%)]  Loss:  3.143382 (3.1388)  Time: 1.553s, 3667.99/s  (0.869s, 6553.06/s)  LR: 2.373e-03  Data: 0.000 (0.036)
2025-06-02 02:55:02,541 - train - INFO - Train: 203 [ 150/224 ( 67%)]  Loss:  3.130288 (3.1367)  Time: 0.554s, 10289.66/s  (0.850s, 6700.49/s)  LR: 2.373e-03  Data: 0.000 (0.024)
2025-06-02 02:55:44,120 - train - INFO - Train: 203 [ 200/224 ( 90%)]  Loss:  3.137696 (3.1369)  Time: 1.570s, 3627.77/s  (0.845s, 6737.05/s)  LR: 2.373e-03  Data: 0.000 (0.018)
2025-06-02 02:56:02,200 - train - INFO - Train: 203 [ 223/224 (100%)]  Loss:  3.205136 (3.1483)  Time: 0.550s, 10351.03/s  (0.839s, 6786.06/s)  LR: 2.373e-03  Data: 0.000 (0.017)
2025-06-02 02:56:07,105 - train - INFO - Test: [   0/70]  Time: 4.667 (4.667)  Loss:  1.5156 (1.5156)  Acc@1: 75.5091 (75.5091)  Acc@5: 91.0112 (91.0112)
2025-06-02 02:56:49,720 - train - INFO - Test: [  50/70]  Time: 0.120 (0.927)  Loss:  2.0742 (2.1058)  Acc@1: 60.0070 (59.6817)  Acc@5: 80.5302 (83.0294)
2025-06-02 02:57:06,493 - train - INFO - Test: [  70/70]  Time: 0.034 (0.902)  Loss:  2.8164 (2.1504)  Acc@1: 33.7500 (58.3305)  Acc@5: 74.2969 (81.8515)
2025-06-02 02:57:11,783 - train - INFO - Train: 204 [   0/224 (  0%)]  Loss:  3.100510 (3.1005)  Time: 4.994s, 1140.47/s  (4.994s, 1140.47/s)  LR: 2.329e-03  Data: 4.208 (4.208)
2025-06-02 02:57:52,431 - train - INFO - Train: 204 [  50/224 ( 22%)]  Loss:  3.115434 (3.1080)  Time: 0.549s, 10374.50/s  (0.895s, 6364.82/s)  LR: 2.329e-03  Data: 0.000 (0.155)
2025-06-02 02:58:33,508 - train - INFO - Train: 204 [ 100/224 ( 45%)]  Loss:  3.136389 (3.1174)  Time: 1.564s, 3642.51/s  (0.859s, 6634.24/s)  LR: 2.329e-03  Data: 0.000 (0.078)
2025-06-02 02:59:14,220 - train - INFO - Train: 204 [ 150/224 ( 67%)]  Loss:  3.129648 (3.1205)  Time: 0.969s, 5880.82/s  (0.844s, 6749.70/s)  LR: 2.329e-03  Data: 0.000 (0.052)
2025-06-02 02:59:55,658 - train - INFO - Train: 204 [ 200/224 ( 90%)]  Loss:  3.116770 (3.1198)  Time: 1.505s, 3784.82/s  (0.840s, 6780.01/s)  LR: 2.329e-03  Data: 0.000 (0.039)
2025-06-02 03:00:14,027 - train - INFO - Train: 204 [ 223/224 (100%)]  Loss:  3.121678 (3.1201)  Time: 0.546s, 10433.18/s  (0.836s, 6814.60/s)  LR: 2.329e-03  Data: 0.000 (0.035)
2025-06-02 03:00:18,834 - train - INFO - Test: [   0/70]  Time: 4.569 (4.569)  Loss:  1.2510 (1.2510)  Acc@1: 73.1742 (73.1742)  Acc@5: 90.4494 (90.4494)
2025-06-02 03:01:01,034 - train - INFO - Test: [  50/70]  Time: 0.124 (0.917)  Loss:  2.1895 (1.8200)  Acc@1: 55.0562 (61.6380)  Acc@5: 78.9326 (83.8841)
2025-06-02 03:01:17,538 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.4395 (1.9163)  Acc@1: 47.5000 (59.9900)  Acc@5: 76.2500 (82.2680)
2025-06-02 03:01:22,318 - train - INFO - Train: 205 [   0/224 (  0%)]  Loss:  3.114219 (3.1142)  Time: 4.473s, 1273.50/s  (4.473s, 1273.50/s)  LR: 2.285e-03  Data: 3.674 (3.674)
2025-06-02 03:02:03,786 - train - INFO - Train: 205 [  50/224 ( 22%)]  Loss:  3.097221 (3.1057)  Time: 0.550s, 10355.49/s  (0.901s, 6323.52/s)  LR: 2.285e-03  Data: 0.000 (0.120)
2025-06-02 03:02:45,261 - train - INFO - Train: 205 [ 100/224 ( 45%)]  Loss:  3.104667 (3.1054)  Time: 1.464s, 3891.97/s  (0.865s, 6581.40/s)  LR: 2.285e-03  Data: 0.000 (0.061)
2025-06-02 03:03:26,289 - train - INFO - Train: 205 [ 150/224 ( 67%)]  Loss:  3.134266 (3.1126)  Time: 0.551s, 10341.06/s  (0.851s, 6696.60/s)  LR: 2.285e-03  Data: 0.000 (0.041)
2025-06-02 03:04:08,487 - train - INFO - Train: 205 [ 200/224 ( 90%)]  Loss:  3.123789 (3.1148)  Time: 1.700s, 3350.28/s  (0.849s, 6709.72/s)  LR: 2.285e-03  Data: 0.000 (0.031)
2025-06-02 03:04:26,241 - train - INFO - Train: 205 [ 223/224 (100%)]  Loss:  3.142598 (3.1195)  Time: 0.545s, 10446.44/s  (0.841s, 6772.98/s)  LR: 2.285e-03  Data: 0.000 (0.028)
2025-06-02 03:04:31,157 - train - INFO - Test: [   0/70]  Time: 4.664 (4.664)  Loss:  1.4512 (1.4512)  Acc@1: 75.5794 (75.5794)  Acc@5: 90.1510 (90.1510)
2025-06-02 03:05:13,420 - train - INFO - Test: [  50/70]  Time: 0.120 (0.920)  Loss:  2.0098 (1.8816)  Acc@1: 58.1636 (60.9950)  Acc@5: 79.5471 (83.6614)
2025-06-02 03:05:29,742 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.6680 (1.9385)  Acc@1: 40.5469 (59.6080)  Acc@5: 71.8750 (82.4883)
2025-06-02 03:05:34,679 - train - INFO - Train: 206 [   0/224 (  0%)]  Loss:  3.126910 (3.1269)  Time: 4.634s, 1229.20/s  (4.634s, 1229.20/s)  LR: 2.241e-03  Data: 4.082 (4.082)
2025-06-02 03:06:15,487 - train - INFO - Train: 206 [  50/224 ( 22%)]  Loss:  3.156884 (3.1419)  Time: 0.549s, 10366.83/s  (0.891s, 6392.79/s)  LR: 2.241e-03  Data: 0.000 (0.298)
2025-06-02 03:06:57,362 - train - INFO - Train: 206 [ 100/224 ( 45%)]  Loss:  3.131675 (3.1385)  Time: 1.763s, 3231.75/s  (0.865s, 6588.75/s)  LR: 2.241e-03  Data: 0.000 (0.161)
2025-06-02 03:07:38,171 - train - INFO - Train: 206 [ 150/224 ( 67%)]  Loss:  3.120328 (3.1339)  Time: 0.556s, 10249.73/s  (0.848s, 6713.12/s)  LR: 2.241e-03  Data: 0.000 (0.108)
2025-06-02 03:08:19,731 - train - INFO - Train: 206 [ 200/224 ( 90%)]  Loss:  3.167571 (3.1407)  Time: 1.654s, 3442.86/s  (0.844s, 6747.44/s)  LR: 2.241e-03  Data: 0.000 (0.081)
2025-06-02 03:08:37,215 - train - INFO - Train: 206 [ 223/224 (100%)]  Loss:  3.122806 (3.1377)  Time: 0.552s, 10327.91/s  (0.836s, 6817.12/s)  LR: 2.241e-03  Data: 0.000 (0.073)
2025-06-02 03:08:41,913 - train - INFO - Test: [   0/70]  Time: 4.461 (4.461)  Loss:  0.9980 (0.9980)  Acc@1: 77.8792 (77.8792)  Acc@5: 92.3631 (92.3631)
2025-06-02 03:09:24,154 - train - INFO - Test: [  50/70]  Time: 0.120 (0.916)  Loss:  1.5645 (1.6487)  Acc@1: 66.3272 (62.4804)  Acc@5: 85.5513 (84.7347)
2025-06-02 03:09:40,456 - train - INFO - Test: [  70/70]  Time: 0.034 (0.887)  Loss:  2.7637 (1.7290)  Acc@1: 34.1406 (61.0070)  Acc@5: 70.0781 (83.4210)
2025-06-02 03:09:45,571 - train - INFO - Train: 207 [   0/224 (  0%)]  Loss:  3.157822 (3.1578)  Time: 4.804s, 1185.62/s  (4.804s, 1185.62/s)  LR: 2.197e-03  Data: 4.063 (4.063)
2025-06-02 03:10:26,123 - train - INFO - Train: 207 [  50/224 ( 22%)]  Loss:  3.133018 (3.1454)  Time: 0.550s, 10350.57/s  (0.889s, 6405.42/s)  LR: 2.197e-03  Data: 0.000 (0.256)
2025-06-02 03:11:07,174 - train - INFO - Train: 207 [ 100/224 ( 45%)]  Loss:  3.134258 (3.1417)  Time: 1.316s, 4328.57/s  (0.855s, 6658.39/s)  LR: 2.197e-03  Data: 0.403 (0.206)
2025-06-02 03:11:47,822 - train - INFO - Train: 207 [ 150/224 ( 67%)]  Loss:  3.133733 (3.1397)  Time: 0.548s, 10391.52/s  (0.841s, 6769.84/s)  LR: 2.197e-03  Data: 0.000 (0.144)
2025-06-02 03:12:30,249 - train - INFO - Train: 207 [ 200/224 ( 90%)]  Loss:  3.136715 (3.1391)  Time: 1.541s, 3697.45/s  (0.843s, 6755.61/s)  LR: 2.197e-03  Data: 0.000 (0.109)
2025-06-02 03:12:48,005 - train - INFO - Train: 207 [ 223/224 (100%)]  Loss:  3.153752 (3.1415)  Time: 0.544s, 10465.16/s  (0.836s, 6814.70/s)  LR: 2.197e-03  Data: 0.000 (0.098)
2025-06-02 03:12:52,933 - train - INFO - Test: [   0/70]  Time: 4.677 (4.677)  Loss:  1.1318 (1.1318)  Acc@1: 74.3329 (74.3329)  Acc@5: 91.3624 (91.3624)
2025-06-02 03:13:35,337 - train - INFO - Test: [  50/70]  Time: 0.120 (0.923)  Loss:  1.5820 (1.6986)  Acc@1: 64.8174 (61.4108)  Acc@5: 84.9544 (84.0724)
2025-06-02 03:13:51,908 - train - INFO - Test: [  70/70]  Time: 0.034 (0.897)  Loss:  1.8145 (1.7548)  Acc@1: 54.8438 (59.9965)  Acc@5: 86.1719 (83.0690)
2025-06-02 03:13:56,549 - train - INFO - Train: 208 [   0/224 (  0%)]  Loss:  3.154537 (3.1545)  Time: 4.322s, 1318.00/s  (4.322s, 1318.00/s)  LR: 2.154e-03  Data: 3.735 (3.735)
2025-06-02 03:14:37,116 - train - INFO - Train: 208 [  50/224 ( 22%)]  Loss:  3.126847 (3.1407)  Time: 0.549s, 10375.14/s  (0.880s, 6471.74/s)  LR: 2.154e-03  Data: 0.000 (0.281)
2025-06-02 03:15:18,778 - train - INFO - Train: 208 [ 100/224 ( 45%)]  Loss:  3.135642 (3.1390)  Time: 1.534s, 3712.21/s  (0.857s, 6647.20/s)  LR: 2.154e-03  Data: 0.993 (0.274)
2025-06-02 03:15:59,286 - train - INFO - Train: 208 [ 150/224 ( 67%)]  Loss:  3.206113 (3.1558)  Time: 0.548s, 10391.25/s  (0.841s, 6769.66/s)  LR: 2.154e-03  Data: 0.000 (0.270)
2025-06-02 03:16:39,756 - train - INFO - Train: 208 [ 200/224 ( 90%)]  Loss:  3.135682 (3.1518)  Time: 1.475s, 3860.88/s  (0.833s, 6834.34/s)  LR: 2.154e-03  Data: 0.934 (0.268)
2025-06-02 03:16:57,352 - train - INFO - Train: 208 [ 223/224 (100%)]  Loss:  3.139664 (3.1497)  Time: 0.546s, 10426.61/s  (0.826s, 6892.46/s)  LR: 2.154e-03  Data: 0.000 (0.262)
2025-06-02 03:17:02,122 - train - INFO - Test: [   0/70]  Time: 4.515 (4.515)  Loss:  1.3359 (1.3359)  Acc@1: 71.0674 (71.0674)  Acc@5: 90.3090 (90.3090)
2025-06-02 03:17:44,253 - train - INFO - Test: [  50/70]  Time: 0.223 (0.915)  Loss:  1.7822 (1.6511)  Acc@1: 60.5337 (62.7038)  Acc@5: 83.0056 (85.3630)
2025-06-02 03:18:00,552 - train - INFO - Test: [  70/70]  Time: 0.034 (0.887)  Loss:  2.0527 (1.7428)  Acc@1: 42.5000 (61.0060)  Acc@5: 81.8750 (83.7400)
2025-06-02 03:18:05,553 - train - INFO - Train: 209 [   0/224 (  0%)]  Loss:  3.137936 (3.1379)  Time: 4.691s, 1214.31/s  (4.691s, 1214.31/s)  LR: 2.111e-03  Data: 4.013 (4.013)
2025-06-02 03:18:46,690 - train - INFO - Train: 209 [  50/224 ( 22%)]  Loss:  3.078186 (3.1081)  Time: 0.556s, 10239.58/s  (0.899s, 6338.99/s)  LR: 2.111e-03  Data: 0.000 (0.118)
2025-06-02 03:19:28,649 - train - INFO - Train: 209 [ 100/224 ( 45%)]  Loss:  3.117075 (3.1111)  Time: 1.572s, 3623.62/s  (0.869s, 6553.53/s)  LR: 2.111e-03  Data: 0.000 (0.060)
2025-06-02 03:20:08,609 - train - INFO - Train: 209 [ 150/224 ( 67%)]  Loss:  3.167525 (3.1252)  Time: 0.549s, 10366.09/s  (0.846s, 6733.00/s)  LR: 2.111e-03  Data: 0.000 (0.040)
2025-06-02 03:20:50,208 - train - INFO - Train: 209 [ 200/224 ( 90%)]  Loss:  3.108179 (3.1218)  Time: 1.413s, 4031.67/s  (0.842s, 6760.94/s)  LR: 2.111e-03  Data: 0.000 (0.030)
2025-06-02 03:21:08,117 - train - INFO - Train: 209 [ 223/224 (100%)]  Loss:  3.103346 (3.1187)  Time: 0.546s, 10433.76/s  (0.836s, 6814.01/s)  LR: 2.111e-03  Data: 0.000 (0.027)
2025-06-02 03:21:12,863 - train - INFO - Test: [   0/70]  Time: 4.500 (4.500)  Loss:  1.1582 (1.1582)  Acc@1: 73.3673 (73.3673)  Acc@5: 90.7654 (90.7654)
2025-06-02 03:21:55,275 - train - INFO - Test: [  50/70]  Time: 0.159 (0.920)  Loss:  1.8271 (1.7248)  Acc@1: 58.6903 (60.5833)  Acc@5: 81.8118 (83.2838)
2025-06-02 03:22:11,705 - train - INFO - Test: [  70/70]  Time: 0.034 (0.892)  Loss:  2.5469 (1.8356)  Acc@1: 38.5156 (58.4993)  Acc@5: 74.9219 (81.5683)
2025-06-02 03:22:16,692 - train - INFO - Train: 210 [   0/224 (  0%)]  Loss:  3.143292 (3.1433)  Time: 4.682s, 1216.69/s  (4.682s, 1216.69/s)  LR: 2.069e-03  Data: 4.007 (4.007)
2025-06-02 03:22:58,208 - train - INFO - Train: 210 [  50/224 ( 22%)]  Loss:  3.143942 (3.1436)  Time: 0.557s, 10222.13/s  (0.906s, 6288.27/s)  LR: 2.069e-03  Data: 0.000 (0.152)
2025-06-02 03:23:39,663 - train - INFO - Train: 210 [ 100/224 ( 45%)]  Loss:  3.124762 (3.1373)  Time: 1.539s, 3701.43/s  (0.868s, 6563.59/s)  LR: 2.069e-03  Data: 0.000 (0.077)
2025-06-02 03:24:20,555 - train - INFO - Train: 210 [ 150/224 ( 67%)]  Loss:  3.156561 (3.1421)  Time: 0.554s, 10284.07/s  (0.851s, 6691.40/s)  LR: 2.069e-03  Data: 0.000 (0.051)
2025-06-02 03:25:02,615 - train - INFO - Train: 210 [ 200/224 ( 90%)]  Loss:  3.120503 (3.1378)  Time: 1.869s, 3047.91/s  (0.849s, 6711.12/s)  LR: 2.069e-03  Data: 0.000 (0.039)
2025-06-02 03:25:20,320 - train - INFO - Train: 210 [ 223/224 (100%)]  Loss:  3.122705 (3.1353)  Time: 0.552s, 10320.83/s  (0.841s, 6775.92/s)  LR: 2.069e-03  Data: 0.000 (0.035)
2025-06-02 03:25:25,047 - train - INFO - Test: [   0/70]  Time: 4.469 (4.469)  Loss:  2.1465 (2.1465)  Acc@1: 68.1180 (68.1180)  Acc@5: 87.2191 (87.2191)
2025-06-02 03:26:07,213 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  2.4512 (2.2975)  Acc@1: 48.8764 (58.5867)  Acc@5: 77.1067 (81.7939)
2025-06-02 03:26:23,184 - train - INFO - Test: [  70/70]  Time: 0.034 (0.882)  Loss:  3.0781 (2.3422)  Acc@1: 30.6250 (56.8840)  Acc@5: 73.7500 (80.5760)
2025-06-02 03:26:28,094 - train - INFO - Train: 211 [   0/224 (  0%)]  Loss:  3.133028 (3.1330)  Time: 4.605s, 1237.00/s  (4.605s, 1237.00/s)  LR: 2.027e-03  Data: 3.901 (3.901)
2025-06-02 03:27:09,188 - train - INFO - Train: 211 [  50/224 ( 22%)]  Loss:  3.166786 (3.1499)  Time: 0.549s, 10369.57/s  (0.896s, 6356.94/s)  LR: 2.027e-03  Data: 0.000 (0.198)
2025-06-02 03:27:51,459 - train - INFO - Train: 211 [ 100/224 ( 45%)]  Loss:  3.116297 (3.1387)  Time: 1.715s, 3322.13/s  (0.871s, 6539.91/s)  LR: 2.027e-03  Data: 0.000 (0.101)
2025-06-02 03:28:32,030 - train - INFO - Train: 211 [ 150/224 ( 67%)]  Loss:  3.117544 (3.1334)  Time: 0.550s, 10361.72/s  (0.851s, 6691.40/s)  LR: 2.027e-03  Data: 0.000 (0.068)
2025-06-02 03:29:14,135 - train - INFO - Train: 211 [ 200/224 ( 90%)]  Loss:  3.126094 (3.1319)  Time: 1.802s, 3160.30/s  (0.849s, 6709.43/s)  LR: 2.027e-03  Data: 0.000 (0.051)
2025-06-02 03:29:31,760 - train - INFO - Train: 211 [ 223/224 (100%)]  Loss:  3.193284 (3.1422)  Time: 0.552s, 10319.80/s  (0.840s, 6777.23/s)  LR: 2.027e-03  Data: 0.000 (0.046)
2025-06-02 03:29:36,576 - train - INFO - Test: [   0/70]  Time: 4.576 (4.576)  Loss:  1.4102 (1.4102)  Acc@1: 74.7718 (74.7718)  Acc@5: 91.0639 (91.0639)
2025-06-02 03:30:18,942 - train - INFO - Test: [  50/70]  Time: 0.120 (0.920)  Loss:  2.1738 (1.9762)  Acc@1: 57.8125 (60.9823)  Acc@5: 80.0913 (83.4937)
2025-06-02 03:30:35,409 - train - INFO - Test: [  70/70]  Time: 0.034 (0.893)  Loss:  2.6270 (2.0430)  Acc@1: 44.3750 (59.6383)  Acc@5: 71.0938 (82.3845)
2025-06-02 03:30:40,606 - train - INFO - Train: 212 [   0/224 (  0%)]  Loss:  3.148810 (3.1488)  Time: 4.893s, 1164.12/s  (4.893s, 1164.12/s)  LR: 1.985e-03  Data: 3.732 (3.732)
2025-06-02 03:31:21,511 - train - INFO - Train: 212 [  50/224 ( 22%)]  Loss:  3.162363 (3.1556)  Time: 0.551s, 10337.96/s  (0.898s, 6343.58/s)  LR: 1.985e-03  Data: 0.000 (0.101)
2025-06-02 03:32:03,572 - train - INFO - Train: 212 [ 100/224 ( 45%)]  Loss:  3.129713 (3.1470)  Time: 1.673s, 3403.83/s  (0.870s, 6548.58/s)  LR: 1.985e-03  Data: 0.000 (0.051)
2025-06-02 03:32:44,093 - train - INFO - Train: 212 [ 150/224 ( 67%)]  Loss:  3.180961 (3.1555)  Time: 0.550s, 10363.17/s  (0.850s, 6700.22/s)  LR: 1.985e-03  Data: 0.000 (0.034)
2025-06-02 03:33:25,986 - train - INFO - Train: 212 [ 200/224 ( 90%)]  Loss:  3.101963 (3.1448)  Time: 1.676s, 3397.99/s  (0.847s, 6724.46/s)  LR: 1.985e-03  Data: 0.000 (0.026)
2025-06-02 03:33:43,934 - train - INFO - Train: 212 [ 223/224 (100%)]  Loss:  3.133126 (3.1428)  Time: 0.545s, 10447.18/s  (0.840s, 6779.37/s)  LR: 1.985e-03  Data: 0.000 (0.023)
2025-06-02 03:33:48,732 - train - INFO - Test: [   0/70]  Time: 4.553 (4.553)  Loss:  1.2070 (1.2070)  Acc@1: 75.0000 (75.0000)  Acc@5: 90.8181 (90.8181)
2025-06-02 03:34:30,682 - train - INFO - Test: [  50/70]  Time: 0.120 (0.912)  Loss:  1.9111 (1.6465)  Acc@1: 57.7949 (63.3847)  Acc@5: 82.1278 (85.4969)
2025-06-02 03:34:47,373 - train - INFO - Test: [  70/70]  Time: 0.035 (0.890)  Loss:  2.5312 (1.7423)  Acc@1: 40.0781 (61.4868)  Acc@5: 73.7500 (83.9028)
2025-06-02 03:34:52,505 - train - INFO - Train: 213 [   0/224 (  0%)]  Loss:  3.146818 (3.1468)  Time: 4.825s, 1180.42/s  (4.825s, 1180.42/s)  LR: 1.944e-03  Data: 3.706 (3.706)
2025-06-02 03:35:33,374 - train - INFO - Train: 213 [  50/224 ( 22%)]  Loss:  3.151970 (3.1494)  Time: 0.555s, 10256.57/s  (0.896s, 6357.86/s)  LR: 1.944e-03  Data: 0.000 (0.086)
2025-06-02 03:36:15,542 - train - INFO - Train: 213 [ 100/224 ( 45%)]  Loss:  3.155473 (3.1514)  Time: 1.782s, 3195.72/s  (0.870s, 6548.14/s)  LR: 1.944e-03  Data: 0.000 (0.044)
2025-06-02 03:36:56,014 - train - INFO - Train: 213 [ 150/224 ( 67%)]  Loss:  3.104940 (3.1398)  Time: 0.557s, 10220.26/s  (0.850s, 6702.35/s)  LR: 1.944e-03  Data: 0.000 (0.029)
2025-06-02 03:37:38,181 - train - INFO - Train: 213 [ 200/224 ( 90%)]  Loss:  3.140775 (3.1400)  Time: 1.528s, 3727.08/s  (0.848s, 6715.30/s)  LR: 1.944e-03  Data: 0.000 (0.022)
2025-06-02 03:37:56,040 - train - INFO - Train: 213 [ 223/224 (100%)]  Loss:  3.136297 (3.1394)  Time: 0.552s, 10310.55/s  (0.841s, 6774.25/s)  LR: 1.944e-03  Data: 0.000 (0.020)
2025-06-02 03:38:00,908 - train - INFO - Test: [   0/70]  Time: 4.610 (4.610)  Loss:  1.3193 (1.3193)  Acc@1: 73.1742 (73.1742)  Acc@5: 92.4157 (92.4157)
2025-06-02 03:38:42,640 - train - INFO - Test: [  50/70]  Time: 0.120 (0.909)  Loss:  1.8262 (1.8637)  Acc@1: 61.6573 (61.5224)  Acc@5: 82.4438 (84.3165)
2025-06-02 03:38:59,060 - train - INFO - Test: [  70/70]  Time: 0.034 (0.884)  Loss:  2.1562 (1.9348)  Acc@1: 47.5000 (60.0400)  Acc@5: 81.8750 (82.9160)
2025-06-02 03:39:03,916 - train - INFO - Train: 214 [   0/224 (  0%)]  Loss:  3.147999 (3.1480)  Time: 4.561s, 1248.81/s  (4.561s, 1248.81/s)  LR: 1.902e-03  Data: 3.778 (3.778)
2025-06-02 03:39:44,765 - train - INFO - Train: 214 [  50/224 ( 22%)]  Loss:  3.145977 (3.1470)  Time: 0.550s, 10353.03/s  (0.890s, 6397.34/s)  LR: 1.902e-03  Data: 0.000 (0.202)
2025-06-02 03:40:26,202 - train - INFO - Train: 214 [ 100/224 ( 45%)]  Loss:  3.103384 (3.1325)  Time: 1.581s, 3602.45/s  (0.860s, 6624.45/s)  LR: 1.902e-03  Data: 0.000 (0.112)
2025-06-02 03:41:06,074 - train - INFO - Train: 214 [ 150/224 ( 67%)]  Loss:  3.139087 (3.1341)  Time: 0.555s, 10270.66/s  (0.839s, 6787.63/s)  LR: 1.902e-03  Data: 0.000 (0.075)
2025-06-02 03:41:47,927 - train - INFO - Train: 214 [ 200/224 ( 90%)]  Loss:  3.142856 (3.1359)  Time: 1.766s, 3225.66/s  (0.839s, 6791.99/s)  LR: 1.902e-03  Data: 0.000 (0.056)
2025-06-02 03:42:05,699 - train - INFO - Train: 214 [ 223/224 (100%)]  Loss:  3.102816 (3.1304)  Time: 0.545s, 10448.99/s  (0.832s, 6847.33/s)  LR: 1.902e-03  Data: 0.000 (0.051)
2025-06-02 03:42:10,495 - train - INFO - Test: [   0/70]  Time: 4.552 (4.552)  Loss:  1.2334 (1.2334)  Acc@1: 71.5414 (71.5414)  Acc@5: 89.6243 (89.6243)
2025-06-02 03:42:53,478 - train - INFO - Test: [  50/70]  Time: 0.120 (0.932)  Loss:  1.6152 (1.6822)  Acc@1: 66.2921 (60.7974)  Acc@5: 84.3574 (83.9970)
2025-06-02 03:43:10,161 - train - INFO - Test: [  70/70]  Time: 0.034 (0.904)  Loss:  2.1758 (1.7625)  Acc@1: 44.6094 (59.4013)  Acc@5: 76.5625 (82.7765)
2025-06-02 03:43:14,960 - train - INFO - Train: 215 [   0/224 (  0%)]  Loss:  3.134684 (3.1347)  Time: 4.497s, 1266.48/s  (4.497s, 1266.48/s)  LR: 1.862e-03  Data: 3.500 (3.500)
2025-06-02 03:43:56,363 - train - INFO - Train: 215 [  50/224 ( 22%)]  Loss:  3.098440 (3.1166)  Time: 0.555s, 10268.58/s  (0.900s, 6329.04/s)  LR: 1.862e-03  Data: 0.000 (0.176)
2025-06-02 03:44:38,763 - train - INFO - Train: 215 [ 100/224 ( 45%)]  Loss:  3.098249 (3.1105)  Time: 1.939s, 2938.08/s  (0.874s, 6515.40/s)  LR: 1.862e-03  Data: 0.000 (0.089)
2025-06-02 03:45:19,349 - train - INFO - Train: 215 [ 150/224 ( 67%)]  Loss:  3.125150 (3.1141)  Time: 0.557s, 10234.07/s  (0.854s, 6673.50/s)  LR: 1.862e-03  Data: 0.000 (0.060)
2025-06-02 03:46:00,765 - train - INFO - Train: 215 [ 200/224 ( 90%)]  Loss:  3.130580 (3.1174)  Time: 1.827s, 3116.91/s  (0.847s, 6723.04/s)  LR: 1.862e-03  Data: 0.000 (0.045)
2025-06-02 03:46:18,557 - train - INFO - Train: 215 [ 223/224 (100%)]  Loss:  3.124291 (3.1186)  Time: 0.546s, 10427.65/s  (0.840s, 6783.72/s)  LR: 1.862e-03  Data: 0.000 (0.040)
2025-06-02 03:46:23,438 - train - INFO - Test: [   0/70]  Time: 4.618 (4.618)  Loss:  1.2490 (1.2490)  Acc@1: 74.1573 (74.1573)  Acc@5: 91.8539 (91.8539)
2025-06-02 03:47:06,396 - train - INFO - Test: [  50/70]  Time: 0.121 (0.933)  Loss:  2.2012 (1.8296)  Acc@1: 57.1629 (62.0153)  Acc@5: 75.2809 (84.1788)
2025-06-02 03:47:23,225 - train - INFO - Test: [  70/70]  Time: 0.034 (0.907)  Loss:  2.4980 (1.9002)  Acc@1: 42.5000 (60.4100)  Acc@5: 73.7500 (82.7320)
2025-06-02 03:47:28,216 - train - INFO - Train: 216 [   0/224 (  0%)]  Loss:  3.165987 (3.1660)  Time: 4.682s, 1216.56/s  (4.682s, 1216.56/s)  LR: 1.821e-03  Data: 4.089 (4.089)
2025-06-02 03:48:09,451 - train - INFO - Train: 216 [  50/224 ( 22%)]  Loss:  3.090770 (3.1284)  Time: 0.549s, 10368.33/s  (0.900s, 6327.02/s)  LR: 1.821e-03  Data: 0.000 (0.105)
2025-06-02 03:48:51,262 - train - INFO - Train: 216 [ 100/224 ( 45%)]  Loss:  3.164753 (3.1405)  Time: 0.980s, 5810.12/s  (0.869s, 6558.31/s)  LR: 1.821e-03  Data: 0.000 (0.053)
2025-06-02 03:49:32,801 - train - INFO - Train: 216 [ 150/224 ( 67%)]  Loss:  3.171391 (3.1482)  Time: 0.551s, 10331.54/s  (0.856s, 6654.19/s)  LR: 1.821e-03  Data: 0.000 (0.036)
2025-06-02 03:50:13,878 - train - INFO - Train: 216 [ 200/224 ( 90%)]  Loss:  3.120151 (3.1426)  Time: 1.608s, 3541.63/s  (0.847s, 6721.67/s)  LR: 1.821e-03  Data: 0.000 (0.027)
2025-06-02 03:50:32,055 - train - INFO - Train: 216 [ 223/224 (100%)]  Loss:  3.131980 (3.1408)  Time: 0.545s, 10445.87/s  (0.842s, 6768.67/s)  LR: 1.821e-03  Data: 0.000 (0.024)
2025-06-02 03:50:36,803 - train - INFO - Test: [   0/70]  Time: 4.502 (4.502)  Loss:  1.2588 (1.2588)  Acc@1: 72.0506 (72.0506)  Acc@5: 93.1180 (93.1180)
2025-06-02 03:51:19,141 - train - INFO - Test: [  50/70]  Time: 0.120 (0.918)  Loss:  2.0449 (1.9410)  Acc@1: 58.5674 (58.5509)  Acc@5: 79.9157 (82.7165)
2025-06-02 03:51:35,629 - train - INFO - Test: [  70/70]  Time: 0.034 (0.892)  Loss:  2.0000 (2.0397)  Acc@1: 51.8750 (57.0120)  Acc@5: 83.7500 (81.0600)
2025-06-02 03:51:40,556 - train - INFO - Train: 217 [   0/224 (  0%)]  Loss:  3.090698 (3.0907)  Time: 4.625s, 1231.44/s  (4.625s, 1231.44/s)  LR: 1.781e-03  Data: 3.436 (3.436)
2025-06-02 03:52:21,825 - train - INFO - Train: 217 [  50/224 ( 22%)]  Loss:  3.125928 (3.1083)  Time: 0.547s, 10415.79/s  (0.900s, 6329.78/s)  LR: 1.781e-03  Data: 0.000 (0.080)
2025-06-02 03:53:03,373 - train - INFO - Train: 217 [ 100/224 ( 45%)]  Loss:  3.139029 (3.1186)  Time: 1.140s, 4997.79/s  (0.866s, 6579.34/s)  LR: 1.781e-03  Data: 0.000 (0.040)
2025-06-02 03:53:44,294 - train - INFO - Train: 217 [ 150/224 ( 67%)]  Loss:  3.125749 (3.1204)  Time: 0.547s, 10414.80/s  (0.850s, 6700.71/s)  LR: 1.781e-03  Data: 0.000 (0.027)
2025-06-02 03:54:26,008 - train - INFO - Train: 217 [ 200/224 ( 90%)]  Loss:  3.139020 (3.1241)  Time: 1.271s, 4482.55/s  (0.846s, 6731.91/s)  LR: 1.781e-03  Data: 0.000 (0.020)
2025-06-02 03:54:44,551 - train - INFO - Train: 217 [ 223/224 (100%)]  Loss:  3.156847 (3.1295)  Time: 0.545s, 10445.04/s  (0.842s, 6764.70/s)  LR: 1.781e-03  Data: 0.000 (0.018)
2025-06-02 03:54:49,219 - train - INFO - Test: [   0/70]  Time: 4.425 (4.425)  Loss:  1.0117 (1.0117)  Acc@1: 74.0695 (74.0695)  Acc@5: 92.1875 (92.1875)
2025-06-02 03:55:30,953 - train - INFO - Test: [  50/70]  Time: 0.121 (0.905)  Loss:  1.7402 (1.6379)  Acc@1: 62.0260 (61.8904)  Acc@5: 80.7760 (84.1516)
2025-06-02 03:55:47,088 - train - INFO - Test: [  70/70]  Time: 0.034 (0.877)  Loss:  1.6660 (1.7351)  Acc@1: 50.7031 (60.1485)  Acc@5: 87.1875 (82.5815)
2025-06-02 03:55:52,033 - train - INFO - Train: 218 [   0/224 (  0%)]  Loss:  3.132675 (3.1327)  Time: 4.630s, 1230.27/s  (4.630s, 1230.27/s)  LR: 1.741e-03  Data: 3.835 (3.835)
2025-06-02 03:56:32,751 - train - INFO - Train: 218 [  50/224 ( 22%)]  Loss:  3.115518 (3.1241)  Time: 0.549s, 10375.60/s  (0.889s, 6406.24/s)  LR: 1.741e-03  Data: 0.000 (0.161)
2025-06-02 03:57:13,800 - train - INFO - Train: 218 [ 100/224 ( 45%)]  Loss:  3.139422 (3.1292)  Time: 0.549s, 10382.62/s  (0.855s, 6659.20/s)  LR: 1.741e-03  Data: 0.000 (0.081)
2025-06-02 03:57:55,303 - train - INFO - Train: 218 [ 150/224 ( 67%)]  Loss:  3.138537 (3.1315)  Time: 0.549s, 10366.93/s  (0.847s, 6725.19/s)  LR: 1.741e-03  Data: 0.000 (0.054)
2025-06-02 03:58:35,075 - train - INFO - Train: 218 [ 200/224 ( 90%)]  Loss:  3.132372 (3.1317)  Time: 0.551s, 10329.38/s  (0.834s, 6828.68/s)  LR: 1.741e-03  Data: 0.000 (0.041)
2025-06-02 03:58:53,941 - train - INFO - Train: 218 [ 223/224 (100%)]  Loss:  3.157776 (3.1361)  Time: 0.547s, 10418.62/s  (0.833s, 6840.50/s)  LR: 1.741e-03  Data: 0.000 (0.037)
2025-06-02 03:58:58,795 - train - INFO - Test: [   0/70]  Time: 4.595 (4.595)  Loss:  1.5137 (1.5137)  Acc@1: 69.5225 (69.5225)  Acc@5: 91.0112 (91.0112)
2025-06-02 03:59:42,144 - train - INFO - Test: [  50/70]  Time: 0.120 (0.940)  Loss:  1.9355 (1.9452)  Acc@1: 59.5506 (59.3220)  Acc@5: 83.1461 (82.9671)
2025-06-02 03:59:59,719 - train - INFO - Test: [  70/70]  Time: 0.035 (0.923)  Loss:  2.5449 (2.0312)  Acc@1: 44.3750 (57.8560)  Acc@5: 76.2500 (81.5600)
2025-06-02 04:00:04,650 - train - INFO - Train: 219 [   0/224 (  0%)]  Loss:  3.133186 (3.1332)  Time: 4.605s, 1237.04/s  (4.605s, 1237.04/s)  LR: 1.702e-03  Data: 4.048 (4.048)
2025-06-02 04:00:45,734 - train - INFO - Train: 219 [  50/224 ( 22%)]  Loss:  3.118344 (3.1258)  Time: 0.549s, 10371.34/s  (0.896s, 6358.64/s)  LR: 1.702e-03  Data: 0.000 (0.136)
2025-06-02 04:01:27,950 - train - INFO - Train: 219 [ 100/224 ( 45%)]  Loss:  3.172399 (3.1413)  Time: 1.700s, 3350.97/s  (0.870s, 6544.94/s)  LR: 1.702e-03  Data: 0.000 (0.069)
2025-06-02 04:02:09,575 - train - INFO - Train: 219 [ 150/224 ( 67%)]  Loss:  3.112925 (3.1342)  Time: 0.550s, 10364.62/s  (0.858s, 6640.49/s)  LR: 1.702e-03  Data: 0.000 (0.046)
2025-06-02 04:02:51,168 - train - INFO - Train: 219 [ 200/224 ( 90%)]  Loss:  3.124306 (3.1322)  Time: 1.716s, 3320.10/s  (0.851s, 6690.85/s)  LR: 1.702e-03  Data: 0.000 (0.035)
2025-06-02 04:03:08,943 - train - INFO - Train: 219 [ 223/224 (100%)]  Loss:  3.128089 (3.1315)  Time: 0.546s, 10432.80/s  (0.843s, 6754.89/s)  LR: 1.702e-03  Data: 0.000 (0.031)
2025-06-02 04:03:13,908 - train - INFO - Test: [   0/70]  Time: 4.718 (4.718)  Loss:  1.6934 (1.6934)  Acc@1: 70.1018 (70.1018)  Acc@5: 89.4312 (89.4312)
2025-06-02 04:03:56,527 - train - INFO - Test: [  50/70]  Time: 0.120 (0.928)  Loss:  2.2227 (2.0284)  Acc@1: 55.4775 (60.7661)  Acc@5: 80.8462 (83.6225)
2025-06-02 04:04:13,106 - train - INFO - Test: [  70/70]  Time: 0.034 (0.900)  Loss:  2.2695 (2.0754)  Acc@1: 53.6719 (59.4190)  Acc@5: 78.3594 (82.3753)
2025-06-02 04:04:18,183 - train - INFO - Train: 220 [   0/224 (  0%)]  Loss:  3.157442 (3.1574)  Time: 4.769s, 1194.44/s  (4.769s, 1194.44/s)  LR: 1.663e-03  Data: 3.763 (3.763)
2025-06-02 04:04:59,863 - train - INFO - Train: 220 [  50/224 ( 22%)]  Loss:  3.135456 (3.1464)  Time: 0.548s, 10395.76/s  (0.911s, 6254.38/s)  LR: 1.663e-03  Data: 0.000 (0.090)
2025-06-02 04:05:41,588 - train - INFO - Train: 220 [ 100/224 ( 45%)]  Loss:  3.129225 (3.1407)  Time: 1.711s, 3329.75/s  (0.873s, 6524.77/s)  LR: 1.663e-03  Data: 0.000 (0.045)
2025-06-02 04:06:22,194 - train - INFO - Train: 220 [ 150/224 ( 67%)]  Loss:  3.142073 (3.1410)  Time: 0.551s, 10345.09/s  (0.853s, 6679.05/s)  LR: 1.663e-03  Data: 0.000 (0.030)
2025-06-02 04:07:03,543 - train - INFO - Train: 220 [ 200/224 ( 90%)]  Loss:  3.134344 (3.1397)  Time: 1.020s, 5586.14/s  (0.846s, 6729.81/s)  LR: 1.663e-03  Data: 0.000 (0.023)
2025-06-02 04:07:22,180 - train - INFO - Train: 220 [ 223/224 (100%)]  Loss:  3.155443 (3.1423)  Time: 0.547s, 10419.53/s  (0.843s, 6759.41/s)  LR: 1.663e-03  Data: 0.000 (0.021)
2025-06-02 04:07:27,003 - train - INFO - Test: [   0/70]  Time: 4.583 (4.583)  Loss:  1.4932 (1.4932)  Acc@1: 72.0506 (72.0506)  Acc@5: 89.0449 (89.0449)
2025-06-02 04:08:09,048 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  1.8975 (1.9568)  Acc@1: 60.2528 (60.0022)  Acc@5: 82.7247 (82.9285)
2025-06-02 04:08:25,565 - train - INFO - Test: [  70/70]  Time: 0.034 (0.889)  Loss:  2.1738 (2.0063)  Acc@1: 45.6250 (58.4560)  Acc@5: 80.0000 (81.7980)
2025-06-02 04:08:30,525 - train - INFO - Train: 221 [   0/224 (  0%)]  Loss:  3.149274 (3.1493)  Time: 4.651s, 1224.80/s  (4.651s, 1224.80/s)  LR: 1.624e-03  Data: 3.686 (3.686)
2025-06-02 04:09:12,617 - train - INFO - Train: 221 [  50/224 ( 22%)]  Loss:  3.106165 (3.1277)  Time: 0.550s, 10359.39/s  (0.916s, 6214.95/s)  LR: 1.624e-03  Data: 0.000 (0.098)
2025-06-02 04:09:54,376 - train - INFO - Train: 221 [ 100/224 ( 45%)]  Loss:  3.063850 (3.1064)  Time: 1.750s, 3254.45/s  (0.876s, 6500.57/s)  LR: 1.624e-03  Data: 0.000 (0.049)
2025-06-02 04:10:35,107 - train - INFO - Train: 221 [ 150/224 ( 67%)]  Loss:  3.162646 (3.1205)  Time: 0.555s, 10257.11/s  (0.856s, 6655.63/s)  LR: 1.624e-03  Data: 0.000 (0.033)
2025-06-02 04:11:17,042 - train - INFO - Train: 221 [ 200/224 ( 90%)]  Loss:  3.113317 (3.1191)  Time: 1.604s, 3550.97/s  (0.852s, 6688.97/s)  LR: 1.624e-03  Data: 0.000 (0.025)
2025-06-02 04:11:35,053 - train - INFO - Train: 221 [ 223/224 (100%)]  Loss:  3.143444 (3.1231)  Time: 0.736s, 7738.91/s  (0.845s, 6744.68/s)  LR: 1.624e-03  Data: 0.000 (0.022)
2025-06-02 04:11:40,012 - train - INFO - Test: [   0/70]  Time: 4.718 (4.718)  Loss:  1.3613 (1.3613)  Acc@1: 71.5239 (71.5239)  Acc@5: 90.6075 (90.6075)
2025-06-02 04:12:22,035 - train - INFO - Test: [  50/70]  Time: 0.120 (0.916)  Loss:  1.9482 (1.8777)  Acc@1: 58.8834 (60.4397)  Acc@5: 81.5134 (83.4703)
2025-06-02 04:12:38,513 - train - INFO - Test: [  70/70]  Time: 0.034 (0.890)  Loss:  2.5859 (1.9590)  Acc@1: 44.2188 (58.7257)  Acc@5: 74.3750 (82.0060)
2025-06-02 04:12:43,532 - train - INFO - Train: 222 [   0/224 (  0%)]  Loss:  3.151531 (3.1515)  Time: 4.710s, 1209.30/s  (4.710s, 1209.30/s)  LR: 1.586e-03  Data: 4.167 (4.167)
2025-06-02 04:13:23,739 - train - INFO - Train: 222 [  50/224 ( 22%)]  Loss:  3.128789 (3.1402)  Time: 0.551s, 10342.78/s  (0.881s, 6467.42/s)  LR: 1.586e-03  Data: 0.000 (0.236)
2025-06-02 04:14:06,458 - train - INFO - Train: 222 [ 100/224 ( 45%)]  Loss:  3.138381 (3.1396)  Time: 1.637s, 3480.00/s  (0.868s, 6564.77/s)  LR: 1.586e-03  Data: 0.000 (0.122)
2025-06-02 04:14:46,861 - train - INFO - Train: 222 [ 150/224 ( 67%)]  Loss:  3.103365 (3.1305)  Time: 0.550s, 10349.43/s  (0.848s, 6717.65/s)  LR: 1.586e-03  Data: 0.000 (0.081)
2025-06-02 04:15:26,954 - train - INFO - Train: 222 [ 200/224 ( 90%)]  Loss:  3.117521 (3.1279)  Time: 1.620s, 3515.09/s  (0.836s, 6809.70/s)  LR: 1.586e-03  Data: 0.000 (0.061)
2025-06-02 04:15:44,833 - train - INFO - Train: 222 [ 223/224 (100%)]  Loss:  3.155758 (3.1326)  Time: 0.546s, 10439.56/s  (0.830s, 6859.50/s)  LR: 1.586e-03  Data: 0.000 (0.055)
2025-06-02 04:15:49,882 - train - INFO - Test: [   0/70]  Time: 4.816 (4.816)  Loss:  1.0615 (1.0615)  Acc@1: 74.0169 (74.0169)  Acc@5: 92.4157 (92.4157)
2025-06-02 04:16:32,567 - train - INFO - Test: [  50/70]  Time: 0.782 (0.931)  Loss:  1.6709 (1.6658)  Acc@1: 63.0618 (61.8198)  Acc@5: 81.6011 (84.4074)
2025-06-02 04:16:48,381 - train - INFO - Test: [  70/70]  Time: 0.034 (0.892)  Loss:  1.8535 (1.7311)  Acc@1: 48.1250 (60.5620)  Acc@5: 82.5000 (83.2480)
2025-06-02 04:16:53,625 - train - INFO - Train: 223 [   0/224 (  0%)]  Loss:  3.140537 (3.1405)  Time: 4.915s, 1158.81/s  (4.915s, 1158.81/s)  LR: 1.548e-03  Data: 3.648 (3.648)
2025-06-02 04:17:34,960 - train - INFO - Train: 223 [  50/224 ( 22%)]  Loss:  3.148176 (3.1444)  Time: 0.554s, 10278.36/s  (0.907s, 6281.11/s)  LR: 1.548e-03  Data: 0.000 (0.082)
2025-06-02 04:18:16,656 - train - INFO - Train: 223 [ 100/224 ( 45%)]  Loss:  3.138572 (3.1424)  Time: 1.658s, 3436.01/s  (0.871s, 6541.71/s)  LR: 1.548e-03  Data: 0.000 (0.042)
2025-06-02 04:18:57,331 - train - INFO - Train: 223 [ 150/224 ( 67%)]  Loss:  3.122074 (3.1373)  Time: 0.550s, 10363.12/s  (0.852s, 6687.33/s)  LR: 1.548e-03  Data: 0.000 (0.028)
2025-06-02 04:19:39,806 - train - INFO - Train: 223 [ 200/224 ( 90%)]  Loss:  3.174417 (3.1448)  Time: 1.566s, 3636.48/s  (0.851s, 6691.76/s)  LR: 1.548e-03  Data: 0.000 (0.021)
2025-06-02 04:19:57,745 - train - INFO - Train: 223 [ 223/224 (100%)]  Loss:  3.112324 (3.1394)  Time: 0.546s, 10439.27/s  (0.844s, 6749.82/s)  LR: 1.548e-03  Data: 0.000 (0.019)
2025-06-02 04:20:03,012 - train - INFO - Test: [   0/70]  Time: 5.012 (5.012)  Loss:  1.2041 (1.2041)  Acc@1: 73.4551 (73.4551)  Acc@5: 90.3090 (90.3090)
2025-06-02 04:20:44,441 - train - INFO - Test: [  50/70]  Time: 0.120 (0.911)  Loss:  1.8750 (1.6751)  Acc@1: 58.5674 (62.0263)  Acc@5: 80.8989 (84.4046)
2025-06-02 04:21:01,118 - train - INFO - Test: [  70/70]  Time: 0.035 (0.889)  Loss:  2.1699 (1.7567)  Acc@1: 47.5000 (60.4520)  Acc@5: 81.2500 (83.0640)
2025-06-02 04:21:06,148 - train - INFO - Train: 224 [   0/224 (  0%)]  Loss:  3.102838 (3.1028)  Time: 4.710s, 1209.37/s  (4.710s, 1209.37/s)  LR: 1.510e-03  Data: 4.166 (4.166)
2025-06-02 04:21:47,011 - train - INFO - Train: 224 [  50/224 ( 22%)]  Loss:  3.101489 (3.1022)  Time: 0.548s, 10395.41/s  (0.893s, 6375.00/s)  LR: 1.510e-03  Data: 0.000 (0.341)
2025-06-02 04:22:28,678 - train - INFO - Train: 224 [ 100/224 ( 45%)]  Loss:  3.118071 (3.1075)  Time: 1.678s, 3394.19/s  (0.864s, 6595.04/s)  LR: 1.510e-03  Data: 0.467 (0.272)
2025-06-02 04:23:08,610 - train - INFO - Train: 224 [ 150/224 ( 67%)]  Loss:  3.120348 (3.1107)  Time: 0.549s, 10370.62/s  (0.842s, 6763.92/s)  LR: 1.510e-03  Data: 0.000 (0.231)
2025-06-02 04:23:49,496 - train - INFO - Train: 224 [ 200/224 ( 90%)]  Loss:  3.145009 (3.1176)  Time: 1.040s, 5477.89/s  (0.836s, 6813.15/s)  LR: 1.510e-03  Data: 0.430 (0.200)
2025-06-02 04:24:07,920 - train - INFO - Train: 224 [ 223/224 (100%)]  Loss:  3.117108 (3.1175)  Time: 0.804s, 7085.92/s  (0.832s, 6842.69/s)  LR: 1.510e-03  Data: 0.263 (0.184)
2025-06-02 04:24:12,644 - train - INFO - Test: [   0/70]  Time: 4.473 (4.473)  Loss:  1.7480 (1.7480)  Acc@1: 76.5449 (76.5449)  Acc@5: 93.8202 (93.8202)
2025-06-02 04:24:54,764 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  2.2871 (2.5544)  Acc@1: 60.3933 (58.1653)  Acc@5: 82.3034 (82.0170)
2025-06-02 04:25:10,833 - train - INFO - Test: [  70/70]  Time: 0.034 (0.883)  Loss:  3.1270 (2.6035)  Acc@1: 41.8750 (56.7740)  Acc@5: 71.8750 (80.5260)
2025-06-02 04:25:15,632 - train - INFO - Train: 225 [   0/224 (  0%)]  Loss:  3.138314 (3.1383)  Time: 4.477s, 1272.15/s  (4.477s, 1272.15/s)  LR: 1.473e-03  Data: 3.544 (3.544)
2025-06-02 04:25:56,794 - train - INFO - Train: 225 [  50/224 ( 22%)]  Loss:  3.135344 (3.1368)  Time: 0.551s, 10337.28/s  (0.895s, 6365.30/s)  LR: 1.473e-03  Data: 0.000 (0.103)
2025-06-02 04:26:38,376 - train - INFO - Train: 225 [ 100/224 ( 45%)]  Loss:  3.099635 (3.1244)  Time: 1.639s, 3476.11/s  (0.864s, 6596.06/s)  LR: 1.473e-03  Data: 0.001 (0.052)
2025-06-02 04:27:18,909 - train - INFO - Train: 225 [ 150/224 ( 67%)]  Loss:  3.134869 (3.1270)  Time: 0.551s, 10330.91/s  (0.846s, 6732.64/s)  LR: 1.473e-03  Data: 0.000 (0.035)
2025-06-02 04:27:59,861 - train - INFO - Train: 225 [ 200/224 ( 90%)]  Loss:  3.162585 (3.1341)  Time: 0.962s, 5920.96/s  (0.839s, 6786.55/s)  LR: 1.473e-03  Data: 0.000 (0.026)
2025-06-02 04:28:18,208 - train - INFO - Train: 225 [ 223/224 (100%)]  Loss:  3.109975 (3.1301)  Time: 0.555s, 10269.16/s  (0.835s, 6821.31/s)  LR: 1.473e-03  Data: 0.000 (0.024)
2025-06-02 04:28:22,950 - train - INFO - Test: [   0/70]  Time: 4.488 (4.488)  Loss:  1.1904 (1.1904)  Acc@1: 76.2640 (76.2640)  Acc@5: 92.5562 (92.5562)
2025-06-02 04:29:04,789 - train - INFO - Test: [  50/70]  Time: 0.207 (0.908)  Loss:  1.8203 (1.8690)  Acc@1: 61.6573 (60.9193)  Acc@5: 83.1461 (83.7409)
2025-06-02 04:29:20,986 - train - INFO - Test: [  70/70]  Time: 0.034 (0.881)  Loss:  2.2988 (1.9491)  Acc@1: 50.6250 (59.0540)  Acc@5: 78.1250 (82.2100)
2025-06-02 04:29:26,019 - train - INFO - Train: 226 [   0/224 (  0%)]  Loss:  3.146175 (3.1462)  Time: 4.724s, 1205.73/s  (4.724s, 1205.73/s)  LR: 1.436e-03  Data: 4.015 (4.015)
2025-06-02 04:30:07,155 - train - INFO - Train: 226 [  50/224 ( 22%)]  Loss:  3.116566 (3.1314)  Time: 0.550s, 10348.81/s  (0.899s, 6334.54/s)  LR: 1.436e-03  Data: 0.000 (0.249)
2025-06-02 04:30:49,000 - train - INFO - Train: 226 [ 100/224 ( 45%)]  Loss:  3.127910 (3.1302)  Time: 1.639s, 3475.69/s  (0.868s, 6559.61/s)  LR: 1.436e-03  Data: 0.010 (0.187)
2025-06-02 04:31:29,838 - train - INFO - Train: 226 [ 150/224 ( 67%)]  Loss:  3.134439 (3.1313)  Time: 0.549s, 10373.25/s  (0.851s, 6691.31/s)  LR: 1.436e-03  Data: 0.000 (0.125)
2025-06-02 04:32:11,502 - train - INFO - Train: 226 [ 200/224 ( 90%)]  Loss:  3.118586 (3.1287)  Time: 1.554s, 3665.07/s  (0.847s, 6726.69/s)  LR: 1.436e-03  Data: 0.000 (0.094)
2025-06-02 04:32:29,255 - train - INFO - Train: 226 [ 223/224 (100%)]  Loss:  3.114389 (3.1263)  Time: 0.546s, 10437.54/s  (0.839s, 6788.38/s)  LR: 1.436e-03  Data: 0.000 (0.085)
2025-06-02 04:32:34,188 - train - INFO - Test: [   0/70]  Time: 4.697 (4.697)  Loss:  1.3076 (1.3076)  Acc@1: 72.1910 (72.1910)  Acc@5: 91.2921 (91.2921)
2025-06-02 04:33:17,191 - train - INFO - Test: [  50/70]  Time: 0.120 (0.935)  Loss:  1.9072 (1.7680)  Acc@1: 59.4101 (61.2855)  Acc@5: 81.6011 (83.9172)
2025-06-02 04:33:33,838 - train - INFO - Test: [  70/70]  Time: 0.035 (0.906)  Loss:  2.0762 (1.8530)  Acc@1: 57.5000 (59.6920)  Acc@5: 79.3750 (82.4960)
2025-06-02 04:33:38,856 - train - INFO - Train: 227 [   0/224 (  0%)]  Loss:  3.144657 (3.1447)  Time: 4.720s, 1206.69/s  (4.720s, 1206.69/s)  LR: 1.400e-03  Data: 4.178 (4.178)
2025-06-02 04:34:19,651 - train - INFO - Train: 227 [  50/224 ( 22%)]  Loss:  3.101487 (3.1231)  Time: 0.552s, 10326.33/s  (0.892s, 6382.48/s)  LR: 1.400e-03  Data: 0.000 (0.328)
2025-06-02 04:35:01,121 - train - INFO - Train: 227 [ 100/224 ( 45%)]  Loss:  3.089975 (3.1120)  Time: 1.478s, 3854.95/s  (0.861s, 6613.85/s)  LR: 1.400e-03  Data: 0.266 (0.266)
2025-06-02 04:35:41,356 - train - INFO - Train: 227 [ 150/224 ( 67%)]  Loss:  3.114487 (3.1127)  Time: 0.555s, 10255.48/s  (0.842s, 6760.86/s)  LR: 1.400e-03  Data: 0.000 (0.180)
2025-06-02 04:36:23,871 - train - INFO - Train: 227 [ 200/224 ( 90%)]  Loss:  3.119153 (3.1140)  Time: 1.573s, 3621.50/s  (0.844s, 6745.36/s)  LR: 1.400e-03  Data: 0.000 (0.135)
2025-06-02 04:36:41,754 - train - INFO - Train: 227 [ 223/224 (100%)]  Loss:  3.147379 (3.1195)  Time: 0.547s, 10419.37/s  (0.838s, 6800.72/s)  LR: 1.400e-03  Data: 0.000 (0.122)
2025-06-02 04:36:46,493 - train - INFO - Test: [   0/70]  Time: 4.506 (4.506)  Loss:  1.4775 (1.4775)  Acc@1: 69.2416 (69.2416)  Acc@5: 88.3427 (88.3427)
2025-06-02 04:37:28,933 - train - INFO - Test: [  50/70]  Time: 0.120 (0.920)  Loss:  1.9990 (1.7267)  Acc@1: 56.6011 (61.6959)  Acc@5: 78.7921 (84.4211)
2025-06-02 04:37:45,922 - train - INFO - Test: [  70/70]  Time: 0.035 (0.900)  Loss:  2.1113 (1.8062)  Acc@1: 50.6250 (60.3360)  Acc@5: 80.6250 (83.1280)
2025-06-02 04:37:50,918 - train - INFO - Train: 228 [   0/224 (  0%)]  Loss:  3.157689 (3.1577)  Time: 4.701s, 1211.54/s  (4.701s, 1211.54/s)  LR: 1.364e-03  Data: 3.828 (3.828)
2025-06-02 04:38:31,331 - train - INFO - Train: 228 [  50/224 ( 22%)]  Loss:  3.153409 (3.1555)  Time: 0.549s, 10383.99/s  (0.885s, 6439.43/s)  LR: 1.364e-03  Data: 0.000 (0.303)
2025-06-02 04:39:13,598 - train - INFO - Train: 228 [ 100/224 ( 45%)]  Loss:  3.113691 (3.1416)  Time: 1.688s, 3373.92/s  (0.865s, 6584.00/s)  LR: 1.364e-03  Data: 0.185 (0.229)
2025-06-02 04:39:54,988 - train - INFO - Train: 228 [ 150/224 ( 67%)]  Loss:  3.099222 (3.1310)  Time: 0.557s, 10235.03/s  (0.853s, 6679.49/s)  LR: 1.364e-03  Data: 0.000 (0.156)
2025-06-02 04:40:36,857 - train - INFO - Train: 228 [ 200/224 ( 90%)]  Loss:  3.157620 (3.1363)  Time: 1.582s, 3600.31/s  (0.849s, 6709.60/s)  LR: 1.364e-03  Data: 0.000 (0.117)
2025-06-02 04:40:54,655 - train - INFO - Train: 228 [ 223/224 (100%)]  Loss:  3.114585 (3.1327)  Time: 0.545s, 10451.63/s  (0.841s, 6771.15/s)  LR: 1.364e-03  Data: 0.000 (0.105)
2025-06-02 04:40:59,483 - train - INFO - Test: [   0/70]  Time: 4.578 (4.578)  Loss:  1.4600 (1.4600)  Acc@1: 72.3315 (72.3315)  Acc@5: 90.1685 (90.1685)
2025-06-02 04:41:41,317 - train - INFO - Test: [  50/70]  Time: 0.154 (0.910)  Loss:  2.0293 (1.8935)  Acc@1: 61.6573 (60.2225)  Acc@5: 79.9157 (83.0497)
2025-06-02 04:41:58,149 - train - INFO - Test: [  70/70]  Time: 0.035 (0.891)  Loss:  2.2832 (1.9529)  Acc@1: 47.5000 (59.0760)  Acc@5: 81.8750 (82.1020)
2025-06-02 04:42:03,235 - train - INFO - Train: 229 [   0/224 (  0%)]  Loss:  3.148685 (3.1487)  Time: 4.785s, 1190.50/s  (4.785s, 1190.50/s)  LR: 1.328e-03  Data: 3.742 (3.742)
2025-06-02 04:42:44,447 - train - INFO - Train: 229 [  50/224 ( 22%)]  Loss:  3.114336 (3.1315)  Time: 0.549s, 10369.99/s  (0.902s, 6315.74/s)  LR: 1.328e-03  Data: 0.000 (0.108)
2025-06-02 04:43:26,882 - train - INFO - Train: 229 [ 100/224 ( 45%)]  Loss:  3.074121 (3.1124)  Time: 1.605s, 3548.03/s  (0.876s, 6505.69/s)  LR: 1.328e-03  Data: 0.000 (0.055)
2025-06-02 04:44:07,155 - train - INFO - Train: 229 [ 150/224 ( 67%)]  Loss:  3.143642 (3.1202)  Time: 0.548s, 10388.43/s  (0.852s, 6682.87/s)  LR: 1.328e-03  Data: 0.000 (0.037)
2025-06-02 04:44:48,576 - train - INFO - Train: 229 [ 200/224 ( 90%)]  Loss:  3.124867 (3.1211)  Time: 1.696s, 3359.14/s  (0.846s, 6729.91/s)  LR: 1.328e-03  Data: 0.000 (0.027)
2025-06-02 04:45:06,236 - train - INFO - Train: 229 [ 223/224 (100%)]  Loss:  3.121130 (3.1211)  Time: 0.554s, 10285.48/s  (0.838s, 6794.74/s)  LR: 1.328e-03  Data: 0.000 (0.025)
2025-06-02 04:45:11,091 - train - INFO - Test: [   0/70]  Time: 4.603 (4.603)  Loss:  1.3271 (1.3271)  Acc@1: 71.0674 (71.0674)  Acc@5: 88.3427 (88.3427)
2025-06-02 04:45:53,144 - train - INFO - Test: [  50/70]  Time: 0.124 (0.915)  Loss:  1.8135 (1.7998)  Acc@1: 59.6910 (59.5203)  Acc@5: 82.4438 (82.7302)
2025-06-02 04:46:09,572 - train - INFO - Test: [  70/70]  Time: 0.034 (0.889)  Loss:  2.7012 (1.8721)  Acc@1: 33.1250 (58.1240)  Acc@5: 72.5000 (81.5420)
2025-06-02 04:46:14,391 - train - INFO - Train: 230 [   0/224 (  0%)]  Loss:  3.163249 (3.1632)  Time: 4.505s, 1264.27/s  (4.505s, 1264.27/s)  LR: 1.293e-03  Data: 3.705 (3.705)
2025-06-02 04:46:55,942 - train - INFO - Train: 230 [  50/224 ( 22%)]  Loss:  3.133756 (3.1485)  Time: 0.550s, 10353.71/s  (0.903s, 6307.45/s)  LR: 1.293e-03  Data: 0.000 (0.348)
2025-06-02 04:47:38,213 - train - INFO - Train: 230 [ 100/224 ( 45%)]  Loss:  3.133343 (3.1434)  Time: 1.516s, 3758.23/s  (0.875s, 6513.31/s)  LR: 1.293e-03  Data: 0.967 (0.321)
2025-06-02 04:48:19,436 - train - INFO - Train: 230 [ 150/224 ( 67%)]  Loss:  3.128875 (3.1398)  Time: 0.557s, 10234.24/s  (0.858s, 6639.24/s)  LR: 1.293e-03  Data: 0.000 (0.305)
2025-06-02 04:49:00,203 - train - INFO - Train: 230 [ 200/224 ( 90%)]  Loss:  3.127161 (3.1373)  Time: 1.517s, 3755.38/s  (0.847s, 6722.28/s)  LR: 1.293e-03  Data: 0.968 (0.294)
2025-06-02 04:49:18,164 - train - INFO - Train: 230 [ 223/224 (100%)]  Loss:  3.166924 (3.1422)  Time: 0.544s, 10471.48/s  (0.840s, 6776.92/s)  LR: 1.293e-03  Data: 0.000 (0.288)
2025-06-02 04:49:23,077 - train - INFO - Test: [   0/70]  Time: 4.679 (4.679)  Loss:  1.3379 (1.3379)  Acc@1: 71.3483 (71.3483)  Acc@5: 89.3259 (89.3259)
2025-06-02 04:50:05,312 - train - INFO - Test: [  50/70]  Time: 0.120 (0.920)  Loss:  1.7051 (1.7804)  Acc@1: 63.3427 (61.5609)  Acc@5: 83.0056 (84.0852)
2025-06-02 04:50:21,907 - train - INFO - Test: [  70/70]  Time: 0.035 (0.894)  Loss:  2.1387 (1.8341)  Acc@1: 43.7500 (60.3960)  Acc@5: 80.6250 (82.9260)
2025-06-02 04:50:26,917 - train - INFO - Train: 231 [   0/224 (  0%)]  Loss:  3.067681 (3.0677)  Time: 4.695s, 1213.10/s  (4.695s, 1213.10/s)  LR: 1.258e-03  Data: 3.606 (3.606)
2025-06-02 04:51:07,829 - train - INFO - Train: 231 [  50/224 ( 22%)]  Loss:  3.115479 (3.0916)  Time: 0.551s, 10332.08/s  (0.894s, 6369.62/s)  LR: 1.258e-03  Data: 0.000 (0.283)
2025-06-02 04:51:49,765 - train - INFO - Train: 231 [ 100/224 ( 45%)]  Loss:  3.099813 (3.0943)  Time: 1.837s, 3101.09/s  (0.867s, 6571.70/s)  LR: 1.258e-03  Data: 0.365 (0.206)
2025-06-02 04:52:30,227 - train - INFO - Train: 231 [ 150/224 ( 67%)]  Loss:  3.135261 (3.1046)  Time: 0.548s, 10400.43/s  (0.848s, 6719.42/s)  LR: 1.258e-03  Data: 0.000 (0.145)
2025-06-02 04:53:11,900 - train - INFO - Train: 231 [ 200/224 ( 90%)]  Loss:  3.127354 (3.1091)  Time: 1.503s, 3788.92/s  (0.844s, 6747.72/s)  LR: 1.258e-03  Data: 0.000 (0.109)
2025-06-02 04:53:30,073 - train - INFO - Train: 231 [ 223/224 (100%)]  Loss:  3.134238 (3.1133)  Time: 0.554s, 10285.35/s  (0.839s, 6792.37/s)  LR: 1.258e-03  Data: 0.000 (0.098)
2025-06-02 04:53:34,846 - train - INFO - Test: [   0/70]  Time: 4.508 (4.508)  Loss:  1.0508 (1.0508)  Acc@1: 77.2472 (77.2472)  Acc@5: 92.9775 (92.9775)
2025-06-02 04:54:17,164 - train - INFO - Test: [  50/70]  Time: 0.149 (0.918)  Loss:  1.8057 (1.6107)  Acc@1: 61.2360 (63.4997)  Acc@5: 83.2865 (85.2611)
2025-06-02 04:54:34,015 - train - INFO - Test: [  70/70]  Time: 0.035 (0.897)  Loss:  2.1973 (1.6964)  Acc@1: 51.8750 (61.8720)  Acc@5: 78.1250 (83.9780)
2025-06-02 04:54:39,021 - train - INFO - Train: 232 [   0/224 (  0%)]  Loss:  3.132370 (3.1324)  Time: 4.705s, 1210.75/s  (4.705s, 1210.75/s)  LR: 1.224e-03  Data: 4.152 (4.152)
2025-06-02 04:55:19,381 - train - INFO - Train: 232 [  50/224 ( 22%)]  Loss:  3.141554 (3.1370)  Time: 0.555s, 10264.43/s  (0.884s, 6446.37/s)  LR: 1.224e-03  Data: 0.000 (0.265)
2025-06-02 04:56:00,494 - train - INFO - Train: 232 [ 100/224 ( 45%)]  Loss:  3.103345 (3.1258)  Time: 1.521s, 3744.88/s  (0.853s, 6675.89/s)  LR: 1.224e-03  Data: 0.228 (0.184)
2025-06-02 04:56:40,411 - train - INFO - Train: 232 [ 150/224 ( 67%)]  Loss:  3.119347 (3.1242)  Time: 0.638s, 8926.91/s  (0.835s, 6821.27/s)  LR: 1.224e-03  Data: 0.000 (0.131)
2025-06-02 04:57:21,252 - train - INFO - Train: 232 [ 200/224 ( 90%)]  Loss:  3.152649 (3.1299)  Time: 0.657s, 8668.04/s  (0.830s, 6858.54/s)  LR: 1.224e-03  Data: 0.000 (0.100)
2025-06-02 04:57:40,270 - train - INFO - Train: 232 [ 223/224 (100%)]  Loss:  3.125817 (3.1292)  Time: 0.546s, 10438.03/s  (0.830s, 6861.62/s)  LR: 1.224e-03  Data: 0.000 (0.090)
2025-06-02 04:57:45,071 - train - INFO - Test: [   0/70]  Time: 4.551 (4.551)  Loss:  1.3086 (1.3086)  Acc@1: 74.7191 (74.7191)  Acc@5: 91.5730 (91.5730)
2025-06-02 04:58:27,294 - train - INFO - Test: [  50/70]  Time: 0.120 (0.917)  Loss:  1.9043 (1.7832)  Acc@1: 60.3933 (61.9850)  Acc@5: 81.0393 (84.1870)
2025-06-02 04:58:43,840 - train - INFO - Test: [  70/70]  Time: 0.034 (0.892)  Loss:  2.0957 (1.8768)  Acc@1: 46.8750 (60.0980)  Acc@5: 81.2500 (82.5320)
2025-06-02 04:58:48,910 - train - INFO - Train: 233 [   0/224 (  0%)]  Loss:  3.146615 (3.1466)  Time: 4.770s, 1194.08/s  (4.770s, 1194.08/s)  LR: 1.190e-03  Data: 3.755 (3.755)
2025-06-02 04:59:29,501 - train - INFO - Train: 233 [  50/224 ( 22%)]  Loss:  3.115488 (3.1311)  Time: 0.550s, 10363.81/s  (0.889s, 6404.19/s)  LR: 1.190e-03  Data: 0.000 (0.118)
2025-06-02 05:00:11,023 - train - INFO - Train: 233 [ 100/224 ( 45%)]  Loss:  3.100481 (3.1209)  Time: 1.580s, 3604.09/s  (0.860s, 6621.69/s)  LR: 1.190e-03  Data: 0.000 (0.060)
2025-06-02 05:00:52,090 - train - INFO - Train: 233 [ 150/224 ( 67%)]  Loss:  3.122902 (3.1214)  Time: 1.582s, 3599.79/s  (0.847s, 6722.37/s)  LR: 1.190e-03  Data: 0.000 (0.040)
2025-06-02 05:01:32,497 - train - INFO - Train: 233 [ 200/224 ( 90%)]  Loss:  3.152973 (3.1277)  Time: 0.582s, 9790.33/s  (0.838s, 6800.67/s)  LR: 1.190e-03  Data: 0.000 (0.030)
2025-06-02 05:01:50,738 - train - INFO - Train: 233 [ 223/224 (100%)]  Loss:  3.153366 (3.1320)  Time: 0.553s, 10300.60/s  (0.833s, 6838.03/s)  LR: 1.190e-03  Data: 0.000 (0.027)
2025-06-02 05:01:55,503 - train - INFO - Test: [   0/70]  Time: 4.513 (4.513)  Loss:  1.5449 (1.5449)  Acc@1: 74.4382 (74.4382)  Acc@5: 92.1348 (92.1348)
2025-06-02 05:02:37,642 - train - INFO - Test: [  50/70]  Time: 0.120 (0.915)  Loss:  2.0234 (2.0671)  Acc@1: 60.5337 (60.8036)  Acc@5: 82.8652 (83.7712)
2025-06-02 05:02:54,155 - train - INFO - Test: [  70/70]  Time: 0.035 (0.890)  Loss:  2.7988 (2.0967)  Acc@1: 38.1250 (59.5200)  Acc@5: 71.8750 (82.6100)
2025-06-02 05:02:59,412 - train - INFO - Train: 234 [   0/224 (  0%)]  Loss:  3.124461 (3.1245)  Time: 4.952s, 1150.33/s  (4.952s, 1150.33/s)  LR: 1.156e-03  Data: 3.929 (3.929)
2025-06-02 05:03:40,402 - train - INFO - Train: 234 [  50/224 ( 22%)]  Loss:  3.144588 (3.1345)  Time: 0.550s, 10355.26/s  (0.901s, 6323.32/s)  LR: 1.156e-03  Data: 0.000 (0.112)
2025-06-02 05:04:21,760 - train - INFO - Train: 234 [ 100/224 ( 45%)]  Loss:  3.156627 (3.1419)  Time: 1.551s, 3673.25/s  (0.864s, 6590.09/s)  LR: 1.156e-03  Data: 0.000 (0.057)
2025-06-02 05:05:01,827 - train - INFO - Train: 234 [ 150/224 ( 67%)]  Loss:  3.145808 (3.1429)  Time: 0.550s, 10355.00/s  (0.843s, 6753.16/s)  LR: 1.156e-03  Data: 0.000 (0.038)
2025-06-02 05:05:42,926 - train - INFO - Train: 234 [ 200/224 ( 90%)]  Loss:  3.153070 (3.1449)  Time: 1.552s, 3670.33/s  (0.838s, 6796.23/s)  LR: 1.156e-03  Data: 0.000 (0.029)
2025-06-02 05:06:00,766 - train - INFO - Train: 234 [ 223/224 (100%)]  Loss:  3.153966 (3.1464)  Time: 0.552s, 10310.10/s  (0.832s, 6848.70/s)  LR: 1.156e-03  Data: 0.000 (0.026)
2025-06-02 05:06:05,762 - train - INFO - Test: [   0/70]  Time: 4.750 (4.750)  Loss:  1.1865 (1.1865)  Acc@1: 75.9831 (75.9831)  Acc@5: 91.0112 (91.0112)
2025-06-02 05:06:47,577 - train - INFO - Test: [  50/70]  Time: 0.123 (0.913)  Loss:  1.7979 (1.7769)  Acc@1: 62.3596 (61.8033)  Acc@5: 82.3034 (84.2697)
2025-06-02 05:07:04,072 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.9688 (1.8636)  Acc@1: 45.0000 (60.2120)  Acc@5: 65.0000 (82.8640)
2025-06-02 05:07:09,093 - train - INFO - Train: 235 [   0/224 (  0%)]  Loss:  3.137566 (3.1376)  Time: 4.708s, 1209.91/s  (4.708s, 1209.91/s)  LR: 1.123e-03  Data: 4.157 (4.157)
2025-06-02 05:07:50,172 - train - INFO - Train: 235 [  50/224 ( 22%)]  Loss:  3.126153 (3.1319)  Time: 0.557s, 10233.98/s  (0.898s, 6344.70/s)  LR: 1.123e-03  Data: 0.000 (0.159)
2025-06-02 05:08:31,579 - train - INFO - Train: 235 [ 100/224 ( 45%)]  Loss:  3.092761 (3.1188)  Time: 1.578s, 3609.37/s  (0.863s, 6598.11/s)  LR: 1.123e-03  Data: 0.000 (0.080)
2025-06-02 05:09:11,661 - train - INFO - Train: 235 [ 150/224 ( 67%)]  Loss:  3.082295 (3.1097)  Time: 0.562s, 10139.39/s  (0.843s, 6758.04/s)  LR: 1.123e-03  Data: 0.000 (0.054)
2025-06-02 05:09:53,230 - train - INFO - Train: 235 [ 200/224 ( 90%)]  Loss:  3.129557 (3.1137)  Time: 1.490s, 3821.56/s  (0.840s, 6781.08/s)  LR: 1.123e-03  Data: 0.000 (0.040)
2025-06-02 05:10:11,067 - train - INFO - Train: 235 [ 223/224 (100%)]  Loss:  3.094912 (3.1105)  Time: 0.552s, 10315.81/s  (0.833s, 6835.02/s)  LR: 1.123e-03  Data: 0.000 (0.036)
2025-06-02 05:10:15,797 - train - INFO - Test: [   0/70]  Time: 4.498 (4.498)  Loss:  1.0742 (1.0742)  Acc@1: 75.7022 (75.7022)  Acc@5: 92.9775 (92.9775)
2025-06-02 05:10:57,460 - train - INFO - Test: [  50/70]  Time: 0.121 (0.905)  Loss:  1.5947 (1.6808)  Acc@1: 66.8539 (62.0153)  Acc@5: 84.9719 (84.4872)
2025-06-02 05:11:14,034 - train - INFO - Test: [  70/70]  Time: 0.034 (0.884)  Loss:  2.1875 (1.7521)  Acc@1: 45.0000 (60.6800)  Acc@5: 78.7500 (83.3260)
2025-06-02 05:11:19,095 - train - INFO - Train: 236 [   0/224 (  0%)]  Loss:  3.105736 (3.1057)  Time: 4.752s, 1198.55/s  (4.752s, 1198.55/s)  LR: 1.090e-03  Data: 3.511 (3.511)
2025-06-02 05:11:59,572 - train - INFO - Train: 236 [  50/224 ( 22%)]  Loss:  3.142166 (3.1240)  Time: 0.831s, 6857.80/s  (0.887s, 6422.94/s)  LR: 1.090e-03  Data: 0.000 (0.111)
2025-06-02 05:12:40,628 - train - INFO - Train: 236 [ 100/224 ( 45%)]  Loss:  3.155818 (3.1346)  Time: 1.199s, 4751.54/s  (0.854s, 6667.48/s)  LR: 1.090e-03  Data: 0.000 (0.056)
2025-06-02 05:13:20,917 - train - INFO - Train: 236 [ 150/224 ( 67%)]  Loss:  3.121726 (3.1314)  Time: 0.549s, 10369.40/s  (0.838s, 6795.35/s)  LR: 1.090e-03  Data: 0.000 (0.038)
2025-06-02 05:14:02,114 - train - INFO - Train: 236 [ 200/224 ( 90%)]  Loss:  3.103929 (3.1259)  Time: 1.256s, 4534.34/s  (0.835s, 6824.30/s)  LR: 1.090e-03  Data: 0.000 (0.028)
2025-06-02 05:14:20,146 - train - INFO - Train: 236 [ 223/224 (100%)]  Loss:  3.138224 (3.1279)  Time: 0.548s, 10385.98/s  (0.829s, 6867.13/s)  LR: 1.090e-03  Data: 0.000 (0.026)
2025-06-02 05:14:25,107 - train - INFO - Test: [   0/70]  Time: 4.714 (4.714)  Loss:  1.2920 (1.2920)  Acc@1: 69.1011 (69.1011)  Acc@5: 89.6067 (89.6067)
2025-06-02 05:15:07,234 - train - INFO - Test: [  50/70]  Time: 0.120 (0.918)  Loss:  1.7568 (1.6948)  Acc@1: 61.9382 (60.7761)  Acc@5: 82.4438 (83.7574)
2025-06-02 05:15:23,491 - train - INFO - Test: [  70/70]  Time: 0.034 (0.889)  Loss:  2.3750 (1.7765)  Acc@1: 47.5000 (59.5160)  Acc@5: 74.3750 (82.4220)
2025-06-02 05:15:28,658 - train - INFO - Train: 237 [   0/224 (  0%)]  Loss:  3.166865 (3.1669)  Time: 4.839s, 1177.17/s  (4.839s, 1177.17/s)  LR: 1.058e-03  Data: 3.897 (3.897)
2025-06-02 05:16:09,468 - train - INFO - Train: 237 [  50/224 ( 22%)]  Loss:  3.134358 (3.1506)  Time: 0.552s, 10310.79/s  (0.895s, 6364.43/s)  LR: 1.058e-03  Data: 0.000 (0.173)
2025-06-02 05:16:50,480 - train - INFO - Train: 237 [ 100/224 ( 45%)]  Loss:  3.156037 (3.1524)  Time: 1.449s, 3931.35/s  (0.858s, 6638.94/s)  LR: 1.058e-03  Data: 0.000 (0.089)
2025-06-02 05:17:31,331 - train - INFO - Train: 237 [ 150/224 ( 67%)]  Loss:  3.109149 (3.1416)  Time: 0.549s, 10383.45/s  (0.844s, 6745.60/s)  LR: 1.058e-03  Data: 0.000 (0.062)
2025-06-02 05:18:11,991 - train - INFO - Train: 237 [ 200/224 ( 90%)]  Loss:  3.159297 (3.1451)  Time: 1.542s, 3694.17/s  (0.837s, 6808.27/s)  LR: 1.058e-03  Data: 0.000 (0.047)
2025-06-02 05:18:29,749 - train - INFO - Train: 237 [ 223/224 (100%)]  Loss:  3.128700 (3.1424)  Time: 0.547s, 10415.27/s  (0.830s, 6862.72/s)  LR: 1.058e-03  Data: 0.000 (0.042)
2025-06-02 05:18:34,576 - train - INFO - Test: [   0/70]  Time: 4.586 (4.586)  Loss:  1.2900 (1.2900)  Acc@1: 72.7528 (72.7528)  Acc@5: 89.4663 (89.4663)
2025-06-02 05:19:16,951 - train - INFO - Test: [  50/70]  Time: 0.212 (0.921)  Loss:  1.8926 (1.7710)  Acc@1: 60.5337 (61.3296)  Acc@5: 80.6180 (83.9364)
2025-06-02 05:19:33,325 - train - INFO - Test: [  70/70]  Time: 0.039 (0.892)  Loss:  2.9258 (1.8681)  Acc@1: 36.8750 (59.5820)  Acc@5: 65.6250 (82.3000)
2025-06-02 05:19:38,512 - train - INFO - Train: 238 [   0/224 (  0%)]  Loss:  3.129276 (3.1293)  Time: 4.881s, 1166.97/s  (4.881s, 1166.97/s)  LR: 1.026e-03  Data: 3.797 (3.797)
2025-06-02 05:20:19,096 - train - INFO - Train: 238 [  50/224 ( 22%)]  Loss:  3.118392 (3.1238)  Time: 0.549s, 10380.38/s  (0.891s, 6389.79/s)  LR: 1.026e-03  Data: 0.000 (0.184)
2025-06-02 05:21:01,374 - train - INFO - Train: 238 [ 100/224 ( 45%)]  Loss:  3.092930 (3.1135)  Time: 1.794s, 3175.11/s  (0.869s, 6556.89/s)  LR: 1.026e-03  Data: 0.000 (0.093)
2025-06-02 05:21:42,722 - train - INFO - Train: 238 [ 150/224 ( 67%)]  Loss:  3.113469 (3.1135)  Time: 0.550s, 10360.32/s  (0.855s, 6662.94/s)  LR: 1.026e-03  Data: 0.000 (0.062)
2025-06-02 05:22:24,598 - train - INFO - Train: 238 [ 200/224 ( 90%)]  Loss:  3.151097 (3.1210)  Time: 1.418s, 4015.59/s  (0.851s, 6696.82/s)  LR: 1.026e-03  Data: 0.000 (0.047)
2025-06-02 05:22:43,135 - train - INFO - Train: 238 [ 223/224 (100%)]  Loss:  3.097924 (3.1172)  Time: 0.544s, 10467.11/s  (0.846s, 6733.10/s)  LR: 1.026e-03  Data: 0.000 (0.042)
2025-06-02 05:22:47,870 - train - INFO - Test: [   0/70]  Time: 4.490 (4.490)  Loss:  1.7275 (1.7275)  Acc@1: 68.9607 (68.9607)  Acc@5: 89.3259 (89.3259)
2025-06-02 05:23:30,475 - train - INFO - Test: [  50/70]  Time: 0.120 (0.923)  Loss:  2.1309 (2.0136)  Acc@1: 57.5843 (60.8256)  Acc@5: 80.3371 (83.8648)
2025-06-02 05:23:47,211 - train - INFO - Test: [  70/70]  Time: 0.034 (0.899)  Loss:  2.4316 (2.0817)  Acc@1: 43.7500 (59.4200)  Acc@5: 76.8750 (82.5720)
2025-06-02 05:23:52,199 - train - INFO - Train: 239 [   0/224 (  0%)]  Loss:  3.107602 (3.1076)  Time: 4.677s, 1217.97/s  (4.677s, 1217.97/s)  LR: 9.949e-04  Data: 3.696 (3.696)
2025-06-02 05:24:33,478 - train - INFO - Train: 239 [  50/224 ( 22%)]  Loss:  3.152956 (3.1303)  Time: 0.550s, 10348.54/s  (0.901s, 6321.35/s)  LR: 9.949e-04  Data: 0.000 (0.129)
2025-06-02 05:25:16,485 - train - INFO - Train: 239 [ 100/224 ( 45%)]  Loss:  3.109038 (3.1232)  Time: 1.653s, 3445.28/s  (0.881s, 6466.93/s)  LR: 9.949e-04  Data: 0.000 (0.065)
2025-06-02 05:25:56,721 - train - INFO - Train: 239 [ 150/224 ( 67%)]  Loss:  3.095675 (3.1163)  Time: 0.549s, 10382.78/s  (0.856s, 6657.42/s)  LR: 9.949e-04  Data: 0.000 (0.044)
2025-06-02 05:26:38,366 - train - INFO - Train: 239 [ 200/224 ( 90%)]  Loss:  3.157228 (3.1245)  Time: 1.739s, 3274.63/s  (0.850s, 6701.70/s)  LR: 9.949e-04  Data: 0.000 (0.033)
2025-06-02 05:26:56,464 - train - INFO - Train: 239 [ 223/224 (100%)]  Loss:  3.132732 (3.1259)  Time: 0.546s, 10428.21/s  (0.843s, 6753.18/s)  LR: 9.949e-04  Data: 0.000 (0.030)
2025-06-02 05:27:01,198 - train - INFO - Test: [   0/70]  Time: 4.479 (4.479)  Loss:  1.4775 (1.4775)  Acc@1: 71.6292 (71.6292)  Acc@5: 90.4494 (90.4494)
2025-06-02 05:27:43,017 - train - INFO - Test: [  50/70]  Time: 0.120 (0.908)  Loss:  1.7832 (1.8355)  Acc@1: 62.0786 (61.8308)  Acc@5: 83.4270 (84.6359)
2025-06-02 05:27:59,303 - train - INFO - Test: [  70/70]  Time: 0.034 (0.881)  Loss:  2.3809 (1.9138)  Acc@1: 48.1250 (60.3220)  Acc@5: 78.7500 (83.0980)
2025-06-02 05:28:04,294 - train - INFO - Train: 240 [   0/224 (  0%)]  Loss:  3.174361 (3.1744)  Time: 4.672s, 1219.05/s  (4.672s, 1219.05/s)  LR: 9.640e-04  Data: 4.021 (4.021)
2025-06-02 05:28:45,422 - train - INFO - Train: 240 [  50/224 ( 22%)]  Loss:  3.118589 (3.1465)  Time: 0.550s, 10365.52/s  (0.898s, 6342.72/s)  LR: 9.640e-04  Data: 0.000 (0.341)
2025-06-02 05:29:27,393 - train - INFO - Train: 240 [ 100/224 ( 45%)]  Loss:  3.133795 (3.1422)  Time: 1.581s, 3602.61/s  (0.869s, 6554.63/s)  LR: 9.640e-04  Data: 1.034 (0.313)
2025-06-02 05:30:07,998 - train - INFO - Train: 240 [ 150/224 ( 67%)]  Loss:  3.088278 (3.1288)  Time: 0.551s, 10334.15/s  (0.850s, 6699.98/s)  LR: 9.640e-04  Data: 0.000 (0.254)
2025-06-02 05:30:50,371 - train - INFO - Train: 240 [ 200/224 ( 90%)]  Loss:  3.117599 (3.1265)  Time: 1.915s, 2973.83/s  (0.849s, 6705.29/s)  LR: 9.640e-04  Data: 0.000 (0.191)
2025-06-02 05:31:08,449 - train - INFO - Train: 240 [ 223/224 (100%)]  Loss:  3.096226 (3.1215)  Time: 0.545s, 10460.17/s  (0.843s, 6757.17/s)  LR: 9.640e-04  Data: 0.000 (0.171)
2025-06-02 05:31:13,358 - train - INFO - Test: [   0/70]  Time: 4.667 (4.667)  Loss:  1.7412 (1.7412)  Acc@1: 70.6461 (70.6461)  Acc@5: 87.5000 (87.5000)
2025-06-02 05:31:55,699 - train - INFO - Test: [  50/70]  Time: 0.120 (0.922)  Loss:  2.2012 (2.0538)  Acc@1: 55.8989 (58.7987)  Acc@5: 79.7753 (82.4466)
2025-06-02 05:32:12,494 - train - INFO - Test: [  70/70]  Time: 0.034 (0.899)  Loss:  2.6758 (2.1198)  Acc@1: 43.1250 (57.4700)  Acc@5: 75.6250 (81.2920)
2025-06-02 05:32:17,481 - train - INFO - Train: 241 [   0/224 (  0%)]  Loss:  3.098490 (3.0985)  Time: 4.674s, 1218.67/s  (4.674s, 1218.67/s)  LR: 9.334e-04  Data: 4.124 (4.124)
2025-06-02 05:32:58,385 - train - INFO - Train: 241 [  50/224 ( 22%)]  Loss:  3.146472 (3.1225)  Time: 0.552s, 10322.31/s  (0.894s, 6373.75/s)  LR: 9.334e-04  Data: 0.000 (0.148)
2025-06-02 05:33:40,161 - train - INFO - Train: 241 [ 100/224 ( 45%)]  Loss:  3.075063 (3.1067)  Time: 1.591s, 3581.23/s  (0.865s, 6585.95/s)  LR: 9.334e-04  Data: 0.000 (0.075)
2025-06-02 05:34:21,064 - train - INFO - Train: 241 [ 150/224 ( 67%)]  Loss:  3.115356 (3.1088)  Time: 0.552s, 10312.12/s  (0.849s, 6706.39/s)  LR: 9.334e-04  Data: 0.000 (0.050)
2025-06-02 05:35:02,437 - train - INFO - Train: 241 [ 200/224 ( 90%)]  Loss:  3.149226 (3.1169)  Time: 1.677s, 3397.09/s  (0.844s, 6749.73/s)  LR: 9.334e-04  Data: 0.000 (0.038)
2025-06-02 05:35:20,458 - train - INFO - Train: 241 [ 223/224 (100%)]  Loss:  3.119552 (3.1174)  Time: 0.662s, 8598.22/s  (0.838s, 6799.75/s)  LR: 9.334e-04  Data: 0.000 (0.034)
2025-06-02 05:35:25,268 - train - INFO - Test: [   0/70]  Time: 4.554 (4.554)  Loss:  1.1709 (1.1709)  Acc@1: 72.4719 (72.4719)  Acc@5: 93.1180 (93.1180)
2025-06-02 05:36:07,070 - train - INFO - Test: [  50/70]  Time: 0.120 (0.909)  Loss:  1.8262 (1.6763)  Acc@1: 62.5000 (62.6046)  Acc@5: 82.1629 (85.2335)
2025-06-02 05:36:23,365 - train - INFO - Test: [  70/70]  Time: 0.034 (0.882)  Loss:  2.7363 (1.7632)  Acc@1: 31.8750 (61.1240)  Acc@5: 71.8750 (83.9020)
2025-06-02 05:36:28,399 - train - INFO - Train: 242 [   0/224 (  0%)]  Loss:  3.132747 (3.1327)  Time: 4.717s, 1207.46/s  (4.717s, 1207.46/s)  LR: 9.034e-04  Data: 3.756 (3.756)
2025-06-02 05:37:09,193 - train - INFO - Train: 242 [  50/224 ( 22%)]  Loss:  3.126727 (3.1297)  Time: 0.551s, 10331.46/s  (0.892s, 6383.05/s)  LR: 9.034e-04  Data: 0.000 (0.233)
2025-06-02 05:37:50,908 - train - INFO - Train: 242 [ 100/224 ( 45%)]  Loss:  3.166714 (3.1421)  Time: 1.552s, 3669.42/s  (0.864s, 6595.64/s)  LR: 9.034e-04  Data: 0.000 (0.118)
2025-06-02 05:38:31,881 - train - INFO - Train: 242 [ 150/224 ( 67%)]  Loss:  3.138244 (3.1411)  Time: 1.134s, 5022.75/s  (0.849s, 6709.29/s)  LR: 9.034e-04  Data: 0.000 (0.079)
2025-06-02 05:39:13,373 - train - INFO - Train: 242 [ 200/224 ( 90%)]  Loss:  3.115910 (3.1361)  Time: 1.190s, 4785.55/s  (0.844s, 6747.25/s)  LR: 9.034e-04  Data: 0.000 (0.059)
2025-06-02 05:39:32,014 - train - INFO - Train: 242 [ 223/224 (100%)]  Loss:  3.137671 (3.1363)  Time: 0.552s, 10316.78/s  (0.841s, 6775.04/s)  LR: 9.034e-04  Data: 0.000 (0.053)
2025-06-02 05:39:36,778 - train - INFO - Test: [   0/70]  Time: 4.506 (4.506)  Loss:  1.6162 (1.6162)  Acc@1: 72.7528 (72.7528)  Acc@5: 89.8876 (89.8876)
2025-06-02 05:40:19,251 - train - INFO - Test: [  50/70]  Time: 0.120 (0.921)  Loss:  2.1172 (2.0182)  Acc@1: 58.9888 (60.2803)  Acc@5: 78.7921 (83.1351)
2025-06-02 05:40:35,957 - train - INFO - Test: [  70/70]  Time: 0.034 (0.897)  Loss:  2.8574 (2.0878)  Acc@1: 38.7500 (58.8040)  Acc@5: 70.6250 (81.8060)
2025-06-02 05:40:40,876 - train - INFO - Train: 243 [   0/224 (  0%)]  Loss:  3.110732 (3.1107)  Time: 4.616s, 1233.91/s  (4.616s, 1233.91/s)  LR: 8.737e-04  Data: 4.010 (4.010)
2025-06-02 05:41:22,321 - train - INFO - Train: 243 [  50/224 ( 22%)]  Loss:  3.126477 (3.1186)  Time: 0.561s, 10147.76/s  (0.903s, 6307.05/s)  LR: 8.737e-04  Data: 0.000 (0.164)
2025-06-02 05:42:03,502 - train - INFO - Train: 243 [ 100/224 ( 45%)]  Loss:  3.109102 (3.1154)  Time: 1.619s, 3517.16/s  (0.864s, 6594.50/s)  LR: 8.737e-04  Data: 0.000 (0.083)
2025-06-02 05:42:43,582 - train - INFO - Train: 243 [ 150/224 ( 67%)]  Loss:  3.068359 (3.1037)  Time: 0.551s, 10342.22/s  (0.843s, 6755.54/s)  LR: 8.737e-04  Data: 0.000 (0.057)
2025-06-02 05:43:24,221 - train - INFO - Train: 243 [ 200/224 ( 90%)]  Loss:  3.091731 (3.1013)  Time: 0.814s, 7001.48/s  (0.836s, 6816.70/s)  LR: 8.737e-04  Data: 0.000 (0.043)
2025-06-02 05:43:42,463 - train - INFO - Train: 243 [ 223/224 (100%)]  Loss:  3.110825 (3.1029)  Time: 0.544s, 10475.95/s  (0.831s, 6852.48/s)  LR: 8.737e-04  Data: 0.000 (0.038)
2025-06-02 05:43:47,148 - train - INFO - Test: [   0/70]  Time: 4.432 (4.432)  Loss:  1.0771 (1.0771)  Acc@1: 76.5449 (76.5449)  Acc@5: 93.2584 (93.2584)
2025-06-02 05:44:28,802 - train - INFO - Test: [  50/70]  Time: 0.120 (0.904)  Loss:  1.8457 (1.7212)  Acc@1: 61.0955 (62.3706)  Acc@5: 82.5843 (84.4321)
2025-06-02 05:44:45,248 - train - INFO - Test: [  70/70]  Time: 0.035 (0.881)  Loss:  2.1699 (1.8103)  Acc@1: 49.3750 (60.8720)  Acc@5: 78.1250 (83.0840)
2025-06-02 05:44:50,208 - train - INFO - Train: 244 [   0/224 (  0%)]  Loss:  3.148126 (3.1481)  Time: 4.660s, 1222.41/s  (4.660s, 1222.41/s)  LR: 8.446e-04  Data: 4.051 (4.051)
2025-06-02 05:45:31,623 - train - INFO - Train: 244 [  50/224 ( 22%)]  Loss:  3.100812 (3.1245)  Time: 0.549s, 10377.00/s  (0.903s, 6305.18/s)  LR: 8.446e-04  Data: 0.000 (0.128)
2025-06-02 05:46:13,657 - train - INFO - Train: 244 [ 100/224 ( 45%)]  Loss:  3.112796 (3.1206)  Time: 1.592s, 3578.98/s  (0.872s, 6529.65/s)  LR: 8.446e-04  Data: 0.000 (0.065)
2025-06-02 05:46:54,200 - train - INFO - Train: 244 [ 150/224 ( 67%)]  Loss:  3.093941 (3.1139)  Time: 0.557s, 10223.19/s  (0.852s, 6685.65/s)  LR: 8.446e-04  Data: 0.000 (0.043)
2025-06-02 05:47:35,699 - train - INFO - Train: 244 [ 200/224 ( 90%)]  Loss:  3.121216 (3.1154)  Time: 1.723s, 3306.00/s  (0.846s, 6728.92/s)  LR: 8.446e-04  Data: 0.000 (0.033)
2025-06-02 05:47:53,652 - train - INFO - Train: 244 [ 223/224 (100%)]  Loss:  3.138544 (3.1192)  Time: 0.553s, 10294.13/s  (0.840s, 6783.24/s)  LR: 8.446e-04  Data: 0.000 (0.029)
2025-06-02 05:47:58,396 - train - INFO - Test: [   0/70]  Time: 4.498 (4.498)  Loss:  1.4473 (1.4473)  Acc@1: 75.7022 (75.7022)  Acc@5: 92.6966 (92.6966)
2025-06-02 05:48:41,423 - train - INFO - Test: [  50/70]  Time: 0.120 (0.932)  Loss:  2.1543 (2.0296)  Acc@1: 57.1629 (60.0242)  Acc@5: 78.7921 (83.0910)
2025-06-02 05:48:57,908 - train - INFO - Test: [  70/70]  Time: 0.034 (0.902)  Loss:  2.5801 (2.0915)  Acc@1: 40.6250 (58.7880)  Acc@5: 76.2500 (81.8720)
2025-06-02 05:49:02,884 - train - INFO - Train: 245 [   0/224 (  0%)]  Loss:  3.119192 (3.1192)  Time: 4.663s, 1221.41/s  (4.663s, 1221.41/s)  LR: 8.158e-04  Data: 3.659 (3.659)
2025-06-02 05:49:44,079 - train - INFO - Train: 245 [  50/224 ( 22%)]  Loss:  3.137857 (3.1285)  Time: 0.555s, 10266.62/s  (0.899s, 6334.93/s)  LR: 8.158e-04  Data: 0.000 (0.105)
2025-06-02 05:50:26,329 - train - INFO - Train: 245 [ 100/224 ( 45%)]  Loss:  3.173760 (3.1436)  Time: 1.679s, 3392.13/s  (0.872s, 6529.73/s)  LR: 8.158e-04  Data: 0.000 (0.053)
2025-06-02 05:51:06,210 - train - INFO - Train: 245 [ 150/224 ( 67%)]  Loss:  3.099924 (3.1327)  Time: 0.550s, 10347.76/s  (0.848s, 6720.38/s)  LR: 8.158e-04  Data: 0.000 (0.035)
2025-06-02 05:51:47,428 - train - INFO - Train: 245 [ 200/224 ( 90%)]  Loss:  3.073540 (3.1209)  Time: 1.554s, 3665.44/s  (0.842s, 6766.54/s)  LR: 8.158e-04  Data: 0.000 (0.027)
2025-06-02 05:52:05,620 - train - INFO - Train: 245 [ 223/224 (100%)]  Loss:  3.114837 (3.1199)  Time: 0.545s, 10458.52/s  (0.837s, 6808.83/s)  LR: 8.158e-04  Data: 0.000 (0.024)
2025-06-02 05:52:10,367 - train - INFO - Test: [   0/70]  Time: 4.503 (4.503)  Loss:  1.2744 (1.2744)  Acc@1: 73.8764 (73.8764)  Acc@5: 89.1854 (89.1854)
2025-06-02 05:52:52,343 - train - INFO - Test: [  50/70]  Time: 0.120 (0.911)  Loss:  1.9980 (1.7594)  Acc@1: 57.1629 (60.8201)  Acc@5: 78.7921 (83.3499)
2025-06-02 05:53:08,524 - train - INFO - Test: [  70/70]  Time: 0.035 (0.883)  Loss:  2.6074 (1.8578)  Acc@1: 35.6250 (58.9180)  Acc@5: 73.7500 (81.7500)
2025-06-02 05:53:13,365 - train - INFO - Train: 246 [   0/224 (  0%)]  Loss:  3.144138 (3.1441)  Time: 4.528s, 1258.07/s  (4.528s, 1258.07/s)  LR: 7.876e-04  Data: 3.555 (3.555)
2025-06-02 05:53:54,494 - train - INFO - Train: 246 [  50/224 ( 22%)]  Loss:  3.143046 (3.1436)  Time: 0.549s, 10381.04/s  (0.895s, 6362.75/s)  LR: 7.876e-04  Data: 0.000 (0.139)
2025-06-02 05:54:36,096 - train - INFO - Train: 246 [ 100/224 ( 45%)]  Loss:  3.124819 (3.1373)  Time: 1.634s, 3486.04/s  (0.864s, 6593.15/s)  LR: 7.876e-04  Data: 0.095 (0.104)
2025-06-02 05:55:16,866 - train - INFO - Train: 246 [ 150/224 ( 67%)]  Loss:  3.139865 (3.1380)  Time: 0.550s, 10348.01/s  (0.848s, 6718.25/s)  LR: 7.876e-04  Data: 0.000 (0.070)
2025-06-02 05:55:58,840 - train - INFO - Train: 246 [ 200/224 ( 90%)]  Loss:  3.134432 (3.1373)  Time: 1.401s, 4066.13/s  (0.846s, 6734.80/s)  LR: 7.876e-04  Data: 0.000 (0.054)
2025-06-02 05:56:16,546 - train - INFO - Train: 246 [ 223/224 (100%)]  Loss:  3.110364 (3.1328)  Time: 0.555s, 10258.04/s  (0.838s, 6797.49/s)  LR: 7.876e-04  Data: 0.000 (0.049)
2025-06-02 05:56:21,301 - train - INFO - Test: [   0/70]  Time: 4.495 (4.495)  Loss:  1.3574 (1.3574)  Acc@1: 75.0000 (75.0000)  Acc@5: 91.9944 (91.9944)
2025-06-02 05:57:03,472 - train - INFO - Test: [  50/70]  Time: 0.120 (0.915)  Loss:  2.0938 (1.9485)  Acc@1: 61.2360 (61.1836)  Acc@5: 81.3202 (83.9695)
2025-06-02 05:57:19,859 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.4609 (2.0266)  Acc@1: 45.0000 (59.6560)  Acc@5: 76.8750 (82.6020)
2025-06-02 05:57:24,726 - train - INFO - Train: 247 [   0/224 (  0%)]  Loss:  3.128272 (3.1283)  Time: 4.542s, 1254.16/s  (4.542s, 1254.16/s)  LR: 7.598e-04  Data: 3.944 (3.944)
2025-06-02 05:58:05,897 - train - INFO - Train: 247 [  50/224 ( 22%)]  Loss:  3.162019 (3.1451)  Time: 0.549s, 10374.48/s  (0.896s, 6355.11/s)  LR: 7.598e-04  Data: 0.000 (0.166)
2025-06-02 05:58:47,021 - train - INFO - Train: 247 [ 100/224 ( 45%)]  Loss:  3.185546 (3.1586)  Time: 1.340s, 4250.48/s  (0.860s, 6625.36/s)  LR: 7.598e-04  Data: 0.000 (0.084)
2025-06-02 05:59:27,929 - train - INFO - Train: 247 [ 150/224 ( 67%)]  Loss:  3.164445 (3.1601)  Time: 0.557s, 10222.46/s  (0.846s, 6733.25/s)  LR: 7.598e-04  Data: 0.000 (0.056)
2025-06-02 06:00:08,757 - train - INFO - Train: 247 [ 200/224 ( 90%)]  Loss:  3.133222 (3.1547)  Time: 1.499s, 3799.55/s  (0.839s, 6791.99/s)  LR: 7.598e-04  Data: 0.000 (0.042)
2025-06-02 06:00:26,674 - train - INFO - Train: 247 [ 223/224 (100%)]  Loss:  3.100482 (3.1457)  Time: 0.553s, 10306.72/s  (0.833s, 6841.99/s)  LR: 7.598e-04  Data: 0.000 (0.038)
2025-06-02 06:00:31,546 - train - INFO - Test: [   0/70]  Time: 4.625 (4.625)  Loss:  1.5664 (1.5664)  Acc@1: 71.0674 (71.0674)  Acc@5: 89.1854 (89.1854)
2025-06-02 06:01:12,917 - train - INFO - Test: [  50/70]  Time: 0.120 (0.902)  Loss:  1.8418 (1.8416)  Acc@1: 61.6573 (61.2249)  Acc@5: 82.5843 (83.5922)
2025-06-02 06:01:29,527 - train - INFO - Test: [  70/70]  Time: 0.034 (0.882)  Loss:  2.0781 (1.9111)  Acc@1: 44.3750 (59.4960)  Acc@5: 81.2500 (82.2900)
2025-06-02 06:01:34,607 - train - INFO - Train: 248 [   0/224 (  0%)]  Loss:  3.160661 (3.1607)  Time: 4.767s, 1194.93/s  (4.767s, 1194.93/s)  LR: 7.325e-04  Data: 3.657 (3.657)
2025-06-02 06:02:15,582 - train - INFO - Train: 248 [  50/224 ( 22%)]  Loss:  3.088381 (3.1245)  Time: 0.554s, 10272.86/s  (0.897s, 6350.97/s)  LR: 7.325e-04  Data: 0.000 (0.140)
2025-06-02 06:02:57,791 - train - INFO - Train: 248 [ 100/224 ( 45%)]  Loss:  3.126871 (3.1253)  Time: 1.579s, 3606.59/s  (0.871s, 6541.44/s)  LR: 7.325e-04  Data: 0.000 (0.071)
2025-06-02 06:03:38,760 - train - INFO - Train: 248 [ 150/224 ( 67%)]  Loss:  3.102755 (3.1197)  Time: 0.552s, 10318.47/s  (0.854s, 6671.91/s)  LR: 7.325e-04  Data: 0.000 (0.047)
2025-06-02 06:04:20,379 - train - INFO - Train: 248 [ 200/224 ( 90%)]  Loss:  3.083743 (3.1125)  Time: 1.574s, 3619.33/s  (0.848s, 6713.76/s)  LR: 7.325e-04  Data: 0.000 (0.036)
2025-06-02 06:04:38,131 - train - INFO - Train: 248 [ 223/224 (100%)]  Loss:  3.124923 (3.1146)  Time: 0.547s, 10420.74/s  (0.841s, 6776.60/s)  LR: 7.325e-04  Data: 0.000 (0.032)
2025-06-02 06:04:42,893 - train - INFO - Test: [   0/70]  Time: 4.506 (4.506)  Loss:  1.1211 (1.1211)  Acc@1: 75.1404 (75.1404)  Acc@5: 91.8539 (91.8539)
2025-06-02 06:05:25,322 - train - INFO - Test: [  50/70]  Time: 0.120 (0.920)  Loss:  1.8066 (1.7359)  Acc@1: 63.7640 (62.7451)  Acc@5: 81.8820 (84.5148)
2025-06-02 06:05:41,831 - train - INFO - Test: [  70/70]  Time: 0.034 (0.894)  Loss:  2.4238 (1.8225)  Acc@1: 43.7500 (61.0180)  Acc@5: 78.1250 (83.0940)
2025-06-02 06:05:46,434 - train - INFO - Train: 249 [   0/224 (  0%)]  Loss:  3.122802 (3.1228)  Time: 4.284s, 1329.57/s  (4.284s, 1329.57/s)  LR: 7.056e-04  Data: 3.506 (3.506)
2025-06-02 06:06:27,475 - train - INFO - Train: 249 [  50/224 ( 22%)]  Loss:  3.143138 (3.1330)  Time: 0.548s, 10390.77/s  (0.889s, 6409.45/s)  LR: 7.056e-04  Data: 0.000 (0.148)
2025-06-02 06:07:09,022 - train - INFO - Train: 249 [ 100/224 ( 45%)]  Loss:  3.117248 (3.1277)  Time: 1.577s, 3611.91/s  (0.860s, 6622.69/s)  LR: 7.056e-04  Data: 0.000 (0.080)
2025-06-02 06:07:49,618 - train - INFO - Train: 249 [ 150/224 ( 67%)]  Loss:  3.134396 (3.1294)  Time: 0.555s, 10260.90/s  (0.844s, 6747.89/s)  LR: 7.056e-04  Data: 0.000 (0.054)
2025-06-02 06:08:30,408 - train - INFO - Train: 249 [ 200/224 ( 90%)]  Loss:  3.137534 (3.1310)  Time: 0.806s, 7064.87/s  (0.837s, 6804.85/s)  LR: 7.056e-04  Data: 0.000 (0.040)
2025-06-02 06:08:49,241 - train - INFO - Train: 249 [ 223/224 (100%)]  Loss:  3.133662 (3.1315)  Time: 0.551s, 10330.84/s  (0.835s, 6820.24/s)  LR: 7.056e-04  Data: 0.000 (0.036)
2025-06-02 06:08:54,048 - train - INFO - Test: [   0/70]  Time: 4.570 (4.570)  Loss:  1.3008 (1.3008)  Acc@1: 73.4551 (73.4551)  Acc@5: 90.7303 (90.7303)
2025-06-02 06:09:36,369 - train - INFO - Test: [  50/70]  Time: 0.120 (0.919)  Loss:  1.8662 (1.7276)  Acc@1: 60.2528 (62.2742)  Acc@5: 82.1629 (84.5616)
2025-06-02 06:09:52,799 - train - INFO - Test: [  70/70]  Time: 0.034 (0.892)  Loss:  2.1582 (1.8010)  Acc@1: 46.8750 (60.7120)  Acc@5: 79.3750 (83.2180)
2025-06-02 06:09:57,717 - train - INFO - Train: 250 [   0/224 (  0%)]  Loss:  3.131830 (3.1318)  Time: 4.621s, 1232.51/s  (4.621s, 1232.51/s)  LR: 6.792e-04  Data: 3.699 (3.699)
2025-06-02 06:10:38,719 - train - INFO - Train: 250 [  50/224 ( 22%)]  Loss:  3.117300 (3.1246)  Time: 0.550s, 10347.70/s  (0.895s, 6367.30/s)  LR: 6.792e-04  Data: 0.000 (0.151)
2025-06-02 06:11:20,442 - train - INFO - Train: 250 [ 100/224 ( 45%)]  Loss:  3.120638 (3.1233)  Time: 1.629s, 3496.76/s  (0.865s, 6586.53/s)  LR: 6.792e-04  Data: 0.000 (0.103)
2025-06-02 06:12:01,365 - train - INFO - Train: 250 [ 150/224 ( 67%)]  Loss:  3.119793 (3.1224)  Time: 0.549s, 10382.13/s  (0.849s, 6705.54/s)  LR: 6.792e-04  Data: 0.000 (0.069)
2025-06-02 06:12:42,545 - train - INFO - Train: 250 [ 200/224 ( 90%)]  Loss:  3.134472 (3.1248)  Time: 1.182s, 4819.49/s  (0.843s, 6756.75/s)  LR: 6.792e-04  Data: 0.000 (0.052)
2025-06-02 06:13:00,917 - train - INFO - Train: 250 [ 223/224 (100%)]  Loss:  3.108518 (3.1221)  Time: 0.545s, 10456.42/s  (0.838s, 6793.38/s)  LR: 6.792e-04  Data: 0.000 (0.047)
2025-06-02 06:13:05,816 - train - INFO - Test: [   0/70]  Time: 4.652 (4.652)  Loss:  1.3037 (1.3037)  Acc@1: 73.5955 (73.5955)  Acc@5: 90.7303 (90.7303)
2025-06-02 06:13:47,888 - train - INFO - Test: [  50/70]  Time: 0.120 (0.916)  Loss:  2.1699 (1.9312)  Acc@1: 55.4775 (58.0442)  Acc@5: 77.5281 (81.9591)
2025-06-02 06:14:04,341 - train - INFO - Test: [  70/70]  Time: 0.034 (0.890)  Loss:  2.9023 (1.9885)  Acc@1: 32.5000 (56.8500)  Acc@5: 68.1250 (80.8100)
2025-06-02 06:14:09,413 - train - INFO - Train: 251 [   0/224 (  0%)]  Loss:  3.096582 (3.0966)  Time: 4.760s, 1196.71/s  (4.760s, 1196.71/s)  LR: 6.533e-04  Data: 3.974 (3.974)
2025-06-02 06:14:50,227 - train - INFO - Train: 251 [  50/224 ( 22%)]  Loss:  3.136032 (3.1163)  Time: 0.549s, 10378.24/s  (0.894s, 6374.50/s)  LR: 6.533e-04  Data: 0.000 (0.287)
2025-06-02 06:15:31,098 - train - INFO - Train: 251 [ 100/224 ( 45%)]  Loss:  3.125401 (3.1193)  Time: 1.192s, 4780.20/s  (0.856s, 6655.31/s)  LR: 6.533e-04  Data: 0.245 (0.196)
2025-06-02 06:16:11,520 - train - INFO - Train: 251 [ 150/224 ( 67%)]  Loss:  3.104886 (3.1157)  Time: 0.548s, 10395.75/s  (0.840s, 6779.82/s)  LR: 6.533e-04  Data: 0.000 (0.145)
2025-06-02 06:16:52,992 - train - INFO - Train: 251 [ 200/224 ( 90%)]  Loss:  3.101744 (3.1129)  Time: 1.412s, 4033.82/s  (0.837s, 6801.40/s)  LR: 6.533e-04  Data: 0.000 (0.110)
2025-06-02 06:17:11,246 - train - INFO - Train: 251 [ 223/224 (100%)]  Loss:  3.135921 (3.1168)  Time: 0.545s, 10444.67/s  (0.833s, 6838.15/s)  LR: 6.533e-04  Data: 0.000 (0.099)
2025-06-02 06:17:16,098 - train - INFO - Test: [   0/70]  Time: 4.586 (4.586)  Loss:  1.4541 (1.4541)  Acc@1: 71.2079 (71.2079)  Acc@5: 88.7640 (88.7640)
2025-06-02 06:17:58,300 - train - INFO - Test: [  50/70]  Time: 0.120 (0.917)  Loss:  1.8750 (1.8065)  Acc@1: 60.6742 (61.1286)  Acc@5: 82.3034 (84.1099)
2025-06-02 06:18:14,809 - train - INFO - Test: [  70/70]  Time: 0.034 (0.892)  Loss:  1.9307 (1.9209)  Acc@1: 49.3750 (58.9140)  Acc@5: 83.1250 (82.1740)
2025-06-02 06:18:19,692 - train - INFO - Train: 252 [   0/224 (  0%)]  Loss:  3.183253 (3.1833)  Time: 4.580s, 1243.56/s  (4.580s, 1243.56/s)  LR: 6.278e-04  Data: 3.832 (3.832)
2025-06-02 06:19:01,232 - train - INFO - Train: 252 [  50/224 ( 22%)]  Loss:  3.123277 (3.1533)  Time: 0.549s, 10376.59/s  (0.904s, 6298.89/s)  LR: 6.278e-04  Data: 0.000 (0.152)
2025-06-02 06:19:43,279 - train - INFO - Train: 252 [ 100/224 ( 45%)]  Loss:  3.142033 (3.1495)  Time: 1.653s, 3445.58/s  (0.873s, 6525.40/s)  LR: 6.278e-04  Data: 0.000 (0.077)
2025-06-02 06:20:24,770 - train - INFO - Train: 252 [ 150/224 ( 67%)]  Loss:  3.117959 (3.1416)  Time: 0.555s, 10264.06/s  (0.859s, 6633.88/s)  LR: 6.278e-04  Data: 0.000 (0.052)
2025-06-02 06:21:07,182 - train - INFO - Train: 252 [ 200/224 ( 90%)]  Loss:  3.107935 (3.1349)  Time: 1.764s, 3228.37/s  (0.856s, 6653.96/s)  LR: 6.278e-04  Data: 0.000 (0.039)
2025-06-02 06:21:25,508 - train - INFO - Train: 252 [ 223/224 (100%)]  Loss:  3.118032 (3.1321)  Time: 0.551s, 10346.82/s  (0.850s, 6701.64/s)  LR: 6.278e-04  Data: 0.000 (0.035)
2025-06-02 06:21:30,364 - train - INFO - Test: [   0/70]  Time: 4.622 (4.622)  Loss:  1.4756 (1.4756)  Acc@1: 70.6461 (70.6461)  Acc@5: 89.1854 (89.1854)
2025-06-02 06:22:13,196 - train - INFO - Test: [  50/70]  Time: 0.120 (0.930)  Loss:  2.0566 (1.8750)  Acc@1: 57.3034 (60.0050)  Acc@5: 79.4944 (83.0882)
2025-06-02 06:22:29,909 - train - INFO - Test: [  70/70]  Time: 0.034 (0.904)  Loss:  2.2246 (1.9479)  Acc@1: 41.2500 (58.3900)  Acc@5: 80.0000 (81.7240)
2025-06-02 06:22:35,076 - train - INFO - Train: 253 [   0/224 (  0%)]  Loss:  3.179603 (3.1796)  Time: 4.846s, 1175.29/s  (4.846s, 1175.29/s)  LR: 6.029e-04  Data: 3.841 (3.841)
2025-06-02 06:23:15,943 - train - INFO - Train: 253 [  50/224 ( 22%)]  Loss:  3.151654 (3.1656)  Time: 0.557s, 10233.09/s  (0.896s, 6354.91/s)  LR: 6.029e-04  Data: 0.000 (0.090)
2025-06-02 06:23:57,752 - train - INFO - Train: 253 [ 100/224 ( 45%)]  Loss:  3.154947 (3.1621)  Time: 1.582s, 3600.31/s  (0.867s, 6573.37/s)  LR: 6.029e-04  Data: 0.000 (0.045)
2025-06-02 06:24:38,156 - train - INFO - Train: 253 [ 150/224 ( 67%)]  Loss:  3.121130 (3.1518)  Time: 0.549s, 10382.53/s  (0.847s, 6723.62/s)  LR: 6.029e-04  Data: 0.000 (0.030)
2025-06-02 06:25:19,557 - train - INFO - Train: 253 [ 200/224 ( 90%)]  Loss:  3.108748 (3.1432)  Time: 1.629s, 3496.84/s  (0.842s, 6761.73/s)  LR: 6.029e-04  Data: 0.000 (0.023)
2025-06-02 06:25:37,501 - train - INFO - Train: 253 [ 223/224 (100%)]  Loss:  3.152264 (3.1447)  Time: 0.546s, 10423.91/s  (0.836s, 6813.41/s)  LR: 6.029e-04  Data: 0.000 (0.021)
2025-06-02 06:25:42,424 - train - INFO - Test: [   0/70]  Time: 4.692 (4.692)  Loss:  1.3682 (1.3682)  Acc@1: 70.2247 (70.2247)  Acc@5: 89.7472 (89.7472)
2025-06-02 06:26:24,692 - train - INFO - Test: [  50/70]  Time: 0.120 (0.921)  Loss:  1.9541 (1.7999)  Acc@1: 59.1292 (60.6714)  Acc@5: 79.7753 (84.0218)
2025-06-02 06:26:41,387 - train - INFO - Test: [  70/70]  Time: 0.034 (0.897)  Loss:  2.9570 (1.8800)  Acc@1: 30.0000 (59.0520)  Acc@5: 69.3750 (82.6100)
2025-06-02 06:26:46,418 - train - INFO - Train: 254 [   0/224 (  0%)]  Loss:  3.114207 (3.1142)  Time: 4.729s, 1204.54/s  (4.729s, 1204.54/s)  LR: 5.784e-04  Data: 4.089 (4.089)
2025-06-02 06:27:27,873 - train - INFO - Train: 254 [  50/224 ( 22%)]  Loss:  3.116432 (3.1153)  Time: 0.548s, 10398.04/s  (0.906s, 6290.18/s)  LR: 5.784e-04  Data: 0.000 (0.254)
2025-06-02 06:28:09,719 - train - INFO - Train: 254 [ 100/224 ( 45%)]  Loss:  3.125614 (3.1188)  Time: 1.521s, 3743.70/s  (0.872s, 6535.44/s)  LR: 5.784e-04  Data: 0.000 (0.128)
2025-06-02 06:28:50,641 - train - INFO - Train: 254 [ 150/224 ( 67%)]  Loss:  3.094862 (3.1128)  Time: 0.551s, 10333.79/s  (0.854s, 6670.13/s)  LR: 5.784e-04  Data: 0.000 (0.086)
2025-06-02 06:29:31,886 - train - INFO - Train: 254 [ 200/224 ( 90%)]  Loss:  3.153320 (3.1209)  Time: 1.454s, 3918.06/s  (0.847s, 6727.11/s)  LR: 5.784e-04  Data: 0.000 (0.065)
2025-06-02 06:29:50,033 - train - INFO - Train: 254 [ 223/224 (100%)]  Loss:  3.121586 (3.1210)  Time: 0.548s, 10386.86/s  (0.841s, 6774.57/s)  LR: 5.784e-04  Data: 0.000 (0.058)
2025-06-02 06:29:54,803 - train - INFO - Test: [   0/70]  Time: 4.516 (4.516)  Loss:  1.5176 (1.5176)  Acc@1: 72.0506 (72.0506)  Acc@5: 89.3259 (89.3259)
2025-06-02 06:30:36,749 - train - INFO - Test: [  50/70]  Time: 0.156 (0.911)  Loss:  1.8428 (1.8411)  Acc@1: 62.5000 (61.6050)  Acc@5: 81.7416 (83.8676)
2025-06-02 06:30:53,099 - train - INFO - Test: [  70/70]  Time: 0.034 (0.885)  Loss:  2.9531 (1.9177)  Acc@1: 34.3750 (60.0700)  Acc@5: 65.6250 (82.5080)
2025-06-02 06:30:57,974 - train - INFO - Train: 255 [   0/224 (  0%)]  Loss:  3.114366 (3.1144)  Time: 4.571s, 1246.03/s  (4.571s, 1246.03/s)  LR: 5.544e-04  Data: 3.885 (3.885)
2025-06-02 06:31:39,174 - train - INFO - Train: 255 [  50/224 ( 22%)]  Loss:  3.128484 (3.1214)  Time: 0.549s, 10367.57/s  (0.897s, 6346.92/s)  LR: 5.544e-04  Data: 0.000 (0.216)
2025-06-02 06:32:21,014 - train - INFO - Train: 255 [ 100/224 ( 45%)]  Loss:  3.169426 (3.1374)  Time: 1.106s, 5148.36/s  (0.867s, 6566.78/s)  LR: 5.544e-04  Data: 0.000 (0.109)
2025-06-02 06:33:02,929 - train - INFO - Train: 255 [ 150/224 ( 67%)]  Loss:  3.153051 (3.1413)  Time: 1.043s, 5458.96/s  (0.858s, 6640.69/s)  LR: 5.544e-04  Data: 0.000 (0.073)
2025-06-02 06:33:44,452 - train - INFO - Train: 255 [ 200/224 ( 90%)]  Loss:  3.071417 (3.1273)  Time: 0.752s, 7579.41/s  (0.851s, 6693.69/s)  LR: 5.544e-04  Data: 0.000 (0.055)
2025-06-02 06:34:03,248 - train - INFO - Train: 255 [ 223/224 (100%)]  Loss:  3.118240 (3.1258)  Time: 0.545s, 10446.12/s  (0.847s, 6721.06/s)  LR: 5.544e-04  Data: 0.000 (0.049)
2025-06-02 06:34:07,967 - train - INFO - Test: [   0/70]  Time: 4.471 (4.471)  Loss:  1.2861 (1.2861)  Acc@1: 75.7022 (75.7022)  Acc@5: 92.6966 (92.6966)
2025-06-02 06:34:50,332 - train - INFO - Test: [  50/70]  Time: 0.120 (0.918)  Loss:  1.7500 (1.8317)  Acc@1: 64.0449 (61.6022)  Acc@5: 84.8315 (84.3413)
2025-06-02 06:35:06,951 - train - INFO - Test: [  70/70]  Time: 0.034 (0.894)  Loss:  2.4238 (1.9086)  Acc@1: 45.6250 (59.9900)  Acc@5: 74.3750 (83.0380)
2025-06-02 06:35:12,131 - train - INFO - Train: 256 [   0/224 (  0%)]  Loss:  3.155516 (3.1555)  Time: 4.873s, 1168.86/s  (4.873s, 1168.86/s)  LR: 5.309e-04  Data: 4.323 (4.323)
2025-06-02 06:35:53,121 - train - INFO - Train: 256 [  50/224 ( 22%)]  Loss:  3.116044 (3.1358)  Time: 0.554s, 10290.72/s  (0.899s, 6334.15/s)  LR: 5.309e-04  Data: 0.000 (0.148)
2025-06-02 06:36:35,537 - train - INFO - Train: 256 [ 100/224 ( 45%)]  Loss:  3.144670 (3.1387)  Time: 1.794s, 3174.18/s  (0.874s, 6517.03/s)  LR: 5.309e-04  Data: 0.000 (0.075)
2025-06-02 06:37:16,616 - train - INFO - Train: 256 [ 150/224 ( 67%)]  Loss:  3.098325 (3.1286)  Time: 0.555s, 10257.56/s  (0.857s, 6649.28/s)  LR: 5.309e-04  Data: 0.000 (0.050)
2025-06-02 06:37:58,291 - train - INFO - Train: 256 [ 200/224 ( 90%)]  Loss:  3.124443 (3.1278)  Time: 1.580s, 3605.97/s  (0.851s, 6694.34/s)  LR: 5.309e-04  Data: 0.000 (0.038)
2025-06-02 06:38:16,253 - train - INFO - Train: 256 [ 223/224 (100%)]  Loss:  3.133560 (3.1288)  Time: 0.546s, 10429.98/s  (0.844s, 6751.30/s)  LR: 5.309e-04  Data: 0.000 (0.034)
2025-06-02 06:38:21,252 - train - INFO - Test: [   0/70]  Time: 4.743 (4.743)  Loss:  2.1816 (2.1816)  Acc@1: 72.1910 (72.1910)  Acc@5: 87.5000 (87.5000)
2025-06-02 06:39:02,753 - train - INFO - Test: [  50/70]  Time: 0.120 (0.907)  Loss:  2.2285 (2.3126)  Acc@1: 60.3933 (59.9857)  Acc@5: 81.1798 (82.7357)
2025-06-02 06:39:19,254 - train - INFO - Test: [  70/70]  Time: 0.034 (0.884)  Loss:  2.8789 (2.3473)  Acc@1: 36.8750 (58.5800)  Acc@5: 75.6250 (81.7740)
2025-06-02 06:39:24,429 - train - INFO - Train: 257 [   0/224 (  0%)]  Loss:  3.111552 (3.1116)  Time: 4.854s, 1173.52/s  (4.854s, 1173.52/s)  LR: 5.079e-04  Data: 4.306 (4.306)
2025-06-02 06:40:04,668 - train - INFO - Train: 257 [  50/224 ( 22%)]  Loss:  3.123457 (3.1175)  Time: 0.550s, 10363.35/s  (0.884s, 6442.48/s)  LR: 5.079e-04  Data: 0.000 (0.125)
2025-06-02 06:40:46,814 - train - INFO - Train: 257 [ 100/224 ( 45%)]  Loss:  3.088633 (3.1079)  Time: 1.512s, 3768.24/s  (0.864s, 6594.84/s)  LR: 5.079e-04  Data: 0.000 (0.063)
2025-06-02 06:41:27,245 - train - INFO - Train: 257 [ 150/224 ( 67%)]  Loss:  3.143455 (3.1168)  Time: 0.558s, 10210.93/s  (0.845s, 6737.13/s)  LR: 5.079e-04  Data: 0.000 (0.042)
2025-06-02 06:42:08,761 - train - INFO - Train: 257 [ 200/224 ( 90%)]  Loss:  3.123201 (3.1181)  Time: 1.615s, 3526.21/s  (0.842s, 6767.35/s)  LR: 5.079e-04  Data: 0.000 (0.032)
2025-06-02 06:42:26,734 - train - INFO - Train: 257 [ 223/224 (100%)]  Loss:  3.134404 (3.1208)  Time: 0.545s, 10453.19/s  (0.835s, 6817.55/s)  LR: 5.079e-04  Data: 0.000 (0.029)
2025-06-02 06:42:31,589 - train - INFO - Test: [   0/70]  Time: 4.602 (4.602)  Loss:  1.3633 (1.3633)  Acc@1: 73.1742 (73.1742)  Acc@5: 89.6067 (89.6067)
2025-06-02 06:43:13,955 - train - INFO - Test: [  50/70]  Time: 0.120 (0.921)  Loss:  1.7256 (1.7853)  Acc@1: 63.3427 (62.3485)  Acc@5: 84.2697 (84.6111)
2025-06-02 06:43:30,635 - train - INFO - Test: [  70/70]  Time: 0.034 (0.896)  Loss:  2.8613 (1.8537)  Acc@1: 37.5000 (60.8900)  Acc@5: 70.0000 (83.4680)
2025-06-02 06:43:35,611 - train - INFO - Train: 258 [   0/224 (  0%)]  Loss:  3.152145 (3.1521)  Time: 4.669s, 1219.98/s  (4.669s, 1219.98/s)  LR: 4.854e-04  Data: 3.963 (3.963)
2025-06-02 06:44:16,368 - train - INFO - Train: 258 [  50/224 ( 22%)]  Loss:  3.120400 (3.1363)  Time: 0.548s, 10399.01/s  (0.891s, 6395.21/s)  LR: 4.854e-04  Data: 0.000 (0.132)
2025-06-02 06:44:57,850 - train - INFO - Train: 258 [ 100/224 ( 45%)]  Loss:  3.150420 (3.1410)  Time: 0.854s, 6669.50/s  (0.860s, 6619.90/s)  LR: 4.854e-04  Data: 0.000 (0.067)
2025-06-02 06:45:39,852 - train - INFO - Train: 258 [ 150/224 ( 67%)]  Loss:  3.133936 (3.1392)  Time: 0.548s, 10399.04/s  (0.854s, 6672.31/s)  LR: 4.854e-04  Data: 0.000 (0.045)
2025-06-02 06:46:21,154 - train - INFO - Train: 258 [ 200/224 ( 90%)]  Loss:  3.135206 (3.1384)  Time: 0.563s, 10125.01/s  (0.847s, 6726.58/s)  LR: 4.854e-04  Data: 0.000 (0.034)
2025-06-02 06:46:40,129 - train - INFO - Train: 258 [ 223/224 (100%)]  Loss:  3.149094 (3.1402)  Time: 0.547s, 10418.66/s  (0.845s, 6744.40/s)  LR: 4.854e-04  Data: 0.000 (0.030)
2025-06-02 06:46:44,923 - train - INFO - Test: [   0/70]  Time: 4.545 (4.545)  Loss:  1.3740 (1.3740)  Acc@1: 75.2809 (75.2809)  Acc@5: 93.2584 (93.2584)
2025-06-02 06:47:26,817 - train - INFO - Test: [  50/70]  Time: 0.121 (0.911)  Loss:  1.8057 (1.9292)  Acc@1: 67.5562 (62.8608)  Acc@5: 84.8315 (84.9554)
2025-06-02 06:47:43,395 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  2.5137 (2.0127)  Acc@1: 44.3750 (61.2100)  Acc@5: 75.6250 (83.4380)
2025-06-02 06:47:48,376 - train - INFO - Train: 259 [   0/224 (  0%)]  Loss:  3.096408 (3.0964)  Time: 4.659s, 1222.65/s  (4.659s, 1222.65/s)  LR: 4.634e-04  Data: 4.063 (4.063)
2025-06-02 06:48:29,531 - train - INFO - Train: 259 [  50/224 ( 22%)]  Loss:  3.128899 (3.1127)  Time: 0.550s, 10365.34/s  (0.898s, 6340.96/s)  LR: 4.634e-04  Data: 0.000 (0.127)
2025-06-02 06:49:10,947 - train - INFO - Train: 259 [ 100/224 ( 45%)]  Loss:  3.109463 (3.1116)  Time: 1.021s, 5580.36/s  (0.864s, 6595.44/s)  LR: 4.634e-04  Data: 0.000 (0.064)
2025-06-02 06:49:52,725 - train - INFO - Train: 259 [ 150/224 ( 67%)]  Loss:  3.110860 (3.1114)  Time: 0.548s, 10397.48/s  (0.854s, 6667.26/s)  LR: 4.634e-04  Data: 0.000 (0.043)
2025-06-02 06:50:35,166 - train - INFO - Train: 259 [ 200/224 ( 90%)]  Loss:  3.145409 (3.1182)  Time: 1.582s, 3600.66/s  (0.853s, 6678.02/s)  LR: 4.634e-04  Data: 0.000 (0.032)
2025-06-02 06:50:53,212 - train - INFO - Train: 259 [ 223/224 (100%)]  Loss:  3.139242 (3.1217)  Time: 0.553s, 10308.04/s  (0.846s, 6733.43/s)  LR: 4.634e-04  Data: 0.000 (0.029)
2025-06-02 06:50:57,868 - train - INFO - Test: [   0/70]  Time: 4.416 (4.416)  Loss:  0.9331 (0.9331)  Acc@1: 75.7022 (75.7022)  Acc@5: 94.2416 (94.2416)
2025-06-02 06:51:39,976 - train - INFO - Test: [  50/70]  Time: 0.121 (0.912)  Loss:  1.9131 (1.6482)  Acc@1: 57.1629 (61.2084)  Acc@5: 79.6348 (84.0907)
2025-06-02 06:51:56,892 - train - INFO - Test: [  70/70]  Time: 0.034 (0.894)  Loss:  1.7354 (1.7221)  Acc@1: 52.5000 (60.0020)  Acc@5: 85.0000 (82.9320)
2025-06-02 06:52:02,082 - train - INFO - Train: 260 [   0/224 (  0%)]  Loss:  3.112509 (3.1125)  Time: 4.885s, 1165.93/s  (4.885s, 1165.93/s)  LR: 4.418e-04  Data: 4.082 (4.082)
2025-06-02 06:52:43,095 - train - INFO - Train: 260 [  50/224 ( 22%)]  Loss:  3.150909 (3.1317)  Time: 0.550s, 10351.86/s  (0.900s, 6329.16/s)  LR: 4.418e-04  Data: 0.000 (0.250)
2025-06-02 06:53:24,846 - train - INFO - Train: 260 [ 100/224 ( 45%)]  Loss:  3.114270 (3.1259)  Time: 1.409s, 4042.64/s  (0.868s, 6563.77/s)  LR: 4.418e-04  Data: 0.000 (0.126)
2025-06-02 06:54:05,982 - train - INFO - Train: 260 [ 150/224 ( 67%)]  Loss:  3.113304 (3.1227)  Time: 0.548s, 10388.29/s  (0.853s, 6678.73/s)  LR: 4.418e-04  Data: 0.000 (0.085)
2025-06-02 06:54:47,520 - train - INFO - Train: 260 [ 200/224 ( 90%)]  Loss:  3.154843 (3.1292)  Time: 0.549s, 10383.94/s  (0.847s, 6722.17/s)  LR: 4.418e-04  Data: 0.000 (0.064)
2025-06-02 06:55:06,252 - train - INFO - Train: 260 [ 223/224 (100%)]  Loss:  3.112647 (3.1264)  Time: 0.544s, 10462.03/s  (0.844s, 6749.12/s)  LR: 4.418e-04  Data: 0.000 (0.057)
2025-06-02 06:55:10,950 - train - INFO - Test: [   0/70]  Time: 4.447 (4.447)  Loss:  1.6338 (1.6338)  Acc@1: 72.8933 (72.8933)  Acc@5: 91.9944 (91.9944)
2025-06-02 06:55:53,739 - train - INFO - Test: [  50/70]  Time: 0.120 (0.926)  Loss:  2.0918 (2.0150)  Acc@1: 55.3371 (59.8480)  Acc@5: 80.3371 (82.9285)
2025-06-02 06:56:10,429 - train - INFO - Test: [  70/70]  Time: 0.034 (0.900)  Loss:  2.9062 (2.0944)  Acc@1: 38.1250 (58.1040)  Acc@5: 68.1250 (81.3940)
2025-06-02 06:56:15,436 - train - INFO - Train: 261 [   0/224 (  0%)]  Loss:  3.105224 (3.1052)  Time: 4.698s, 1212.52/s  (4.698s, 1212.52/s)  LR: 4.208e-04  Data: 3.565 (3.565)
2025-06-02 06:56:56,756 - train - INFO - Train: 261 [  50/224 ( 22%)]  Loss:  3.151905 (3.1286)  Time: 0.559s, 10184.96/s  (0.902s, 6312.88/s)  LR: 4.208e-04  Data: 0.000 (0.097)
2025-06-02 06:57:37,986 - train - INFO - Train: 261 [ 100/224 ( 45%)]  Loss:  3.173178 (3.1434)  Time: 1.571s, 3625.11/s  (0.864s, 6594.00/s)  LR: 4.208e-04  Data: 0.000 (0.049)
2025-06-02 06:58:18,191 - train - INFO - Train: 261 [ 150/224 ( 67%)]  Loss:  3.154290 (3.1461)  Time: 0.554s, 10278.36/s  (0.844s, 6748.59/s)  LR: 4.208e-04  Data: 0.000 (0.033)
2025-06-02 06:59:00,474 - train - INFO - Train: 261 [ 200/224 ( 90%)]  Loss:  3.119164 (3.1408)  Time: 1.787s, 3188.17/s  (0.844s, 6745.41/s)  LR: 4.208e-04  Data: 0.000 (0.025)
2025-06-02 06:59:18,561 - train - INFO - Train: 261 [ 223/224 (100%)]  Loss:  3.146605 (3.1417)  Time: 0.547s, 10421.27/s  (0.838s, 6793.35/s)  LR: 4.208e-04  Data: 0.000 (0.022)
2025-06-02 06:59:23,318 - train - INFO - Test: [   0/70]  Time: 4.496 (4.496)  Loss:  1.2354 (1.2354)  Acc@1: 72.1910 (72.1910)  Acc@5: 91.0112 (91.0112)
2025-06-02 07:00:05,175 - train - INFO - Test: [  50/70]  Time: 0.120 (0.909)  Loss:  1.7500 (1.7052)  Acc@1: 59.8315 (60.8504)  Acc@5: 83.0056 (83.6473)
2025-06-02 07:00:21,804 - train - INFO - Test: [  70/70]  Time: 0.034 (0.887)  Loss:  1.7119 (1.7771)  Acc@1: 56.2500 (59.4600)  Acc@5: 86.2500 (82.5620)
2025-06-02 07:00:26,977 - train - INFO - Train: 262 [   0/224 (  0%)]  Loss:  3.086499 (3.0865)  Time: 4.876s, 1168.16/s  (4.876s, 1168.16/s)  LR: 4.003e-04  Data: 3.739 (3.739)
2025-06-02 07:01:08,010 - train - INFO - Train: 262 [  50/224 ( 22%)]  Loss:  3.113828 (3.1002)  Time: 0.556s, 10243.15/s  (0.900s, 6327.77/s)  LR: 4.003e-04  Data: 0.000 (0.139)
2025-06-02 07:01:49,692 - train - INFO - Train: 262 [ 100/224 ( 45%)]  Loss:  3.131559 (3.1106)  Time: 0.993s, 5736.60/s  (0.867s, 6568.20/s)  LR: 4.003e-04  Data: 0.000 (0.070)
2025-06-02 07:02:31,330 - train - INFO - Train: 262 [ 150/224 ( 67%)]  Loss:  3.116020 (3.1120)  Time: 0.551s, 10345.57/s  (0.856s, 6655.81/s)  LR: 4.003e-04  Data: 0.000 (0.047)
2025-06-02 07:03:12,306 - train - INFO - Train: 262 [ 200/224 ( 90%)]  Loss:  3.152299 (3.1200)  Time: 0.549s, 10371.14/s  (0.847s, 6726.79/s)  LR: 4.003e-04  Data: 0.000 (0.035)
2025-06-02 07:03:31,500 - train - INFO - Train: 262 [ 223/224 (100%)]  Loss:  3.094196 (3.1157)  Time: 1.103s, 5162.63/s  (0.846s, 6736.84/s)  LR: 4.003e-04  Data: 0.000 (0.032)
2025-06-02 07:03:36,523 - train - INFO - Test: [   0/70]  Time: 4.770 (4.770)  Loss:  1.2822 (1.2822)  Acc@1: 74.4382 (74.4382)  Acc@5: 92.5562 (92.5562)
2025-06-02 07:04:19,131 - train - INFO - Test: [  50/70]  Time: 0.121 (0.929)  Loss:  1.8994 (1.9672)  Acc@1: 64.0449 (61.2029)  Acc@5: 83.8483 (83.8235)
2025-06-02 07:04:35,890 - train - INFO - Test: [  70/70]  Time: 0.035 (0.903)  Loss:  2.6543 (2.0400)  Acc@1: 46.2500 (59.5420)  Acc@5: 75.0000 (82.3900)
2025-06-02 07:04:40,832 - train - INFO - Train: 263 [   0/224 (  0%)]  Loss:  3.125428 (3.1254)  Time: 4.612s, 1234.95/s  (4.612s, 1234.95/s)  LR: 3.803e-04  Data: 3.494 (3.494)
2025-06-02 07:05:22,631 - train - INFO - Train: 263 [  50/224 ( 22%)]  Loss:  3.120074 (3.1228)  Time: 0.549s, 10380.71/s  (0.910s, 6259.76/s)  LR: 3.803e-04  Data: 0.000 (0.088)
2025-06-02 07:06:04,835 - train - INFO - Train: 263 [ 100/224 ( 45%)]  Loss:  3.124392 (3.1233)  Time: 1.456s, 3912.97/s  (0.877s, 6492.70/s)  LR: 3.803e-04  Data: 0.000 (0.044)
2025-06-02 07:06:45,835 - train - INFO - Train: 263 [ 150/224 ( 67%)]  Loss:  3.126332 (3.1241)  Time: 0.944s, 6036.57/s  (0.858s, 6636.36/s)  LR: 3.803e-04  Data: 0.000 (0.030)
2025-06-02 07:07:27,462 - train - INFO - Train: 263 [ 200/224 ( 90%)]  Loss:  3.142670 (3.1278)  Time: 1.521s, 3745.38/s  (0.852s, 6686.43/s)  LR: 3.803e-04  Data: 0.000 (0.022)
2025-06-02 07:07:45,739 - train - INFO - Train: 263 [ 223/224 (100%)]  Loss:  3.105719 (3.1241)  Time: 0.545s, 10442.31/s  (0.846s, 6733.03/s)  LR: 3.803e-04  Data: 0.000 (0.020)
2025-06-02 07:07:50,773 - train - INFO - Test: [   0/70]  Time: 4.793 (4.793)  Loss:  1.2539 (1.2539)  Acc@1: 74.2978 (74.2978)  Acc@5: 91.7135 (91.7135)
2025-06-02 07:08:33,392 - train - INFO - Test: [  50/70]  Time: 0.125 (0.930)  Loss:  1.7881 (1.7589)  Acc@1: 63.9045 (61.4700)  Acc@5: 83.4270 (84.2724)
2025-06-02 07:08:50,095 - train - INFO - Test: [  70/70]  Time: 0.035 (0.903)  Loss:  2.8262 (1.8596)  Acc@1: 38.1250 (59.7060)  Acc@5: 71.2500 (82.7820)
2025-06-02 07:08:55,108 - train - INFO - Train: 264 [   0/224 (  0%)]  Loss:  3.139566 (3.1396)  Time: 4.712s, 1208.77/s  (4.712s, 1208.77/s)  LR: 3.608e-04  Data: 4.167 (4.167)
2025-06-02 07:09:35,741 - train - INFO - Train: 264 [  50/224 ( 22%)]  Loss:  3.142735 (3.1412)  Time: 0.557s, 10230.80/s  (0.889s, 6406.39/s)  LR: 3.608e-04  Data: 0.000 (0.196)
2025-06-02 07:10:17,523 - train - INFO - Train: 264 [ 100/224 ( 45%)]  Loss:  3.119287 (3.1339)  Time: 1.459s, 3904.11/s  (0.863s, 6603.09/s)  LR: 3.608e-04  Data: 0.000 (0.099)
2025-06-02 07:10:58,812 - train - INFO - Train: 264 [ 150/224 ( 67%)]  Loss:  3.137049 (3.1347)  Time: 0.555s, 10263.17/s  (0.850s, 6697.86/s)  LR: 3.608e-04  Data: 0.000 (0.066)
2025-06-02 07:11:40,090 - train - INFO - Train: 264 [ 200/224 ( 90%)]  Loss:  3.135079 (3.1347)  Time: 0.843s, 6755.19/s  (0.844s, 6747.02/s)  LR: 3.608e-04  Data: 0.000 (0.050)
2025-06-02 07:11:58,953 - train - INFO - Train: 264 [ 223/224 (100%)]  Loss:  3.142427 (3.1360)  Time: 0.551s, 10336.51/s  (0.842s, 6766.94/s)  LR: 3.608e-04  Data: 0.000 (0.045)
2025-06-02 07:12:03,894 - train - INFO - Test: [   0/70]  Time: 4.695 (4.695)  Loss:  1.1055 (1.1055)  Acc@1: 74.2978 (74.2978)  Acc@5: 91.0112 (91.0112)
2025-06-02 07:12:46,003 - train - INFO - Test: [  50/70]  Time: 0.120 (0.918)  Loss:  2.0293 (1.6728)  Acc@1: 53.9326 (61.2938)  Acc@5: 80.0562 (83.9227)
2025-06-02 07:13:02,419 - train - INFO - Test: [  70/70]  Time: 0.034 (0.890)  Loss:  2.5156 (1.7843)  Acc@1: 39.3750 (59.3900)  Acc@5: 72.5000 (82.1620)
2025-06-02 07:13:07,363 - train - INFO - Train: 265 [   0/224 (  0%)]  Loss:  3.119546 (3.1195)  Time: 4.636s, 1228.65/s  (4.636s, 1228.65/s)  LR: 3.418e-04  Data: 4.026 (4.026)
2025-06-02 07:13:48,474 - train - INFO - Train: 265 [  50/224 ( 22%)]  Loss:  3.121925 (3.1207)  Time: 0.546s, 10423.05/s  (0.897s, 6350.66/s)  LR: 3.418e-04  Data: 0.000 (0.167)
2025-06-02 07:14:30,716 - train - INFO - Train: 265 [ 100/224 ( 45%)]  Loss:  3.136541 (3.1260)  Time: 1.756s, 3243.63/s  (0.871s, 6538.72/s)  LR: 3.418e-04  Data: 0.000 (0.085)
2025-06-02 07:15:10,767 - train - INFO - Train: 265 [ 150/224 ( 67%)]  Loss:  3.111676 (3.1224)  Time: 0.550s, 10364.15/s  (0.848s, 6717.73/s)  LR: 3.418e-04  Data: 0.000 (0.057)
2025-06-02 07:15:52,679 - train - INFO - Train: 265 [ 200/224 ( 90%)]  Loss:  3.107156 (3.1194)  Time: 1.597s, 3565.79/s  (0.845s, 6736.88/s)  LR: 3.418e-04  Data: 0.000 (0.043)
2025-06-02 07:16:10,653 - train - INFO - Train: 265 [ 223/224 (100%)]  Loss:  3.110413 (3.1179)  Time: 0.545s, 10458.94/s  (0.839s, 6789.74/s)  LR: 3.418e-04  Data: 0.000 (0.038)
2025-06-02 07:16:15,495 - train - INFO - Test: [   0/70]  Time: 4.585 (4.585)  Loss:  1.5508 (1.5508)  Acc@1: 73.7360 (73.7360)  Acc@5: 89.7472 (89.7472)
2025-06-02 07:16:57,874 - train - INFO - Test: [  50/70]  Time: 0.120 (0.921)  Loss:  2.2129 (1.9267)  Acc@1: 57.8652 (62.6267)  Acc@5: 81.0393 (84.8397)
2025-06-02 07:17:14,303 - train - INFO - Test: [  70/70]  Time: 0.034 (0.893)  Loss:  2.9238 (2.0159)  Acc@1: 43.1250 (61.2620)  Acc@5: 72.5000 (83.5900)
2025-06-02 07:17:19,298 - train - INFO - Train: 266 [   0/224 (  0%)]  Loss:  3.148268 (3.1483)  Time: 4.688s, 1215.01/s  (4.688s, 1215.01/s)  LR: 3.233e-04  Data: 4.132 (4.132)
2025-06-02 07:18:00,293 - train - INFO - Train: 266 [  50/224 ( 22%)]  Loss:  3.132424 (3.1403)  Time: 0.554s, 10281.09/s  (0.896s, 6359.24/s)  LR: 3.233e-04  Data: 0.000 (0.180)
2025-06-02 07:18:42,043 - train - INFO - Train: 266 [ 100/224 ( 45%)]  Loss:  3.137142 (3.1393)  Time: 1.569s, 3629.82/s  (0.866s, 6580.07/s)  LR: 3.233e-04  Data: 0.000 (0.091)
2025-06-02 07:19:22,810 - train - INFO - Train: 266 [ 150/224 ( 67%)]  Loss:  3.097582 (3.1289)  Time: 0.550s, 10361.75/s  (0.849s, 6709.26/s)  LR: 3.233e-04  Data: 0.000 (0.061)
2025-06-02 07:20:04,697 - train - INFO - Train: 266 [ 200/224 ( 90%)]  Loss:  3.116661 (3.1264)  Time: 1.595s, 3570.95/s  (0.846s, 6731.48/s)  LR: 3.233e-04  Data: 0.000 (0.046)
2025-06-02 07:20:22,758 - train - INFO - Train: 266 [ 223/224 (100%)]  Loss:  3.104406 (3.1227)  Time: 0.544s, 10469.39/s  (0.840s, 6781.63/s)  LR: 3.233e-04  Data: 0.000 (0.041)
2025-06-02 07:20:27,623 - train - INFO - Test: [   0/70]  Time: 4.613 (4.613)  Loss:  1.0400 (1.0400)  Acc@1: 76.8258 (76.8258)  Acc@5: 93.6798 (93.6798)
2025-06-02 07:21:10,377 - train - INFO - Test: [  50/70]  Time: 0.120 (0.929)  Loss:  1.9756 (1.7717)  Acc@1: 58.5674 (61.1203)  Acc@5: 80.4775 (83.9915)
2025-06-02 07:21:27,106 - train - INFO - Test: [  70/70]  Time: 0.035 (0.903)  Loss:  2.0137 (1.8682)  Acc@1: 52.5000 (59.3480)  Acc@5: 82.5000 (82.2960)
2025-06-02 07:21:32,306 - train - INFO - Train: 267 [   0/224 (  0%)]  Loss:  3.116658 (3.1167)  Time: 4.892s, 1164.35/s  (4.892s, 1164.35/s)  LR: 3.053e-04  Data: 3.533 (3.533)
2025-06-02 07:22:12,960 - train - INFO - Train: 267 [  50/224 ( 22%)]  Loss:  3.115452 (3.1161)  Time: 0.564s, 10097.98/s  (0.893s, 6378.30/s)  LR: 3.053e-04  Data: 0.000 (0.080)
2025-06-02 07:22:54,176 - train - INFO - Train: 267 [ 100/224 ( 45%)]  Loss:  3.129995 (3.1207)  Time: 1.366s, 4170.42/s  (0.859s, 6630.99/s)  LR: 3.053e-04  Data: 0.000 (0.041)
2025-06-02 07:23:34,947 - train - INFO - Train: 267 [ 150/224 ( 67%)]  Loss:  3.104002 (3.1165)  Time: 0.549s, 10374.06/s  (0.845s, 6744.37/s)  LR: 3.053e-04  Data: 0.000 (0.027)
2025-06-02 07:24:16,342 - train - INFO - Train: 267 [ 200/224 ( 90%)]  Loss:  3.126810 (3.1186)  Time: 1.481s, 3846.60/s  (0.840s, 6777.64/s)  LR: 3.053e-04  Data: 0.000 (0.021)
2025-06-02 07:24:34,222 - train - INFO - Train: 267 [ 223/224 (100%)]  Loss:  3.149552 (3.1237)  Time: 0.545s, 10442.94/s  (0.834s, 6830.27/s)  LR: 3.053e-04  Data: 0.000 (0.019)
2025-06-02 07:24:39,048 - train - INFO - Test: [   0/70]  Time: 4.581 (4.581)  Loss:  1.1943 (1.1943)  Acc@1: 72.6124 (72.6124)  Acc@5: 90.5899 (90.5899)
2025-06-02 07:25:21,863 - train - INFO - Test: [  50/70]  Time: 0.124 (0.929)  Loss:  1.9229 (1.6494)  Acc@1: 58.4270 (62.2494)  Acc@5: 79.7753 (84.4569)
2025-06-02 07:25:38,463 - train - INFO - Test: [  70/70]  Time: 0.034 (0.901)  Loss:  2.3340 (1.7225)  Acc@1: 41.8750 (60.7200)  Acc@5: 75.6250 (83.2320)
2025-06-02 07:25:43,376 - train - INFO - Train: 268 [   0/224 (  0%)]  Loss:  3.119154 (3.1192)  Time: 4.600s, 1238.20/s  (4.600s, 1238.20/s)  LR: 2.878e-04  Data: 4.011 (4.011)
2025-06-02 07:26:23,828 - train - INFO - Train: 268 [  50/224 ( 22%)]  Loss:  3.144072 (3.1316)  Time: 0.547s, 10410.37/s  (0.883s, 6448.57/s)  LR: 2.878e-04  Data: 0.000 (0.274)
2025-06-02 07:27:05,684 - train - INFO - Train: 268 [ 100/224 ( 45%)]  Loss:  3.114668 (3.1260)  Time: 1.751s, 3252.98/s  (0.860s, 6619.99/s)  LR: 2.878e-04  Data: 0.000 (0.180)
2025-06-02 07:27:45,679 - train - INFO - Train: 268 [ 150/224 ( 67%)]  Loss:  3.138660 (3.1291)  Time: 0.555s, 10267.51/s  (0.840s, 6777.98/s)  LR: 2.878e-04  Data: 0.000 (0.120)
2025-06-02 07:28:26,992 - train - INFO - Train: 268 [ 200/224 ( 90%)]  Loss:  3.089816 (3.1213)  Time: 1.592s, 3578.05/s  (0.837s, 6806.49/s)  LR: 2.878e-04  Data: 0.000 (0.090)
2025-06-02 07:28:44,766 - train - INFO - Train: 268 [ 223/224 (100%)]  Loss:  3.144400 (3.1251)  Time: 0.552s, 10316.72/s  (0.830s, 6860.49/s)  LR: 2.878e-04  Data: 0.000 (0.081)
2025-06-02 07:28:49,324 - train - INFO - Test: [   0/70]  Time: 4.315 (4.315)  Loss:  1.1240 (1.1240)  Acc@1: 75.1404 (75.1404)  Acc@5: 90.5899 (90.5899)
2025-06-02 07:29:31,346 - train - INFO - Test: [  50/70]  Time: 0.291 (0.909)  Loss:  1.6543 (1.6298)  Acc@1: 62.3596 (63.0948)  Acc@5: 83.8483 (84.8976)
2025-06-02 07:29:47,511 - train - INFO - Test: [  70/70]  Time: 0.034 (0.880)  Loss:  2.3125 (1.6851)  Acc@1: 45.0000 (61.9260)  Acc@5: 76.8750 (83.9440)
2025-06-02 07:29:52,707 - train - INFO - Train: 269 [   0/224 (  0%)]  Loss:  3.116950 (3.1169)  Time: 4.893s, 1164.09/s  (4.893s, 1164.09/s)  LR: 2.709e-04  Data: 3.945 (3.945)
2025-06-02 07:30:33,511 - train - INFO - Train: 269 [  50/224 ( 22%)]  Loss:  3.125184 (3.1211)  Time: 0.549s, 10372.28/s  (0.896s, 6357.31/s)  LR: 2.709e-04  Data: 0.000 (0.313)
2025-06-02 07:31:15,187 - train - INFO - Train: 269 [ 100/224 ( 45%)]  Loss:  3.164549 (3.1356)  Time: 1.360s, 4187.64/s  (0.865s, 6584.63/s)  LR: 2.709e-04  Data: 0.000 (0.226)
2025-06-02 07:31:55,555 - train - INFO - Train: 269 [ 150/224 ( 67%)]  Loss:  3.111167 (3.1295)  Time: 0.620s, 9184.45/s  (0.846s, 6733.46/s)  LR: 2.709e-04  Data: 0.000 (0.162)
2025-06-02 07:32:37,602 - train - INFO - Train: 269 [ 200/224 ( 90%)]  Loss:  3.169568 (3.1375)  Time: 1.791s, 3180.98/s  (0.845s, 6743.39/s)  LR: 2.709e-04  Data: 0.000 (0.121)
2025-06-02 07:32:55,242 - train - INFO - Train: 269 [ 223/224 (100%)]  Loss:  3.114935 (3.1337)  Time: 0.547s, 10418.35/s  (0.837s, 6807.75/s)  LR: 2.709e-04  Data: 0.000 (0.109)
2025-06-02 07:33:00,101 - train - INFO - Test: [   0/70]  Time: 4.606 (4.606)  Loss:  1.2588 (1.2588)  Acc@1: 73.5955 (73.5955)  Acc@5: 91.8539 (91.8539)
2025-06-02 07:33:42,969 - train - INFO - Test: [  50/70]  Time: 0.120 (0.931)  Loss:  1.9619 (1.9055)  Acc@1: 60.1124 (61.3654)  Acc@5: 81.0393 (83.8098)
2025-06-02 07:33:59,644 - train - INFO - Test: [  70/70]  Time: 0.039 (0.904)  Loss:  2.3105 (1.9783)  Acc@1: 45.6250 (59.7320)  Acc@5: 82.5000 (82.5040)
2025-06-02 07:34:04,535 - train - INFO - Train: 270 [   0/224 (  0%)]  Loss:  3.136209 (3.1362)  Time: 4.590s, 1240.99/s  (4.590s, 1240.99/s)  LR: 2.545e-04  Data: 3.938 (3.938)
2025-06-02 07:34:45,699 - train - INFO - Train: 270 [  50/224 ( 22%)]  Loss:  3.116721 (3.1265)  Time: 0.550s, 10360.56/s  (0.897s, 6349.28/s)  LR: 2.545e-04  Data: 0.000 (0.133)
2025-06-02 07:35:27,535 - train - INFO - Train: 270 [ 100/224 ( 45%)]  Loss:  3.135130 (3.1294)  Time: 1.635s, 3483.58/s  (0.867s, 6568.31/s)  LR: 2.545e-04  Data: 0.000 (0.067)
2025-06-02 07:36:07,839 - train - INFO - Train: 270 [ 150/224 ( 67%)]  Loss:  3.138937 (3.1317)  Time: 0.550s, 10361.53/s  (0.847s, 6725.31/s)  LR: 2.545e-04  Data: 0.000 (0.045)
2025-06-02 07:36:49,017 - train - INFO - Train: 270 [ 200/224 ( 90%)]  Loss:  3.106912 (3.1268)  Time: 0.826s, 6893.53/s  (0.841s, 6771.89/s)  LR: 2.545e-04  Data: 0.000 (0.034)
2025-06-02 07:37:07,735 - train - INFO - Train: 270 [ 223/224 (100%)]  Loss:  3.114270 (3.1247)  Time: 0.802s, 7102.61/s  (0.838s, 6794.58/s)  LR: 2.545e-04  Data: 0.000 (0.031)
2025-06-02 07:37:12,491 - train - INFO - Test: [   0/70]  Time: 4.515 (4.515)  Loss:  1.1338 (1.1338)  Acc@1: 75.1404 (75.1404)  Acc@5: 91.8539 (91.8539)
2025-06-02 07:37:54,716 - train - INFO - Test: [  50/70]  Time: 0.120 (0.916)  Loss:  1.6895 (1.7476)  Acc@1: 65.3090 (60.6934)  Acc@5: 83.9888 (83.5894)
2025-06-02 07:38:11,124 - train - INFO - Test: [  70/70]  Time: 0.034 (0.889)  Loss:  2.8828 (1.8511)  Acc@1: 35.6250 (58.5500)  Acc@5: 66.8750 (81.8860)
2025-06-02 07:38:15,972 - train - INFO - Train: 271 [   0/224 (  0%)]  Loss:  3.096975 (3.0970)  Time: 4.537s, 1255.55/s  (4.537s, 1255.55/s)  LR: 2.386e-04  Data: 3.919 (3.919)
2025-06-02 07:38:56,950 - train - INFO - Train: 271 [  50/224 ( 22%)]  Loss:  3.138966 (3.1180)  Time: 0.550s, 10362.21/s  (0.892s, 6382.65/s)  LR: 2.386e-04  Data: 0.000 (0.154)
2025-06-02 07:39:38,572 - train - INFO - Train: 271 [ 100/224 ( 45%)]  Loss:  3.124015 (3.1200)  Time: 1.577s, 3611.92/s  (0.863s, 6602.41/s)  LR: 2.386e-04  Data: 0.000 (0.078)
2025-06-02 07:40:19,390 - train - INFO - Train: 271 [ 150/224 ( 67%)]  Loss:  3.130654 (3.1227)  Time: 0.549s, 10375.73/s  (0.847s, 6722.08/s)  LR: 2.386e-04  Data: 0.000 (0.052)
2025-06-02 07:41:01,260 - train - INFO - Train: 271 [ 200/224 ( 90%)]  Loss:  3.133341 (3.1248)  Time: 1.846s, 3085.07/s  (0.845s, 6741.88/s)  LR: 2.386e-04  Data: 0.000 (0.039)
2025-06-02 07:41:19,073 - train - INFO - Train: 271 [ 223/224 (100%)]  Loss:  3.179162 (3.1339)  Time: 0.546s, 10440.52/s  (0.838s, 6800.08/s)  LR: 2.386e-04  Data: 0.000 (0.035)
2025-06-02 07:41:23,577 - train - INFO - Test: [   0/70]  Time: 4.258 (4.258)  Loss:  1.1875 (1.1875)  Acc@1: 73.7360 (73.7360)  Acc@5: 91.5730 (91.5730)
2025-06-02 07:42:05,642 - train - INFO - Test: [  50/70]  Time: 0.121 (0.908)  Loss:  1.7959 (1.6600)  Acc@1: 60.8146 (62.2577)  Acc@5: 81.8820 (84.5010)
2025-06-02 07:42:22,243 - train - INFO - Test: [  70/70]  Time: 0.034 (0.886)  Loss:  2.3379 (1.7453)  Acc@1: 45.0000 (60.5140)  Acc@5: 75.0000 (83.2180)
2025-06-02 07:42:27,299 - train - INFO - Train: 272 [   0/224 (  0%)]  Loss:  3.120365 (3.1204)  Time: 4.750s, 1199.17/s  (4.750s, 1199.17/s)  LR: 2.232e-04  Data: 4.199 (4.199)
2025-06-02 07:43:08,431 - train - INFO - Train: 272 [  50/224 ( 22%)]  Loss:  3.133017 (3.1267)  Time: 0.550s, 10350.59/s  (0.900s, 6331.64/s)  LR: 2.232e-04  Data: 0.000 (0.226)
2025-06-02 07:43:50,229 - train - INFO - Train: 272 [ 100/224 ( 45%)]  Loss:  3.167506 (3.1403)  Time: 1.663s, 3424.25/s  (0.868s, 6561.71/s)  LR: 2.232e-04  Data: 0.000 (0.115)
2025-06-02 07:44:30,387 - train - INFO - Train: 272 [ 150/224 ( 67%)]  Loss:  3.163316 (3.1461)  Time: 0.555s, 10255.42/s  (0.847s, 6728.36/s)  LR: 2.232e-04  Data: 0.000 (0.085)
2025-06-02 07:45:11,486 - train - INFO - Train: 272 [ 200/224 ( 90%)]  Loss:  3.102504 (3.1373)  Time: 1.605s, 3549.67/s  (0.840s, 6777.44/s)  LR: 2.232e-04  Data: 0.396 (0.090)
2025-06-02 07:45:29,061 - train - INFO - Train: 272 [ 223/224 (100%)]  Loss:  3.124865 (3.1353)  Time: 0.551s, 10340.50/s  (0.833s, 6841.27/s)  LR: 2.232e-04  Data: 0.000 (0.091)
2025-06-02 07:45:33,712 - train - INFO - Test: [   0/70]  Time: 4.400 (4.400)  Loss:  1.3154 (1.3154)  Acc@1: 73.3146 (73.3146)  Acc@5: 89.8876 (89.8876)
2025-06-02 07:46:15,399 - train - INFO - Test: [  50/70]  Time: 0.120 (0.904)  Loss:  1.7959 (1.6960)  Acc@1: 63.0618 (63.8742)  Acc@5: 83.2865 (85.2859)
2025-06-02 07:46:31,677 - train - INFO - Test: [  70/70]  Time: 0.034 (0.878)  Loss:  2.2832 (1.7788)  Acc@1: 44.3750 (62.0980)  Acc@5: 79.3750 (83.9900)
2025-06-02 07:46:36,692 - train - INFO - Train: 273 [   0/224 (  0%)]  Loss:  3.121938 (3.1219)  Time: 4.706s, 1210.36/s  (4.706s, 1210.36/s)  LR: 2.083e-04  Data: 3.994 (3.994)
2025-06-02 07:47:17,326 - train - INFO - Train: 273 [  50/224 ( 22%)]  Loss:  3.142456 (3.1322)  Time: 0.549s, 10371.09/s  (0.889s, 6407.31/s)  LR: 2.083e-04  Data: 0.000 (0.280)
2025-06-02 07:47:58,217 - train - INFO - Train: 273 [ 100/224 ( 45%)]  Loss:  3.139200 (3.1345)  Time: 1.615s, 3525.99/s  (0.854s, 6671.85/s)  LR: 2.083e-04  Data: 0.497 (0.231)
2025-06-02 07:48:38,234 - train - INFO - Train: 273 [ 150/224 ( 67%)]  Loss:  3.091154 (3.1237)  Time: 0.549s, 10379.60/s  (0.836s, 6812.99/s)  LR: 2.083e-04  Data: 0.000 (0.190)
2025-06-02 07:49:19,227 - train - INFO - Train: 273 [ 200/224 ( 90%)]  Loss:  3.126356 (3.1242)  Time: 1.622s, 3510.85/s  (0.832s, 6846.08/s)  LR: 2.083e-04  Data: 0.071 (0.156)
2025-06-02 07:49:37,025 - train - INFO - Train: 273 [ 223/224 (100%)]  Loss:  3.153852 (3.1292)  Time: 0.550s, 10351.56/s  (0.826s, 6895.67/s)  LR: 2.083e-04  Data: 0.000 (0.140)
2025-06-02 07:49:41,993 - train - INFO - Test: [   0/70]  Time: 4.728 (4.728)  Loss:  1.5557 (1.5557)  Acc@1: 71.9101 (71.9101)  Acc@5: 90.3090 (90.3090)
2025-06-02 07:50:23,749 - train - INFO - Test: [  50/70]  Time: 0.120 (0.911)  Loss:  1.7119 (1.8467)  Acc@1: 64.0449 (62.2081)  Acc@5: 84.6910 (84.6222)
2025-06-02 07:50:40,113 - train - INFO - Test: [  70/70]  Time: 0.034 (0.885)  Loss:  2.8926 (1.9305)  Acc@1: 39.3750 (60.3620)  Acc@5: 70.0000 (83.0880)
2025-06-02 07:50:45,276 - train - INFO - Train: 274 [   0/224 (  0%)]  Loss:  3.097640 (3.0976)  Time: 4.858s, 1172.58/s  (4.858s, 1172.58/s)  LR: 1.940e-04  Data: 3.931 (3.931)
2025-06-02 07:51:25,654 - train - INFO - Train: 274 [  50/224 ( 22%)]  Loss:  3.085592 (3.0916)  Time: 0.555s, 10263.52/s  (0.887s, 6422.23/s)  LR: 1.940e-04  Data: 0.000 (0.146)
2025-06-02 07:52:06,436 - train - INFO - Train: 274 [ 100/224 ( 45%)]  Loss:  3.118757 (3.1007)  Time: 1.208s, 4714.90/s  (0.852s, 6688.44/s)  LR: 1.940e-04  Data: 0.000 (0.081)
2025-06-02 07:52:46,835 - train - INFO - Train: 274 [ 150/224 ( 67%)]  Loss:  3.124405 (3.1066)  Time: 0.555s, 10271.95/s  (0.837s, 6803.96/s)  LR: 1.940e-04  Data: 0.000 (0.054)
2025-06-02 07:53:27,956 - train - INFO - Train: 274 [ 200/224 ( 90%)]  Loss:  3.146615 (3.1146)  Time: 1.553s, 3667.48/s  (0.833s, 6833.97/s)  LR: 1.940e-04  Data: 0.000 (0.041)
2025-06-02 07:53:46,082 - train - INFO - Train: 274 [ 223/224 (100%)]  Loss:  3.109790 (3.1138)  Time: 0.546s, 10425.54/s  (0.829s, 6872.48/s)  LR: 1.940e-04  Data: 0.000 (0.037)
2025-06-02 07:53:50,983 - train - INFO - Test: [   0/70]  Time: 4.655 (4.655)  Loss:  1.5195 (1.5195)  Acc@1: 73.0337 (73.0337)  Acc@5: 91.7135 (91.7135)
2025-06-02 07:54:32,515 - train - INFO - Test: [  50/70]  Time: 0.141 (0.906)  Loss:  2.0137 (1.9804)  Acc@1: 57.3034 (60.2473)  Acc@5: 82.8652 (83.5068)
2025-06-02 07:54:49,005 - train - INFO - Test: [  70/70]  Time: 0.039 (0.883)  Loss:  2.4004 (2.0288)  Acc@1: 49.3750 (58.9900)  Acc@5: 81.2500 (82.3400)
2025-06-02 07:54:53,860 - train - INFO - Train: 275 [   0/224 (  0%)]  Loss:  3.087868 (3.0879)  Time: 4.537s, 1255.43/s  (4.537s, 1255.43/s)  LR: 1.802e-04  Data: 3.537 (3.537)
2025-06-02 07:55:34,858 - train - INFO - Train: 275 [  50/224 ( 22%)]  Loss:  3.134039 (3.1110)  Time: 0.552s, 10327.09/s  (0.893s, 6379.94/s)  LR: 1.802e-04  Data: 0.000 (0.243)
2025-06-02 07:56:16,144 - train - INFO - Train: 275 [ 100/224 ( 45%)]  Loss:  3.149047 (3.1237)  Time: 1.774s, 3210.60/s  (0.860s, 6626.47/s)  LR: 1.802e-04  Data: 0.000 (0.134)
2025-06-02 07:56:55,987 - train - INFO - Train: 275 [ 150/224 ( 67%)]  Loss:  3.086624 (3.1144)  Time: 0.551s, 10335.03/s  (0.839s, 6790.60/s)  LR: 1.802e-04  Data: 0.000 (0.090)
2025-06-02 07:57:37,125 - train - INFO - Train: 275 [ 200/224 ( 90%)]  Loss:  3.099429 (3.1114)  Time: 1.568s, 3633.33/s  (0.835s, 6823.10/s)  LR: 1.802e-04  Data: 0.000 (0.067)
2025-06-02 07:57:55,169 - train - INFO - Train: 275 [ 223/224 (100%)]  Loss:  3.139037 (3.1160)  Time: 0.545s, 10457.45/s  (0.830s, 6865.67/s)  LR: 1.802e-04  Data: 0.000 (0.061)
2025-06-02 07:57:59,993 - train - INFO - Test: [   0/70]  Time: 4.579 (4.579)  Loss:  1.2314 (1.2314)  Acc@1: 71.7697 (71.7697)  Acc@5: 89.3259 (89.3259)
2025-06-02 07:58:41,740 - train - INFO - Test: [  50/70]  Time: 0.120 (0.908)  Loss:  1.7256 (1.6983)  Acc@1: 58.2865 (60.7485)  Acc@5: 82.5843 (83.2149)
2025-06-02 07:58:58,073 - train - INFO - Test: [  70/70]  Time: 0.034 (0.883)  Loss:  2.1094 (1.7743)  Acc@1: 49.3750 (59.2560)  Acc@5: 80.0000 (82.1220)
2025-06-02 07:59:02,847 - train - INFO - Train: 276 [   0/224 (  0%)]  Loss:  3.191004 (3.1910)  Time: 4.458s, 1277.79/s  (4.458s, 1277.79/s)  LR: 1.669e-04  Data: 3.851 (3.851)
2025-06-02 07:59:43,286 - train - INFO - Train: 276 [  50/224 ( 22%)]  Loss:  3.121125 (3.1561)  Time: 0.559s, 10187.78/s  (0.880s, 6470.54/s)  LR: 1.669e-04  Data: 0.000 (0.101)
2025-06-02 08:00:24,840 - train - INFO - Train: 276 [ 100/224 ( 45%)]  Loss:  3.109890 (3.1407)  Time: 1.330s, 4282.98/s  (0.856s, 6655.06/s)  LR: 1.669e-04  Data: 0.000 (0.051)
2025-06-02 08:01:05,770 - train - INFO - Train: 276 [ 150/224 ( 67%)]  Loss:  3.147039 (3.1423)  Time: 1.126s, 5057.85/s  (0.844s, 6752.68/s)  LR: 1.669e-04  Data: 0.000 (0.034)
2025-06-02 08:01:46,528 - train - INFO - Train: 276 [ 200/224 ( 90%)]  Loss:  3.093389 (3.1325)  Time: 1.174s, 4850.32/s  (0.836s, 6809.69/s)  LR: 1.669e-04  Data: 0.000 (0.026)
2025-06-02 08:02:04,929 - train - INFO - Train: 276 [ 223/224 (100%)]  Loss:  3.143819 (3.1344)  Time: 0.546s, 10427.11/s  (0.833s, 6840.29/s)  LR: 1.669e-04  Data: 0.000 (0.023)
2025-06-02 08:02:09,724 - train - INFO - Test: [   0/70]  Time: 4.564 (4.564)  Loss:  1.5762 (1.5762)  Acc@1: 71.2079 (71.2079)  Acc@5: 88.3427 (88.3427)
2025-06-02 08:02:51,525 - train - INFO - Test: [  50/70]  Time: 0.258 (0.909)  Loss:  1.9824 (1.9115)  Acc@1: 61.6573 (62.2466)  Acc@5: 81.1798 (84.3826)
2025-06-02 08:03:08,057 - train - INFO - Test: [  70/70]  Time: 0.034 (0.886)  Loss:  3.2188 (1.9750)  Acc@1: 30.6250 (60.6780)  Acc@5: 66.2500 (83.0460)
2025-06-02 08:03:12,916 - train - INFO - Train: 277 [   0/224 (  0%)]  Loss:  3.099002 (3.0990)  Time: 4.556s, 1250.23/s  (4.556s, 1250.23/s)  LR: 1.542e-04  Data: 4.009 (4.009)
2025-06-02 08:03:53,477 - train - INFO - Train: 277 [  50/224 ( 22%)]  Loss:  3.130442 (3.1147)  Time: 0.550s, 10350.70/s  (0.885s, 6438.95/s)  LR: 1.542e-04  Data: 0.000 (0.314)
2025-06-02 08:04:34,815 - train - INFO - Train: 277 [ 100/224 ( 45%)]  Loss:  3.116784 (3.1154)  Time: 1.175s, 4848.42/s  (0.856s, 6654.56/s)  LR: 1.542e-04  Data: 0.632 (0.269)
2025-06-02 08:05:15,646 - train - INFO - Train: 277 [ 150/224 ( 67%)]  Loss:  3.114805 (3.1153)  Time: 0.549s, 10367.77/s  (0.843s, 6757.40/s)  LR: 1.542e-04  Data: 0.000 (0.222)
2025-06-02 08:05:56,511 - train - INFO - Train: 277 [ 200/224 ( 90%)]  Loss:  3.119105 (3.1160)  Time: 1.449s, 3931.46/s  (0.837s, 6809.01/s)  LR: 1.542e-04  Data: 0.902 (0.215)
2025-06-02 08:06:14,093 - train - INFO - Train: 277 [ 223/224 (100%)]  Loss:  3.126795 (3.1178)  Time: 0.546s, 10426.53/s  (0.829s, 6869.82/s)  LR: 1.542e-04  Data: 0.000 (0.207)
2025-06-02 08:06:18,916 - train - INFO - Test: [   0/70]  Time: 4.566 (4.566)  Loss:  1.2812 (1.2812)  Acc@1: 70.7865 (70.7865)  Acc@5: 89.7472 (89.7472)
2025-06-02 08:07:00,662 - train - INFO - Test: [  50/70]  Time: 0.120 (0.908)  Loss:  1.8193 (1.6400)  Acc@1: 61.6573 (63.0480)  Acc@5: 82.0225 (85.3464)
2025-06-02 08:07:16,636 - train - INFO - Test: [  70/70]  Time: 0.034 (0.877)  Loss:  2.3926 (1.7386)  Acc@1: 45.0000 (61.2180)  Acc@5: 75.6250 (83.8180)
2025-06-02 08:07:21,675 - train - INFO - Train: 278 [   0/224 (  0%)]  Loss:  3.150061 (3.1501)  Time: 4.726s, 1205.27/s  (4.726s, 1205.27/s)  LR: 1.420e-04  Data: 3.694 (3.694)
2025-06-02 08:08:02,302 - train - INFO - Train: 278 [  50/224 ( 22%)]  Loss:  3.116936 (3.1335)  Time: 0.556s, 10247.08/s  (0.889s, 6405.62/s)  LR: 1.420e-04  Data: 0.000 (0.159)
2025-06-02 08:08:43,465 - train - INFO - Train: 278 [ 100/224 ( 45%)]  Loss:  3.130746 (3.1326)  Time: 0.998s, 5708.53/s  (0.857s, 6649.80/s)  LR: 1.420e-04  Data: 0.000 (0.083)
2025-06-02 08:09:24,936 - train - INFO - Train: 278 [ 150/224 ( 67%)]  Loss:  3.140642 (3.1346)  Time: 1.098s, 5186.17/s  (0.848s, 6720.45/s)  LR: 1.420e-04  Data: 0.000 (0.056)
2025-06-02 08:10:06,368 - train - INFO - Train: 278 [ 200/224 ( 90%)]  Loss:  3.166943 (3.1411)  Time: 1.557s, 3658.67/s  (0.843s, 6758.07/s)  LR: 1.420e-04  Data: 0.000 (0.042)
2025-06-02 08:10:24,187 - train - INFO - Train: 278 [ 223/224 (100%)]  Loss:  3.138752 (3.1407)  Time: 0.546s, 10431.78/s  (0.836s, 6814.69/s)  LR: 1.420e-04  Data: 0.000 (0.038)
2025-06-02 08:10:29,068 - train - INFO - Test: [   0/70]  Time: 4.645 (4.645)  Loss:  1.1104 (1.1104)  Acc@1: 75.1404 (75.1404)  Acc@5: 90.5899 (90.5899)
2025-06-02 08:11:10,849 - train - INFO - Test: [  50/70]  Time: 0.120 (0.910)  Loss:  1.7822 (1.6093)  Acc@1: 59.6910 (62.1943)  Acc@5: 81.0393 (84.6662)
2025-06-02 08:11:27,222 - train - INFO - Test: [  70/70]  Time: 0.034 (0.884)  Loss:  2.4629 (1.6986)  Acc@1: 43.1250 (60.5760)  Acc@5: 71.8750 (83.2360)
2025-06-02 08:11:32,187 - train - INFO - Train: 279 [   0/224 (  0%)]  Loss:  3.121438 (3.1214)  Time: 4.650s, 1224.96/s  (4.650s, 1224.96/s)  LR: 1.303e-04  Data: 3.417 (3.417)
2025-06-02 08:12:13,241 - train - INFO - Train: 279 [  50/224 ( 22%)]  Loss:  3.150248 (3.1358)  Time: 0.551s, 10336.00/s  (0.896s, 6356.22/s)  LR: 1.303e-04  Data: 0.000 (0.148)
2025-06-02 08:12:54,612 - train - INFO - Train: 279 [ 100/224 ( 45%)]  Loss:  3.132555 (3.1347)  Time: 1.599s, 3561.22/s  (0.862s, 6607.05/s)  LR: 1.303e-04  Data: 0.000 (0.075)
2025-06-02 08:13:35,638 - train - INFO - Train: 279 [ 150/224 ( 67%)]  Loss:  3.132735 (3.1342)  Time: 0.556s, 10246.19/s  (0.848s, 6714.46/s)  LR: 1.303e-04  Data: 0.000 (0.050)
2025-06-02 08:14:17,673 - train - INFO - Train: 279 [ 200/224 ( 90%)]  Loss:  3.132778 (3.1340)  Time: 1.650s, 3453.16/s  (0.846s, 6729.55/s)  LR: 1.303e-04  Data: 0.000 (0.038)
2025-06-02 08:14:35,647 - train - INFO - Train: 279 [ 223/224 (100%)]  Loss:  3.118758 (3.1314)  Time: 0.554s, 10290.34/s  (0.840s, 6783.04/s)  LR: 1.303e-04  Data: 0.000 (0.034)
2025-06-02 08:14:40,405 - train - INFO - Test: [   0/70]  Time: 4.515 (4.515)  Loss:  1.2412 (1.2412)  Acc@1: 73.4551 (73.4551)  Acc@5: 93.1180 (93.1180)
2025-06-02 08:15:23,094 - train - INFO - Test: [  50/70]  Time: 0.120 (0.926)  Loss:  1.8271 (1.8520)  Acc@1: 63.0618 (61.1258)  Acc@5: 83.0056 (83.8428)
2025-06-02 08:15:40,004 - train - INFO - Test: [  70/70]  Time: 0.034 (0.903)  Loss:  2.2988 (1.9276)  Acc@1: 46.2500 (59.5460)  Acc@5: 77.5000 (82.4040)
2025-06-02 08:15:45,006 - train - INFO - Train: 280 [   0/224 (  0%)]  Loss:  3.119033 (3.1190)  Time: 4.687s, 1215.15/s  (4.687s, 1215.15/s)  LR: 1.192e-04  Data: 4.139 (4.139)
2025-06-02 08:16:25,905 - train - INFO - Train: 280 [  50/224 ( 22%)]  Loss:  3.132641 (3.1258)  Time: 0.549s, 10374.36/s  (0.894s, 6372.73/s)  LR: 1.192e-04  Data: 0.000 (0.319)
2025-06-02 08:17:07,525 - train - INFO - Train: 280 [ 100/224 ( 45%)]  Loss:  3.125389 (3.1257)  Time: 1.652s, 3448.42/s  (0.863s, 6597.15/s)  LR: 1.192e-04  Data: 1.110 (0.300)
2025-06-02 08:17:48,157 - train - INFO - Train: 280 [ 150/224 ( 67%)]  Loss:  3.126072 (3.1258)  Time: 0.550s, 10357.09/s  (0.847s, 6728.20/s)  LR: 1.192e-04  Data: 0.000 (0.268)
2025-06-02 08:18:28,791 - train - INFO - Train: 280 [ 200/224 ( 90%)]  Loss:  3.066391 (3.1139)  Time: 0.575s, 9906.49/s  (0.838s, 6795.94/s)  LR: 1.192e-04  Data: 0.033 (0.219)
2025-06-02 08:18:47,570 - train - INFO - Train: 280 [ 223/224 (100%)]  Loss:  3.148347 (3.1196)  Time: 0.544s, 10471.13/s  (0.836s, 6814.09/s)  LR: 1.192e-04  Data: 0.000 (0.202)
2025-06-02 08:18:52,486 - train - INFO - Test: [   0/70]  Time: 4.658 (4.658)  Loss:  1.7119 (1.7119)  Acc@1: 69.9438 (69.9438)  Acc@5: 89.3259 (89.3259)
2025-06-02 08:19:34,408 - train - INFO - Test: [  50/70]  Time: 0.120 (0.913)  Loss:  2.4004 (2.1580)  Acc@1: 54.3539 (58.0332)  Acc@5: 79.2135 (81.8297)
2025-06-02 08:19:50,860 - train - INFO - Test: [  70/70]  Time: 0.034 (0.888)  Loss:  3.1797 (2.2460)  Acc@1: 33.1250 (56.5320)  Acc@5: 63.7500 (80.2820)
2025-06-02 08:19:55,855 - train - INFO - Train: 281 [   0/224 (  0%)]  Loss:  3.097704 (3.0977)  Time: 4.688s, 1214.97/s  (4.688s, 1214.97/s)  LR: 1.085e-04  Data: 4.138 (4.138)
2025-06-02 08:20:36,631 - train - INFO - Train: 281 [  50/224 ( 22%)]  Loss:  3.126893 (3.1123)  Time: 0.549s, 10367.47/s  (0.891s, 6389.80/s)  LR: 1.085e-04  Data: 0.000 (0.293)
2025-06-02 08:21:18,610 - train - INFO - Train: 281 [ 100/224 ( 45%)]  Loss:  3.131513 (3.1187)  Time: 1.754s, 3246.72/s  (0.866s, 6579.34/s)  LR: 1.085e-04  Data: 0.000 (0.197)
2025-06-02 08:21:59,212 - train - INFO - Train: 281 [ 150/224 ( 67%)]  Loss:  3.149508 (3.1264)  Time: 0.720s, 7910.14/s  (0.848s, 6717.32/s)  LR: 1.085e-04  Data: 0.000 (0.139)
2025-06-02 08:22:40,815 - train - INFO - Train: 281 [ 200/224 ( 90%)]  Loss:  3.175507 (3.1362)  Time: 1.499s, 3799.40/s  (0.844s, 6748.86/s)  LR: 1.085e-04  Data: 0.000 (0.104)
2025-06-02 08:22:58,568 - train - INFO - Train: 281 [ 223/224 (100%)]  Loss:  3.126799 (3.1347)  Time: 0.552s, 10323.85/s  (0.837s, 6808.62/s)  LR: 1.085e-04  Data: 0.000 (0.093)
2025-06-02 08:23:03,874 - train - INFO - Test: [   0/70]  Time: 5.070 (5.070)  Loss:  1.2256 (1.2256)  Acc@1: 74.1573 (74.1573)  Acc@5: 89.8876 (89.8876)
2025-06-02 08:23:47,131 - train - INFO - Test: [  50/70]  Time: 0.120 (0.948)  Loss:  1.8135 (1.6577)  Acc@1: 60.1124 (62.1613)  Acc@5: 82.3034 (84.9141)
2025-06-02 08:24:03,720 - train - INFO - Test: [  70/70]  Time: 0.034 (0.914)  Loss:  2.3301 (1.7455)  Acc@1: 48.7500 (60.7880)  Acc@5: 76.2500 (83.4940)
2025-06-02 08:24:08,731 - train - INFO - Train: 282 [   0/224 (  0%)]  Loss:  3.118461 (3.1185)  Time: 4.699s, 1212.15/s  (4.699s, 1212.15/s)  LR: 9.848e-05  Data: 4.086 (4.086)
2025-06-02 08:24:49,588 - train - INFO - Train: 282 [  50/224 ( 22%)]  Loss:  3.121214 (3.1198)  Time: 0.548s, 10386.39/s  (0.893s, 6376.82/s)  LR: 9.848e-05  Data: 0.000 (0.222)
2025-06-02 08:25:30,492 - train - INFO - Train: 282 [ 100/224 ( 45%)]  Loss:  3.136605 (3.1254)  Time: 1.441s, 3952.16/s  (0.856s, 6654.15/s)  LR: 9.848e-05  Data: 0.244 (0.120)
2025-06-02 08:26:10,753 - train - INFO - Train: 282 [ 150/224 ( 67%)]  Loss:  3.133219 (3.1274)  Time: 0.555s, 10256.58/s  (0.839s, 6787.55/s)  LR: 9.848e-05  Data: 0.000 (0.082)
2025-06-02 08:26:52,031 - train - INFO - Train: 282 [ 200/224 ( 90%)]  Loss:  3.163253 (3.1346)  Time: 1.551s, 3672.77/s  (0.836s, 6815.15/s)  LR: 9.848e-05  Data: 0.000 (0.062)
2025-06-02 08:27:09,989 - train - INFO - Train: 282 [ 223/224 (100%)]  Loss:  3.113914 (3.1311)  Time: 0.551s, 10342.78/s  (0.830s, 6861.59/s)  LR: 9.848e-05  Data: 0.000 (0.056)
2025-06-02 08:27:14,976 - train - INFO - Test: [   0/70]  Time: 4.736 (4.736)  Loss:  1.3633 (1.3633)  Acc@1: 72.4719 (72.4719)  Acc@5: 89.6067 (89.6067)
2025-06-02 08:27:56,423 - train - INFO - Test: [  50/70]  Time: 0.120 (0.906)  Loss:  1.9229 (1.8299)  Acc@1: 59.1292 (59.7957)  Acc@5: 82.5843 (82.9533)
2025-06-02 08:28:13,184 - train - INFO - Test: [  70/70]  Time: 0.035 (0.887)  Loss:  2.5723 (1.9244)  Acc@1: 38.7500 (58.0900)  Acc@5: 74.3750 (81.4380)
2025-06-02 08:28:18,228 - train - INFO - Train: 283 [   0/224 (  0%)]  Loss:  3.100348 (3.1003)  Time: 4.725s, 1205.46/s  (4.725s, 1205.46/s)  LR: 8.894e-05  Data: 3.728 (3.728)
2025-06-02 08:28:59,284 - train - INFO - Train: 283 [  50/224 ( 22%)]  Loss:  3.112349 (3.1063)  Time: 0.549s, 10382.88/s  (0.898s, 6345.53/s)  LR: 8.894e-05  Data: 0.000 (0.273)
2025-06-02 08:29:41,572 - train - INFO - Train: 283 [ 100/224 ( 45%)]  Loss:  3.112393 (3.1084)  Time: 1.540s, 3697.96/s  (0.872s, 6532.58/s)  LR: 8.894e-05  Data: 1.000 (0.284)
2025-06-02 08:30:22,740 - train - INFO - Train: 283 [ 150/224 ( 67%)]  Loss:  3.103192 (3.1071)  Time: 0.549s, 10370.45/s  (0.856s, 6655.45/s)  LR: 8.894e-05  Data: 0.000 (0.281)
2025-06-02 08:31:04,784 - train - INFO - Train: 283 [ 200/224 ( 90%)]  Loss:  3.120005 (3.1097)  Time: 1.860s, 3062.20/s  (0.852s, 6684.58/s)  LR: 8.894e-05  Data: 1.320 (0.284)
2025-06-02 08:31:22,555 - train - INFO - Train: 283 [ 223/224 (100%)]  Loss:  3.145729 (3.1157)  Time: 0.544s, 10471.93/s  (0.844s, 6749.27/s)  LR: 8.894e-05  Data: 0.000 (0.278)
2025-06-02 08:31:27,602 - train - INFO - Test: [   0/70]  Time: 4.783 (4.783)  Loss:  1.7266 (1.7266)  Acc@1: 70.7865 (70.7865)  Acc@5: 90.1685 (90.1685)
2025-06-02 08:32:10,245 - train - INFO - Test: [  50/70]  Time: 0.120 (0.930)  Loss:  2.2715 (2.3299)  Acc@1: 58.4270 (56.6314)  Acc@5: 79.9157 (81.0008)
2025-06-02 08:32:26,851 - train - INFO - Test: [  70/70]  Time: 0.034 (0.902)  Loss:  2.8770 (2.3812)  Acc@1: 41.8750 (55.3860)  Acc@5: 75.0000 (79.6100)
2025-06-02 08:32:31,830 - train - INFO - Train: 284 [   0/224 (  0%)]  Loss:  3.189024 (3.1890)  Time: 4.676s, 1218.09/s  (4.676s, 1218.09/s)  LR: 7.995e-05  Data: 3.976 (3.976)
2025-06-02 08:33:12,574 - train - INFO - Train: 284 [  50/224 ( 22%)]  Loss:  3.126717 (3.1579)  Time: 0.549s, 10383.37/s  (0.891s, 6396.05/s)  LR: 7.995e-05  Data: 0.000 (0.150)
2025-06-02 08:33:54,137 - train - INFO - Train: 284 [ 100/224 ( 45%)]  Loss:  3.116095 (3.1439)  Time: 1.498s, 3803.18/s  (0.861s, 6614.22/s)  LR: 7.995e-05  Data: 0.000 (0.076)
2025-06-02 08:34:34,343 - train - INFO - Train: 284 [ 150/224 ( 67%)]  Loss:  3.118929 (3.1377)  Time: 0.555s, 10257.23/s  (0.842s, 6762.61/s)  LR: 7.995e-05  Data: 0.000 (0.051)
2025-06-02 08:35:15,499 - train - INFO - Train: 284 [ 200/224 ( 90%)]  Loss:  3.130543 (3.1363)  Time: 1.423s, 4002.29/s  (0.837s, 6801.21/s)  LR: 7.995e-05  Data: 0.000 (0.038)
2025-06-02 08:35:34,033 - train - INFO - Train: 284 [ 223/224 (100%)]  Loss:  3.168512 (3.1416)  Time: 0.546s, 10435.32/s  (0.834s, 6827.74/s)  LR: 7.995e-05  Data: 0.000 (0.034)
2025-06-02 08:35:38,957 - train - INFO - Test: [   0/70]  Time: 4.669 (4.669)  Loss:  1.3135 (1.3135)  Acc@1: 74.1573 (74.1573)  Acc@5: 91.0112 (91.0112)
2025-06-02 08:36:20,960 - train - INFO - Test: [  50/70]  Time: 0.120 (0.915)  Loss:  1.8975 (1.8085)  Acc@1: 58.9888 (61.7041)  Acc@5: 81.7416 (84.7323)
2025-06-02 08:36:37,459 - train - INFO - Test: [  70/70]  Time: 0.034 (0.890)  Loss:  2.2051 (1.8611)  Acc@1: 45.6250 (60.5180)  Acc@5: 81.2500 (83.6040)
2025-06-02 08:36:42,479 - train - INFO - Train: 285 [   0/224 (  0%)]  Loss:  3.153547 (3.1535)  Time: 4.717s, 1207.46/s  (4.717s, 1207.46/s)  LR: 7.150e-05  Data: 3.977 (3.977)
2025-06-02 08:37:23,619 - train - INFO - Train: 285 [  50/224 ( 22%)]  Loss:  3.166287 (3.1599)  Time: 0.555s, 10270.66/s  (0.899s, 6335.09/s)  LR: 7.150e-05  Data: 0.000 (0.159)
2025-06-02 08:38:05,259 - train - INFO - Train: 285 [ 100/224 ( 45%)]  Loss:  3.137314 (3.1524)  Time: 1.432s, 3976.44/s  (0.866s, 6575.27/s)  LR: 7.150e-05  Data: 0.000 (0.081)
2025-06-02 08:38:46,874 - train - INFO - Train: 285 [ 150/224 ( 67%)]  Loss:  3.157142 (3.1536)  Time: 0.559s, 10185.42/s  (0.855s, 6661.87/s)  LR: 7.150e-05  Data: 0.000 (0.054)
2025-06-02 08:39:28,558 - train - INFO - Train: 285 [ 200/224 ( 90%)]  Loss:  3.140055 (3.1509)  Time: 1.613s, 3532.28/s  (0.850s, 6703.53/s)  LR: 7.150e-05  Data: 0.000 (0.041)
2025-06-02 08:39:46,325 - train - INFO - Train: 285 [ 223/224 (100%)]  Loss:  3.108441 (3.1438)  Time: 0.544s, 10461.40/s  (0.842s, 6766.72/s)  LR: 7.150e-05  Data: 0.000 (0.037)
2025-06-02 08:39:51,244 - train - INFO - Test: [   0/70]  Time: 4.678 (4.678)  Loss:  1.1260 (1.1260)  Acc@1: 72.8933 (72.8933)  Acc@5: 90.4494 (90.4494)
2025-06-02 08:40:33,535 - train - INFO - Test: [  50/70]  Time: 0.120 (0.921)  Loss:  1.8838 (1.6163)  Acc@1: 56.6011 (62.0731)  Acc@5: 79.9157 (84.6745)
2025-06-02 08:40:50,029 - train - INFO - Test: [  70/70]  Time: 0.039 (0.894)  Loss:  2.1191 (1.6934)  Acc@1: 46.2500 (60.4720)  Acc@5: 81.2500 (83.4060)
2025-06-02 08:40:54,949 - train - INFO - Train: 286 [   0/224 (  0%)]  Loss:  3.119170 (3.1192)  Time: 4.626s, 1231.27/s  (4.626s, 1231.27/s)  LR: 6.358e-05  Data: 3.468 (3.468)
2025-06-02 08:41:36,095 - train - INFO - Train: 286 [  50/224 ( 22%)]  Loss:  3.139906 (3.1295)  Time: 0.550s, 10360.70/s  (0.897s, 6346.90/s)  LR: 6.358e-05  Data: 0.000 (0.078)
2025-06-02 08:42:17,606 - train - INFO - Train: 286 [ 100/224 ( 45%)]  Loss:  3.108577 (3.1226)  Time: 1.392s, 4092.80/s  (0.864s, 6591.47/s)  LR: 6.358e-05  Data: 0.000 (0.039)
2025-06-02 08:42:58,501 - train - INFO - Train: 286 [ 150/224 ( 67%)]  Loss:  3.127063 (3.1237)  Time: 0.555s, 10254.26/s  (0.849s, 6710.49/s)  LR: 6.358e-05  Data: 0.000 (0.026)
2025-06-02 08:43:40,935 - train - INFO - Train: 286 [ 200/224 ( 90%)]  Loss:  3.109250 (3.1208)  Time: 1.245s, 4576.83/s  (0.849s, 6710.84/s)  LR: 6.358e-05  Data: 0.000 (0.020)
2025-06-02 08:43:58,948 - train - INFO - Train: 286 [ 223/224 (100%)]  Loss:  3.132052 (3.1227)  Time: 0.552s, 10316.58/s  (0.842s, 6764.54/s)  LR: 6.358e-05  Data: 0.000 (0.018)
2025-06-02 08:44:03,707 - train - INFO - Test: [   0/70]  Time: 4.511 (4.511)  Loss:  1.2188 (1.2188)  Acc@1: 72.4719 (72.4719)  Acc@5: 90.1685 (90.1685)
2025-06-02 08:44:46,148 - train - INFO - Test: [  50/70]  Time: 0.120 (0.921)  Loss:  1.7354 (1.7282)  Acc@1: 62.5000 (60.7403)  Acc@5: 83.4270 (83.7382)
2025-06-02 08:45:02,802 - train - INFO - Test: [  70/70]  Time: 0.035 (0.896)  Loss:  2.0781 (1.8240)  Acc@1: 44.3750 (59.1540)  Acc@5: 83.7500 (82.3020)
2025-06-02 08:45:07,854 - train - INFO - Train: 287 [   0/224 (  0%)]  Loss:  3.134394 (3.1344)  Time: 4.748s, 1199.66/s  (4.748s, 1199.66/s)  LR: 5.621e-05  Data: 3.972 (3.972)
2025-06-02 08:45:49,536 - train - INFO - Train: 287 [  50/224 ( 22%)]  Loss:  3.105893 (3.1201)  Time: 0.556s, 10238.43/s  (0.910s, 6256.87/s)  LR: 5.621e-05  Data: 0.000 (0.163)
2025-06-02 08:46:31,534 - train - INFO - Train: 287 [ 100/224 ( 45%)]  Loss:  3.107461 (3.1159)  Time: 1.658s, 3436.31/s  (0.875s, 6506.05/s)  LR: 5.621e-05  Data: 0.000 (0.082)
2025-06-02 08:47:12,827 - train - INFO - Train: 287 [ 150/224 ( 67%)]  Loss:  3.091655 (3.1099)  Time: 0.552s, 10327.23/s  (0.859s, 6630.59/s)  LR: 5.621e-05  Data: 0.000 (0.055)
2025-06-02 08:47:54,783 - train - INFO - Train: 287 [ 200/224 ( 90%)]  Loss:  3.119025 (3.1117)  Time: 1.731s, 3290.51/s  (0.854s, 6669.11/s)  LR: 5.621e-05  Data: 0.000 (0.041)
2025-06-02 08:48:12,778 - train - INFO - Train: 287 [ 223/224 (100%)]  Loss:  3.129233 (3.1146)  Time: 0.546s, 10440.97/s  (0.847s, 6727.09/s)  LR: 5.621e-05  Data: 0.000 (0.037)
2025-06-02 08:48:17,557 - train - INFO - Test: [   0/70]  Time: 4.531 (4.531)  Loss:  1.4463 (1.4463)  Acc@1: 71.7697 (71.7697)  Acc@5: 87.0787 (87.0787)
2025-06-02 08:48:59,787 - train - INFO - Test: [  50/70]  Time: 0.120 (0.917)  Loss:  1.8262 (1.7142)  Acc@1: 62.0786 (61.9878)  Acc@5: 81.6011 (84.4955)
2025-06-02 08:49:16,282 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.3145 (1.7985)  Acc@1: 46.8750 (60.2680)  Acc@5: 76.2500 (83.1560)
2025-06-02 08:49:21,250 - train - INFO - Train: 288 [   0/224 (  0%)]  Loss:  3.088323 (3.0883)  Time: 4.671s, 1219.45/s  (4.671s, 1219.45/s)  LR: 4.939e-05  Data: 3.482 (3.482)
2025-06-02 08:50:03,803 - train - INFO - Train: 288 [  50/224 ( 22%)]  Loss:  3.104265 (3.0963)  Time: 0.552s, 10309.96/s  (0.926s, 6151.55/s)  LR: 4.939e-05  Data: 0.000 (0.084)
2025-06-02 08:50:46,247 - train - INFO - Train: 288 [ 100/224 ( 45%)]  Loss:  3.112278 (3.1016)  Time: 1.656s, 3440.01/s  (0.888s, 6416.02/s)  LR: 4.939e-05  Data: 0.000 (0.043)
2025-06-02 08:51:26,754 - train - INFO - Train: 288 [ 150/224 ( 67%)]  Loss:  3.112627 (3.1044)  Time: 0.548s, 10387.54/s  (0.862s, 6607.46/s)  LR: 4.939e-05  Data: 0.000 (0.029)
2025-06-02 08:52:08,649 - train - INFO - Train: 288 [ 200/224 ( 90%)]  Loss:  3.131564 (3.1098)  Time: 1.613s, 3530.75/s  (0.856s, 6653.86/s)  LR: 4.939e-05  Data: 0.000 (0.022)
2025-06-02 08:52:26,512 - train - INFO - Train: 288 [ 223/224 (100%)]  Loss:  3.129489 (3.1131)  Time: 0.546s, 10441.43/s  (0.848s, 6717.87/s)  LR: 4.939e-05  Data: 0.000 (0.019)
2025-06-02 08:52:31,506 - train - INFO - Test: [   0/70]  Time: 4.734 (4.734)  Loss:  0.9878 (0.9878)  Acc@1: 77.2472 (77.2472)  Acc@5: 91.7135 (91.7135)
2025-06-02 08:53:13,805 - train - INFO - Test: [  50/70]  Time: 0.120 (0.922)  Loss:  1.8271 (1.6642)  Acc@1: 58.7079 (60.9440)  Acc@5: 82.3034 (83.8180)
2025-06-02 08:53:30,347 - train - INFO - Test: [  70/70]  Time: 0.034 (0.895)  Loss:  2.3359 (1.7402)  Acc@1: 43.1250 (59.5260)  Acc@5: 75.6250 (82.6540)
2025-06-02 08:53:35,613 - train - INFO - Train: 289 [   0/224 (  0%)]  Loss:  3.141549 (3.1415)  Time: 4.955s, 1149.51/s  (4.955s, 1149.51/s)  LR: 4.310e-05  Data: 4.100 (4.100)
2025-06-02 08:54:16,173 - train - INFO - Train: 289 [  50/224 ( 22%)]  Loss:  3.091897 (3.1167)  Time: 0.549s, 10380.62/s  (0.892s, 6382.80/s)  LR: 4.310e-05  Data: 0.000 (0.168)
2025-06-02 08:54:58,698 - train - INFO - Train: 289 [ 100/224 ( 45%)]  Loss:  3.087967 (3.1071)  Time: 1.673s, 3404.91/s  (0.872s, 6534.86/s)  LR: 4.310e-05  Data: 0.000 (0.085)
2025-06-02 08:55:39,424 - train - INFO - Train: 289 [ 150/224 ( 67%)]  Loss:  3.132934 (3.1136)  Time: 0.549s, 10369.38/s  (0.853s, 6679.79/s)  LR: 4.310e-05  Data: 0.000 (0.057)
2025-06-02 08:56:22,254 - train - INFO - Train: 289 [ 200/224 ( 90%)]  Loss:  3.125745 (3.1160)  Time: 1.731s, 3289.93/s  (0.854s, 6672.37/s)  LR: 4.310e-05  Data: 0.000 (0.043)
2025-06-02 08:56:40,149 - train - INFO - Train: 289 [ 223/224 (100%)]  Loss:  3.079834 (3.1100)  Time: 0.551s, 10337.68/s  (0.846s, 6733.66/s)  LR: 4.310e-05  Data: 0.000 (0.038)
2025-06-02 08:56:44,978 - train - INFO - Test: [   0/70]  Time: 4.580 (4.580)  Loss:  1.2178 (1.2178)  Acc@1: 74.1573 (74.1573)  Acc@5: 91.9944 (91.9944)
2025-06-02 08:57:27,372 - train - INFO - Test: [  50/70]  Time: 0.120 (0.921)  Loss:  1.5410 (1.7468)  Acc@1: 66.4326 (62.2687)  Acc@5: 86.9382 (84.2862)
2025-06-02 08:57:43,950 - train - INFO - Test: [  70/70]  Time: 0.034 (0.895)  Loss:  2.1504 (1.8278)  Acc@1: 46.2500 (60.3940)  Acc@5: 80.0000 (82.8080)
2025-06-02 08:57:49,262 - train - INFO - Train: 290 [   0/224 (  0%)]  Loss:  3.141064 (3.1411)  Time: 5.008s, 1137.47/s  (5.008s, 1137.47/s)  LR: 3.736e-05  Data: 4.232 (4.232)
2025-06-02 08:58:29,880 - train - INFO - Train: 290 [  50/224 ( 22%)]  Loss:  3.107529 (3.1243)  Time: 0.550s, 10351.12/s  (0.895s, 6367.05/s)  LR: 3.736e-05  Data: 0.000 (0.180)
2025-06-02 08:59:11,681 - train - INFO - Train: 290 [ 100/224 ( 45%)]  Loss:  3.099879 (3.1162)  Time: 1.048s, 5433.69/s  (0.866s, 6580.46/s)  LR: 3.736e-05  Data: 0.000 (0.091)
2025-06-02 08:59:53,065 - train - INFO - Train: 290 [ 150/224 ( 67%)]  Loss:  3.147133 (3.1239)  Time: 0.575s, 9898.64/s  (0.853s, 6677.36/s)  LR: 3.736e-05  Data: 0.000 (0.061)
2025-06-02 09:00:35,132 - train - INFO - Train: 290 [ 200/224 ( 90%)]  Loss:  3.110722 (3.1213)  Time: 1.610s, 3538.32/s  (0.850s, 6700.31/s)  LR: 3.736e-05  Data: 0.000 (0.046)
2025-06-02 09:00:53,169 - train - INFO - Train: 290 [ 223/224 (100%)]  Loss:  3.129008 (3.1226)  Time: 0.550s, 10356.18/s  (0.843s, 6754.18/s)  LR: 3.736e-05  Data: 0.000 (0.041)
2025-06-02 09:00:57,850 - train - INFO - Test: [   0/70]  Time: 4.440 (4.440)  Loss:  1.1943 (1.1943)  Acc@1: 74.7191 (74.7191)  Acc@5: 91.1517 (91.1517)
2025-06-02 09:01:39,880 - train - INFO - Test: [  50/70]  Time: 0.124 (0.911)  Loss:  1.6650 (1.7199)  Acc@1: 64.6067 (61.4480)  Acc@5: 83.0056 (83.8896)
2025-06-02 09:01:56,190 - train - INFO - Test: [  70/70]  Time: 0.034 (0.884)  Loss:  2.4004 (1.7898)  Acc@1: 40.0000 (59.9100)  Acc@5: 75.0000 (82.6620)
2025-06-02 09:02:01,135 - train - INFO - Train: 291 [   0/224 (  0%)]  Loss:  3.164372 (3.1644)  Time: 4.632s, 1229.63/s  (4.632s, 1229.63/s)  LR: 3.217e-05  Data: 4.080 (4.080)
2025-06-02 09:02:43,877 - train - INFO - Train: 291 [  50/224 ( 22%)]  Loss:  3.125811 (3.1451)  Time: 0.550s, 10357.42/s  (0.929s, 6132.19/s)  LR: 3.217e-05  Data: 0.000 (0.119)
2025-06-02 09:03:24,994 - train - INFO - Train: 291 [ 100/224 ( 45%)]  Loss:  3.146088 (3.1454)  Time: 0.556s, 10253.04/s  (0.876s, 6501.33/s)  LR: 3.217e-05  Data: 0.000 (0.060)
2025-06-02 09:04:07,197 - train - INFO - Train: 291 [ 150/224 ( 67%)]  Loss:  3.104779 (3.1353)  Time: 0.550s, 10354.17/s  (0.865s, 6581.20/s)  LR: 3.217e-05  Data: 0.000 (0.040)
2025-06-02 09:04:48,253 - train - INFO - Train: 291 [ 200/224 ( 90%)]  Loss:  3.124206 (3.1331)  Time: 0.550s, 10361.31/s  (0.854s, 6666.27/s)  LR: 3.217e-05  Data: 0.000 (0.030)
2025-06-02 09:05:07,632 - train - INFO - Train: 291 [ 223/224 (100%)]  Loss:  3.133089 (3.1331)  Time: 0.547s, 10421.03/s  (0.853s, 6675.82/s)  LR: 3.217e-05  Data: 0.000 (0.027)
2025-06-02 09:05:12,412 - train - INFO - Test: [   0/70]  Time: 4.538 (4.538)  Loss:  1.0117 (1.0117)  Acc@1: 75.8427 (75.8427)  Acc@5: 91.4326 (91.4326)
2025-06-02 09:05:55,577 - train - INFO - Test: [  50/70]  Time: 0.121 (0.935)  Loss:  1.8037 (1.6340)  Acc@1: 58.2865 (61.5444)  Acc@5: 81.4607 (84.3220)
2025-06-02 09:06:12,812 - train - INFO - Test: [  70/70]  Time: 0.039 (0.915)  Loss:  2.4707 (1.7256)  Acc@1: 41.8750 (59.9580)  Acc@5: 76.8750 (82.8480)
2025-06-02 09:06:18,062 - train - INFO - Train: 292 [   0/224 (  0%)]  Loss:  3.133075 (3.1331)  Time: 4.926s, 1156.33/s  (4.926s, 1156.33/s)  LR: 2.752e-05  Data: 4.251 (4.251)
2025-06-02 09:06:59,738 - train - INFO - Train: 292 [  50/224 ( 22%)]  Loss:  3.070543 (3.1018)  Time: 0.549s, 10384.20/s  (0.914s, 6233.71/s)  LR: 2.752e-05  Data: 0.000 (0.249)
2025-06-02 09:07:42,038 - train - INFO - Train: 292 [ 100/224 ( 45%)]  Loss:  3.139171 (3.1143)  Time: 1.496s, 3807.57/s  (0.880s, 6471.34/s)  LR: 2.752e-05  Data: 0.000 (0.153)
2025-06-02 09:08:23,757 - train - INFO - Train: 292 [ 150/224 ( 67%)]  Loss:  3.152290 (3.1238)  Time: 0.548s, 10401.87/s  (0.865s, 6584.89/s)  LR: 2.752e-05  Data: 0.000 (0.102)
2025-06-02 09:09:05,464 - train - INFO - Train: 292 [ 200/224 ( 90%)]  Loss:  3.093164 (3.1176)  Time: 1.544s, 3688.11/s  (0.857s, 6643.92/s)  LR: 2.752e-05  Data: 0.000 (0.077)
2025-06-02 09:09:23,829 - train - INFO - Train: 292 [ 223/224 (100%)]  Loss:  3.137264 (3.1209)  Time: 0.551s, 10339.56/s  (0.851s, 6691.08/s)  LR: 2.752e-05  Data: 0.000 (0.069)
2025-06-02 09:09:28,760 - train - INFO - Test: [   0/70]  Time: 4.673 (4.673)  Loss:  1.8115 (1.8115)  Acc@1: 71.9101 (71.9101)  Acc@5: 90.0281 (90.0281)
2025-06-02 09:10:11,327 - train - INFO - Test: [  50/70]  Time: 0.120 (0.926)  Loss:  2.2031 (2.2134)  Acc@1: 60.8146 (60.4649)  Acc@5: 81.3202 (83.3994)
2025-06-02 09:10:28,128 - train - INFO - Test: [  70/70]  Time: 0.034 (0.902)  Loss:  2.2168 (2.2651)  Acc@1: 53.1250 (58.8740)  Acc@5: 85.6250 (82.0460)
2025-06-02 09:10:34,111 - train - INFO - Train: 293 [   0/224 (  0%)]  Loss:  3.073469 (3.0735)  Time: 5.668s, 1004.92/s  (5.668s, 1004.92/s)  LR: 2.341e-05  Data: 3.650 (3.650)
2025-06-02 09:11:14,920 - train - INFO - Train: 293 [  50/224 ( 22%)]  Loss:  3.101832 (3.0877)  Time: 0.550s, 10358.11/s  (0.911s, 6250.45/s)  LR: 2.341e-05  Data: 0.000 (0.072)
2025-06-02 09:11:56,066 - train - INFO - Train: 293 [ 100/224 ( 45%)]  Loss:  3.134973 (3.1034)  Time: 1.469s, 3878.11/s  (0.868s, 6565.80/s)  LR: 2.341e-05  Data: 0.000 (0.036)
2025-06-02 09:12:36,480 - train - INFO - Train: 293 [ 150/224 ( 67%)]  Loss:  3.111006 (3.1053)  Time: 0.552s, 10324.64/s  (0.848s, 6717.76/s)  LR: 2.341e-05  Data: 0.000 (0.024)
2025-06-02 09:13:17,338 - train - INFO - Train: 293 [ 200/224 ( 90%)]  Loss:  3.110562 (3.1064)  Time: 1.075s, 5298.31/s  (0.840s, 6778.96/s)  LR: 2.341e-05  Data: 0.000 (0.018)
2025-06-02 09:13:35,815 - train - INFO - Train: 293 [ 223/224 (100%)]  Loss:  3.111421 (3.1072)  Time: 0.544s, 10474.76/s  (0.836s, 6809.72/s)  LR: 2.341e-05  Data: 0.000 (0.017)
2025-06-02 09:13:40,903 - train - INFO - Test: [   0/70]  Time: 4.832 (4.832)  Loss:  1.0947 (1.0947)  Acc@1: 75.9831 (75.9831)  Acc@5: 91.7135 (91.7135)
2025-06-02 09:14:23,456 - train - INFO - Test: [  50/70]  Time: 0.120 (0.929)  Loss:  1.8506 (1.7580)  Acc@1: 60.3933 (60.4098)  Acc@5: 82.0225 (83.5234)
2025-06-02 09:14:40,528 - train - INFO - Test: [  70/70]  Time: 0.035 (0.908)  Loss:  2.3281 (1.8345)  Acc@1: 41.8750 (59.0320)  Acc@5: 78.1250 (82.2160)
2025-06-02 09:14:45,565 - train - INFO - Train: 294 [   0/224 (  0%)]  Loss:  3.131111 (3.1311)  Time: 4.708s, 1209.96/s  (4.708s, 1209.96/s)  LR: 1.986e-05  Data: 4.071 (4.071)
2025-06-02 09:15:26,896 - train - INFO - Train: 294 [  50/224 ( 22%)]  Loss:  3.085856 (3.1085)  Time: 0.554s, 10272.34/s  (0.903s, 6310.17/s)  LR: 1.986e-05  Data: 0.000 (0.233)
2025-06-02 09:16:08,749 - train - INFO - Train: 294 [ 100/224 ( 45%)]  Loss:  3.092025 (3.1030)  Time: 1.673s, 3404.99/s  (0.870s, 6545.78/s)  LR: 1.986e-05  Data: 0.000 (0.118)
2025-06-02 09:16:49,253 - train - INFO - Train: 294 [ 150/224 ( 67%)]  Loss:  3.107987 (3.1042)  Time: 0.553s, 10302.58/s  (0.850s, 6699.15/s)  LR: 1.986e-05  Data: 0.000 (0.079)
2025-06-02 09:17:30,303 - train - INFO - Train: 294 [ 200/224 ( 90%)]  Loss:  3.170155 (3.1174)  Time: 1.573s, 3621.32/s  (0.843s, 6757.02/s)  LR: 1.986e-05  Data: 0.000 (0.059)
2025-06-02 09:17:48,384 - train - INFO - Train: 294 [ 223/224 (100%)]  Loss:  3.156481 (3.1239)  Time: 0.552s, 10321.55/s  (0.837s, 6804.20/s)  LR: 1.986e-05  Data: 0.000 (0.053)
2025-06-02 09:17:53,150 - train - INFO - Test: [   0/70]  Time: 4.515 (4.515)  Loss:  1.5762 (1.5762)  Acc@1: 73.0337 (73.0337)  Acc@5: 90.5899 (90.5899)
2025-06-02 09:18:35,449 - train - INFO - Test: [  50/70]  Time: 0.121 (0.918)  Loss:  2.1270 (2.0694)  Acc@1: 57.8652 (60.6439)  Acc@5: 81.4607 (84.0466)
2025-06-02 09:18:51,910 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.6562 (2.1459)  Acc@1: 46.2500 (59.3340)  Acc@5: 79.3750 (82.6500)
2025-06-02 09:18:56,982 - train - INFO - Train: 295 [   0/224 (  0%)]  Loss:  3.115290 (3.1153)  Time: 4.753s, 1198.40/s  (4.753s, 1198.40/s)  LR: 1.685e-05  Data: 4.207 (4.207)
2025-06-02 09:19:37,302 - train - INFO - Train: 295 [  50/224 ( 22%)]  Loss:  3.111768 (3.1135)  Time: 0.556s, 10239.79/s  (0.884s, 6445.11/s)  LR: 1.685e-05  Data: 0.000 (0.213)
2025-06-02 09:20:18,612 - train - INFO - Train: 295 [ 100/224 ( 45%)]  Loss:  3.125082 (3.1174)  Time: 1.576s, 3614.52/s  (0.855s, 6659.96/s)  LR: 1.685e-05  Data: 0.315 (0.124)
2025-06-02 09:20:58,339 - train - INFO - Train: 295 [ 150/224 ( 67%)]  Loss:  3.148969 (3.1253)  Time: 0.549s, 10368.21/s  (0.835s, 6820.36/s)  LR: 1.685e-05  Data: 0.000 (0.113)
2025-06-02 09:21:40,079 - train - INFO - Train: 295 [ 200/224 ( 90%)]  Loss:  3.142318 (3.1287)  Time: 1.001s, 5691.51/s  (0.835s, 6821.14/s)  LR: 1.685e-05  Data: 0.000 (0.085)
2025-06-02 09:21:59,317 - train - INFO - Train: 295 [ 223/224 (100%)]  Loss:  3.104587 (3.1247)  Time: 0.546s, 10429.50/s  (0.835s, 6820.00/s)  LR: 1.685e-05  Data: 0.000 (0.076)
2025-06-02 09:22:04,152 - train - INFO - Test: [   0/70]  Time: 4.588 (4.588)  Loss:  1.5693 (1.5693)  Acc@1: 70.9270 (70.9270)  Acc@5: 89.6067 (89.6067)
2025-06-02 09:22:46,054 - train - INFO - Test: [  50/70]  Time: 0.120 (0.912)  Loss:  2.0840 (2.0619)  Acc@1: 57.0225 (58.4655)  Acc@5: 79.3539 (81.6149)
2025-06-02 09:23:02,485 - train - INFO - Test: [  70/70]  Time: 0.034 (0.886)  Loss:  2.9648 (2.1446)  Acc@1: 35.0000 (56.6220)  Acc@5: 65.0000 (79.9840)
2025-06-02 09:23:07,366 - train - INFO - Train: 296 [   0/224 (  0%)]  Loss:  3.128907 (3.1289)  Time: 4.581s, 1243.42/s  (4.581s, 1243.42/s)  LR: 1.438e-05  Data: 3.964 (3.964)
2025-06-02 09:23:48,926 - train - INFO - Train: 296 [  50/224 ( 22%)]  Loss:  3.091316 (3.1101)  Time: 0.548s, 10386.08/s  (0.905s, 6296.24/s)  LR: 1.438e-05  Data: 0.000 (0.120)
2025-06-02 09:24:30,740 - train - INFO - Train: 296 [ 100/224 ( 45%)]  Loss:  3.125478 (3.1152)  Time: 1.657s, 3437.60/s  (0.871s, 6541.23/s)  LR: 1.438e-05  Data: 0.000 (0.060)
2025-06-02 09:25:11,626 - train - INFO - Train: 296 [ 150/224 ( 67%)]  Loss:  3.099273 (3.1112)  Time: 0.550s, 10355.97/s  (0.853s, 6675.96/s)  LR: 1.438e-05  Data: 0.000 (0.041)
2025-06-02 09:25:53,357 - train - INFO - Train: 296 [ 200/224 ( 90%)]  Loss:  3.152558 (3.1195)  Time: 1.484s, 3839.18/s  (0.849s, 6712.47/s)  LR: 1.438e-05  Data: 0.000 (0.030)
2025-06-02 09:26:11,329 - train - INFO - Train: 296 [ 223/224 (100%)]  Loss:  3.120641 (3.1197)  Time: 0.548s, 10391.77/s  (0.842s, 6767.53/s)  LR: 1.438e-05  Data: 0.000 (0.027)
2025-06-02 09:26:16,283 - train - INFO - Test: [   0/70]  Time: 4.704 (4.704)  Loss:  1.2900 (1.2900)  Acc@1: 73.5955 (73.5955)  Acc@5: 89.0449 (89.0449)
2025-06-02 09:26:58,484 - train - INFO - Test: [  50/70]  Time: 0.120 (0.920)  Loss:  1.7100 (1.7344)  Acc@1: 60.2528 (60.2611)  Acc@5: 83.2865 (83.3223)
2025-06-02 09:27:15,281 - train - INFO - Test: [  70/70]  Time: 0.034 (0.897)  Loss:  2.7539 (1.8182)  Acc@1: 37.5000 (58.5900)  Acc@5: 73.7500 (81.9840)
2025-06-02 09:27:20,029 - train - INFO - Train: 297 [   0/224 (  0%)]  Loss:  3.169363 (3.1694)  Time: 4.427s, 1286.59/s  (4.427s, 1286.59/s)  LR: 1.246e-05  Data: 3.639 (3.639)
2025-06-02 09:28:01,483 - train - INFO - Train: 297 [  50/224 ( 22%)]  Loss:  3.114804 (3.1421)  Time: 0.549s, 10382.20/s  (0.900s, 6331.70/s)  LR: 1.246e-05  Data: 0.000 (0.116)
2025-06-02 09:28:43,854 - train - INFO - Train: 297 [ 100/224 ( 45%)]  Loss:  3.102998 (3.1291)  Time: 1.723s, 3305.97/s  (0.874s, 6518.99/s)  LR: 1.246e-05  Data: 0.000 (0.059)
2025-06-02 09:29:24,440 - train - INFO - Train: 297 [ 150/224 ( 67%)]  Loss:  3.175879 (3.1408)  Time: 0.555s, 10261.56/s  (0.853s, 6675.99/s)  LR: 1.246e-05  Data: 0.000 (0.039)
2025-06-02 09:30:06,202 - train - INFO - Train: 297 [ 200/224 ( 90%)]  Loss:  3.161412 (3.1449)  Time: 1.761s, 3234.36/s  (0.849s, 6711.27/s)  LR: 1.246e-05  Data: 0.000 (0.030)
2025-06-02 09:30:24,386 - train - INFO - Train: 297 [ 223/224 (100%)]  Loss:  3.162347 (3.1478)  Time: 0.551s, 10334.87/s  (0.843s, 6758.79/s)  LR: 1.246e-05  Data: 0.000 (0.027)
2025-06-02 09:30:29,074 - train - INFO - Test: [   0/70]  Time: 4.423 (4.423)  Loss:  1.0850 (1.0850)  Acc@1: 76.1236 (76.1236)  Acc@5: 91.9944 (91.9944)
2025-06-02 09:31:11,745 - train - INFO - Test: [  50/70]  Time: 0.120 (0.923)  Loss:  1.7910 (1.6282)  Acc@1: 60.1124 (62.7616)  Acc@5: 83.1461 (85.0848)
2025-06-02 09:31:28,463 - train - INFO - Test: [  70/70]  Time: 0.035 (0.899)  Loss:  2.3105 (1.7164)  Acc@1: 43.7500 (61.0060)  Acc@5: 79.3750 (83.6800)
2025-06-02 09:31:33,308 - train - INFO - Train: 298 [   0/224 (  0%)]  Loss:  3.097590 (3.0976)  Time: 4.540s, 1254.62/s  (4.540s, 1254.62/s)  LR: 1.110e-05  Data: 3.503 (3.503)
2025-06-02 09:32:13,825 - train - INFO - Train: 298 [  50/224 ( 22%)]  Loss:  3.172972 (3.1353)  Time: 0.616s, 9242.17/s  (0.883s, 6447.52/s)  LR: 1.110e-05  Data: 0.000 (0.111)
2025-06-02 09:32:55,406 - train - INFO - Train: 298 [ 100/224 ( 45%)]  Loss:  3.077710 (3.1161)  Time: 1.651s, 3449.08/s  (0.858s, 6640.39/s)  LR: 1.110e-05  Data: 0.000 (0.056)
2025-06-02 09:33:35,421 - train - INFO - Train: 298 [ 150/224 ( 67%)]  Loss:  3.098989 (3.1118)  Time: 0.549s, 10376.80/s  (0.839s, 6791.21/s)  LR: 1.110e-05  Data: 0.000 (0.038)
2025-06-02 09:34:16,649 - train - INFO - Train: 298 [ 200/224 ( 90%)]  Loss:  3.134891 (3.1164)  Time: 1.445s, 3941.14/s  (0.835s, 6819.98/s)  LR: 1.110e-05  Data: 0.000 (0.028)
2025-06-02 09:34:34,503 - train - INFO - Train: 298 [ 223/224 (100%)]  Loss:  3.187176 (3.1282)  Time: 0.545s, 10442.70/s  (0.829s, 6869.79/s)  LR: 1.110e-05  Data: 0.000 (0.026)
2025-06-02 09:34:39,198 - train - INFO - Test: [   0/70]  Time: 4.443 (4.443)  Loss:  1.2412 (1.2412)  Acc@1: 73.8764 (73.8764)  Acc@5: 91.2921 (91.2921)
2025-06-02 09:35:21,960 - train - INFO - Test: [  50/70]  Time: 0.120 (0.926)  Loss:  1.9473 (1.7887)  Acc@1: 60.2528 (62.4807)  Acc@5: 80.8989 (84.8177)
2025-06-02 09:35:38,447 - train - INFO - Test: [  70/70]  Time: 0.034 (0.897)  Loss:  2.2285 (1.8493)  Acc@1: 46.2500 (61.2300)  Acc@5: 78.7500 (83.7920)
2025-06-02 09:35:43,464 - train - INFO - Train: 299 [   0/224 (  0%)]  Loss:  3.121382 (3.1214)  Time: 4.697s, 1212.74/s  (4.697s, 1212.74/s)  LR: 1.027e-05  Data: 3.766 (3.766)
2025-06-02 09:36:24,556 - train - INFO - Train: 299 [  50/224 ( 22%)]  Loss:  3.156748 (3.1391)  Time: 0.555s, 10267.68/s  (0.898s, 6344.36/s)  LR: 1.027e-05  Data: 0.000 (0.218)
2025-06-02 09:37:06,493 - train - INFO - Train: 299 [ 100/224 ( 45%)]  Loss:  3.076063 (3.1181)  Time: 1.740s, 3274.00/s  (0.869s, 6558.01/s)  LR: 1.027e-05  Data: 0.000 (0.113)
2025-06-02 09:37:47,524 - train - INFO - Train: 299 [ 150/224 ( 67%)]  Loss:  3.132670 (3.1217)  Time: 0.549s, 10383.18/s  (0.853s, 6680.17/s)  LR: 1.027e-05  Data: 0.000 (0.076)
2025-06-02 09:38:29,011 - train - INFO - Train: 299 [ 200/224 ( 90%)]  Loss:  3.122889 (3.1220)  Time: 1.748s, 3258.89/s  (0.847s, 6725.20/s)  LR: 1.027e-05  Data: 0.000 (0.057)
2025-06-02 09:38:46,634 - train - INFO - Train: 299 [ 223/224 (100%)]  Loss:  3.109124 (3.1198)  Time: 0.546s, 10439.22/s  (0.839s, 6791.73/s)  LR: 1.027e-05  Data: 0.000 (0.051)
2025-06-02 09:38:51,378 - train - INFO - Test: [   0/70]  Time: 4.497 (4.497)  Loss:  0.9810 (0.9810)  Acc@1: 77.6685 (77.6685)  Acc@5: 92.8371 (92.8371)
2025-06-02 09:39:33,522 - train - INFO - Test: [  50/70]  Time: 0.170 (0.915)  Loss:  1.8496 (1.6596)  Acc@1: 59.8315 (62.4256)  Acc@5: 80.3371 (84.7461)
2025-06-02 09:39:50,017 - train - INFO - Test: [  70/70]  Time: 0.034 (0.889)  Loss:  2.3535 (1.7268)  Acc@1: 44.3750 (61.0340)  Acc@5: 78.1250 (83.5040)
2025-06-02 09:39:55,061 - train - INFO - Train: 300 [   0/224 (  0%)]  Loss:  3.150025 (3.1500)  Time: 4.747s, 1199.97/s  (4.747s, 1199.97/s)  LR: 1.000e-05  Data: 4.052 (4.052)
2025-06-02 09:40:36,142 - train - INFO - Train: 300 [  50/224 ( 22%)]  Loss:  3.146676 (3.1484)  Time: 0.548s, 10390.93/s  (0.899s, 6338.97/s)  LR: 1.000e-05  Data: 0.000 (0.132)
2025-06-02 09:41:17,698 - train - INFO - Train: 300 [ 100/224 ( 45%)]  Loss:  3.098623 (3.1318)  Time: 1.595s, 3570.26/s  (0.865s, 6583.75/s)  LR: 1.000e-05  Data: 0.000 (0.067)
2025-06-02 09:41:58,178 - train - INFO - Train: 300 [ 150/224 ( 67%)]  Loss:  3.140545 (3.1340)  Time: 0.556s, 10247.33/s  (0.847s, 6726.94/s)  LR: 1.000e-05  Data: 0.000 (0.045)
2025-06-02 09:42:39,766 - train - INFO - Train: 300 [ 200/224 ( 90%)]  Loss:  3.137512 (3.1347)  Time: 1.201s, 4742.66/s  (0.843s, 6756.73/s)  LR: 1.000e-05  Data: 0.000 (0.034)
2025-06-02 09:42:58,053 - train - INFO - Train: 300 [ 223/224 (100%)]  Loss:  3.058596 (3.1220)  Time: 0.746s, 7638.03/s  (0.838s, 6796.49/s)  LR: 1.000e-05  Data: 0.000 (0.030)
2025-06-02 09:43:03,030 - train - INFO - Test: [   0/70]  Time: 4.734 (4.734)  Loss:  1.3770 (1.3770)  Acc@1: 76.1236 (76.1236)  Acc@5: 91.9944 (91.9944)
2025-06-02 09:43:45,864 - train - INFO - Test: [  50/70]  Time: 0.120 (0.933)  Loss:  1.7891 (1.8563)  Acc@1: 64.3258 (61.6766)  Acc@5: 84.9719 (84.4597)
2025-06-02 09:44:02,586 - train - INFO - Test: [  70/70]  Time: 0.034 (0.906)  Loss:  2.1074 (1.9400)  Acc@1: 51.2500 (60.3460)  Acc@5: 83.7500 (83.2240)
2025-06-02 09:44:07,572 - train - INFO - Train: 301 [   0/224 (  0%)]  Loss:  3.119728 (3.1197)  Time: 4.617s, 1233.81/s  (4.617s, 1233.81/s)  LR: 1.000e-05  Data: 4.066 (4.066)
2025-06-02 09:44:49,148 - train - INFO - Train: 301 [  50/224 ( 22%)]  Loss:  3.122455 (3.1211)  Time: 0.549s, 10374.10/s  (0.906s, 6289.01/s)  LR: 1.000e-05  Data: 0.000 (0.150)
2025-06-02 09:45:30,748 - train - INFO - Train: 301 [ 100/224 ( 45%)]  Loss:  3.088983 (3.1104)  Time: 1.661s, 3428.31/s  (0.869s, 6553.15/s)  LR: 1.000e-05  Data: 0.000 (0.076)
2025-06-02 09:46:10,774 - train - INFO - Train: 301 [ 150/224 ( 67%)]  Loss:  3.103113 (3.1086)  Time: 0.548s, 10385.47/s  (0.846s, 6729.27/s)  LR: 1.000e-05  Data: 0.000 (0.051)
2025-06-02 09:46:52,038 - train - INFO - Train: 301 [ 200/224 ( 90%)]  Loss:  3.133081 (3.1135)  Time: 1.616s, 3524.32/s  (0.841s, 6771.47/s)  LR: 1.000e-05  Data: 0.000 (0.038)
2025-06-02 09:47:09,887 - train - INFO - Train: 301 [ 223/224 (100%)]  Loss:  3.113454 (3.1135)  Time: 0.545s, 10453.91/s  (0.834s, 6825.78/s)  LR: 1.000e-05  Data: 0.000 (0.034)
2025-06-02 09:47:14,638 - train - INFO - Test: [   0/70]  Time: 4.501 (4.501)  Loss:  1.4395 (1.4395)  Acc@1: 70.9270 (70.9270)  Acc@5: 90.1685 (90.1685)
2025-06-02 09:47:56,752 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  1.9043 (1.7854)  Acc@1: 59.1292 (62.0484)  Acc@5: 81.3202 (84.2118)
2025-06-02 09:48:13,150 - train - INFO - Test: [  70/70]  Time: 0.039 (0.888)  Loss:  1.8926 (1.8426)  Acc@1: 52.5000 (60.6800)  Acc@5: 81.8750 (83.1780)
2025-06-02 09:48:18,095 - train - INFO - Train: 302 [   0/224 (  0%)]  Loss:  3.063037 (3.0630)  Time: 4.628s, 1230.72/s  (4.628s, 1230.72/s)  LR: 1.000e-05  Data: 3.843 (3.843)
2025-06-02 09:48:59,265 - train - INFO - Train: 302 [  50/224 ( 22%)]  Loss:  3.116768 (3.0899)  Time: 0.558s, 10205.22/s  (0.898s, 6342.99/s)  LR: 1.000e-05  Data: 0.000 (0.117)
2025-06-02 09:49:40,637 - train - INFO - Train: 302 [ 100/224 ( 45%)]  Loss:  3.103615 (3.0945)  Time: 1.499s, 3798.64/s  (0.863s, 6599.85/s)  LR: 1.000e-05  Data: 0.000 (0.059)
2025-06-02 09:50:20,972 - train - INFO - Train: 302 [ 150/224 ( 67%)]  Loss:  3.115143 (3.0996)  Time: 0.557s, 10229.83/s  (0.844s, 6745.79/s)  LR: 1.000e-05  Data: 0.000 (0.040)
2025-06-02 09:51:02,270 - train - INFO - Train: 302 [ 200/224 ( 90%)]  Loss:  3.126445 (3.1050)  Time: 1.439s, 3959.46/s  (0.840s, 6782.65/s)  LR: 1.000e-05  Data: 0.000 (0.030)
2025-06-02 09:51:19,994 - train - INFO - Train: 302 [ 223/224 (100%)]  Loss:  3.097952 (3.1038)  Time: 0.551s, 10339.23/s  (0.833s, 6840.56/s)  LR: 1.000e-05  Data: 0.000 (0.027)
2025-06-02 09:51:24,774 - train - INFO - Test: [   0/70]  Time: 4.529 (4.529)  Loss:  1.1826 (1.1826)  Acc@1: 72.7528 (72.7528)  Acc@5: 90.5899 (90.5899)
2025-06-02 09:52:06,880 - train - INFO - Test: [  50/70]  Time: 0.120 (0.914)  Loss:  1.5527 (1.6194)  Acc@1: 65.7303 (63.3950)  Acc@5: 85.9551 (85.2886)
2025-06-02 09:52:23,500 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.3965 (1.7023)  Acc@1: 39.3750 (61.7840)  Acc@5: 76.2500 (83.9340)
2025-06-02 09:52:28,562 - train - INFO - Train: 303 [   0/224 (  0%)]  Loss:  3.085311 (3.0853)  Time: 4.758s, 1197.19/s  (4.758s, 1197.19/s)  LR: 1.000e-05  Data: 3.705 (3.705)
2025-06-02 09:53:10,297 - train - INFO - Train: 303 [  50/224 ( 22%)]  Loss:  3.133442 (3.1094)  Time: 0.555s, 10253.92/s  (0.912s, 6248.49/s)  LR: 1.000e-05  Data: 0.000 (0.179)
2025-06-02 09:53:51,515 - train - INFO - Train: 303 [ 100/224 ( 45%)]  Loss:  3.105918 (3.1082)  Time: 1.587s, 3588.71/s  (0.868s, 6559.24/s)  LR: 1.000e-05  Data: 0.000 (0.090)
2025-06-02 09:54:32,217 - train - INFO - Train: 303 [ 150/224 ( 67%)]  Loss:  3.128416 (3.1133)  Time: 0.554s, 10274.64/s  (0.850s, 6698.18/s)  LR: 1.000e-05  Data: 0.000 (0.060)
2025-06-02 09:55:13,997 - train - INFO - Train: 303 [ 200/224 ( 90%)]  Loss:  3.162759 (3.1232)  Time: 1.679s, 3391.78/s  (0.847s, 6727.32/s)  LR: 1.000e-05  Data: 0.000 (0.045)
2025-06-02 09:55:31,779 - train - INFO - Train: 303 [ 223/224 (100%)]  Loss:  3.133521 (3.1249)  Time: 0.553s, 10297.20/s  (0.839s, 6787.91/s)  LR: 1.000e-05  Data: 0.000 (0.041)
2025-06-02 09:55:36,689 - train - INFO - Test: [   0/70]  Time: 4.660 (4.660)  Loss:  1.5557 (1.5557)  Acc@1: 72.8933 (72.8933)  Acc@5: 91.7135 (91.7135)
2025-06-02 09:56:18,242 - train - INFO - Test: [  50/70]  Time: 0.120 (0.906)  Loss:  1.9541 (2.0537)  Acc@1: 62.2191 (60.9716)  Acc@5: 84.5506 (83.8290)
2025-06-02 09:56:34,658 - train - INFO - Test: [  70/70]  Time: 0.034 (0.882)  Loss:  3.4023 (2.1351)  Acc@1: 36.8750 (59.0160)  Acc@5: 65.0000 (82.1540)
2025-06-02 09:56:39,435 - train - INFO - Train: 304 [   0/224 (  0%)]  Loss:  3.162922 (3.1629)  Time: 4.468s, 1274.92/s  (4.468s, 1274.92/s)  LR: 1.000e-05  Data: 3.909 (3.909)
2025-06-02 09:57:20,747 - train - INFO - Train: 304 [  50/224 ( 22%)]  Loss:  3.133417 (3.1482)  Time: 0.567s, 10040.86/s  (0.898s, 6345.66/s)  LR: 1.000e-05  Data: 0.000 (0.331)
2025-06-02 09:58:03,060 - train - INFO - Train: 304 [ 100/224 ( 45%)]  Loss:  3.131529 (3.1426)  Time: 1.678s, 3394.87/s  (0.872s, 6530.87/s)  LR: 1.000e-05  Data: 1.131 (0.312)
2025-06-02 09:58:44,254 - train - INFO - Train: 304 [ 150/224 ( 67%)]  Loss:  3.136814 (3.1412)  Time: 0.556s, 10243.84/s  (0.856s, 6652.85/s)  LR: 1.000e-05  Data: 0.000 (0.298)
2025-06-02 09:59:26,383 - train - INFO - Train: 304 [ 200/224 ( 90%)]  Loss:  3.095783 (3.1321)  Time: 1.808s, 3150.78/s  (0.853s, 6679.29/s)  LR: 1.000e-05  Data: 1.267 (0.296)
2025-06-02 09:59:44,229 - train - INFO - Train: 304 [ 223/224 (100%)]  Loss:  3.131461 (3.1320)  Time: 0.551s, 10329.11/s  (0.845s, 6741.74/s)  LR: 1.000e-05  Data: 0.000 (0.289)
2025-06-02 09:59:49,038 - train - INFO - Test: [   0/70]  Time: 4.554 (4.554)  Loss:  1.0938 (1.0938)  Acc@1: 77.9494 (77.9494)  Acc@5: 93.1180 (93.1180)
2025-06-02 10:00:31,809 - train - INFO - Test: [  50/70]  Time: 0.120 (0.928)  Loss:  1.7832 (1.7281)  Acc@1: 62.6404 (62.5496)  Acc@5: 84.1292 (84.6607)
2025-06-02 10:00:48,574 - train - INFO - Test: [  70/70]  Time: 0.036 (0.903)  Loss:  2.0801 (1.8079)  Acc@1: 43.1250 (60.8820)  Acc@5: 82.5000 (83.4380)
2025-06-02 10:00:53,420 - train - INFO - Train: 305 [   0/224 (  0%)]  Loss:  3.059780 (3.0598)  Time: 4.540s, 1254.71/s  (4.540s, 1254.71/s)  LR: 1.000e-05  Data: 3.993 (3.993)
2025-06-02 10:01:34,625 - train - INFO - Train: 305 [  50/224 ( 22%)]  Loss:  3.114726 (3.0873)  Time: 0.550s, 10358.30/s  (0.897s, 6350.49/s)  LR: 1.000e-05  Data: 0.000 (0.234)
2025-06-02 10:02:16,791 - train - INFO - Train: 305 [ 100/224 ( 45%)]  Loss:  3.140698 (3.1051)  Time: 1.583s, 3597.53/s  (0.870s, 6544.23/s)  LR: 1.000e-05  Data: 0.000 (0.118)
2025-06-02 10:02:57,680 - train - INFO - Train: 305 [ 150/224 ( 67%)]  Loss:  3.131340 (3.1116)  Time: 0.568s, 10034.32/s  (0.853s, 6678.00/s)  LR: 1.000e-05  Data: 0.000 (0.079)
2025-06-02 10:03:39,717 - train - INFO - Train: 305 [ 200/224 ( 90%)]  Loss:  3.114687 (3.1122)  Time: 1.644s, 3463.77/s  (0.850s, 6701.87/s)  LR: 1.000e-05  Data: 0.000 (0.060)
2025-06-02 10:03:57,799 - train - INFO - Train: 305 [ 223/224 (100%)]  Loss:  3.162503 (3.1206)  Time: 0.546s, 10434.45/s  (0.843s, 6753.90/s)  LR: 1.000e-05  Data: 0.000 (0.054)
2025-06-02 10:04:02,620 - train - INFO - Test: [   0/70]  Time: 4.568 (4.568)  Loss:  1.1650 (1.1650)  Acc@1: 75.4213 (75.4213)  Acc@5: 92.4157 (92.4157)
2025-06-02 10:04:44,663 - train - INFO - Test: [  50/70]  Time: 0.124 (0.914)  Loss:  1.7412 (1.7241)  Acc@1: 62.0786 (62.2935)  Acc@5: 83.1461 (84.4074)
2025-06-02 10:05:01,303 - train - INFO - Test: [  70/70]  Time: 0.034 (0.891)  Loss:  2.1152 (1.8088)  Acc@1: 46.2500 (60.4520)  Acc@5: 79.3750 (82.8700)
2025-06-02 10:05:06,402 - train - INFO - Train: 306 [   0/224 (  0%)]  Loss:  3.055989 (3.0560)  Time: 4.783s, 1190.91/s  (4.783s, 1190.91/s)  LR: 1.000e-05  Data: 4.231 (4.231)
2025-06-02 10:05:48,149 - train - INFO - Train: 306 [  50/224 ( 22%)]  Loss:  3.130824 (3.0934)  Time: 0.567s, 10042.13/s  (0.912s, 6243.40/s)  LR: 1.000e-05  Data: 0.000 (0.154)
2025-06-02 10:06:29,994 - train - INFO - Train: 306 [ 100/224 ( 45%)]  Loss:  3.129483 (3.1054)  Time: 1.481s, 3845.00/s  (0.875s, 6509.94/s)  LR: 1.000e-05  Data: 0.000 (0.078)
2025-06-02 10:07:10,408 - train - INFO - Train: 306 [ 150/224 ( 67%)]  Loss:  3.122384 (3.1097)  Time: 0.551s, 10345.66/s  (0.853s, 6678.57/s)  LR: 1.000e-05  Data: 0.000 (0.052)
2025-06-02 10:07:51,942 - train - INFO - Train: 306 [ 200/224 ( 90%)]  Loss:  3.102212 (3.1082)  Time: 1.615s, 3526.09/s  (0.847s, 6722.17/s)  LR: 1.000e-05  Data: 0.000 (0.039)
2025-06-02 10:08:10,114 - train - INFO - Train: 306 [ 223/224 (100%)]  Loss:  3.118252 (3.1099)  Time: 0.546s, 10426.42/s  (0.841s, 6769.14/s)  LR: 1.000e-05  Data: 0.000 (0.035)
2025-06-02 10:08:14,990 - train - INFO - Test: [   0/70]  Time: 4.631 (4.631)  Loss:  1.4600 (1.4600)  Acc@1: 72.1910 (72.1910)  Acc@5: 89.4663 (89.4663)
2025-06-02 10:08:57,034 - train - INFO - Test: [  50/70]  Time: 0.120 (0.915)  Loss:  1.8584 (1.8596)  Acc@1: 64.0449 (61.9795)  Acc@5: 85.1124 (84.9003)
2025-06-02 10:09:13,764 - train - INFO - Test: [  70/70]  Time: 0.034 (0.893)  Loss:  2.7480 (1.9348)  Acc@1: 36.2500 (60.4600)  Acc@5: 70.0000 (83.4720)
2025-06-02 10:09:18,814 - train - INFO - Train: 307 [   0/224 (  0%)]  Loss:  3.093566 (3.0936)  Time: 4.749s, 1199.29/s  (4.749s, 1199.29/s)  LR: 1.000e-05  Data: 4.199 (4.199)
2025-06-02 10:09:59,903 - train - INFO - Train: 307 [  50/224 ( 22%)]  Loss:  3.093762 (3.0937)  Time: 0.548s, 10386.73/s  (0.899s, 6337.53/s)  LR: 1.000e-05  Data: 0.000 (0.306)
2025-06-02 10:10:42,208 - train - INFO - Train: 307 [ 100/224 ( 45%)]  Loss:  3.115508 (3.1009)  Time: 1.333s, 4274.46/s  (0.873s, 6527.13/s)  LR: 1.000e-05  Data: 0.000 (0.175)
2025-06-02 10:11:23,920 - train - INFO - Train: 307 [ 150/224 ( 67%)]  Loss:  3.113093 (3.1040)  Time: 0.549s, 10367.15/s  (0.860s, 6623.82/s)  LR: 1.000e-05  Data: 0.000 (0.117)
2025-06-02 10:12:05,000 - train - INFO - Train: 307 [ 200/224 ( 90%)]  Loss:  3.128022 (3.1088)  Time: 0.798s, 7140.86/s  (0.850s, 6698.19/s)  LR: 1.000e-05  Data: 0.000 (0.088)
2025-06-02 10:12:23,972 - train - INFO - Train: 307 [ 223/224 (100%)]  Loss:  3.113636 (3.1096)  Time: 0.545s, 10447.53/s  (0.848s, 6718.96/s)  LR: 1.000e-05  Data: 0.000 (0.079)
2025-06-02 10:12:28,832 - train - INFO - Test: [   0/70]  Time: 4.602 (4.602)  Loss:  1.3740 (1.3740)  Acc@1: 73.4551 (73.4551)  Acc@5: 90.7303 (90.7303)
2025-06-02 10:13:11,606 - train - INFO - Test: [  50/70]  Time: 0.121 (0.929)  Loss:  1.9043 (1.8060)  Acc@1: 59.6910 (62.6074)  Acc@5: 83.7079 (84.6745)
2025-06-02 10:13:28,489 - train - INFO - Test: [  70/70]  Time: 0.035 (0.905)  Loss:  2.1562 (1.8876)  Acc@1: 50.6250 (60.8940)  Acc@5: 81.2500 (83.2540)
2025-06-02 10:13:33,370 - train - INFO - Train: 308 [   0/224 (  0%)]  Loss:  3.120882 (3.1209)  Time: 4.574s, 1245.28/s  (4.574s, 1245.28/s)  LR: 1.000e-05  Data: 3.820 (3.820)
2025-06-02 10:14:14,347 - train - INFO - Train: 308 [  50/224 ( 22%)]  Loss:  3.114215 (3.1175)  Time: 0.548s, 10387.99/s  (0.893s, 6377.64/s)  LR: 1.000e-05  Data: 0.000 (0.130)
2025-06-02 10:14:56,200 - train - INFO - Train: 308 [ 100/224 ( 45%)]  Loss:  3.101570 (3.1122)  Time: 1.742s, 3269.11/s  (0.865s, 6582.30/s)  LR: 1.000e-05  Data: 0.000 (0.066)
2025-06-02 10:15:36,984 - train - INFO - Train: 308 [ 150/224 ( 67%)]  Loss:  3.162709 (3.1248)  Time: 0.556s, 10249.77/s  (0.849s, 6709.90/s)  LR: 1.000e-05  Data: 0.000 (0.044)
2025-06-02 10:16:18,467 - train - INFO - Train: 308 [ 200/224 ( 90%)]  Loss:  3.143519 (3.1286)  Time: 1.272s, 4476.92/s  (0.844s, 6747.99/s)  LR: 1.000e-05  Data: 0.000 (0.033)
2025-06-02 10:16:36,535 - train - INFO - Train: 308 [ 223/224 (100%)]  Loss:  3.114283 (3.1262)  Time: 0.545s, 10458.46/s  (0.838s, 6796.41/s)  LR: 1.000e-05  Data: 0.000 (0.030)
2025-06-02 10:16:41,280 - train - INFO - Test: [   0/70]  Time: 4.503 (4.503)  Loss:  1.3965 (1.3965)  Acc@1: 75.0000 (75.0000)  Acc@5: 90.3090 (90.3090)
2025-06-02 10:17:23,935 - train - INFO - Test: [  50/70]  Time: 0.124 (0.925)  Loss:  1.7510 (1.8239)  Acc@1: 62.9214 (62.0594)  Acc@5: 84.1292 (84.5533)
2025-06-02 10:17:40,562 - train - INFO - Test: [  70/70]  Time: 0.034 (0.898)  Loss:  2.2676 (1.9048)  Acc@1: 45.6250 (60.2580)  Acc@5: 80.0000 (83.0640)
2025-06-02 10:17:45,883 - train - INFO - Train: 309 [   0/224 (  0%)]  Loss:  3.126318 (3.1263)  Time: 5.016s, 1135.51/s  (5.016s, 1135.51/s)  LR: 1.000e-05  Data: 4.336 (4.336)
2025-06-02 10:18:27,383 - train - INFO - Train: 309 [  50/224 ( 22%)]  Loss:  3.145703 (3.1360)  Time: 0.552s, 10326.29/s  (0.912s, 6245.28/s)  LR: 1.000e-05  Data: 0.000 (0.121)
2025-06-02 10:19:09,636 - train - INFO - Train: 309 [ 100/224 ( 45%)]  Loss:  3.152529 (3.1415)  Time: 1.556s, 3660.99/s  (0.879s, 6481.20/s)  LR: 1.000e-05  Data: 0.000 (0.061)
2025-06-02 10:19:50,688 - train - INFO - Train: 309 [ 150/224 ( 67%)]  Loss:  3.128863 (3.1384)  Time: 0.549s, 10373.73/s  (0.860s, 6625.64/s)  LR: 1.000e-05  Data: 0.000 (0.041)
2025-06-02 10:20:33,080 - train - INFO - Train: 309 [ 200/224 ( 90%)]  Loss:  3.149090 (3.1405)  Time: 1.676s, 3398.08/s  (0.857s, 6648.52/s)  LR: 1.000e-05  Data: 0.000 (0.031)
2025-06-02 10:20:51,124 - train - INFO - Train: 309 [ 223/224 (100%)]  Loss:  3.151140 (3.1423)  Time: 0.553s, 10294.56/s  (0.849s, 6706.57/s)  LR: 1.000e-05  Data: 0.000 (0.028)
2025-06-02 10:20:56,068 - train - INFO - Test: [   0/70]  Time: 4.700 (4.700)  Loss:  1.5801 (1.5801)  Acc@1: 72.7528 (72.7528)  Acc@5: 90.1685 (90.1685)
2025-06-02 10:21:38,425 - train - INFO - Test: [  50/70]  Time: 0.120 (0.923)  Loss:  2.1230 (2.0339)  Acc@1: 60.3933 (60.8201)  Acc@5: 81.3202 (83.3333)
2025-06-02 10:21:54,930 - train - INFO - Test: [  70/70]  Time: 0.036 (0.895)  Loss:  2.2012 (2.1006)  Acc@1: 53.1250 (59.3100)  Acc@5: 83.7500 (82.0700)
2025-06-02 10:21:55,244 - train - INFO - Best accuracy: 62.71800060424805, epoch: 200
