2024-08-28 21:25:41,494 - train - INFO - len loader.dataset:50000
2024-08-28 21:25:42,155 - train - INFO - target_block_size:4
2024-08-28 21:25:42,774 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:25:42,776 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:25:42,777 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:25:42,779 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:25:42,780 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:25:42,782 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:25:42,783 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:25:42,785 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:25:42,787 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:25:42,788 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:25:42,790 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:25:42,791 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:25:42,792 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:25:42,793 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:25:42,794 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:25:42,795 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:25:42,796 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:25:42,797 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:25:42,799 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:25:42,800 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:25:42,801 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:25:43,232 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:25:43,234 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:25:43,235 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:25:43,237 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:25:43,238 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:25:43,240 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:25:43,242 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:25:43,243 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:25:43,245 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:25:43,246 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:25:43,248 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:25:43,251 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:25:43,254 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:25:43,256 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:25:43,258 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:25:43,260 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:25:43,262 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:25:43,264 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:25:43,266 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:25:43,268 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:25:43,270 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:25:43,720 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:25:43,724 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:25:43,728 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:25:43,732 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:25:43,736 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:25:43,740 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:25:43,744 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:25:43,747 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:25:43,751 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:25:43,754 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:25:43,758 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:25:43,761 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:25:43,763 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:25:43,765 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:25:43,767 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:25:43,769 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:25:43,771 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:25:43,773 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:25:43,775 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:25:43,777 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:25:43,779 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:25:44,228 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:25:44,230 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:25:44,232 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:25:44,237 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:25:44,240 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:25:44,242 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:25:44,244 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:25:44,246 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:25:44,248 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:25:44,251 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:25:44,253 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:25:44,255 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:25:44,256 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:25:44,258 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:25:44,259 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:25:44,261 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:25:44,262 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:25:44,264 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:25:44,265 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:25:44,267 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:25:44,268 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:25:44,738 - train - INFO - latency_accumulation_b6:75.96500396728516
2024-08-28 21:25:44,740 - train - INFO - latency_accumulation_b7:75.96500396728516
2024-08-28 21:25:44,743 - train - INFO - latency_accumulation_b8:75.96500396728516
2024-08-28 21:25:44,746 - train - INFO - latency_accumulation_b9:125.25833892822266
2024-08-28 21:25:44,749 - train - INFO - latency_accumulation_b10:125.25833892822266
2024-08-28 21:25:44,752 - train - INFO - latency_accumulation_b11:125.25833892822266
2024-08-28 21:25:44,755 - train - INFO - latency_accumulation_b12:125.25833892822266
2024-08-28 21:25:44,759 - train - INFO - latency_accumulation_b13:125.25833892822266
2024-08-28 21:25:44,762 - train - INFO - latency_accumulation_b14:125.25834655761719
2024-08-28 21:25:44,765 - train - INFO - latency_accumulation_b15:125.25834655761719
2024-08-28 21:25:44,768 - train - INFO - latency_accumulation_b16:125.25834655761719
2024-08-28 21:25:44,771 - train - INFO - latency_accumulation_b17:125.25834655761719
2024-08-28 21:25:44,773 - train - INFO - latency_accumulation_b18:178.24000549316406
2024-08-28 21:25:44,774 - train - INFO - latency_accumulation_b19:178.24000549316406
2024-08-28 21:25:44,776 - train - INFO - latency_accumulation_b20:178.24000549316406
2024-08-28 21:25:44,777 - train - INFO - latency_accumulation_b21:178.24000549316406
2024-08-28 21:25:44,779 - train - INFO - latency_accumulation_b22:178.24000549316406
2024-08-28 21:25:44,780 - train - INFO - latency_accumulation_b23:178.24000549316406
2024-08-28 21:25:44,781 - train - INFO - latency_accumulation_b24:178.24000549316406
2024-08-28 21:25:44,783 - train - INFO - latency_accumulation_b25:178.24000549316406
2024-08-28 21:25:44,784 - train - INFO - latency_accumulation_b26:178.24000549316406
2024-08-28 21:25:45,159 - train - INFO - latency_accumulation_b6:55.96625518798828
2024-08-28 21:25:45,166 - train - INFO - latency_accumulation_b7:55.96625518798828
2024-08-28 21:25:45,172 - train - INFO - latency_accumulation_b8:55.96625900268555
2024-08-28 21:25:45,181 - train - INFO - latency_accumulation_b9:60.56000518798828
2024-08-28 21:25:45,189 - train - INFO - latency_accumulation_b10:60.56000518798828
2024-08-28 21:25:45,197 - train - INFO - latency_accumulation_b11:60.56000518798828
2024-08-28 21:25:45,205 - train - INFO - latency_accumulation_b12:60.56000900268555
2024-08-28 21:25:45,213 - train - INFO - latency_accumulation_b13:60.56000900268555
2024-08-28 21:25:45,221 - train - INFO - latency_accumulation_b14:60.56000900268555
2024-08-28 21:25:45,229 - train - INFO - latency_accumulation_b15:60.56000900268555
2024-08-28 21:25:45,237 - train - INFO - latency_accumulation_b16:60.56000900268555
2024-08-28 21:25:45,245 - train - INFO - latency_accumulation_b17:60.56000900268555
2024-08-28 21:25:45,251 - train - INFO - latency_accumulation_b18:139.65000915527344
2024-08-28 21:25:45,256 - train - INFO - latency_accumulation_b19:139.65000915527344
2024-08-28 21:25:45,261 - train - INFO - latency_accumulation_b20:139.65000915527344
2024-08-28 21:25:45,267 - train - INFO - latency_accumulation_b21:139.65000915527344
2024-08-28 21:25:45,272 - train - INFO - latency_accumulation_b22:139.65000915527344
2024-08-28 21:25:45,277 - train - INFO - latency_accumulation_b23:139.65000915527344
2024-08-28 21:25:45,283 - train - INFO - latency_accumulation_b24:139.65000915527344
2024-08-28 21:25:45,288 - train - INFO - latency_accumulation_b25:139.65000915527344
2024-08-28 21:25:45,293 - train - INFO - latency_accumulation_b26:139.65000915527344
2024-08-28 21:25:45,563 - train - INFO - latency_accumulation_b6:55.96625518798828
2024-08-28 21:25:45,570 - train - INFO - latency_accumulation_b7:55.96625518798828
2024-08-28 21:25:45,577 - train - INFO - latency_accumulation_b8:55.96625900268555
2024-08-28 21:25:45,585 - train - INFO - latency_accumulation_b9:60.56000518798828
2024-08-28 21:25:45,593 - train - INFO - latency_accumulation_b10:60.56000518798828
2024-08-28 21:25:45,601 - train - INFO - latency_accumulation_b11:60.56000518798828
2024-08-28 21:25:45,609 - train - INFO - latency_accumulation_b12:60.56000900268555
2024-08-28 21:25:45,617 - train - INFO - latency_accumulation_b13:60.56000900268555
2024-08-28 21:25:45,625 - train - INFO - latency_accumulation_b14:60.56000900268555
2024-08-28 21:25:45,633 - train - INFO - latency_accumulation_b15:60.56000900268555
2024-08-28 21:25:45,642 - train - INFO - latency_accumulation_b16:60.56000900268555
2024-08-28 21:25:45,649 - train - INFO - latency_accumulation_b17:60.56000900268555
2024-08-28 21:25:45,654 - train - INFO - latency_accumulation_b18:139.65000915527344
2024-08-28 21:25:45,659 - train - INFO - latency_accumulation_b19:139.65000915527344
2024-08-28 21:25:45,664 - train - INFO - latency_accumulation_b20:139.65000915527344
2024-08-28 21:25:45,669 - train - INFO - latency_accumulation_b21:139.65000915527344
2024-08-28 21:25:45,674 - train - INFO - latency_accumulation_b22:139.65000915527344
2024-08-28 21:25:45,678 - train - INFO - latency_accumulation_b23:139.65000915527344
2024-08-28 21:25:45,683 - train - INFO - latency_accumulation_b24:139.65000915527344
2024-08-28 21:25:45,687 - train - INFO - latency_accumulation_b25:139.65000915527344
2024-08-28 21:25:45,692 - train - INFO - latency_accumulation_b26:139.65000915527344
2024-08-28 21:25:45,944 - train - INFO - latency_accumulation_b6:55.96625518798828
2024-08-28 21:25:45,948 - train - INFO - latency_accumulation_b7:55.96625518798828
2024-08-28 21:25:45,952 - train - INFO - latency_accumulation_b8:55.96625900268555
2024-08-28 21:25:45,957 - train - INFO - latency_accumulation_b9:60.56000518798828
2024-08-28 21:25:45,962 - train - INFO - latency_accumulation_b10:60.56000518798828
2024-08-28 21:25:45,967 - train - INFO - latency_accumulation_b11:60.56000518798828
2024-08-28 21:25:45,972 - train - INFO - latency_accumulation_b12:60.56000900268555
2024-08-28 21:25:45,977 - train - INFO - latency_accumulation_b13:60.56000900268555
2024-08-28 21:25:45,982 - train - INFO - latency_accumulation_b14:60.56000900268555
2024-08-28 21:25:45,987 - train - INFO - latency_accumulation_b15:60.56000900268555
2024-08-28 21:25:45,992 - train - INFO - latency_accumulation_b16:60.56000900268555
2024-08-28 21:25:45,996 - train - INFO - latency_accumulation_b17:60.56000900268555
2024-08-28 21:25:46,000 - train - INFO - latency_accumulation_b18:139.65000915527344
2024-08-28 21:25:46,003 - train - INFO - latency_accumulation_b19:139.65000915527344
2024-08-28 21:25:46,006 - train - INFO - latency_accumulation_b20:139.65000915527344
2024-08-28 21:25:46,009 - train - INFO - latency_accumulation_b21:139.65000915527344
2024-08-28 21:25:46,012 - train - INFO - latency_accumulation_b22:139.65000915527344
2024-08-28 21:25:46,016 - train - INFO - latency_accumulation_b23:139.65000915527344
2024-08-28 21:25:46,019 - train - INFO - latency_accumulation_b24:139.65000915527344
2024-08-28 21:25:46,022 - train - INFO - latency_accumulation_b25:139.65000915527344
2024-08-28 21:25:46,025 - train - INFO - latency_accumulation_b26:139.65000915527344
2024-08-28 21:25:46,322 - train - INFO - latency_accumulation_b6:82.65250396728516
2024-08-28 21:25:46,331 - train - INFO - latency_accumulation_b7:82.65250396728516
2024-08-28 21:25:46,347 - train - INFO - latency_accumulation_b8:82.65251159667969
2024-08-28 21:25:46,369 - train - INFO - latency_accumulation_b9:139.65000915527344
2024-08-28 21:25:46,388 - train - INFO - latency_accumulation_b10:139.65000915527344
2024-08-28 21:25:46,406 - train - INFO - latency_accumulation_b11:139.65000915527344
2024-08-28 21:25:46,421 - train - INFO - latency_accumulation_b12:139.65000915527344
2024-08-28 21:25:46,435 - train - INFO - latency_accumulation_b13:139.65000915527344
2024-08-28 21:25:46,448 - train - INFO - latency_accumulation_b14:139.65000915527344
2024-08-28 21:25:46,461 - train - INFO - latency_accumulation_b15:139.65000915527344
2024-08-28 21:25:46,473 - train - INFO - latency_accumulation_b16:139.65000915527344
2024-08-28 21:25:46,485 - train - INFO - latency_accumulation_b17:139.65000915527344
2024-08-28 21:25:46,490 - train - INFO - latency_accumulation_b18:190.24000549316406
2024-08-28 21:25:46,496 - train - INFO - latency_accumulation_b19:190.24000549316406
2024-08-28 21:25:46,501 - train - INFO - latency_accumulation_b20:190.24000549316406
2024-08-28 21:25:46,506 - train - INFO - latency_accumulation_b21:190.24000549316406
2024-08-28 21:25:46,512 - train - INFO - latency_accumulation_b22:190.24002075195312
2024-08-28 21:25:46,517 - train - INFO - latency_accumulation_b23:190.24002075195312
2024-08-28 21:25:46,522 - train - INFO - latency_accumulation_b24:190.24002075195312
2024-08-28 21:25:46,528 - train - INFO - latency_accumulation_b25:190.24002075195312
2024-08-28 21:25:46,533 - train - INFO - latency_accumulation_b26:190.24002075195312
2024-08-28 21:25:46,836 - train - INFO - latency_accumulation_b6:64.56001281738281
2024-08-28 21:25:46,862 - train - INFO - latency_accumulation_b7:64.56002044677734
2024-08-28 21:25:46,887 - train - INFO - latency_accumulation_b8:64.56002044677734
2024-08-28 21:25:46,919 - train - INFO - latency_accumulation_b9:63.56001281738281
2024-08-28 21:25:46,951 - train - INFO - latency_accumulation_b10:63.56001281738281
2024-08-28 21:25:46,982 - train - INFO - latency_accumulation_b11:63.56001281738281
2024-08-28 21:25:47,014 - train - INFO - latency_accumulation_b12:63.56001281738281
2024-08-28 21:25:47,045 - train - INFO - latency_accumulation_b13:63.56001663208008
2024-08-28 21:25:47,077 - train - INFO - latency_accumulation_b14:63.56001663208008
2024-08-28 21:25:47,109 - train - INFO - latency_accumulation_b15:63.56001663208008
2024-08-28 21:25:47,140 - train - INFO - latency_accumulation_b16:63.56001663208008
2024-08-28 21:25:47,172 - train - INFO - latency_accumulation_b17:63.560020446777344
2024-08-28 21:25:47,193 - train - INFO - latency_accumulation_b18:189.32907104492188
2024-08-28 21:25:47,213 - train - INFO - latency_accumulation_b19:189.32907104492188
2024-08-28 21:25:47,234 - train - INFO - latency_accumulation_b20:189.32907104492188
2024-08-28 21:25:47,255 - train - INFO - latency_accumulation_b21:189.32907104492188
2024-08-28 21:25:47,276 - train - INFO - latency_accumulation_b22:189.32907104492188
2024-08-28 21:25:47,296 - train - INFO - latency_accumulation_b23:189.32907104492188
2024-08-28 21:25:47,317 - train - INFO - latency_accumulation_b24:189.32907104492188
2024-08-28 21:25:47,338 - train - INFO - latency_accumulation_b25:189.32908630371094
2024-08-28 21:25:47,357 - train - INFO - latency_accumulation_b26:189.32908630371094
2024-08-28 21:25:47,550 - train - INFO - latency_accumulation_b6:64.56001281738281
2024-08-28 21:25:47,568 - train - INFO - latency_accumulation_b7:64.56002044677734
2024-08-28 21:25:47,585 - train - INFO - latency_accumulation_b8:64.56002044677734
2024-08-28 21:25:47,606 - train - INFO - latency_accumulation_b9:63.56001281738281
2024-08-28 21:25:47,627 - train - INFO - latency_accumulation_b10:63.56001281738281
2024-08-28 21:25:47,648 - train - INFO - latency_accumulation_b11:63.56001281738281
2024-08-28 21:25:47,670 - train - INFO - latency_accumulation_b12:63.56001281738281
2024-08-28 21:25:47,691 - train - INFO - latency_accumulation_b13:63.56001663208008
2024-08-28 21:25:47,713 - train - INFO - latency_accumulation_b14:63.56001663208008
2024-08-28 21:25:47,734 - train - INFO - latency_accumulation_b15:63.56001663208008
2024-08-28 21:25:47,755 - train - INFO - latency_accumulation_b16:63.56001663208008
2024-08-28 21:25:47,777 - train - INFO - latency_accumulation_b17:63.560020446777344
2024-08-28 21:25:47,791 - train - INFO - latency_accumulation_b18:189.32907104492188
2024-08-28 21:25:47,805 - train - INFO - latency_accumulation_b19:189.32907104492188
2024-08-28 21:25:47,819 - train - INFO - latency_accumulation_b20:189.32907104492188
2024-08-28 21:25:47,833 - train - INFO - latency_accumulation_b21:189.32907104492188
2024-08-28 21:25:47,846 - train - INFO - latency_accumulation_b22:189.32907104492188
2024-08-28 21:25:47,860 - train - INFO - latency_accumulation_b23:189.32907104492188
2024-08-28 21:25:47,875 - train - INFO - latency_accumulation_b24:189.32907104492188
2024-08-28 21:25:47,889 - train - INFO - latency_accumulation_b25:189.32908630371094
2024-08-28 21:25:47,903 - train - INFO - latency_accumulation_b26:189.32908630371094
2024-08-28 21:25:48,131 - train - INFO - latency_accumulation_b6:64.56001281738281
2024-08-28 21:25:48,157 - train - INFO - latency_accumulation_b7:64.56002044677734
2024-08-28 21:25:48,182 - train - INFO - latency_accumulation_b8:64.56002044677734
2024-08-28 21:25:48,214 - train - INFO - latency_accumulation_b9:63.56001281738281
2024-08-28 21:25:48,245 - train - INFO - latency_accumulation_b10:63.56001281738281
2024-08-28 21:25:48,277 - train - INFO - latency_accumulation_b11:63.56001281738281
2024-08-28 21:25:48,308 - train - INFO - latency_accumulation_b12:63.56001281738281
2024-08-28 21:25:48,340 - train - INFO - latency_accumulation_b13:63.56001663208008
2024-08-28 21:25:48,374 - train - INFO - latency_accumulation_b14:63.56001663208008
2024-08-28 21:25:48,406 - train - INFO - latency_accumulation_b15:63.56001663208008
2024-08-28 21:25:48,437 - train - INFO - latency_accumulation_b16:63.56001663208008
2024-08-28 21:25:48,469 - train - INFO - latency_accumulation_b17:63.560020446777344
2024-08-28 21:25:48,489 - train - INFO - latency_accumulation_b18:189.32907104492188
2024-08-28 21:25:48,510 - train - INFO - latency_accumulation_b19:189.32907104492188
2024-08-28 21:25:48,531 - train - INFO - latency_accumulation_b20:189.32907104492188
2024-08-28 21:25:48,550 - train - INFO - latency_accumulation_b21:189.32907104492188
2024-08-28 21:25:48,568 - train - INFO - latency_accumulation_b22:189.32907104492188
2024-08-28 21:25:48,585 - train - INFO - latency_accumulation_b23:189.32907104492188
2024-08-28 21:25:48,601 - train - INFO - latency_accumulation_b24:189.32907104492188
2024-08-28 21:25:48,619 - train - INFO - latency_accumulation_b25:189.32908630371094
2024-08-28 21:25:48,634 - train - INFO - latency_accumulation_b26:189.32908630371094
2024-08-28 21:25:48,844 - train - INFO - latency_accumulation_b6:117.61351776123047
2024-08-28 21:25:48,894 - train - INFO - latency_accumulation_b7:117.61351776123047
2024-08-28 21:25:48,938 - train - INFO - latency_accumulation_b8:117.613525390625
2024-08-28 21:25:48,989 - train - INFO - latency_accumulation_b9:189.32907104492188
2024-08-28 21:25:49,035 - train - INFO - latency_accumulation_b10:189.32907104492188
2024-08-28 21:25:49,082 - train - INFO - latency_accumulation_b11:189.32907104492188
2024-08-28 21:25:49,132 - train - INFO - latency_accumulation_b12:189.32907104492188
2024-08-28 21:25:49,179 - train - INFO - latency_accumulation_b13:189.32908630371094
2024-08-28 21:25:49,226 - train - INFO - latency_accumulation_b14:189.32908630371094
2024-08-28 21:25:49,273 - train - INFO - latency_accumulation_b15:189.32908630371094
2024-08-28 21:25:49,319 - train - INFO - latency_accumulation_b16:189.32908630371094
2024-08-28 21:25:49,366 - train - INFO - latency_accumulation_b17:189.32908630371094
2024-08-28 21:25:49,390 - train - INFO - latency_accumulation_b18:196.24002075195312
2024-08-28 21:25:49,411 - train - INFO - latency_accumulation_b19:196.24002075195312
2024-08-28 21:25:49,432 - train - INFO - latency_accumulation_b20:196.24002075195312
2024-08-28 21:25:49,453 - train - INFO - latency_accumulation_b21:196.24002075195312
2024-08-28 21:25:49,473 - train - INFO - latency_accumulation_b22:196.24002075195312
2024-08-28 21:25:49,494 - train - INFO - latency_accumulation_b23:196.24002075195312
2024-08-28 21:25:49,515 - train - INFO - latency_accumulation_b24:196.2400360107422
2024-08-28 21:25:49,536 - train - INFO - latency_accumulation_b25:196.2400360107422
2024-08-28 21:25:49,555 - train - INFO - latency_accumulation_b26:196.2400360107422
2024-08-28 21:25:49,925 - train - INFO - latency_accumulation_b6:111.2082748413086
2024-08-28 21:25:50,033 - train - INFO - latency_accumulation_b7:111.20828247070312
2024-08-28 21:25:50,138 - train - INFO - latency_accumulation_b8:111.20829010009766
2024-08-28 21:25:50,268 - train - INFO - latency_accumulation_b9:114.12004852294922
2024-08-28 21:25:50,392 - train - INFO - latency_accumulation_b10:114.12004852294922
2024-08-28 21:25:50,486 - train - INFO - latency_accumulation_b11:114.12005615234375
2024-08-28 21:25:50,573 - train - INFO - latency_accumulation_b12:114.12005615234375
2024-08-28 21:25:50,656 - train - INFO - latency_accumulation_b13:114.12006378173828
2024-08-28 21:25:50,732 - train - INFO - latency_accumulation_b14:114.12006378173828
2024-08-28 21:25:50,808 - train - INFO - latency_accumulation_b15:114.12007141113281
2024-08-28 21:25:50,888 - train - INFO - latency_accumulation_b16:114.12007141113281
2024-08-28 21:25:50,964 - train - INFO - latency_accumulation_b17:114.12007904052734
2024-08-28 21:25:51,019 - train - INFO - latency_accumulation_b18:316.74993896484375
2024-08-28 21:25:51,076 - train - INFO - latency_accumulation_b19:316.74993896484375
2024-08-28 21:25:51,177 - train - INFO - latency_accumulation_b20:316.74993896484375
2024-08-28 21:25:51,268 - train - INFO - latency_accumulation_b21:316.74993896484375
2024-08-28 21:25:51,357 - train - INFO - latency_accumulation_b22:316.74993896484375
2024-08-28 21:25:51,446 - train - INFO - latency_accumulation_b23:316.7499694824219
2024-08-28 21:25:51,537 - train - INFO - latency_accumulation_b24:316.7499694824219
2024-08-28 21:25:51,626 - train - INFO - latency_accumulation_b25:316.7499694824219
2024-08-28 21:25:51,714 - train - INFO - latency_accumulation_b26:316.7499694824219
2024-08-28 21:25:51,994 - train - INFO - latency_accumulation_b6:111.2082748413086
2024-08-28 21:25:52,060 - train - INFO - latency_accumulation_b7:111.20828247070312
2024-08-28 21:25:52,127 - train - INFO - latency_accumulation_b8:111.20829010009766
2024-08-28 21:25:52,204 - train - INFO - latency_accumulation_b9:114.12004852294922
2024-08-28 21:25:52,283 - train - INFO - latency_accumulation_b10:114.12004852294922
2024-08-28 21:25:52,422 - train - INFO - latency_accumulation_b11:114.12005615234375
2024-08-28 21:25:52,537 - train - INFO - latency_accumulation_b12:114.12005615234375
2024-08-28 21:25:52,631 - train - INFO - latency_accumulation_b13:114.12006378173828
2024-08-28 21:25:52,717 - train - INFO - latency_accumulation_b14:114.12006378173828
2024-08-28 21:25:52,802 - train - INFO - latency_accumulation_b15:114.12007141113281
2024-08-28 21:25:52,884 - train - INFO - latency_accumulation_b16:114.12007141113281
2024-08-28 21:25:52,969 - train - INFO - latency_accumulation_b17:114.12007904052734
2024-08-28 21:25:53,028 - train - INFO - latency_accumulation_b18:316.74993896484375
2024-08-28 21:25:53,090 - train - INFO - latency_accumulation_b19:316.74993896484375
2024-08-28 21:25:53,147 - train - INFO - latency_accumulation_b20:316.74993896484375
2024-08-28 21:25:53,242 - train - INFO - latency_accumulation_b21:316.74993896484375
2024-08-28 21:25:53,330 - train - INFO - latency_accumulation_b22:316.74993896484375
2024-08-28 21:25:53,419 - train - INFO - latency_accumulation_b23:316.7499694824219
2024-08-28 21:25:53,510 - train - INFO - latency_accumulation_b24:316.7499694824219
2024-08-28 21:25:53,599 - train - INFO - latency_accumulation_b25:316.7499694824219
2024-08-28 21:25:53,687 - train - INFO - latency_accumulation_b26:316.7499694824219
2024-08-28 21:25:53,992 - train - INFO - latency_accumulation_b6:111.2082748413086
2024-08-28 21:25:54,055 - train - INFO - latency_accumulation_b7:111.20828247070312
2024-08-28 21:25:54,117 - train - INFO - latency_accumulation_b8:111.20829010009766
2024-08-28 21:25:54,197 - train - INFO - latency_accumulation_b9:114.12004852294922
2024-08-28 21:25:54,276 - train - INFO - latency_accumulation_b10:114.12004852294922
2024-08-28 21:25:54,356 - train - INFO - latency_accumulation_b11:114.12005615234375
2024-08-28 21:25:54,434 - train - INFO - latency_accumulation_b12:114.12005615234375
2024-08-28 21:25:54,512 - train - INFO - latency_accumulation_b13:114.12006378173828
2024-08-28 21:25:54,594 - train - INFO - latency_accumulation_b14:114.12006378173828
2024-08-28 21:25:54,673 - train - INFO - latency_accumulation_b15:114.12007141113281
2024-08-28 21:25:54,755 - train - INFO - latency_accumulation_b16:114.12007141113281
2024-08-28 21:25:54,843 - train - INFO - latency_accumulation_b17:114.12007904052734
2024-08-28 21:25:54,901 - train - INFO - latency_accumulation_b18:316.74993896484375
2024-08-28 21:25:54,955 - train - INFO - latency_accumulation_b19:316.74993896484375
2024-08-28 21:25:55,044 - train - INFO - latency_accumulation_b20:316.74993896484375
2024-08-28 21:25:55,166 - train - INFO - latency_accumulation_b21:316.74993896484375
2024-08-28 21:25:55,255 - train - INFO - latency_accumulation_b22:316.74993896484375
2024-08-28 21:25:55,344 - train - INFO - latency_accumulation_b23:316.7499694824219
2024-08-28 21:25:55,436 - train - INFO - latency_accumulation_b24:316.7499694824219
2024-08-28 21:25:55,525 - train - INFO - latency_accumulation_b25:316.7499694824219
2024-08-28 21:25:55,587 - train - INFO - latency_accumulation_b26:316.7499694824219
2024-08-28 21:25:55,588 - train - INFO - origin_latency:2379.3054542541504
2024-08-28 21:25:55,588 - train - INFO - cir_idx:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
2024-08-28 21:27:24,578 - train - INFO - Model ResNet18 created, param count:11220132
2024-08-28 21:27:24,579 - train - INFO - Get QAT model...
2024-08-28 21:27:25,383 - train - INFO - ResNet(
  (relu): ReLU(
    (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
  )
  (conv1): QConv2d(
    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
    (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
    (quan_a_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False)
  )
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False)
      )
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False)
      )
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
  )
  (fc): QLinear(
    in_features=512, out_features=100, bias=True
    (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
    (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
  )
)
2024-08-28 21:27:25,654 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-08-28 21:27:25,655 - train - INFO - Scheduled epochs: 310
2024-08-28 21:27:29,962 - train - INFO - Test: [   0/9]  Time: 2.102 (2.102)  Loss:  1.0938 (1.0938)  Acc@1: 78.9062 (78.9062)  Acc@5: 93.8477 (93.8477)
2024-08-28 21:27:33,437 - train - INFO - Test: [   9/9]  Time: 0.950 (0.558)  Loss:  1.0303 (1.0583)  Acc@1: 80.3571 (78.7200)  Acc@5: 93.8775 (94.4000)
2024-08-28 21:27:33,438 - train - INFO - Verifying teacher model
2024-08-28 21:27:33,856 - train - INFO - Test: [   0/9]  Time: 0.417 (0.417)  Loss:  1.0938 (1.0938)  Acc@1: 78.8086 (78.8086)  Acc@5: 93.8477 (93.8477)
2024-08-28 21:27:34,299 - train - INFO - Test: [   9/9]  Time: 0.040 (0.086)  Loss:  1.0303 (1.0582)  Acc@1: 80.3571 (78.7100)  Acc@5: 93.8775 (94.3900)
2024-08-28 21:27:34,299 - train - INFO - Verifying initial model in training dataset
2024-08-28 21:27:38,419 - train - INFO - len loader.dataset:50000
2024-08-28 21:27:39,046 - train - INFO - target_block_size:4
2024-08-28 21:27:39,985 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:27:39,986 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:27:39,988 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:27:39,989 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:27:39,991 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:27:39,992 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:27:39,994 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:27:39,996 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:27:39,997 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:27:39,999 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:27:40,000 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:27:40,002 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:27:40,003 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:27:40,004 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:27:40,005 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:27:40,006 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:27:40,007 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:27:40,008 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:27:40,009 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:27:40,010 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:27:40,011 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:27:41,029 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:27:41,031 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:27:41,032 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:27:41,033 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:27:41,035 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:27:41,036 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:27:41,037 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:27:41,039 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:27:41,040 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:27:41,041 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:27:41,043 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:27:41,044 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:27:41,045 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:27:41,048 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:27:41,050 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:27:41,052 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:27:41,055 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:27:41,056 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:27:41,057 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:27:41,058 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:27:41,059 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:27:41,837 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:27:41,838 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:27:41,839 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:27:41,841 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:27:41,842 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:27:41,844 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:27:41,845 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:27:41,846 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:27:41,847 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:27:41,849 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:27:41,850 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:27:41,852 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:27:41,853 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:27:41,854 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:27:41,855 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:27:41,855 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:27:41,856 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:27:41,857 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:27:41,858 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:27:41,859 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:27:41,860 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:27:42,844 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:27:42,845 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:27:42,846 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:27:42,848 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:27:42,849 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:27:42,851 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:27:42,852 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:27:42,854 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:27:42,855 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:27:42,857 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:27:42,858 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:27:42,860 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:27:42,861 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:27:42,862 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:27:42,863 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:27:42,864 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:27:42,865 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:27:42,866 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:27:42,867 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:27:42,868 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:27:42,869 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:27:43,636 - train - INFO - latency_accumulation_b6:75.96500396728516
2024-08-28 21:27:43,639 - train - INFO - latency_accumulation_b7:75.96500396728516
2024-08-28 21:27:43,641 - train - INFO - latency_accumulation_b8:75.96500396728516
2024-08-28 21:27:43,644 - train - INFO - latency_accumulation_b9:125.25833892822266
2024-08-28 21:27:43,647 - train - INFO - latency_accumulation_b10:125.25833892822266
2024-08-28 21:27:43,650 - train - INFO - latency_accumulation_b11:125.25833892822266
2024-08-28 21:27:43,653 - train - INFO - latency_accumulation_b12:125.25833892822266
2024-08-28 21:27:43,657 - train - INFO - latency_accumulation_b13:125.25833892822266
2024-08-28 21:27:43,660 - train - INFO - latency_accumulation_b14:125.25834655761719
2024-08-28 21:27:43,663 - train - INFO - latency_accumulation_b15:125.25834655761719
2024-08-28 21:27:43,666 - train - INFO - latency_accumulation_b16:125.25834655761719
2024-08-28 21:27:43,669 - train - INFO - latency_accumulation_b17:125.25834655761719
2024-08-28 21:27:43,670 - train - INFO - latency_accumulation_b18:178.24000549316406
2024-08-28 21:27:43,672 - train - INFO - latency_accumulation_b19:178.24000549316406
2024-08-28 21:27:43,673 - train - INFO - latency_accumulation_b20:178.24000549316406
2024-08-28 21:27:43,674 - train - INFO - latency_accumulation_b21:178.24000549316406
2024-08-28 21:27:43,676 - train - INFO - latency_accumulation_b22:178.24000549316406
2024-08-28 21:27:43,677 - train - INFO - latency_accumulation_b23:178.24000549316406
2024-08-28 21:27:43,679 - train - INFO - latency_accumulation_b24:178.24000549316406
2024-08-28 21:27:43,680 - train - INFO - latency_accumulation_b25:178.24000549316406
2024-08-28 21:27:43,681 - train - INFO - latency_accumulation_b26:178.24000549316406
2024-08-28 21:27:44,499 - train - INFO - latency_accumulation_b6:55.96625518798828
2024-08-28 21:27:44,505 - train - INFO - latency_accumulation_b7:55.96625518798828
2024-08-28 21:27:44,510 - train - INFO - latency_accumulation_b8:55.96625900268555
2024-08-28 21:27:44,517 - train - INFO - latency_accumulation_b9:60.56000518798828
2024-08-28 21:27:44,524 - train - INFO - latency_accumulation_b10:60.56000518798828
2024-08-28 21:27:44,530 - train - INFO - latency_accumulation_b11:60.56000518798828
2024-08-28 21:27:44,536 - train - INFO - latency_accumulation_b12:60.56000900268555
2024-08-28 21:27:44,543 - train - INFO - latency_accumulation_b13:60.56000900268555
2024-08-28 21:27:44,549 - train - INFO - latency_accumulation_b14:60.56000900268555
2024-08-28 21:27:44,554 - train - INFO - latency_accumulation_b15:60.56000900268555
2024-08-28 21:27:44,560 - train - INFO - latency_accumulation_b16:60.56000900268555
2024-08-28 21:27:44,566 - train - INFO - latency_accumulation_b17:60.56000900268555
2024-08-28 21:27:44,570 - train - INFO - latency_accumulation_b18:139.65000915527344
2024-08-28 21:27:44,573 - train - INFO - latency_accumulation_b19:139.65000915527344
2024-08-28 21:27:44,577 - train - INFO - latency_accumulation_b20:139.65000915527344
2024-08-28 21:27:44,580 - train - INFO - latency_accumulation_b21:139.65000915527344
2024-08-28 21:27:44,584 - train - INFO - latency_accumulation_b22:139.65000915527344
2024-08-28 21:27:44,588 - train - INFO - latency_accumulation_b23:139.65000915527344
2024-08-28 21:27:44,591 - train - INFO - latency_accumulation_b24:139.65000915527344
2024-08-28 21:27:44,595 - train - INFO - latency_accumulation_b25:139.65000915527344
2024-08-28 21:27:44,598 - train - INFO - latency_accumulation_b26:139.65000915527344
2024-08-28 21:27:45,088 - train - INFO - latency_accumulation_b6:55.96625518798828
2024-08-28 21:27:45,092 - train - INFO - latency_accumulation_b7:55.96625518798828
2024-08-28 21:27:45,096 - train - INFO - latency_accumulation_b8:55.96625900268555
2024-08-28 21:27:45,100 - train - INFO - latency_accumulation_b9:60.56000518798828
2024-08-28 21:27:45,105 - train - INFO - latency_accumulation_b10:60.56000518798828
2024-08-28 21:27:45,110 - train - INFO - latency_accumulation_b11:60.56000518798828
2024-08-28 21:27:45,114 - train - INFO - latency_accumulation_b12:60.56000900268555
2024-08-28 21:27:45,119 - train - INFO - latency_accumulation_b13:60.56000900268555
2024-08-28 21:27:45,124 - train - INFO - latency_accumulation_b14:60.56000900268555
2024-08-28 21:27:45,129 - train - INFO - latency_accumulation_b15:60.56000900268555
2024-08-28 21:27:45,135 - train - INFO - latency_accumulation_b16:60.56000900268555
2024-08-28 21:27:45,140 - train - INFO - latency_accumulation_b17:60.56000900268555
2024-08-28 21:27:45,143 - train - INFO - latency_accumulation_b18:139.65000915527344
2024-08-28 21:27:45,147 - train - INFO - latency_accumulation_b19:139.65000915527344
2024-08-28 21:27:45,150 - train - INFO - latency_accumulation_b20:139.65000915527344
2024-08-28 21:27:45,154 - train - INFO - latency_accumulation_b21:139.65000915527344
2024-08-28 21:27:45,157 - train - INFO - latency_accumulation_b22:139.65000915527344
2024-08-28 21:27:45,160 - train - INFO - latency_accumulation_b23:139.65000915527344
2024-08-28 21:27:45,164 - train - INFO - latency_accumulation_b24:139.65000915527344
2024-08-28 21:27:45,167 - train - INFO - latency_accumulation_b25:139.65000915527344
2024-08-28 21:27:45,171 - train - INFO - latency_accumulation_b26:139.65000915527344
2024-08-28 21:27:45,781 - train - INFO - latency_accumulation_b6:55.96625518798828
2024-08-28 21:27:45,785 - train - INFO - latency_accumulation_b7:55.96625518798828
2024-08-28 21:27:45,789 - train - INFO - latency_accumulation_b8:55.96625900268555
2024-08-28 21:27:45,794 - train - INFO - latency_accumulation_b9:60.56000518798828
2024-08-28 21:27:45,799 - train - INFO - latency_accumulation_b10:60.56000518798828
2024-08-28 21:27:45,804 - train - INFO - latency_accumulation_b11:60.56000518798828
2024-08-28 21:27:45,808 - train - INFO - latency_accumulation_b12:60.56000900268555
2024-08-28 21:27:45,813 - train - INFO - latency_accumulation_b13:60.56000900268555
2024-08-28 21:27:45,818 - train - INFO - latency_accumulation_b14:60.56000900268555
2024-08-28 21:27:45,823 - train - INFO - latency_accumulation_b15:60.56000900268555
2024-08-28 21:27:45,828 - train - INFO - latency_accumulation_b16:60.56000900268555
2024-08-28 21:27:45,833 - train - INFO - latency_accumulation_b17:60.56000900268555
2024-08-28 21:27:45,836 - train - INFO - latency_accumulation_b18:139.65000915527344
2024-08-28 21:27:45,839 - train - INFO - latency_accumulation_b19:139.65000915527344
2024-08-28 21:27:45,842 - train - INFO - latency_accumulation_b20:139.65000915527344
2024-08-28 21:27:45,846 - train - INFO - latency_accumulation_b21:139.65000915527344
2024-08-28 21:27:45,849 - train - INFO - latency_accumulation_b22:139.65000915527344
2024-08-28 21:27:45,852 - train - INFO - latency_accumulation_b23:139.65000915527344
2024-08-28 21:27:45,856 - train - INFO - latency_accumulation_b24:139.65000915527344
2024-08-28 21:27:45,859 - train - INFO - latency_accumulation_b25:139.65000915527344
2024-08-28 21:27:45,863 - train - INFO - latency_accumulation_b26:139.65000915527344
2024-08-28 21:27:46,504 - train - INFO - latency_accumulation_b6:82.65250396728516
2024-08-28 21:27:46,511 - train - INFO - latency_accumulation_b7:82.65250396728516
2024-08-28 21:27:46,518 - train - INFO - latency_accumulation_b8:82.65251159667969
2024-08-28 21:27:46,527 - train - INFO - latency_accumulation_b9:139.65000915527344
2024-08-28 21:27:46,536 - train - INFO - latency_accumulation_b10:139.65000915527344
2024-08-28 21:27:46,545 - train - INFO - latency_accumulation_b11:139.65000915527344
2024-08-28 21:27:46,553 - train - INFO - latency_accumulation_b12:139.65000915527344
2024-08-28 21:27:46,561 - train - INFO - latency_accumulation_b13:139.65000915527344
2024-08-28 21:27:46,570 - train - INFO - latency_accumulation_b14:139.65000915527344
2024-08-28 21:27:46,578 - train - INFO - latency_accumulation_b15:139.65000915527344
2024-08-28 21:27:46,587 - train - INFO - latency_accumulation_b16:139.65000915527344
2024-08-28 21:27:46,595 - train - INFO - latency_accumulation_b17:139.65000915527344
2024-08-28 21:27:46,599 - train - INFO - latency_accumulation_b18:190.24000549316406
2024-08-28 21:27:46,603 - train - INFO - latency_accumulation_b19:190.24000549316406
2024-08-28 21:27:46,606 - train - INFO - latency_accumulation_b20:190.24000549316406
2024-08-28 21:27:46,610 - train - INFO - latency_accumulation_b21:190.24000549316406
2024-08-28 21:27:46,613 - train - INFO - latency_accumulation_b22:190.24002075195312
2024-08-28 21:27:46,617 - train - INFO - latency_accumulation_b23:190.24002075195312
2024-08-28 21:27:46,621 - train - INFO - latency_accumulation_b24:190.24002075195312
2024-08-28 21:27:46,624 - train - INFO - latency_accumulation_b25:190.24002075195312
2024-08-28 21:27:46,628 - train - INFO - latency_accumulation_b26:190.24002075195312
2024-08-28 21:27:47,287 - train - INFO - latency_accumulation_b6:64.56001281738281
2024-08-28 21:27:47,314 - train - INFO - latency_accumulation_b7:64.56002044677734
2024-08-28 21:27:47,339 - train - INFO - latency_accumulation_b8:64.56002044677734
2024-08-28 21:27:47,369 - train - INFO - latency_accumulation_b9:63.56001281738281
2024-08-28 21:27:47,399 - train - INFO - latency_accumulation_b10:63.56001281738281
2024-08-28 21:27:47,430 - train - INFO - latency_accumulation_b11:63.56001281738281
2024-08-28 21:27:47,460 - train - INFO - latency_accumulation_b12:63.56001281738281
2024-08-28 21:27:47,490 - train - INFO - latency_accumulation_b13:63.56001663208008
2024-08-28 21:27:47,521 - train - INFO - latency_accumulation_b14:63.56001663208008
2024-08-28 21:27:47,551 - train - INFO - latency_accumulation_b15:63.56001663208008
2024-08-28 21:27:47,581 - train - INFO - latency_accumulation_b16:63.56001663208008
2024-08-28 21:27:47,612 - train - INFO - latency_accumulation_b17:63.560020446777344
2024-08-28 21:27:47,632 - train - INFO - latency_accumulation_b18:189.32907104492188
2024-08-28 21:27:47,655 - train - INFO - latency_accumulation_b19:189.32907104492188
2024-08-28 21:27:47,675 - train - INFO - latency_accumulation_b20:189.32907104492188
2024-08-28 21:27:47,695 - train - INFO - latency_accumulation_b21:189.32907104492188
2024-08-28 21:27:47,715 - train - INFO - latency_accumulation_b22:189.32907104492188
2024-08-28 21:27:47,735 - train - INFO - latency_accumulation_b23:189.32907104492188
2024-08-28 21:27:47,755 - train - INFO - latency_accumulation_b24:189.32907104492188
2024-08-28 21:27:47,775 - train - INFO - latency_accumulation_b25:189.32908630371094
2024-08-28 21:27:47,795 - train - INFO - latency_accumulation_b26:189.32908630371094
2024-08-28 21:27:48,343 - train - INFO - latency_accumulation_b6:64.56001281738281
2024-08-28 21:27:48,360 - train - INFO - latency_accumulation_b7:64.56002044677734
2024-08-28 21:27:48,376 - train - INFO - latency_accumulation_b8:64.56002044677734
2024-08-28 21:27:48,397 - train - INFO - latency_accumulation_b9:63.56001281738281
2024-08-28 21:27:48,417 - train - INFO - latency_accumulation_b10:63.56001281738281
2024-08-28 21:27:48,437 - train - INFO - latency_accumulation_b11:63.56001281738281
2024-08-28 21:27:48,458 - train - INFO - latency_accumulation_b12:63.56001281738281
2024-08-28 21:27:48,480 - train - INFO - latency_accumulation_b13:63.56001663208008
2024-08-28 21:27:48,501 - train - INFO - latency_accumulation_b14:63.56001663208008
2024-08-28 21:27:48,521 - train - INFO - latency_accumulation_b15:63.56001663208008
2024-08-28 21:27:48,541 - train - INFO - latency_accumulation_b16:63.56001663208008
2024-08-28 21:27:48,561 - train - INFO - latency_accumulation_b17:63.560020446777344
2024-08-28 21:27:48,575 - train - INFO - latency_accumulation_b18:189.32907104492188
2024-08-28 21:27:48,588 - train - INFO - latency_accumulation_b19:189.32907104492188
2024-08-28 21:27:48,602 - train - INFO - latency_accumulation_b20:189.32907104492188
2024-08-28 21:27:48,615 - train - INFO - latency_accumulation_b21:189.32907104492188
2024-08-28 21:27:48,629 - train - INFO - latency_accumulation_b22:189.32907104492188
2024-08-28 21:27:48,643 - train - INFO - latency_accumulation_b23:189.32907104492188
2024-08-28 21:27:48,656 - train - INFO - latency_accumulation_b24:189.32907104492188
2024-08-28 21:27:48,669 - train - INFO - latency_accumulation_b25:189.32908630371094
2024-08-28 21:27:48,683 - train - INFO - latency_accumulation_b26:189.32908630371094
2024-08-28 21:27:49,032 - train - INFO - latency_accumulation_b6:64.56001281738281
2024-08-28 21:27:49,047 - train - INFO - latency_accumulation_b7:64.56002044677734
2024-08-28 21:27:49,063 - train - INFO - latency_accumulation_b8:64.56002044677734
2024-08-28 21:27:49,083 - train - INFO - latency_accumulation_b9:63.56001281738281
2024-08-28 21:27:49,103 - train - INFO - latency_accumulation_b10:63.56001281738281
2024-08-28 21:27:49,123 - train - INFO - latency_accumulation_b11:63.56001281738281
2024-08-28 21:27:49,144 - train - INFO - latency_accumulation_b12:63.56001281738281
2024-08-28 21:27:49,167 - train - INFO - latency_accumulation_b13:63.56001663208008
2024-08-28 21:27:49,188 - train - INFO - latency_accumulation_b14:63.56001663208008
2024-08-28 21:27:49,208 - train - INFO - latency_accumulation_b15:63.56001663208008
2024-08-28 21:27:49,229 - train - INFO - latency_accumulation_b16:63.56001663208008
2024-08-28 21:27:49,250 - train - INFO - latency_accumulation_b17:63.560020446777344
2024-08-28 21:27:49,264 - train - INFO - latency_accumulation_b18:189.32907104492188
2024-08-28 21:27:49,279 - train - INFO - latency_accumulation_b19:189.32907104492188
2024-08-28 21:27:49,294 - train - INFO - latency_accumulation_b20:189.32907104492188
2024-08-28 21:27:49,308 - train - INFO - latency_accumulation_b21:189.32907104492188
2024-08-28 21:27:49,321 - train - INFO - latency_accumulation_b22:189.32907104492188
2024-08-28 21:27:49,335 - train - INFO - latency_accumulation_b23:189.32907104492188
2024-08-28 21:27:49,348 - train - INFO - latency_accumulation_b24:189.32907104492188
2024-08-28 21:27:49,362 - train - INFO - latency_accumulation_b25:189.32908630371094
2024-08-28 21:27:49,375 - train - INFO - latency_accumulation_b26:189.32908630371094
2024-08-28 21:27:49,884 - train - INFO - latency_accumulation_b6:117.61351776123047
2024-08-28 21:27:49,907 - train - INFO - latency_accumulation_b7:117.61351776123047
2024-08-28 21:27:49,929 - train - INFO - latency_accumulation_b8:117.613525390625
2024-08-28 21:27:49,965 - train - INFO - latency_accumulation_b9:189.32907104492188
2024-08-28 21:27:49,995 - train - INFO - latency_accumulation_b10:189.32907104492188
2024-08-28 21:27:50,025 - train - INFO - latency_accumulation_b11:189.32907104492188
2024-08-28 21:27:50,087 - train - INFO - latency_accumulation_b12:189.32907104492188
2024-08-28 21:27:50,145 - train - INFO - latency_accumulation_b13:189.32908630371094
2024-08-28 21:27:50,190 - train - INFO - latency_accumulation_b14:189.32908630371094
2024-08-28 21:27:50,253 - train - INFO - latency_accumulation_b15:189.32908630371094
2024-08-28 21:27:50,307 - train - INFO - latency_accumulation_b16:189.32908630371094
2024-08-28 21:27:50,352 - train - INFO - latency_accumulation_b17:189.32908630371094
2024-08-28 21:27:50,372 - train - INFO - latency_accumulation_b18:196.24002075195312
2024-08-28 21:27:50,392 - train - INFO - latency_accumulation_b19:196.24002075195312
2024-08-28 21:27:50,412 - train - INFO - latency_accumulation_b20:196.24002075195312
2024-08-28 21:27:50,432 - train - INFO - latency_accumulation_b21:196.24002075195312
2024-08-28 21:27:50,452 - train - INFO - latency_accumulation_b22:196.24002075195312
2024-08-28 21:27:50,472 - train - INFO - latency_accumulation_b23:196.24002075195312
2024-08-28 21:27:50,492 - train - INFO - latency_accumulation_b24:196.2400360107422
2024-08-28 21:27:50,515 - train - INFO - latency_accumulation_b25:196.2400360107422
2024-08-28 21:27:50,535 - train - INFO - latency_accumulation_b26:196.2400360107422
2024-08-28 21:27:51,178 - train - INFO - latency_accumulation_b6:111.2082748413086
2024-08-28 21:27:51,314 - train - INFO - latency_accumulation_b7:111.20828247070312
2024-08-28 21:27:51,420 - train - INFO - latency_accumulation_b8:111.20829010009766
2024-08-28 21:27:51,547 - train - INFO - latency_accumulation_b9:114.12004852294922
2024-08-28 21:27:51,670 - train - INFO - latency_accumulation_b10:114.12004852294922
2024-08-28 21:27:51,793 - train - INFO - latency_accumulation_b11:114.12005615234375
2024-08-28 21:27:51,918 - train - INFO - latency_accumulation_b12:114.12005615234375
2024-08-28 21:27:52,028 - train - INFO - latency_accumulation_b13:114.12006378173828
2024-08-28 21:27:52,114 - train - INFO - latency_accumulation_b14:114.12006378173828
2024-08-28 21:27:52,192 - train - INFO - latency_accumulation_b15:114.12007141113281
2024-08-28 21:27:52,268 - train - INFO - latency_accumulation_b16:114.12007141113281
2024-08-28 21:27:52,343 - train - INFO - latency_accumulation_b17:114.12007904052734
2024-08-28 21:27:52,395 - train - INFO - latency_accumulation_b18:316.74993896484375
2024-08-28 21:27:52,449 - train - INFO - latency_accumulation_b19:316.74993896484375
2024-08-28 21:27:52,507 - train - INFO - latency_accumulation_b20:316.74993896484375
2024-08-28 21:27:52,561 - train - INFO - latency_accumulation_b21:316.74993896484375
2024-08-28 21:27:52,613 - train - INFO - latency_accumulation_b22:316.74993896484375
2024-08-28 21:27:52,665 - train - INFO - latency_accumulation_b23:316.7499694824219
2024-08-28 21:27:52,725 - train - INFO - latency_accumulation_b24:316.7499694824219
2024-08-28 21:27:52,778 - train - INFO - latency_accumulation_b25:316.7499694824219
2024-08-28 21:27:52,829 - train - INFO - latency_accumulation_b26:316.7499694824219
2024-08-28 21:27:53,244 - train - INFO - latency_accumulation_b6:111.2082748413086
2024-08-28 21:27:53,307 - train - INFO - latency_accumulation_b7:111.20828247070312
2024-08-28 21:27:53,373 - train - INFO - latency_accumulation_b8:111.20829010009766
2024-08-28 21:27:53,450 - train - INFO - latency_accumulation_b9:114.12004852294922
2024-08-28 21:27:53,533 - train - INFO - latency_accumulation_b10:114.12004852294922
2024-08-28 21:27:53,611 - train - INFO - latency_accumulation_b11:114.12005615234375
2024-08-28 21:27:53,689 - train - INFO - latency_accumulation_b12:114.12005615234375
2024-08-28 21:27:53,773 - train - INFO - latency_accumulation_b13:114.12006378173828
2024-08-28 21:27:53,852 - train - INFO - latency_accumulation_b14:114.12006378173828
2024-08-28 21:27:53,928 - train - INFO - latency_accumulation_b15:114.12007141113281
2024-08-28 21:27:54,002 - train - INFO - latency_accumulation_b16:114.12007141113281
2024-08-28 21:27:54,077 - train - INFO - latency_accumulation_b17:114.12007904052734
2024-08-28 21:27:54,130 - train - INFO - latency_accumulation_b18:316.74993896484375
2024-08-28 21:27:54,185 - train - INFO - latency_accumulation_b19:316.74993896484375
2024-08-28 21:27:54,242 - train - INFO - latency_accumulation_b20:316.74993896484375
2024-08-28 21:27:54,300 - train - INFO - latency_accumulation_b21:316.74993896484375
2024-08-28 21:27:54,358 - train - INFO - latency_accumulation_b22:316.74993896484375
2024-08-28 21:27:54,416 - train - INFO - latency_accumulation_b23:316.7499694824219
2024-08-28 21:27:54,472 - train - INFO - latency_accumulation_b24:316.7499694824219
2024-08-28 21:27:54,528 - train - INFO - latency_accumulation_b25:316.7499694824219
2024-08-28 21:27:54,580 - train - INFO - latency_accumulation_b26:316.7499694824219
2024-08-28 21:27:55,078 - train - INFO - latency_accumulation_b6:111.2082748413086
2024-08-28 21:27:55,150 - train - INFO - latency_accumulation_b7:111.20828247070312
2024-08-28 21:27:55,215 - train - INFO - latency_accumulation_b8:111.20829010009766
2024-08-28 21:27:55,291 - train - INFO - latency_accumulation_b9:114.12004852294922
2024-08-28 21:27:55,365 - train - INFO - latency_accumulation_b10:114.12004852294922
2024-08-28 21:27:55,440 - train - INFO - latency_accumulation_b11:114.12005615234375
2024-08-28 21:27:55,519 - train - INFO - latency_accumulation_b12:114.12005615234375
2024-08-28 21:27:55,603 - train - INFO - latency_accumulation_b13:114.12006378173828
2024-08-28 21:27:55,688 - train - INFO - latency_accumulation_b14:114.12006378173828
2024-08-28 21:27:55,769 - train - INFO - latency_accumulation_b15:114.12007141113281
2024-08-28 21:27:55,843 - train - INFO - latency_accumulation_b16:114.12007141113281
2024-08-28 21:27:55,919 - train - INFO - latency_accumulation_b17:114.12007904052734
2024-08-28 21:27:55,972 - train - INFO - latency_accumulation_b18:316.74993896484375
2024-08-28 21:27:56,029 - train - INFO - latency_accumulation_b19:316.74993896484375
2024-08-28 21:27:56,087 - train - INFO - latency_accumulation_b20:316.74993896484375
2024-08-28 21:27:56,144 - train - INFO - latency_accumulation_b21:316.74993896484375
2024-08-28 21:27:56,204 - train - INFO - latency_accumulation_b22:316.74993896484375
2024-08-28 21:27:56,255 - train - INFO - latency_accumulation_b23:316.7499694824219
2024-08-28 21:27:56,310 - train - INFO - latency_accumulation_b24:316.7499694824219
2024-08-28 21:27:56,363 - train - INFO - latency_accumulation_b25:316.7499694824219
2024-08-28 21:27:56,418 - train - INFO - latency_accumulation_b26:316.7499694824219
2024-08-28 21:27:56,418 - train - INFO - origin_latency:2379.3054542541504
2024-08-28 21:27:56,418 - train - INFO - cir_idx:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
2024-08-28 21:27:57,342 - train - INFO - bw_result:[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]
2024-08-28 21:27:57,343 - train - INFO - ba_result:[6 6 6 5 6 4 6 4 6 3 6 3 6 6 6 2]
2024-08-28 21:27:57,343 - train - INFO - acc_result:[18, 18, 18, 17, 18, 17, 19, 17, 19, 17, 20, 17, 20, 21, 21, 17]
2024-08-28 21:28:23,239 - train - INFO - Model ResNet18 created, param count:11220132
2024-08-28 21:28:23,239 - train - INFO - Get QAT model...
2024-08-28 21:28:24,063 - train - INFO - ResNet(
  (relu): ReLU(
    (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
  )
  (conv1): QConv2d(
    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
    (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
    (quan_a_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False)
  )
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False)
      )
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False)
      )
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
  )
  (fc): QLinear(
    in_features=512, out_features=100, bias=True
    (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
    (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
  )
)
2024-08-28 21:28:24,105 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-08-28 21:28:24,105 - train - INFO - Scheduled epochs: 310
2024-08-28 21:28:27,014 - train - INFO - Test: [   0/9]  Time: 1.454 (1.454)  Loss:  1.0938 (1.0938)  Acc@1: 78.9062 (78.9062)  Acc@5: 93.8477 (93.8477)
2024-08-28 21:28:28,845 - train - INFO - Test: [   9/9]  Time: 0.559 (0.328)  Loss:  1.0303 (1.0583)  Acc@1: 80.3571 (78.7200)  Acc@5: 93.8775 (94.4000)
2024-08-28 21:28:28,846 - train - INFO - Verifying teacher model
2024-08-28 21:28:29,186 - train - INFO - Test: [   0/9]  Time: 0.338 (0.338)  Loss:  1.0938 (1.0938)  Acc@1: 78.8086 (78.8086)  Acc@5: 93.8477 (93.8477)
2024-08-28 21:28:29,513 - train - INFO - Test: [   9/9]  Time: 0.023 (0.067)  Loss:  1.0303 (1.0582)  Acc@1: 80.3571 (78.7100)  Acc@5: 93.8775 (94.3900)
2024-08-28 21:28:29,513 - train - INFO - Verifying initial model in training dataset
2024-08-28 21:28:32,427 - train - INFO - len loader.dataset:50000
2024-08-28 21:28:33,125 - train - INFO - target_block_size:3
2024-08-28 21:28:33,756 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:28:33,758 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:28:33,760 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:28:33,763 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:28:33,765 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:28:33,767 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:28:33,769 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:28:33,772 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:28:33,774 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:28:33,776 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:28:33,779 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:28:33,781 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:28:33,782 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:28:33,784 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:28:33,785 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:28:33,787 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:28:33,788 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:28:33,790 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:28:33,791 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:28:33,793 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:28:33,794 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:28:34,265 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:28:34,267 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:28:34,269 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:28:34,271 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:28:34,274 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:28:34,276 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:28:34,278 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:28:34,281 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:28:34,283 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:28:34,285 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:28:34,288 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:28:34,290 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:28:34,291 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:28:34,293 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:28:34,295 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:28:34,296 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:28:34,298 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:28:34,299 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:28:34,301 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:28:34,302 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:28:34,304 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:28:34,755 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:28:34,756 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:28:34,757 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:28:34,759 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:28:34,761 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:28:34,762 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:28:34,764 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:28:34,765 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:28:34,767 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:28:34,768 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:28:34,770 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:28:34,771 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:28:34,772 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:28:34,773 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:28:34,774 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:28:34,775 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:28:34,776 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:28:34,777 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:28:34,778 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:28:34,779 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:28:34,780 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:28:35,224 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:28:35,226 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:28:35,227 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:28:35,228 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:28:35,230 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:28:35,231 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:28:35,233 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:28:35,234 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:28:35,236 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:28:35,237 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:28:35,239 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:28:35,240 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:28:35,241 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:28:35,242 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:28:35,243 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:28:35,244 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:28:35,245 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:28:35,246 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:28:35,247 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:28:35,248 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:28:35,249 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:28:35,707 - train - INFO - latency_accumulation_b6:75.96500396728516
2024-08-28 21:28:35,709 - train - INFO - latency_accumulation_b7:75.96500396728516
2024-08-28 21:28:35,712 - train - INFO - latency_accumulation_b8:75.96500396728516
2024-08-28 21:28:35,715 - train - INFO - latency_accumulation_b9:125.25833892822266
2024-08-28 21:28:35,718 - train - INFO - latency_accumulation_b10:125.25833892822266
2024-08-28 21:28:35,721 - train - INFO - latency_accumulation_b11:125.25833892822266
2024-08-28 21:28:35,725 - train - INFO - latency_accumulation_b12:125.25833892822266
2024-08-28 21:28:35,728 - train - INFO - latency_accumulation_b13:125.25833892822266
2024-08-28 21:28:35,731 - train - INFO - latency_accumulation_b14:125.25834655761719
2024-08-28 21:28:35,735 - train - INFO - latency_accumulation_b15:125.25834655761719
2024-08-28 21:28:35,738 - train - INFO - latency_accumulation_b16:125.25834655761719
2024-08-28 21:28:35,741 - train - INFO - latency_accumulation_b17:125.25834655761719
2024-08-28 21:28:35,743 - train - INFO - latency_accumulation_b18:178.24000549316406
2024-08-28 21:28:35,744 - train - INFO - latency_accumulation_b19:178.24000549316406
2024-08-28 21:28:35,746 - train - INFO - latency_accumulation_b20:178.24000549316406
2024-08-28 21:28:35,747 - train - INFO - latency_accumulation_b21:178.24000549316406
2024-08-28 21:28:35,749 - train - INFO - latency_accumulation_b22:178.24000549316406
2024-08-28 21:28:35,750 - train - INFO - latency_accumulation_b23:178.24000549316406
2024-08-28 21:28:35,752 - train - INFO - latency_accumulation_b24:178.24000549316406
2024-08-28 21:28:35,753 - train - INFO - latency_accumulation_b25:178.24000549316406
2024-08-28 21:28:35,755 - train - INFO - latency_accumulation_b26:178.24000549316406
2024-08-28 21:28:36,162 - train - INFO - latency_accumulation_b6:55.96625518798828
2024-08-28 21:28:36,169 - train - INFO - latency_accumulation_b7:55.96625518798828
2024-08-28 21:28:36,175 - train - INFO - latency_accumulation_b8:55.96625900268555
2024-08-28 21:28:36,184 - train - INFO - latency_accumulation_b9:60.56000518798828
2024-08-28 21:28:36,192 - train - INFO - latency_accumulation_b10:60.56000518798828
2024-08-28 21:28:36,201 - train - INFO - latency_accumulation_b11:60.56000518798828
2024-08-28 21:28:36,209 - train - INFO - latency_accumulation_b12:60.56000900268555
2024-08-28 21:28:36,217 - train - INFO - latency_accumulation_b13:60.56000900268555
2024-08-28 21:28:36,226 - train - INFO - latency_accumulation_b14:60.56000900268555
2024-08-28 21:28:36,234 - train - INFO - latency_accumulation_b15:60.56000900268555
2024-08-28 21:28:36,242 - train - INFO - latency_accumulation_b16:60.56000900268555
2024-08-28 21:28:36,251 - train - INFO - latency_accumulation_b17:60.56000900268555
2024-08-28 21:28:36,256 - train - INFO - latency_accumulation_b18:139.65000915527344
2024-08-28 21:28:36,262 - train - INFO - latency_accumulation_b19:139.65000915527344
2024-08-28 21:28:36,267 - train - INFO - latency_accumulation_b20:139.65000915527344
2024-08-28 21:28:36,273 - train - INFO - latency_accumulation_b21:139.65000915527344
2024-08-28 21:28:36,278 - train - INFO - latency_accumulation_b22:139.65000915527344
2024-08-28 21:28:36,284 - train - INFO - latency_accumulation_b23:139.65000915527344
2024-08-28 21:28:36,289 - train - INFO - latency_accumulation_b24:139.65000915527344
2024-08-28 21:28:36,296 - train - INFO - latency_accumulation_b25:139.65000915527344
2024-08-28 21:28:36,301 - train - INFO - latency_accumulation_b26:139.65000915527344
2024-08-28 21:28:36,572 - train - INFO - latency_accumulation_b6:55.96625518798828
2024-08-28 21:28:36,579 - train - INFO - latency_accumulation_b7:55.96625518798828
2024-08-28 21:28:36,586 - train - INFO - latency_accumulation_b8:55.96625900268555
2024-08-28 21:28:36,594 - train - INFO - latency_accumulation_b9:60.56000518798828
2024-08-28 21:28:36,602 - train - INFO - latency_accumulation_b10:60.56000518798828
2024-08-28 21:28:36,611 - train - INFO - latency_accumulation_b11:60.56000518798828
2024-08-28 21:28:36,619 - train - INFO - latency_accumulation_b12:60.56000900268555
2024-08-28 21:28:36,628 - train - INFO - latency_accumulation_b13:60.56000900268555
2024-08-28 21:28:36,636 - train - INFO - latency_accumulation_b14:60.56000900268555
2024-08-28 21:28:36,644 - train - INFO - latency_accumulation_b15:60.56000900268555
2024-08-28 21:28:36,653 - train - INFO - latency_accumulation_b16:60.56000900268555
2024-08-28 21:28:36,661 - train - INFO - latency_accumulation_b17:60.56000900268555
2024-08-28 21:28:36,666 - train - INFO - latency_accumulation_b18:139.65000915527344
2024-08-28 21:28:36,672 - train - INFO - latency_accumulation_b19:139.65000915527344
2024-08-28 21:28:36,677 - train - INFO - latency_accumulation_b20:139.65000915527344
2024-08-28 21:28:36,683 - train - INFO - latency_accumulation_b21:139.65000915527344
2024-08-28 21:28:36,688 - train - INFO - latency_accumulation_b22:139.65000915527344
2024-08-28 21:28:36,694 - train - INFO - latency_accumulation_b23:139.65000915527344
2024-08-28 21:28:36,699 - train - INFO - latency_accumulation_b24:139.65000915527344
2024-08-28 21:28:36,705 - train - INFO - latency_accumulation_b25:139.65000915527344
2024-08-28 21:28:36,710 - train - INFO - latency_accumulation_b26:139.65000915527344
2024-08-28 21:28:36,973 - train - INFO - latency_accumulation_b6:55.96625518798828
2024-08-28 21:28:36,978 - train - INFO - latency_accumulation_b7:55.96625518798828
2024-08-28 21:28:36,983 - train - INFO - latency_accumulation_b8:55.96625900268555
2024-08-28 21:28:36,988 - train - INFO - latency_accumulation_b9:60.56000518798828
2024-08-28 21:28:36,993 - train - INFO - latency_accumulation_b10:60.56000518798828
2024-08-28 21:28:36,998 - train - INFO - latency_accumulation_b11:60.56000518798828
2024-08-28 21:28:37,003 - train - INFO - latency_accumulation_b12:60.56000900268555
2024-08-28 21:28:37,008 - train - INFO - latency_accumulation_b13:60.56000900268555
2024-08-28 21:28:37,013 - train - INFO - latency_accumulation_b14:60.56000900268555
2024-08-28 21:28:37,018 - train - INFO - latency_accumulation_b15:60.56000900268555
2024-08-28 21:28:37,024 - train - INFO - latency_accumulation_b16:60.56000900268555
2024-08-28 21:28:37,029 - train - INFO - latency_accumulation_b17:60.56000900268555
2024-08-28 21:28:37,032 - train - INFO - latency_accumulation_b18:139.65000915527344
2024-08-28 21:28:37,035 - train - INFO - latency_accumulation_b19:139.65000915527344
2024-08-28 21:28:37,039 - train - INFO - latency_accumulation_b20:139.65000915527344
2024-08-28 21:28:37,042 - train - INFO - latency_accumulation_b21:139.65000915527344
2024-08-28 21:28:37,045 - train - INFO - latency_accumulation_b22:139.65000915527344
2024-08-28 21:28:37,049 - train - INFO - latency_accumulation_b23:139.65000915527344
2024-08-28 21:28:37,052 - train - INFO - latency_accumulation_b24:139.65000915527344
2024-08-28 21:28:37,055 - train - INFO - latency_accumulation_b25:139.65000915527344
2024-08-28 21:28:37,058 - train - INFO - latency_accumulation_b26:139.65000915527344
2024-08-28 21:28:37,342 - train - INFO - latency_accumulation_b6:82.65250396728516
2024-08-28 21:28:37,347 - train - INFO - latency_accumulation_b7:82.65250396728516
2024-08-28 21:28:37,353 - train - INFO - latency_accumulation_b8:82.65251159667969
2024-08-28 21:28:37,361 - train - INFO - latency_accumulation_b9:139.65000915527344
2024-08-28 21:28:37,370 - train - INFO - latency_accumulation_b10:139.65000915527344
2024-08-28 21:28:37,378 - train - INFO - latency_accumulation_b11:139.65000915527344
2024-08-28 21:28:37,386 - train - INFO - latency_accumulation_b12:139.65000915527344
2024-08-28 21:28:37,395 - train - INFO - latency_accumulation_b13:139.65000915527344
2024-08-28 21:28:37,403 - train - INFO - latency_accumulation_b14:139.65000915527344
2024-08-28 21:28:37,411 - train - INFO - latency_accumulation_b15:139.65000915527344
2024-08-28 21:28:37,420 - train - INFO - latency_accumulation_b16:139.65000915527344
2024-08-28 21:28:37,428 - train - INFO - latency_accumulation_b17:139.65000915527344
2024-08-28 21:28:37,431 - train - INFO - latency_accumulation_b18:190.24000549316406
2024-08-28 21:28:37,435 - train - INFO - latency_accumulation_b19:190.24000549316406
2024-08-28 21:28:37,439 - train - INFO - latency_accumulation_b20:190.24000549316406
2024-08-28 21:28:37,442 - train - INFO - latency_accumulation_b21:190.24000549316406
2024-08-28 21:28:37,446 - train - INFO - latency_accumulation_b22:190.24002075195312
2024-08-28 21:28:37,450 - train - INFO - latency_accumulation_b23:190.24002075195312
2024-08-28 21:28:37,453 - train - INFO - latency_accumulation_b24:190.24002075195312
2024-08-28 21:28:37,457 - train - INFO - latency_accumulation_b25:190.24002075195312
2024-08-28 21:28:37,461 - train - INFO - latency_accumulation_b26:190.24002075195312
2024-08-28 21:28:37,729 - train - INFO - latency_accumulation_b6:64.56001281738281
2024-08-28 21:28:37,745 - train - INFO - latency_accumulation_b7:64.56002044677734
2024-08-28 21:28:37,762 - train - INFO - latency_accumulation_b8:64.56002044677734
2024-08-28 21:28:37,784 - train - INFO - latency_accumulation_b9:63.56001281738281
2024-08-28 21:28:37,804 - train - INFO - latency_accumulation_b10:63.56001281738281
2024-08-28 21:28:37,823 - train - INFO - latency_accumulation_b11:63.56001281738281
2024-08-28 21:28:37,843 - train - INFO - latency_accumulation_b12:63.56001281738281
2024-08-28 21:28:37,862 - train - INFO - latency_accumulation_b13:63.56001663208008
2024-08-28 21:28:37,882 - train - INFO - latency_accumulation_b14:63.56001663208008
2024-08-28 21:28:37,902 - train - INFO - latency_accumulation_b15:63.56001663208008
2024-08-28 21:28:37,921 - train - INFO - latency_accumulation_b16:63.56001663208008
2024-08-28 21:28:37,940 - train - INFO - latency_accumulation_b17:63.560020446777344
2024-08-28 21:28:37,953 - train - INFO - latency_accumulation_b18:189.32907104492188
2024-08-28 21:28:37,966 - train - INFO - latency_accumulation_b19:189.32907104492188
2024-08-28 21:28:37,979 - train - INFO - latency_accumulation_b20:189.32907104492188
2024-08-28 21:28:37,992 - train - INFO - latency_accumulation_b21:189.32907104492188
2024-08-28 21:28:38,005 - train - INFO - latency_accumulation_b22:189.32907104492188
2024-08-28 21:28:38,017 - train - INFO - latency_accumulation_b23:189.32907104492188
2024-08-28 21:28:38,031 - train - INFO - latency_accumulation_b24:189.32907104492188
2024-08-28 21:28:38,045 - train - INFO - latency_accumulation_b25:189.32908630371094
2024-08-28 21:28:38,058 - train - INFO - latency_accumulation_b26:189.32908630371094
2024-08-28 21:28:38,254 - train - INFO - latency_accumulation_b6:64.56001281738281
2024-08-28 21:28:38,270 - train - INFO - latency_accumulation_b7:64.56002044677734
2024-08-28 21:28:38,286 - train - INFO - latency_accumulation_b8:64.56002044677734
2024-08-28 21:28:38,305 - train - INFO - latency_accumulation_b9:63.56001281738281
2024-08-28 21:28:38,324 - train - INFO - latency_accumulation_b10:63.56001281738281
2024-08-28 21:28:38,344 - train - INFO - latency_accumulation_b11:63.56001281738281
2024-08-28 21:28:38,363 - train - INFO - latency_accumulation_b12:63.56001281738281
2024-08-28 21:28:38,382 - train - INFO - latency_accumulation_b13:63.56001663208008
2024-08-28 21:28:38,404 - train - INFO - latency_accumulation_b14:63.56001663208008
2024-08-28 21:28:38,423 - train - INFO - latency_accumulation_b15:63.56001663208008
2024-08-28 21:28:38,443 - train - INFO - latency_accumulation_b16:63.56001663208008
2024-08-28 21:28:38,462 - train - INFO - latency_accumulation_b17:63.560020446777344
2024-08-28 21:28:38,475 - train - INFO - latency_accumulation_b18:189.32907104492188
2024-08-28 21:28:38,488 - train - INFO - latency_accumulation_b19:189.32907104492188
2024-08-28 21:28:38,501 - train - INFO - latency_accumulation_b20:189.32907104492188
2024-08-28 21:28:38,513 - train - INFO - latency_accumulation_b21:189.32907104492188
2024-08-28 21:28:38,526 - train - INFO - latency_accumulation_b22:189.32907104492188
2024-08-28 21:28:38,539 - train - INFO - latency_accumulation_b23:189.32907104492188
2024-08-28 21:28:38,552 - train - INFO - latency_accumulation_b24:189.32907104492188
2024-08-28 21:28:38,565 - train - INFO - latency_accumulation_b25:189.32908630371094
2024-08-28 21:28:38,577 - train - INFO - latency_accumulation_b26:189.32908630371094
2024-08-28 21:28:38,773 - train - INFO - latency_accumulation_b6:64.56001281738281
2024-08-28 21:28:38,789 - train - INFO - latency_accumulation_b7:64.56002044677734
2024-08-28 21:28:38,805 - train - INFO - latency_accumulation_b8:64.56002044677734
2024-08-28 21:28:38,824 - train - INFO - latency_accumulation_b9:63.56001281738281
2024-08-28 21:28:38,844 - train - INFO - latency_accumulation_b10:63.56001281738281
2024-08-28 21:28:38,864 - train - INFO - latency_accumulation_b11:63.56001281738281
2024-08-28 21:28:38,884 - train - INFO - latency_accumulation_b12:63.56001281738281
2024-08-28 21:28:38,903 - train - INFO - latency_accumulation_b13:63.56001663208008
2024-08-28 21:28:38,923 - train - INFO - latency_accumulation_b14:63.56001663208008
2024-08-28 21:28:38,942 - train - INFO - latency_accumulation_b15:63.56001663208008
2024-08-28 21:28:38,961 - train - INFO - latency_accumulation_b16:63.56001663208008
2024-08-28 21:28:38,981 - train - INFO - latency_accumulation_b17:63.560020446777344
2024-08-28 21:28:38,993 - train - INFO - latency_accumulation_b18:189.32907104492188
2024-08-28 21:28:39,006 - train - INFO - latency_accumulation_b19:189.32907104492188
2024-08-28 21:28:39,019 - train - INFO - latency_accumulation_b20:189.32907104492188
2024-08-28 21:28:39,032 - train - INFO - latency_accumulation_b21:189.32907104492188
2024-08-28 21:28:39,047 - train - INFO - latency_accumulation_b22:189.32907104492188
2024-08-28 21:28:39,060 - train - INFO - latency_accumulation_b23:189.32907104492188
2024-08-28 21:28:39,073 - train - INFO - latency_accumulation_b24:189.32907104492188
2024-08-28 21:28:39,086 - train - INFO - latency_accumulation_b25:189.32908630371094
2024-08-28 21:28:39,098 - train - INFO - latency_accumulation_b26:189.32908630371094
2024-08-28 21:28:39,349 - train - INFO - latency_accumulation_b6:117.61351776123047
2024-08-28 21:28:39,377 - train - INFO - latency_accumulation_b7:117.61351776123047
2024-08-28 21:28:39,402 - train - INFO - latency_accumulation_b8:117.613525390625
2024-08-28 21:28:39,435 - train - INFO - latency_accumulation_b9:189.32907104492188
2024-08-28 21:28:39,466 - train - INFO - latency_accumulation_b10:189.32907104492188
2024-08-28 21:28:39,495 - train - INFO - latency_accumulation_b11:189.32907104492188
2024-08-28 21:28:39,524 - train - INFO - latency_accumulation_b12:189.32907104492188
2024-08-28 21:28:39,553 - train - INFO - latency_accumulation_b13:189.32908630371094
2024-08-28 21:28:39,581 - train - INFO - latency_accumulation_b14:189.32908630371094
2024-08-28 21:28:39,610 - train - INFO - latency_accumulation_b15:189.32908630371094
2024-08-28 21:28:39,640 - train - INFO - latency_accumulation_b16:189.32908630371094
2024-08-28 21:28:39,669 - train - INFO - latency_accumulation_b17:189.32908630371094
2024-08-28 21:28:39,685 - train - INFO - latency_accumulation_b18:196.24002075195312
2024-08-28 21:28:39,698 - train - INFO - latency_accumulation_b19:196.24002075195312
2024-08-28 21:28:39,710 - train - INFO - latency_accumulation_b20:196.24002075195312
2024-08-28 21:28:39,724 - train - INFO - latency_accumulation_b21:196.24002075195312
2024-08-28 21:28:39,738 - train - INFO - latency_accumulation_b22:196.24002075195312
2024-08-28 21:28:39,751 - train - INFO - latency_accumulation_b23:196.24002075195312
2024-08-28 21:28:39,765 - train - INFO - latency_accumulation_b24:196.2400360107422
2024-08-28 21:28:39,778 - train - INFO - latency_accumulation_b25:196.2400360107422
2024-08-28 21:28:39,791 - train - INFO - latency_accumulation_b26:196.2400360107422
2024-08-28 21:28:40,197 - train - INFO - latency_accumulation_b6:111.2082748413086
2024-08-28 21:28:40,312 - train - INFO - latency_accumulation_b7:111.20828247070312
2024-08-28 21:28:40,425 - train - INFO - latency_accumulation_b8:111.20829010009766
2024-08-28 21:28:40,557 - train - INFO - latency_accumulation_b9:114.12004852294922
2024-08-28 21:28:40,688 - train - INFO - latency_accumulation_b10:114.12004852294922
2024-08-28 21:28:40,821 - train - INFO - latency_accumulation_b11:114.12005615234375
2024-08-28 21:28:40,936 - train - INFO - latency_accumulation_b12:114.12005615234375
2024-08-28 21:28:41,020 - train - INFO - latency_accumulation_b13:114.12006378173828
2024-08-28 21:28:41,098 - train - INFO - latency_accumulation_b14:114.12006378173828
2024-08-28 21:28:41,181 - train - INFO - latency_accumulation_b15:114.12007141113281
2024-08-28 21:28:41,260 - train - INFO - latency_accumulation_b16:114.12007141113281
2024-08-28 21:28:41,338 - train - INFO - latency_accumulation_b17:114.12007904052734
2024-08-28 21:28:41,394 - train - INFO - latency_accumulation_b18:316.74993896484375
2024-08-28 21:28:41,448 - train - INFO - latency_accumulation_b19:316.74993896484375
2024-08-28 21:28:41,503 - train - INFO - latency_accumulation_b20:316.74993896484375
2024-08-28 21:28:41,564 - train - INFO - latency_accumulation_b21:316.74993896484375
2024-08-28 21:28:41,631 - train - INFO - latency_accumulation_b22:316.74993896484375
2024-08-28 21:28:41,687 - train - INFO - latency_accumulation_b23:316.7499694824219
2024-08-28 21:28:41,742 - train - INFO - latency_accumulation_b24:316.7499694824219
2024-08-28 21:28:41,797 - train - INFO - latency_accumulation_b25:316.7499694824219
2024-08-28 21:28:41,852 - train - INFO - latency_accumulation_b26:316.7499694824219
2024-08-28 21:28:42,120 - train - INFO - latency_accumulation_b6:111.2082748413086
2024-08-28 21:28:42,186 - train - INFO - latency_accumulation_b7:111.20828247070312
2024-08-28 21:28:42,250 - train - INFO - latency_accumulation_b8:111.20829010009766
2024-08-28 21:28:42,328 - train - INFO - latency_accumulation_b9:114.12004852294922
2024-08-28 21:28:42,408 - train - INFO - latency_accumulation_b10:114.12004852294922
2024-08-28 21:28:42,494 - train - INFO - latency_accumulation_b11:114.12005615234375
2024-08-28 21:28:42,575 - train - INFO - latency_accumulation_b12:114.12005615234375
2024-08-28 21:28:42,655 - train - INFO - latency_accumulation_b13:114.12006378173828
2024-08-28 21:28:42,734 - train - INFO - latency_accumulation_b14:114.12006378173828
2024-08-28 21:28:42,812 - train - INFO - latency_accumulation_b15:114.12007141113281
2024-08-28 21:28:42,891 - train - INFO - latency_accumulation_b16:114.12007141113281
2024-08-28 21:28:42,969 - train - INFO - latency_accumulation_b17:114.12007904052734
2024-08-28 21:28:43,024 - train - INFO - latency_accumulation_b18:316.74993896484375
2024-08-28 21:28:43,078 - train - INFO - latency_accumulation_b19:316.74993896484375
2024-08-28 21:28:43,133 - train - INFO - latency_accumulation_b20:316.74993896484375
2024-08-28 21:28:43,190 - train - INFO - latency_accumulation_b21:316.74993896484375
2024-08-28 21:28:43,249 - train - INFO - latency_accumulation_b22:316.74993896484375
2024-08-28 21:28:43,304 - train - INFO - latency_accumulation_b23:316.7499694824219
2024-08-28 21:28:43,360 - train - INFO - latency_accumulation_b24:316.7499694824219
2024-08-28 21:28:43,415 - train - INFO - latency_accumulation_b25:316.7499694824219
2024-08-28 21:28:43,470 - train - INFO - latency_accumulation_b26:316.7499694824219
2024-08-28 21:28:43,740 - train - INFO - latency_accumulation_b6:111.2082748413086
2024-08-28 21:28:43,807 - train - INFO - latency_accumulation_b7:111.20828247070312
2024-08-28 21:28:43,876 - train - INFO - latency_accumulation_b8:111.20829010009766
2024-08-28 21:28:43,955 - train - INFO - latency_accumulation_b9:114.12004852294922
2024-08-28 21:28:44,036 - train - INFO - latency_accumulation_b10:114.12004852294922
2024-08-28 21:28:44,114 - train - INFO - latency_accumulation_b11:114.12005615234375
2024-08-28 21:28:44,193 - train - INFO - latency_accumulation_b12:114.12005615234375
2024-08-28 21:28:44,272 - train - INFO - latency_accumulation_b13:114.12006378173828
2024-08-28 21:28:44,351 - train - INFO - latency_accumulation_b14:114.12006378173828
2024-08-28 21:28:44,433 - train - INFO - latency_accumulation_b15:114.12007141113281
2024-08-28 21:28:44,520 - train - INFO - latency_accumulation_b16:114.12007141113281
2024-08-28 21:28:44,601 - train - INFO - latency_accumulation_b17:114.12007904052734
2024-08-28 21:28:44,656 - train - INFO - latency_accumulation_b18:316.74993896484375
2024-08-28 21:28:44,711 - train - INFO - latency_accumulation_b19:316.74993896484375
2024-08-28 21:28:44,766 - train - INFO - latency_accumulation_b20:316.74993896484375
2024-08-28 21:28:44,820 - train - INFO - latency_accumulation_b21:316.74993896484375
2024-08-28 21:28:44,874 - train - INFO - latency_accumulation_b22:316.74993896484375
2024-08-28 21:28:44,929 - train - INFO - latency_accumulation_b23:316.7499694824219
2024-08-28 21:28:44,983 - train - INFO - latency_accumulation_b24:316.7499694824219
2024-08-28 21:28:45,038 - train - INFO - latency_accumulation_b25:316.7499694824219
2024-08-28 21:28:45,096 - train - INFO - latency_accumulation_b26:316.7499694824219
2024-08-28 21:28:45,096 - train - INFO - origin_latency:1387.1977767944336
2024-08-28 21:28:45,096 - train - INFO - cir_idx:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
2024-08-28 21:28:45,429 - train - INFO - bw_result:[4 4 4 4 4 4 4 4 4 4 4 4 4 3 3 4]
2024-08-28 21:28:45,430 - train - INFO - ba_result:[5 5 5 5 5 4 4 4 4 3 3 3 3 3 3 2]
2024-08-28 21:28:45,431 - train - INFO - acc_result:[17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]
2024-08-28 21:29:23,390 - train - INFO - Model ResNet18 created, param count:11220132
2024-08-28 21:29:23,390 - train - INFO - Get QAT model...
2024-08-28 21:29:24,248 - train - INFO - ResNet(
  (relu): ReLU(
    (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
  )
  (conv1): QConv2d(
    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
    (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
    (quan_a_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False)
  )
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False)
      )
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=False)
      )
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn1): QConvBn2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (convbn2): QConvBn2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Sequential()
      (relu2): ReLU(
        (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
      )
    )
  )
  (fc): QLinear(
    in_features=512, out_features=100, bias=True
    (quan_w_fn): LsqQuantizer(bit=32, pos=2147483647, neg=-2147483647, norm=(False, 1e-05, 1.0), all_positive=False, symmetric=True, per_channel=True)
    (quan_a_fn): LsqQuantizer(bit=32, pos=4294967295, neg=0, norm=(False, 1e-05, 1.0), all_positive=True, symmetric=False, per_channel=False)
  )
)
2024-08-28 21:29:24,299 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-08-28 21:29:24,300 - train - INFO - Scheduled epochs: 310
2024-08-28 21:29:27,312 - train - INFO - Test: [   0/9]  Time: 1.513 (1.513)  Loss:  1.0938 (1.0938)  Acc@1: 78.9062 (78.9062)  Acc@5: 93.8477 (93.8477)
2024-08-28 21:29:28,998 - train - INFO - Test: [   9/9]  Time: 0.469 (0.320)  Loss:  1.0303 (1.0583)  Acc@1: 80.3571 (78.7300)  Acc@5: 93.8775 (94.4000)
2024-08-28 21:29:28,999 - train - INFO - Verifying teacher model
2024-08-28 21:29:29,349 - train - INFO - Test: [   0/9]  Time: 0.350 (0.350)  Loss:  1.0938 (1.0938)  Acc@1: 78.8086 (78.8086)  Acc@5: 93.8477 (93.8477)
2024-08-28 21:29:29,673 - train - INFO - Test: [   9/9]  Time: 0.023 (0.067)  Loss:  1.0303 (1.0582)  Acc@1: 80.3571 (78.7100)  Acc@5: 93.8775 (94.3900)
2024-08-28 21:29:29,674 - train - INFO - Verifying initial model in training dataset
2024-08-28 21:29:32,331 - train - INFO - len loader.dataset:50000
2024-08-28 21:29:33,030 - train - INFO - target_block_size:2
2024-08-28 21:29:33,635 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:29:33,637 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:29:33,639 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:29:33,641 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:29:33,643 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:29:33,645 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:29:33,647 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:29:33,650 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:29:33,652 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:29:33,654 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:29:33,656 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:29:33,658 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:29:33,660 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:29:33,661 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:29:33,662 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:29:33,664 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:29:33,665 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:29:33,667 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:29:33,668 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:29:33,670 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:29:33,671 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:29:34,110 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:29:34,112 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:29:34,114 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:29:34,115 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:29:34,116 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:29:34,118 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:29:34,119 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:29:34,121 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:29:34,122 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:29:34,124 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:29:34,125 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:29:34,127 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:29:34,128 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:29:34,129 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:29:34,129 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:29:34,130 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:29:34,131 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:29:34,132 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:29:34,133 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:29:34,134 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:29:34,135 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:29:34,568 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:29:34,570 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:29:34,571 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:29:34,572 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:29:34,574 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:29:34,575 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:29:34,577 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:29:34,578 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:29:34,580 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:29:34,581 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:29:34,582 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:29:34,584 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:29:34,585 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:29:34,586 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:29:34,586 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:29:34,587 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:29:34,588 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:29:34,589 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:29:34,590 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:29:34,591 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:29:34,592 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:29:35,026 - train - INFO - latency_accumulation_b6:42.17000198364258
2024-08-28 21:29:35,027 - train - INFO - latency_accumulation_b7:42.17000198364258
2024-08-28 21:29:35,029 - train - INFO - latency_accumulation_b8:42.17000198364258
2024-08-28 21:29:35,030 - train - INFO - latency_accumulation_b9:54.560001373291016
2024-08-28 21:29:35,031 - train - INFO - latency_accumulation_b10:54.560001373291016
2024-08-28 21:29:35,033 - train - INFO - latency_accumulation_b11:54.56000518798828
2024-08-28 21:29:35,034 - train - INFO - latency_accumulation_b12:54.56000518798828
2024-08-28 21:29:35,036 - train - INFO - latency_accumulation_b13:54.56000518798828
2024-08-28 21:29:35,037 - train - INFO - latency_accumulation_b14:54.56000518798828
2024-08-28 21:29:35,038 - train - INFO - latency_accumulation_b15:54.56000518798828
2024-08-28 21:29:35,040 - train - INFO - latency_accumulation_b16:54.56000518798828
2024-08-28 21:29:35,041 - train - INFO - latency_accumulation_b17:54.56000518798828
2024-08-28 21:29:35,042 - train - INFO - latency_accumulation_b18:130.010009765625
2024-08-28 21:29:35,043 - train - INFO - latency_accumulation_b19:130.010009765625
2024-08-28 21:29:35,044 - train - INFO - latency_accumulation_b20:130.010009765625
2024-08-28 21:29:35,045 - train - INFO - latency_accumulation_b21:130.010009765625
2024-08-28 21:29:35,046 - train - INFO - latency_accumulation_b22:130.010009765625
2024-08-28 21:29:35,046 - train - INFO - latency_accumulation_b23:130.010009765625
2024-08-28 21:29:35,047 - train - INFO - latency_accumulation_b24:130.010009765625
2024-08-28 21:29:35,048 - train - INFO - latency_accumulation_b25:130.010009765625
2024-08-28 21:29:35,049 - train - INFO - latency_accumulation_b26:130.010009765625
2024-08-28 21:29:35,467 - train - INFO - latency_accumulation_b6:75.96500396728516
2024-08-28 21:29:35,468 - train - INFO - latency_accumulation_b7:75.96500396728516
2024-08-28 21:29:35,469 - train - INFO - latency_accumulation_b8:75.96500396728516
2024-08-28 21:29:35,471 - train - INFO - latency_accumulation_b9:125.25833892822266
2024-08-28 21:29:35,473 - train - INFO - latency_accumulation_b10:125.25833892822266
2024-08-28 21:29:35,475 - train - INFO - latency_accumulation_b11:125.25833892822266
2024-08-28 21:29:35,477 - train - INFO - latency_accumulation_b12:125.25833892822266
2024-08-28 21:29:35,479 - train - INFO - latency_accumulation_b13:125.25833892822266
2024-08-28 21:29:35,481 - train - INFO - latency_accumulation_b14:125.25834655761719
2024-08-28 21:29:35,483 - train - INFO - latency_accumulation_b15:125.25834655761719
2024-08-28 21:29:35,485 - train - INFO - latency_accumulation_b16:125.25834655761719
2024-08-28 21:29:35,486 - train - INFO - latency_accumulation_b17:125.25834655761719
2024-08-28 21:29:35,487 - train - INFO - latency_accumulation_b18:178.24000549316406
2024-08-28 21:29:35,488 - train - INFO - latency_accumulation_b19:178.24000549316406
2024-08-28 21:29:35,489 - train - INFO - latency_accumulation_b20:178.24000549316406
2024-08-28 21:29:35,490 - train - INFO - latency_accumulation_b21:178.24000549316406
2024-08-28 21:29:35,491 - train - INFO - latency_accumulation_b22:178.24000549316406
2024-08-28 21:29:35,492 - train - INFO - latency_accumulation_b23:178.24000549316406
2024-08-28 21:29:35,493 - train - INFO - latency_accumulation_b24:178.24000549316406
2024-08-28 21:29:35,494 - train - INFO - latency_accumulation_b25:178.24000549316406
2024-08-28 21:29:35,495 - train - INFO - latency_accumulation_b26:178.24000549316406
2024-08-28 21:29:35,822 - train - INFO - latency_accumulation_b6:55.96625518798828
2024-08-28 21:29:35,827 - train - INFO - latency_accumulation_b7:55.96625518798828
2024-08-28 21:29:35,831 - train - INFO - latency_accumulation_b8:55.96625900268555
2024-08-28 21:29:35,837 - train - INFO - latency_accumulation_b9:60.56000518798828
2024-08-28 21:29:35,842 - train - INFO - latency_accumulation_b10:60.56000518798828
2024-08-28 21:29:35,848 - train - INFO - latency_accumulation_b11:60.56000518798828
2024-08-28 21:29:35,853 - train - INFO - latency_accumulation_b12:60.56000900268555
2024-08-28 21:29:35,859 - train - INFO - latency_accumulation_b13:60.56000900268555
2024-08-28 21:29:35,864 - train - INFO - latency_accumulation_b14:60.56000900268555
2024-08-28 21:29:35,870 - train - INFO - latency_accumulation_b15:60.56000900268555
2024-08-28 21:29:35,876 - train - INFO - latency_accumulation_b16:60.56000900268555
2024-08-28 21:29:35,881 - train - INFO - latency_accumulation_b17:60.56000900268555
2024-08-28 21:29:35,885 - train - INFO - latency_accumulation_b18:139.65000915527344
2024-08-28 21:29:35,889 - train - INFO - latency_accumulation_b19:139.65000915527344
2024-08-28 21:29:35,892 - train - INFO - latency_accumulation_b20:139.65000915527344
2024-08-28 21:29:35,896 - train - INFO - latency_accumulation_b21:139.65000915527344
2024-08-28 21:29:35,900 - train - INFO - latency_accumulation_b22:139.65000915527344
2024-08-28 21:29:35,903 - train - INFO - latency_accumulation_b23:139.65000915527344
2024-08-28 21:29:35,907 - train - INFO - latency_accumulation_b24:139.65000915527344
2024-08-28 21:29:35,911 - train - INFO - latency_accumulation_b25:139.65000915527344
2024-08-28 21:29:35,915 - train - INFO - latency_accumulation_b26:139.65000915527344
2024-08-28 21:29:36,167 - train - INFO - latency_accumulation_b6:55.96625518798828
2024-08-28 21:29:36,171 - train - INFO - latency_accumulation_b7:55.96625518798828
2024-08-28 21:29:36,176 - train - INFO - latency_accumulation_b8:55.96625900268555
2024-08-28 21:29:36,181 - train - INFO - latency_accumulation_b9:60.56000518798828
2024-08-28 21:29:36,186 - train - INFO - latency_accumulation_b10:60.56000518798828
2024-08-28 21:29:36,191 - train - INFO - latency_accumulation_b11:60.56000518798828
2024-08-28 21:29:36,197 - train - INFO - latency_accumulation_b12:60.56000900268555
2024-08-28 21:29:36,202 - train - INFO - latency_accumulation_b13:60.56000900268555
2024-08-28 21:29:36,208 - train - INFO - latency_accumulation_b14:60.56000900268555
2024-08-28 21:29:36,215 - train - INFO - latency_accumulation_b15:60.56000900268555
2024-08-28 21:29:36,221 - train - INFO - latency_accumulation_b16:60.56000900268555
2024-08-28 21:29:36,226 - train - INFO - latency_accumulation_b17:60.56000900268555
2024-08-28 21:29:36,230 - train - INFO - latency_accumulation_b18:139.65000915527344
2024-08-28 21:29:36,233 - train - INFO - latency_accumulation_b19:139.65000915527344
2024-08-28 21:29:36,236 - train - INFO - latency_accumulation_b20:139.65000915527344
2024-08-28 21:29:36,240 - train - INFO - latency_accumulation_b21:139.65000915527344
2024-08-28 21:29:36,243 - train - INFO - latency_accumulation_b22:139.65000915527344
2024-08-28 21:29:36,247 - train - INFO - latency_accumulation_b23:139.65000915527344
2024-08-28 21:29:36,250 - train - INFO - latency_accumulation_b24:139.65000915527344
2024-08-28 21:29:36,253 - train - INFO - latency_accumulation_b25:139.65000915527344
2024-08-28 21:29:36,256 - train - INFO - latency_accumulation_b26:139.65000915527344
2024-08-28 21:29:36,527 - train - INFO - latency_accumulation_b6:55.96625518798828
2024-08-28 21:29:36,534 - train - INFO - latency_accumulation_b7:55.96625518798828
2024-08-28 21:29:36,541 - train - INFO - latency_accumulation_b8:55.96625900268555
2024-08-28 21:29:36,548 - train - INFO - latency_accumulation_b9:60.56000518798828
2024-08-28 21:29:36,556 - train - INFO - latency_accumulation_b10:60.56000518798828
2024-08-28 21:29:36,564 - train - INFO - latency_accumulation_b11:60.56000518798828
2024-08-28 21:29:36,572 - train - INFO - latency_accumulation_b12:60.56000900268555
2024-08-28 21:29:36,580 - train - INFO - latency_accumulation_b13:60.56000900268555
2024-08-28 21:29:36,588 - train - INFO - latency_accumulation_b14:60.56000900268555
2024-08-28 21:29:36,596 - train - INFO - latency_accumulation_b15:60.56000900268555
2024-08-28 21:29:36,604 - train - INFO - latency_accumulation_b16:60.56000900268555
2024-08-28 21:29:36,611 - train - INFO - latency_accumulation_b17:60.56000900268555
2024-08-28 21:29:36,617 - train - INFO - latency_accumulation_b18:139.65000915527344
2024-08-28 21:29:36,622 - train - INFO - latency_accumulation_b19:139.65000915527344
2024-08-28 21:29:36,627 - train - INFO - latency_accumulation_b20:139.65000915527344
2024-08-28 21:29:36,632 - train - INFO - latency_accumulation_b21:139.65000915527344
2024-08-28 21:29:36,637 - train - INFO - latency_accumulation_b22:139.65000915527344
2024-08-28 21:29:36,643 - train - INFO - latency_accumulation_b23:139.65000915527344
2024-08-28 21:29:36,648 - train - INFO - latency_accumulation_b24:139.65000915527344
2024-08-28 21:29:36,653 - train - INFO - latency_accumulation_b25:139.65000915527344
2024-08-28 21:29:36,658 - train - INFO - latency_accumulation_b26:139.65000915527344
2024-08-28 21:29:36,977 - train - INFO - latency_accumulation_b6:82.65250396728516
2024-08-28 21:29:36,985 - train - INFO - latency_accumulation_b7:82.65250396728516
2024-08-28 21:29:36,994 - train - INFO - latency_accumulation_b8:82.65251159667969
2024-08-28 21:29:37,005 - train - INFO - latency_accumulation_b9:139.65000915527344
2024-08-28 21:29:37,017 - train - INFO - latency_accumulation_b10:139.65000915527344
2024-08-28 21:29:37,029 - train - INFO - latency_accumulation_b11:139.65000915527344
2024-08-28 21:29:37,040 - train - INFO - latency_accumulation_b12:139.65000915527344
2024-08-28 21:29:37,052 - train - INFO - latency_accumulation_b13:139.65000915527344
2024-08-28 21:29:37,064 - train - INFO - latency_accumulation_b14:139.65000915527344
2024-08-28 21:29:37,076 - train - INFO - latency_accumulation_b15:139.65000915527344
2024-08-28 21:29:37,087 - train - INFO - latency_accumulation_b16:139.65000915527344
2024-08-28 21:29:37,099 - train - INFO - latency_accumulation_b17:139.65000915527344
2024-08-28 21:29:37,105 - train - INFO - latency_accumulation_b18:190.24000549316406
2024-08-28 21:29:37,110 - train - INFO - latency_accumulation_b19:190.24000549316406
2024-08-28 21:29:37,115 - train - INFO - latency_accumulation_b20:190.24000549316406
2024-08-28 21:29:37,120 - train - INFO - latency_accumulation_b21:190.24000549316406
2024-08-28 21:29:37,125 - train - INFO - latency_accumulation_b22:190.24002075195312
2024-08-28 21:29:37,131 - train - INFO - latency_accumulation_b23:190.24002075195312
2024-08-28 21:29:37,136 - train - INFO - latency_accumulation_b24:190.24002075195312
2024-08-28 21:29:37,141 - train - INFO - latency_accumulation_b25:190.24002075195312
2024-08-28 21:29:37,146 - train - INFO - latency_accumulation_b26:190.24002075195312
2024-08-28 21:29:37,478 - train - INFO - latency_accumulation_b6:64.56001281738281
2024-08-28 21:29:37,513 - train - INFO - latency_accumulation_b7:64.56002044677734
2024-08-28 21:29:37,543 - train - INFO - latency_accumulation_b8:64.56002044677734
2024-08-28 21:29:37,574 - train - INFO - latency_accumulation_b9:63.56001281738281
2024-08-28 21:29:37,605 - train - INFO - latency_accumulation_b10:63.56001281738281
2024-08-28 21:29:37,636 - train - INFO - latency_accumulation_b11:63.56001281738281
2024-08-28 21:29:37,667 - train - INFO - latency_accumulation_b12:63.56001281738281
2024-08-28 21:29:37,697 - train - INFO - latency_accumulation_b13:63.56001663208008
2024-08-28 21:29:37,728 - train - INFO - latency_accumulation_b14:63.56001663208008
2024-08-28 21:29:37,759 - train - INFO - latency_accumulation_b15:63.56001663208008
2024-08-28 21:29:37,789 - train - INFO - latency_accumulation_b16:63.56001663208008
2024-08-28 21:29:37,825 - train - INFO - latency_accumulation_b17:63.560020446777344
2024-08-28 21:29:37,845 - train - INFO - latency_accumulation_b18:189.32907104492188
2024-08-28 21:29:37,865 - train - INFO - latency_accumulation_b19:189.32907104492188
2024-08-28 21:29:37,885 - train - INFO - latency_accumulation_b20:189.32907104492188
2024-08-28 21:29:37,906 - train - INFO - latency_accumulation_b21:189.32907104492188
2024-08-28 21:29:37,926 - train - INFO - latency_accumulation_b22:189.32907104492188
2024-08-28 21:29:37,946 - train - INFO - latency_accumulation_b23:189.32907104492188
2024-08-28 21:29:37,966 - train - INFO - latency_accumulation_b24:189.32907104492188
2024-08-28 21:29:37,987 - train - INFO - latency_accumulation_b25:189.32908630371094
2024-08-28 21:29:38,007 - train - INFO - latency_accumulation_b26:189.32908630371094
2024-08-28 21:29:38,222 - train - INFO - latency_accumulation_b6:64.56001281738281
2024-08-28 21:29:38,238 - train - INFO - latency_accumulation_b7:64.56002044677734
2024-08-28 21:29:38,254 - train - INFO - latency_accumulation_b8:64.56002044677734
2024-08-28 21:29:38,274 - train - INFO - latency_accumulation_b9:63.56001281738281
2024-08-28 21:29:38,292 - train - INFO - latency_accumulation_b10:63.56001281738281
2024-08-28 21:29:38,310 - train - INFO - latency_accumulation_b11:63.56001281738281
2024-08-28 21:29:38,329 - train - INFO - latency_accumulation_b12:63.56001281738281
2024-08-28 21:29:38,347 - train - INFO - latency_accumulation_b13:63.56001663208008
2024-08-28 21:29:38,365 - train - INFO - latency_accumulation_b14:63.56001663208008
2024-08-28 21:29:38,383 - train - INFO - latency_accumulation_b15:63.56001663208008
2024-08-28 21:29:38,402 - train - INFO - latency_accumulation_b16:63.56001663208008
2024-08-28 21:29:38,420 - train - INFO - latency_accumulation_b17:63.560020446777344
2024-08-28 21:29:38,445 - train - INFO - latency_accumulation_b18:189.32907104492188
2024-08-28 21:29:38,468 - train - INFO - latency_accumulation_b19:189.32907104492188
2024-08-28 21:29:38,489 - train - INFO - latency_accumulation_b20:189.32907104492188
2024-08-28 21:29:38,509 - train - INFO - latency_accumulation_b21:189.32907104492188
2024-08-28 21:29:38,529 - train - INFO - latency_accumulation_b22:189.32907104492188
2024-08-28 21:29:38,550 - train - INFO - latency_accumulation_b23:189.32907104492188
2024-08-28 21:29:38,570 - train - INFO - latency_accumulation_b24:189.32907104492188
2024-08-28 21:29:38,590 - train - INFO - latency_accumulation_b25:189.32908630371094
2024-08-28 21:29:38,610 - train - INFO - latency_accumulation_b26:189.32908630371094
2024-08-28 21:29:38,835 - train - INFO - latency_accumulation_b6:64.56001281738281
2024-08-28 21:29:38,860 - train - INFO - latency_accumulation_b7:64.56002044677734
2024-08-28 21:29:38,885 - train - INFO - latency_accumulation_b8:64.56002044677734
2024-08-28 21:29:38,916 - train - INFO - latency_accumulation_b9:63.56001281738281
2024-08-28 21:29:38,946 - train - INFO - latency_accumulation_b10:63.56001281738281
2024-08-28 21:29:38,979 - train - INFO - latency_accumulation_b11:63.56001281738281
2024-08-28 21:29:39,007 - train - INFO - latency_accumulation_b12:63.56001281738281
2024-08-28 21:29:39,032 - train - INFO - latency_accumulation_b13:63.56001663208008
2024-08-28 21:29:39,055 - train - INFO - latency_accumulation_b14:63.56001663208008
2024-08-28 21:29:39,077 - train - INFO - latency_accumulation_b15:63.56001663208008
2024-08-28 21:29:39,097 - train - INFO - latency_accumulation_b16:63.56001663208008
2024-08-28 21:29:39,117 - train - INFO - latency_accumulation_b17:63.560020446777344
2024-08-28 21:29:39,129 - train - INFO - latency_accumulation_b18:189.32907104492188
2024-08-28 21:29:39,142 - train - INFO - latency_accumulation_b19:189.32907104492188
2024-08-28 21:29:39,154 - train - INFO - latency_accumulation_b20:189.32907104492188
2024-08-28 21:29:39,166 - train - INFO - latency_accumulation_b21:189.32907104492188
2024-08-28 21:29:39,180 - train - INFO - latency_accumulation_b22:189.32907104492188
2024-08-28 21:29:39,194 - train - INFO - latency_accumulation_b23:189.32907104492188
2024-08-28 21:29:39,207 - train - INFO - latency_accumulation_b24:189.32907104492188
2024-08-28 21:29:39,219 - train - INFO - latency_accumulation_b25:189.32908630371094
2024-08-28 21:29:39,231 - train - INFO - latency_accumulation_b26:189.32908630371094
2024-08-28 21:29:39,453 - train - INFO - latency_accumulation_b6:117.61351776123047
2024-08-28 21:29:39,474 - train - INFO - latency_accumulation_b7:117.61351776123047
2024-08-28 21:29:39,495 - train - INFO - latency_accumulation_b8:117.613525390625
2024-08-28 21:29:39,525 - train - INFO - latency_accumulation_b9:189.32907104492188
2024-08-28 21:29:39,554 - train - INFO - latency_accumulation_b10:189.32907104492188
2024-08-28 21:29:39,584 - train - INFO - latency_accumulation_b11:189.32907104492188
2024-08-28 21:29:39,619 - train - INFO - latency_accumulation_b12:189.32907104492188
2024-08-28 21:29:39,649 - train - INFO - latency_accumulation_b13:189.32908630371094
2024-08-28 21:29:39,680 - train - INFO - latency_accumulation_b14:189.32908630371094
2024-08-28 21:29:39,712 - train - INFO - latency_accumulation_b15:189.32908630371094
2024-08-28 21:29:39,743 - train - INFO - latency_accumulation_b16:189.32908630371094
2024-08-28 21:29:39,774 - train - INFO - latency_accumulation_b17:189.32908630371094
2024-08-28 21:29:39,788 - train - INFO - latency_accumulation_b18:196.24002075195312
2024-08-28 21:29:39,803 - train - INFO - latency_accumulation_b19:196.24002075195312
2024-08-28 21:29:39,817 - train - INFO - latency_accumulation_b20:196.24002075195312
2024-08-28 21:29:39,832 - train - INFO - latency_accumulation_b21:196.24002075195312
2024-08-28 21:29:39,846 - train - INFO - latency_accumulation_b22:196.24002075195312
2024-08-28 21:29:39,861 - train - INFO - latency_accumulation_b23:196.24002075195312
2024-08-28 21:29:39,876 - train - INFO - latency_accumulation_b24:196.2400360107422
2024-08-28 21:29:39,892 - train - INFO - latency_accumulation_b25:196.2400360107422
2024-08-28 21:29:39,907 - train - INFO - latency_accumulation_b26:196.2400360107422
2024-08-28 21:29:40,231 - train - INFO - latency_accumulation_b6:111.2082748413086
2024-08-28 21:29:40,300 - train - INFO - latency_accumulation_b7:111.20828247070312
2024-08-28 21:29:40,369 - train - INFO - latency_accumulation_b8:111.20829010009766
2024-08-28 21:29:40,454 - train - INFO - latency_accumulation_b9:114.12004852294922
2024-08-28 21:29:40,539 - train - INFO - latency_accumulation_b10:114.12004852294922
2024-08-28 21:29:40,619 - train - INFO - latency_accumulation_b11:114.12005615234375
2024-08-28 21:29:40,698 - train - INFO - latency_accumulation_b12:114.12005615234375
2024-08-28 21:29:40,778 - train - INFO - latency_accumulation_b13:114.12006378173828
2024-08-28 21:29:40,856 - train - INFO - latency_accumulation_b14:114.12006378173828
2024-08-28 21:29:40,930 - train - INFO - latency_accumulation_b15:114.12007141113281
2024-08-28 21:29:41,004 - train - INFO - latency_accumulation_b16:114.12007141113281
2024-08-28 21:29:41,079 - train - INFO - latency_accumulation_b17:114.12007904052734
2024-08-28 21:29:41,195 - train - INFO - latency_accumulation_b18:316.74993896484375
2024-08-28 21:29:41,281 - train - INFO - latency_accumulation_b19:316.74993896484375
2024-08-28 21:29:41,366 - train - INFO - latency_accumulation_b20:316.74993896484375
2024-08-28 21:29:41,452 - train - INFO - latency_accumulation_b21:316.74993896484375
2024-08-28 21:29:41,539 - train - INFO - latency_accumulation_b22:316.74993896484375
2024-08-28 21:29:41,626 - train - INFO - latency_accumulation_b23:316.7499694824219
2024-08-28 21:29:41,711 - train - INFO - latency_accumulation_b24:316.7499694824219
2024-08-28 21:29:41,795 - train - INFO - latency_accumulation_b25:316.7499694824219
2024-08-28 21:29:41,865 - train - INFO - latency_accumulation_b26:316.7499694824219
2024-08-28 21:29:42,148 - train - INFO - latency_accumulation_b6:111.2082748413086
2024-08-28 21:29:42,287 - train - INFO - latency_accumulation_b7:111.20828247070312
2024-08-28 21:29:42,389 - train - INFO - latency_accumulation_b8:111.20829010009766
2024-08-28 21:29:42,515 - train - INFO - latency_accumulation_b9:114.12004852294922
2024-08-28 21:29:42,639 - train - INFO - latency_accumulation_b10:114.12004852294922
2024-08-28 21:29:42,762 - train - INFO - latency_accumulation_b11:114.12005615234375
2024-08-28 21:29:42,885 - train - INFO - latency_accumulation_b12:114.12005615234375
2024-08-28 21:29:42,990 - train - INFO - latency_accumulation_b13:114.12006378173828
2024-08-28 21:29:43,079 - train - INFO - latency_accumulation_b14:114.12006378173828
2024-08-28 21:29:43,162 - train - INFO - latency_accumulation_b15:114.12007141113281
2024-08-28 21:29:43,240 - train - INFO - latency_accumulation_b16:114.12007141113281
2024-08-28 21:29:43,318 - train - INFO - latency_accumulation_b17:114.12007904052734
2024-08-28 21:29:43,370 - train - INFO - latency_accumulation_b18:316.74993896484375
2024-08-28 21:29:43,421 - train - INFO - latency_accumulation_b19:316.74993896484375
2024-08-28 21:29:43,478 - train - INFO - latency_accumulation_b20:316.74993896484375
2024-08-28 21:29:43,536 - train - INFO - latency_accumulation_b21:316.74993896484375
2024-08-28 21:29:43,593 - train - INFO - latency_accumulation_b22:316.74993896484375
2024-08-28 21:29:43,648 - train - INFO - latency_accumulation_b23:316.7499694824219
2024-08-28 21:29:43,703 - train - INFO - latency_accumulation_b24:316.7499694824219
2024-08-28 21:29:43,758 - train - INFO - latency_accumulation_b25:316.7499694824219
2024-08-28 21:29:43,811 - train - INFO - latency_accumulation_b26:316.7499694824219
2024-08-28 21:29:44,077 - train - INFO - latency_accumulation_b6:111.2082748413086
2024-08-28 21:29:44,142 - train - INFO - latency_accumulation_b7:111.20828247070312
2024-08-28 21:29:44,208 - train - INFO - latency_accumulation_b8:111.20829010009766
2024-08-28 21:29:44,289 - train - INFO - latency_accumulation_b9:114.12004852294922
2024-08-28 21:29:44,376 - train - INFO - latency_accumulation_b10:114.12004852294922
2024-08-28 21:29:44,459 - train - INFO - latency_accumulation_b11:114.12005615234375
2024-08-28 21:29:44,545 - train - INFO - latency_accumulation_b12:114.12005615234375
2024-08-28 21:29:44,631 - train - INFO - latency_accumulation_b13:114.12006378173828
2024-08-28 21:29:44,715 - train - INFO - latency_accumulation_b14:114.12006378173828
2024-08-28 21:29:44,795 - train - INFO - latency_accumulation_b15:114.12007141113281
2024-08-28 21:29:44,877 - train - INFO - latency_accumulation_b16:114.12007141113281
2024-08-28 21:29:44,962 - train - INFO - latency_accumulation_b17:114.12007904052734
2024-08-28 21:29:45,018 - train - INFO - latency_accumulation_b18:316.74993896484375
2024-08-28 21:29:45,079 - train - INFO - latency_accumulation_b19:316.74993896484375
2024-08-28 21:29:45,133 - train - INFO - latency_accumulation_b20:316.74993896484375
2024-08-28 21:29:45,184 - train - INFO - latency_accumulation_b21:316.74993896484375
2024-08-28 21:29:45,237 - train - INFO - latency_accumulation_b22:316.74993896484375
2024-08-28 21:29:45,295 - train - INFO - latency_accumulation_b23:316.7499694824219
2024-08-28 21:29:45,354 - train - INFO - latency_accumulation_b24:316.7499694824219
2024-08-28 21:29:45,411 - train - INFO - latency_accumulation_b25:316.7499694824219
2024-08-28 21:29:45,468 - train - INFO - latency_accumulation_b26:316.7499694824219
2024-08-28 21:29:45,469 - train - INFO - origin_latency:1387.1977462768555
2024-08-28 21:29:45,469 - train - INFO - cir_idx:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
2024-08-28 21:29:45,752 - train - INFO - bw_result:[4 4 4 4 4 4 4 4 4 4 4 4 4 3 3 4]
2024-08-28 21:29:45,753 - train - INFO - ba_result:[5 5 5 5 5 4 4 4 4 3 3 3 3 3 3 2]
2024-08-28 21:29:45,753 - train - INFO - acc_result:[17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]
